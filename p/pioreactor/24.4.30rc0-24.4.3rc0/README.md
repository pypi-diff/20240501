# Comparing `tmp/pioreactor-24.4.30rc0-py3-none-any.whl.zip` & `tmp/pioreactor-24.4.3rc0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,94 +1,90 @@
-Zip file size: 233974 bytes, number of entries: 92
--rw-r--r--  2.0 unx      117 b- defN 24-Apr-30 19:44 pioreactor/__init__.py
--rw-r--r--  2.0 unx     5868 b- defN 24-Apr-30 19:44 pioreactor/config.py
--rw-r--r--  2.0 unx      265 b- defN 24-Apr-30 19:44 pioreactor/error_codes.py
--rw-r--r--  2.0 unx      958 b- defN 24-Apr-30 19:44 pioreactor/exc.py
--rw-r--r--  2.0 unx     3854 b- defN 24-Apr-30 19:44 pioreactor/hardware.py
--rw-r--r--  2.0 unx     6588 b- defN 24-Apr-30 19:44 pioreactor/logging.py
--rw-r--r--  2.0 unx    15631 b- defN 24-Apr-30 19:44 pioreactor/mureq.py
--rw-r--r--  2.0 unx    10903 b- defN 24-Apr-30 19:44 pioreactor/pubsub.py
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-30 19:44 pioreactor/py.typed
--rw-r--r--  2.0 unx     6361 b- defN 24-Apr-30 19:44 pioreactor/structs.py
--rw-r--r--  2.0 unx     3304 b- defN 24-Apr-30 19:44 pioreactor/types.py
--rw-r--r--  2.0 unx     3023 b- defN 24-Apr-30 19:44 pioreactor/version.py
--rw-r--r--  2.0 unx     5844 b- defN 24-Apr-30 19:44 pioreactor/whoami.py
--rw-r--r--  2.0 unx      540 b- defN 24-Apr-30 19:44 pioreactor/actions/__init__.py
--rw-r--r--  2.0 unx     8810 b- defN 24-Apr-30 19:44 pioreactor/actions/led_intensity.py
--rw-r--r--  2.0 unx     9013 b- defN 24-Apr-30 19:44 pioreactor/actions/od_blank.py
--rw-r--r--  2.0 unx    24592 b- defN 24-Apr-30 19:44 pioreactor/actions/od_calibration.py
--rw-r--r--  2.0 unx    19799 b- defN 24-Apr-30 19:44 pioreactor/actions/pump.py
--rw-r--r--  2.0 unx    22445 b- defN 24-Apr-30 19:44 pioreactor/actions/pump_calibration.py
--rw-r--r--  2.0 unx    20149 b- defN 24-Apr-30 19:44 pioreactor/actions/self_test.py
--rw-r--r--  2.0 unx     5339 b- defN 24-Apr-30 19:44 pioreactor/actions/stirring_calibration.py
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-30 19:44 pioreactor/actions/leader/__init__.py
--rw-r--r--  2.0 unx     4902 b- defN 24-Apr-30 19:44 pioreactor/actions/leader/backup_database.py
--rw-r--r--  2.0 unx    25244 b- defN 24-Apr-30 19:44 pioreactor/actions/leader/experiment_profile.py
--rw-r--r--  2.0 unx     6544 b- defN 24-Apr-30 19:44 pioreactor/actions/leader/export_experiment_data.py
--rw-r--r--  2.0 unx      146 b- defN 24-Apr-30 19:44 pioreactor/automations/__init__.py
--rw-r--r--  2.0 unx     1000 b- defN 24-Apr-30 19:44 pioreactor/automations/base.py
--rw-r--r--  2.0 unx      459 b- defN 24-Apr-30 19:44 pioreactor/automations/dosing/__init__.py
--rw-r--r--  2.0 unx    29432 b- defN 24-Apr-30 19:44 pioreactor/automations/dosing/base.py
--rw-r--r--  2.0 unx     1424 b- defN 24-Apr-30 19:44 pioreactor/automations/dosing/chemostat.py
--rw-r--r--  2.0 unx     1497 b- defN 24-Apr-30 19:44 pioreactor/automations/dosing/fed_batch.py
--rw-r--r--  2.0 unx     4962 b- defN 24-Apr-30 19:44 pioreactor/automations/dosing/pid_morbidostat.py
--rw-r--r--  2.0 unx      476 b- defN 24-Apr-30 19:44 pioreactor/automations/dosing/silent.py
--rw-r--r--  2.0 unx     4936 b- defN 24-Apr-30 19:44 pioreactor/automations/dosing/turbidostat.py
--rw-r--r--  2.0 unx      510 b- defN 24-Apr-30 19:44 pioreactor/automations/events/__init__.py
--rw-r--r--  2.0 unx      567 b- defN 24-Apr-30 19:44 pioreactor/automations/led/__init__.py
--rw-r--r--  2.0 unx    12023 b- defN 24-Apr-30 19:44 pioreactor/automations/led/base.py
--rw-r--r--  2.0 unx     3875 b- defN 24-Apr-30 19:44 pioreactor/automations/led/light_dark_cycle.py
--rw-r--r--  2.0 unx      154 b- defN 24-Apr-30 19:44 pioreactor/automations/temperature/__init__.py
--rw-r--r--  2.0 unx     9317 b- defN 24-Apr-30 19:44 pioreactor/automations/temperature/base.py
--rw-r--r--  2.0 unx      561 b- defN 24-Apr-30 19:44 pioreactor/automations/temperature/only_record_temperature.py
--rw-r--r--  2.0 unx     4375 b- defN 24-Apr-30 19:44 pioreactor/automations/temperature/thermostat.py
--rw-r--r--  2.0 unx      715 b- defN 24-Apr-30 19:44 pioreactor/background_jobs/__init__.py
--rw-r--r--  2.0 unx    45137 b- defN 24-Apr-30 19:44 pioreactor/background_jobs/base.py
--rw-r--r--  2.0 unx     7043 b- defN 24-Apr-30 19:44 pioreactor/background_jobs/dosing_control.py
--rw-r--r--  2.0 unx    22053 b- defN 24-Apr-30 19:44 pioreactor/background_jobs/growth_rate_calculating.py
--rw-r--r--  2.0 unx     5806 b- defN 24-Apr-30 19:44 pioreactor/background_jobs/led_control.py
--rw-r--r--  2.0 unx    29820 b- defN 24-Apr-30 19:44 pioreactor/background_jobs/monitor.py
--rw-r--r--  2.0 unx    52952 b- defN 24-Apr-30 19:44 pioreactor/background_jobs/od_reading.py
--rw-r--r--  2.0 unx    18124 b- defN 24-Apr-30 19:44 pioreactor/background_jobs/stirring.py
--rw-r--r--  2.0 unx    26075 b- defN 24-Apr-30 19:44 pioreactor/background_jobs/temperature_control.py
--rw-r--r--  2.0 unx      605 b- defN 24-Apr-30 19:44 pioreactor/background_jobs/leader/__init__.py
--rw-r--r--  2.0 unx    16997 b- defN 24-Apr-30 19:44 pioreactor/background_jobs/leader/mqtt_to_db_streaming.py
--rw-r--r--  2.0 unx     4573 b- defN 24-Apr-30 19:44 pioreactor/background_jobs/leader/watchdog.py
--rw-r--r--  2.0 unx     1094 b- defN 24-Apr-30 19:44 pioreactor/background_jobs/subjobs/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-30 19:44 pioreactor/cli/__init__.py
--rw-r--r--  2.0 unx     1408 b- defN 24-Apr-30 19:44 pioreactor/cli/lazy_group.py
--rw-r--r--  2.0 unx    24433 b- defN 24-Apr-30 19:44 pioreactor/cli/pio.py
--rw-r--r--  2.0 unx    26918 b- defN 24-Apr-30 19:44 pioreactor/cli/pios.py
--rw-r--r--  2.0 unx      365 b- defN 24-Apr-30 19:44 pioreactor/cli/plugins.py
--rw-r--r--  2.0 unx     1949 b- defN 24-Apr-30 19:44 pioreactor/cli/run.py
--rw-r--r--  2.0 unx      700 b- defN 24-Apr-30 19:44 pioreactor/cli/workers.py
--rw-r--r--  2.0 unx    10403 b- defN 24-Apr-30 19:44 pioreactor/cluster_management/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-30 19:44 pioreactor/experiment_profiles/__init__.py
--rw-r--r--  2.0 unx     5488 b- defN 24-Apr-30 19:44 pioreactor/experiment_profiles/parser.py
--rw-r--r--  2.0 unx     2896 b- defN 24-Apr-30 19:44 pioreactor/experiment_profiles/profile_struct.py
--rw-r--r--  2.0 unx      197 b- defN 24-Apr-30 19:44 pioreactor/experiment_profiles/sly/__init__.py
--rw-r--r--  2.0 unx    16273 b- defN 24-Apr-30 19:44 pioreactor/experiment_profiles/sly/lex.py
--rw-r--r--  2.0 unx    83015 b- defN 24-Apr-30 19:44 pioreactor/experiment_profiles/sly/yacc.py
--rw-r--r--  2.0 unx     3807 b- defN 24-Apr-30 19:44 pioreactor/plugin_management/__init__.py
--rw-r--r--  2.0 unx     1439 b- defN 24-Apr-30 19:44 pioreactor/plugin_management/install_plugin.py
--rw-r--r--  2.0 unx     1123 b- defN 24-Apr-30 19:44 pioreactor/plugin_management/list_plugins.py
--rw-r--r--  2.0 unx     1782 b- defN 24-Apr-30 19:44 pioreactor/plugin_management/uninstall_plugin.py
--rw-r--r--  2.0 unx     1194 b- defN 24-Apr-30 19:44 pioreactor/plugin_management/utils.py
--rw-r--r--  2.0 unx    21578 b- defN 24-Apr-30 19:44 pioreactor/utils/__init__.py
--rw-r--r--  2.0 unx     4240 b- defN 24-Apr-30 19:44 pioreactor/utils/adcs.py
--rw-r--r--  2.0 unx     1930 b- defN 24-Apr-30 19:44 pioreactor/utils/dacs.py
--rw-r--r--  2.0 unx      976 b- defN 24-Apr-30 19:44 pioreactor/utils/gpio_helpers.py
--rw-r--r--  2.0 unx     3311 b- defN 24-Apr-30 19:44 pioreactor/utils/math_helpers.py
--rw-r--r--  2.0 unx     5211 b- defN 24-Apr-30 19:44 pioreactor/utils/mock.py
--rw-r--r--  2.0 unx     3622 b- defN 24-Apr-30 19:44 pioreactor/utils/networking.py
--rw-r--r--  2.0 unx    10278 b- defN 24-Apr-30 19:44 pioreactor/utils/pwm.py
--rw-r--r--  2.0 unx     3393 b- defN 24-Apr-30 19:44 pioreactor/utils/rpi_bad_power.py
--rw-r--r--  2.0 unx     7889 b- defN 24-Apr-30 19:44 pioreactor/utils/sqlite_worker.py
--rw-r--r--  2.0 unx    18416 b- defN 24-Apr-30 19:44 pioreactor/utils/streaming_calculations.py
--rw-r--r--  2.0 unx     5827 b- defN 24-Apr-30 19:44 pioreactor/utils/timing.py
--rw-r--r--  2.0 unx     1067 b- defN 24-Apr-30 19:44 pioreactor-24.4.30rc0.dist-info/LICENSE
--rw-r--r--  2.0 unx     3722 b- defN 24-Apr-30 19:44 pioreactor-24.4.30rc0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Apr-30 19:44 pioreactor-24.4.30rc0.dist-info/WHEEL
--rw-r--r--  2.0 unx       79 b- defN 24-Apr-30 19:44 pioreactor-24.4.30rc0.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       11 b- defN 24-Apr-30 19:44 pioreactor-24.4.30rc0.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     8453 b- defN 24-Apr-30 19:44 pioreactor-24.4.30rc0.dist-info/RECORD
-92 files, 800286 bytes uncompressed, 220412 bytes compressed:  72.5%
+Zip file size: 231043 bytes, number of entries: 88
+-rw-r--r--  2.0 unx      117 b- defN 24-Apr-03 15:01 pioreactor/__init__.py
+-rw-r--r--  2.0 unx     5868 b- defN 24-Apr-03 15:01 pioreactor/config.py
+-rw-r--r--  2.0 unx      265 b- defN 24-Apr-03 15:01 pioreactor/error_codes.py
+-rw-r--r--  2.0 unx      958 b- defN 24-Apr-03 15:01 pioreactor/exc.py
+-rw-r--r--  2.0 unx     3854 b- defN 24-Apr-03 15:01 pioreactor/hardware.py
+-rw-r--r--  2.0 unx     6824 b- defN 24-Apr-03 15:01 pioreactor/logging.py
+-rw-r--r--  2.0 unx    15621 b- defN 24-Apr-03 15:01 pioreactor/mureq.py
+-rw-r--r--  2.0 unx    12014 b- defN 24-Apr-03 15:01 pioreactor/pubsub.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-03 15:01 pioreactor/py.typed
+-rw-r--r--  2.0 unx     6386 b- defN 24-Apr-03 15:01 pioreactor/structs.py
+-rw-r--r--  2.0 unx     3304 b- defN 24-Apr-03 15:01 pioreactor/types.py
+-rw-r--r--  2.0 unx     2912 b- defN 24-Apr-03 15:01 pioreactor/version.py
+-rw-r--r--  2.0 unx     5462 b- defN 24-Apr-03 15:01 pioreactor/whoami.py
+-rw-r--r--  2.0 unx      540 b- defN 24-Apr-03 15:01 pioreactor/actions/__init__.py
+-rw-r--r--  2.0 unx     8810 b- defN 24-Apr-03 15:01 pioreactor/actions/led_intensity.py
+-rw-r--r--  2.0 unx     9013 b- defN 24-Apr-03 15:01 pioreactor/actions/od_blank.py
+-rw-r--r--  2.0 unx    24316 b- defN 24-Apr-03 15:01 pioreactor/actions/od_calibration.py
+-rw-r--r--  2.0 unx    19799 b- defN 24-Apr-03 15:01 pioreactor/actions/pump.py
+-rw-r--r--  2.0 unx    22400 b- defN 24-Apr-03 15:01 pioreactor/actions/pump_calibration.py
+-rw-r--r--  2.0 unx    20149 b- defN 24-Apr-03 15:01 pioreactor/actions/self_test.py
+-rw-r--r--  2.0 unx     5339 b- defN 24-Apr-03 15:01 pioreactor/actions/stirring_calibration.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-03 15:01 pioreactor/actions/leader/__init__.py
+-rw-r--r--  2.0 unx     4902 b- defN 24-Apr-03 15:01 pioreactor/actions/leader/backup_database.py
+-rw-r--r--  2.0 unx    24791 b- defN 24-Apr-03 15:01 pioreactor/actions/leader/experiment_profile.py
+-rw-r--r--  2.0 unx     6544 b- defN 24-Apr-03 15:01 pioreactor/actions/leader/export_experiment_data.py
+-rw-r--r--  2.0 unx      146 b- defN 24-Apr-03 15:01 pioreactor/automations/__init__.py
+-rw-r--r--  2.0 unx     1000 b- defN 24-Apr-03 15:01 pioreactor/automations/base.py
+-rw-r--r--  2.0 unx      459 b- defN 24-Apr-03 15:01 pioreactor/automations/dosing/__init__.py
+-rw-r--r--  2.0 unx    29496 b- defN 24-Apr-03 15:01 pioreactor/automations/dosing/base.py
+-rw-r--r--  2.0 unx     1424 b- defN 24-Apr-03 15:01 pioreactor/automations/dosing/chemostat.py
+-rw-r--r--  2.0 unx     1497 b- defN 24-Apr-03 15:01 pioreactor/automations/dosing/fed_batch.py
+-rw-r--r--  2.0 unx     4962 b- defN 24-Apr-03 15:01 pioreactor/automations/dosing/pid_morbidostat.py
+-rw-r--r--  2.0 unx      476 b- defN 24-Apr-03 15:01 pioreactor/automations/dosing/silent.py
+-rw-r--r--  2.0 unx     4613 b- defN 24-Apr-03 15:01 pioreactor/automations/dosing/turbidostat.py
+-rw-r--r--  2.0 unx      510 b- defN 24-Apr-03 15:01 pioreactor/automations/events/__init__.py
+-rw-r--r--  2.0 unx      567 b- defN 24-Apr-03 15:01 pioreactor/automations/led/__init__.py
+-rw-r--r--  2.0 unx    12023 b- defN 24-Apr-03 15:01 pioreactor/automations/led/base.py
+-rw-r--r--  2.0 unx     3875 b- defN 24-Apr-03 15:01 pioreactor/automations/led/light_dark_cycle.py
+-rw-r--r--  2.0 unx      154 b- defN 24-Apr-03 15:01 pioreactor/automations/temperature/__init__.py
+-rw-r--r--  2.0 unx     9317 b- defN 24-Apr-03 15:01 pioreactor/automations/temperature/base.py
+-rw-r--r--  2.0 unx      561 b- defN 24-Apr-03 15:01 pioreactor/automations/temperature/only_record_temperature.py
+-rw-r--r--  2.0 unx     4235 b- defN 24-Apr-03 15:01 pioreactor/automations/temperature/thermostat.py
+-rw-r--r--  2.0 unx      715 b- defN 24-Apr-03 15:01 pioreactor/background_jobs/__init__.py
+-rw-r--r--  2.0 unx    44487 b- defN 24-Apr-03 15:01 pioreactor/background_jobs/base.py
+-rw-r--r--  2.0 unx     7043 b- defN 24-Apr-03 15:01 pioreactor/background_jobs/dosing_control.py
+-rw-r--r--  2.0 unx    22120 b- defN 24-Apr-03 15:01 pioreactor/background_jobs/growth_rate_calculating.py
+-rw-r--r--  2.0 unx     5806 b- defN 24-Apr-03 15:01 pioreactor/background_jobs/led_control.py
+-rw-r--r--  2.0 unx    29084 b- defN 24-Apr-03 15:01 pioreactor/background_jobs/monitor.py
+-rw-r--r--  2.0 unx    52689 b- defN 24-Apr-03 15:01 pioreactor/background_jobs/od_reading.py
+-rw-r--r--  2.0 unx    17978 b- defN 24-Apr-03 15:01 pioreactor/background_jobs/stirring.py
+-rw-r--r--  2.0 unx    24449 b- defN 24-Apr-03 15:01 pioreactor/background_jobs/temperature_control.py
+-rw-r--r--  2.0 unx      605 b- defN 24-Apr-03 15:01 pioreactor/background_jobs/leader/__init__.py
+-rw-r--r--  2.0 unx    17001 b- defN 24-Apr-03 15:01 pioreactor/background_jobs/leader/mqtt_to_db_streaming.py
+-rw-r--r--  2.0 unx     4573 b- defN 24-Apr-03 15:01 pioreactor/background_jobs/leader/watchdog.py
+-rw-r--r--  2.0 unx     1094 b- defN 24-Apr-03 15:01 pioreactor/background_jobs/subjobs/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-03 15:01 pioreactor/cli/__init__.py
+-rw-r--r--  2.0 unx    26493 b- defN 24-Apr-03 15:01 pioreactor/cli/pio.py
+-rw-r--r--  2.0 unx    26132 b- defN 24-Apr-03 15:01 pioreactor/cli/pios.py
+-rw-r--r--  2.0 unx    10177 b- defN 24-Apr-03 15:01 pioreactor/cluster_management/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-03 15:01 pioreactor/experiment_profiles/__init__.py
+-rw-r--r--  2.0 unx     5488 b- defN 24-Apr-03 15:01 pioreactor/experiment_profiles/parser.py
+-rw-r--r--  2.0 unx     2896 b- defN 24-Apr-03 15:01 pioreactor/experiment_profiles/profile_struct.py
+-rw-r--r--  2.0 unx      197 b- defN 24-Apr-03 15:01 pioreactor/experiment_profiles/sly/__init__.py
+-rw-r--r--  2.0 unx    16273 b- defN 24-Apr-03 15:01 pioreactor/experiment_profiles/sly/lex.py
+-rw-r--r--  2.0 unx    83015 b- defN 24-Apr-03 15:01 pioreactor/experiment_profiles/sly/yacc.py
+-rw-r--r--  2.0 unx     3807 b- defN 24-Apr-03 15:01 pioreactor/plugin_management/__init__.py
+-rw-r--r--  2.0 unx     1446 b- defN 24-Apr-03 15:01 pioreactor/plugin_management/install_plugin.py
+-rw-r--r--  2.0 unx     1179 b- defN 24-Apr-03 15:01 pioreactor/plugin_management/list_plugins.py
+-rw-r--r--  2.0 unx     1789 b- defN 24-Apr-03 15:01 pioreactor/plugin_management/uninstall_plugin.py
+-rw-r--r--  2.0 unx     1194 b- defN 24-Apr-03 15:01 pioreactor/plugin_management/utils.py
+-rw-r--r--  2.0 unx    21545 b- defN 24-Apr-03 15:01 pioreactor/utils/__init__.py
+-rw-r--r--  2.0 unx     4240 b- defN 24-Apr-03 15:01 pioreactor/utils/adcs.py
+-rw-r--r--  2.0 unx     1930 b- defN 24-Apr-03 15:01 pioreactor/utils/dacs.py
+-rw-r--r--  2.0 unx      976 b- defN 24-Apr-03 15:01 pioreactor/utils/gpio_helpers.py
+-rw-r--r--  2.0 unx     3311 b- defN 24-Apr-03 15:01 pioreactor/utils/math_helpers.py
+-rw-r--r--  2.0 unx     5211 b- defN 24-Apr-03 15:01 pioreactor/utils/mock.py
+-rw-r--r--  2.0 unx     3622 b- defN 24-Apr-03 15:01 pioreactor/utils/networking.py
+-rw-r--r--  2.0 unx    10149 b- defN 24-Apr-03 15:01 pioreactor/utils/pwm.py
+-rw-r--r--  2.0 unx     3393 b- defN 24-Apr-03 15:01 pioreactor/utils/rpi_bad_power.py
+-rw-r--r--  2.0 unx     7889 b- defN 24-Apr-03 15:01 pioreactor/utils/sqlite_worker.py
+-rw-r--r--  2.0 unx    18416 b- defN 24-Apr-03 15:01 pioreactor/utils/streaming_calculations.py
+-rw-r--r--  2.0 unx     5827 b- defN 24-Apr-03 15:01 pioreactor/utils/timing.py
+-rw-r--r--  2.0 unx     1067 b- defN 24-Apr-03 15:02 pioreactor-24.4.3rc0.dist-info/LICENSE
+-rw-r--r--  2.0 unx     3713 b- defN 24-Apr-03 15:02 pioreactor-24.4.3rc0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-03 15:02 pioreactor-24.4.3rc0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       79 b- defN 24-Apr-03 15:02 pioreactor-24.4.3rc0.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       11 b- defN 24-Apr-03 15:02 pioreactor-24.4.3rc0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     8122 b- defN 24-Apr-03 15:02 pioreactor-24.4.3rc0.dist-info/RECORD
+88 files, 792826 bytes uncompressed, 217995 bytes compressed:  72.5%
```

## zipnote {}

```diff
@@ -162,32 +162,20 @@
 
 Filename: pioreactor/background_jobs/subjobs/__init__.py
 Comment: 
 
 Filename: pioreactor/cli/__init__.py
 Comment: 
 
-Filename: pioreactor/cli/lazy_group.py
-Comment: 
-
 Filename: pioreactor/cli/pio.py
 Comment: 
 
 Filename: pioreactor/cli/pios.py
 Comment: 
 
-Filename: pioreactor/cli/plugins.py
-Comment: 
-
-Filename: pioreactor/cli/run.py
-Comment: 
-
-Filename: pioreactor/cli/workers.py
-Comment: 
-
 Filename: pioreactor/cluster_management/__init__.py
 Comment: 
 
 Filename: pioreactor/experiment_profiles/__init__.py
 Comment: 
 
 Filename: pioreactor/experiment_profiles/parser.py
@@ -252,26 +240,26 @@
 
 Filename: pioreactor/utils/streaming_calculations.py
 Comment: 
 
 Filename: pioreactor/utils/timing.py
 Comment: 
 
-Filename: pioreactor-24.4.30rc0.dist-info/LICENSE
+Filename: pioreactor-24.4.3rc0.dist-info/LICENSE
 Comment: 
 
-Filename: pioreactor-24.4.30rc0.dist-info/METADATA
+Filename: pioreactor-24.4.3rc0.dist-info/METADATA
 Comment: 
 
-Filename: pioreactor-24.4.30rc0.dist-info/WHEEL
+Filename: pioreactor-24.4.3rc0.dist-info/WHEEL
 Comment: 
 
-Filename: pioreactor-24.4.30rc0.dist-info/entry_points.txt
+Filename: pioreactor-24.4.3rc0.dist-info/entry_points.txt
 Comment: 
 
-Filename: pioreactor-24.4.30rc0.dist-info/top_level.txt
+Filename: pioreactor-24.4.3rc0.dist-info/top_level.txt
 Comment: 
 
-Filename: pioreactor-24.4.30rc0.dist-info/RECORD
+Filename: pioreactor-24.4.3rc0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## pioreactor/logging.py

```diff
@@ -1,24 +1,25 @@
 # -*- coding: utf-8 -*-
 from __future__ import annotations
 
 import logging
 from logging import handlers
-from typing import TYPE_CHECKING
 
 from json_log_formatter import JSONFormatter  # type: ignore
 
 from pioreactor.config import config
 from pioreactor.exc import NotAssignedAnExperimentError
+from pioreactor.pubsub import Client
+from pioreactor.pubsub import create_client
+from pioreactor.pubsub import publish_to_pioreactor_cloud
+from pioreactor.utils.timing import current_utc_timestamp
 from pioreactor.whoami import get_assigned_experiment_name
 from pioreactor.whoami import get_unit_name
 from pioreactor.whoami import UNIVERSAL_EXPERIMENT
 
-if TYPE_CHECKING:
-    from pioreactor.pubsub import Client
 
 logging.raiseExceptions = False
 
 
 def add_logging_level(levelName, levelNum):
     """
     Comprehensively adds a new logging level to the `logging` module and the
@@ -67,16 +68,14 @@
         for handler in handlers:
             self.logger.removeHandler(handler)
             handler.close()
 
 
 class CustomisedJSONFormatter(JSONFormatter):
     def json_record(self, message: str, extra: dict, record: logging.LogRecord) -> dict:
-        from pioreactor.utils.timing import current_utc_timestamp
-
         extra["message"] = message
         extra["level"] = record.levelname
         extra["task"] = record.name
         extra["timestamp"] = current_utc_timestamp()
         extra["source"] = record.source  # type: ignore
 
         if record.exc_info:
@@ -111,14 +110,20 @@
 
         if not self.client.is_connected():
             return
 
         mqtt_msg = self.client.publish(
             self.topic, payload, qos=self.qos, retain=self.retain, **self.mqtt_kwargs
         )
+
+        if (record.levelno == logging.ERROR) and config.getboolean(
+            "data_sharing_with_pioreactor", "send_errors_to_Pioreactor", fallback=False
+        ):
+            publish_to_pioreactor_cloud("reported_errors", data_str=payload)
+
         # if Python exits too quickly, the last msg might never make it to the broker.
         mqtt_msg.wait_for_publish(timeout=2)
 
     def close(self) -> None:
         self.client.loop_stop()
         self.client.disconnect()
         super().close()
@@ -140,15 +145,14 @@
         the name of the logger
     source:
         "app" for the core Pioreactor codebase, else the name of the plugin.
     to_mqtt: bool
         connect and log to MQTT
     """
     import colorlog
-    from pioreactor.pubsub import create_client
 
     logger = logging.getLogger(name)
 
     if len(logger.handlers) > 0:
         return CustomLogger(logger, {"source": source})  # type: ignore
 
     logger.setLevel(logging.DEBUG)
```

## pioreactor/mureq.py

```diff
@@ -9,15 +9,17 @@
 # mypy: ignore-errors
 from __future__ import annotations
 
 import contextlib
 import io
 import os.path
 import socket
+import ssl
 import urllib.parse
+from base64 import b64encode
 from http.client import HTTPConnection
 from http.client import HTTPException
 from http.client import HTTPMessage
 from http.client import HTTPResponse
 from http.client import HTTPSConnection
 from typing import Generator
 
@@ -28,16 +30,14 @@
 DEFAULT_TIMEOUT = 15.0
 DEFAULT_UA = "Python/Pioreactor"
 
 JSON_HEADERS = {"Content-Type": "application/json"}
 
 
 def basic_auth(username: str, password: str) -> str:
-    from base64 import b64encode
-
     # get(..., headers={ 'Authorization' : f'Basic {basic_auth(username, password)}'})
     token = b64encode(f"{username}:{password}".encode("utf-8")).decode("ascii")
     return token
 
 
 def request(method, url, *, read_limit=None, **kwargs) -> Response:
     """request performs an HTTP request and reads the entire response body.
@@ -406,16 +406,14 @@
     enc_params="",
     timeout=DEFAULT_TIMEOUT,
     source_address=None,
     unix_socket=None,
     verify=True,
     ssl_context=None,
 ):
-    import ssl
-
     """Parses the URL, returns the path and the right HTTPConnection subclass."""
     parsed_url = urllib.parse.urlparse(url)
 
     is_unix = unix_socket is not None
     scheme = parsed_url.scheme.lower()
     if scheme.endswith("+unix"):
         scheme = scheme[:-5]
```

## pioreactor/pubsub.py

```diff
@@ -356,7 +356,45 @@
         return self.bucket
 
     def __exit__(self, *args):
         # stop listening for messages
         self.client.loop_stop()
         # disconnect from the broker
         self.client.disconnect()
+
+
+def publish_to_pioreactor_cloud(
+    endpoint: str, data_dict: Optional[dict] = None, data_str: Optional[str] = None
+) -> None:
+    """
+    Parameters
+    ------------
+    endpoint: the function to send to the data to
+    json: (optional) data to send in the body.
+
+    """
+    from pioreactor.mureq import post
+    from pioreactor.whoami import get_hashed_serial_number, is_testing_env
+    from pioreactor.utils.timing import current_utc_timestamp
+    from json import dumps
+
+    assert (data_dict is not None) or (data_str is not None)
+
+    if is_testing_env():
+        return
+
+    if data_dict is not None:
+        data_dict["hashed_serial_number"] = get_hashed_serial_number()
+        data_dict["timestamp"] = current_utc_timestamp()
+        body = dumps(data_dict).encode("utf-8")
+    elif data_str is not None:
+        body = data_str.encode("utf-8")
+
+    headers = {"Content-type": "application/json", "Accept": "text/plain"}
+    try:
+        post(
+            f"https://cloud.pioreactor.com/{endpoint}",
+            body=body,
+            headers=headers,
+        )
+    except Exception:
+        pass
```

## pioreactor/structs.py

```diff
@@ -147,15 +147,15 @@
 
 class GrowthRate(Struct):
     growth_rate: float
     timestamp: t.Annotated[datetime, Meta(tz=True)]
 
 
 class ODFiltered(Struct):
-    od_filtered: float
+    od_filtered: t.Annotated[float, Meta(ge=0)]
     timestamp: t.Annotated[datetime, Meta(tz=True)]
 
 
 class ODReading(Struct):
     timestamp: t.Annotated[datetime, Meta(tz=True)]
     angle: pt.PdAngle
     od: pt.OD
```

## pioreactor/version.py

```diff
@@ -3,15 +3,15 @@
 
 import os
 
 # pioreactor version
 # Append ".dev0" if a dev version
 # Append "rc0" if a rc version
 # No zero padding!
-__version__ = "24.4.30rc0"
+__version__ = "24.4.3rc0"
 
 
 def get_hardware_version() -> tuple[int, int] | tuple[int, int, str]:
     if os.environ.get("HARDWARE") is not None:
         # ex: > HARDWARE=1.1 pio ...
         return int(os.environ["HARDWARE"].split(".")[0]), int(os.environ["HARDWARE"].split(".")[1])
 
@@ -77,22 +77,18 @@
         return (0, 0)
 
 
 def tuple_to_text(t: tuple) -> str:
     return ".".join(map(str, t))
 
 
-def version_text_to_tuple(s: str) -> tuple[int, int]:
-    return tuple((safe_int(_) for _ in s.split(".")))  # type: ignore
-
-
 def safe_int(s):
     try:
         return int(s)
     except (ValueError, TypeError):
         return s
 
 
 hardware_version_info = get_hardware_version()
-software_version_info = version_text_to_tuple(__version__)
+software_version_info = tuple(safe_int(c) for c in __version__.split("."))
 serial_number = get_serial_number()
 rpi_version_info = get_rpi_machine()
```

## pioreactor/whoami.py

```diff
@@ -7,15 +7,14 @@
 import warnings
 from functools import cache
 
 from pioreactor import mureq
 from pioreactor.exc import NotAssignedAnExperimentError
 from pioreactor.exc import NoWorkerFoundError
 from pioreactor.version import serial_number
-from pioreactor.version import version_text_to_tuple
 
 
 UNIVERSAL_IDENTIFIER = "$broadcast"
 UNIVERSAL_EXPERIMENT = "$experiment"
 NO_EXPERIMENT = "$no_experiment_present"
 
 
@@ -60,15 +59,15 @@
             return data["experiment"]
         except mureq.HTTPErrorStatus as e:
             if e.status_code == 401:
                 # auth error, something is wrong
                 exit_reason = "auth"
                 break
             elif e.status_code == 404:
-                raise NotAssignedAnExperimentError(f"Worker {unit_name} is not assigned to an experiment")
+                raise NotAssignedAnExperimentError("Worker is not assigned to an experiment")
         except mureq.HTTPException:
             exit_reason = "connection_refused"
         except Exception:
             # some other error? Keep trying
             pass
         time.sleep(0.5 * attempt)
     else:
@@ -82,14 +81,16 @@
         )
     elif exit_reason == "timeout":
         logger.warning(f"Not able to access experiments in UI. Check http://{leader_address}/api/experiments")
     elif exit_reason == "connection_refused":
         logger.warning(
             f"Not able to access experiments in UI. Check http://{leader_address} is online and check network."
         )
+    elif exit_reason == "unassigned":
+        logger.warning(f"Worker {unit_name} not found or not assigned to any experiment.")
     return NO_EXPERIMENT
 
 
 @cache
 def is_active(unit_name: str) -> bool:
     from pioreactor.config import leader_address
 
@@ -104,15 +105,15 @@
     try:
         result = mureq.get(f"http://{leader_address}/api/workers/{unit_name}")
         result.raise_for_status()
         data = result.json()
         return bool(data["is_active"])
     except mureq.HTTPErrorStatus as e:
         if e.status_code == 404:
-            raise NoWorkerFoundError(f"Worker {unit_name} is not present in leader's inventory")
+            raise NoWorkerFoundError("Worker is not present in leader's inventory")
         else:
             raise e
     except mureq.HTTPException as e:
         raise e
 
 
 @cache
@@ -158,31 +159,14 @@
 @cache
 def get_hashed_serial_number() -> str:
     from hashlib import md5
 
     return md5(serial_number.encode()).hexdigest()
 
 
-@cache
-def get_pioreactor_version() -> tuple[int, int]:
-    if os.environ.get("PIO_VERSION"):
-        return version_text_to_tuple(os.environ["PIO_VERSION"])
-
-    from pioreactor.config import config
-
-    return version_text_to_tuple(config.get("pioreactor", "version"))  # type: ignore
-
-
-@cache
-def get_pioreactor_model() -> tuple[str, str]:
-    from pioreactor.config import config
-
-    return config.get("pioreactor", "model")
-
-
 def get_image_git_hash() -> str:
     try:
         with open("/home/pioreactor/.pioreactor/.image_info") as f:
             return f.read().strip().split("=")[1]
     except OSError:  # catch FileNotFoundError, PermissionError, and other file-related exceptions
         return "<Failed to fetch>"
```

## pioreactor/actions/od_calibration.py

```diff
@@ -86,19 +86,14 @@
                 echo("Name cannot be `current`.")
                 continue
             else:
                 return name
 
 
 def get_metadata_from_user() -> tuple[pt.OD600, pt.OD600, pt.mL, pt.PdAngle, pt.PdChannel]:
-    if config["od_config"]["ir_led_intensity"] == "auto":
-        raise ValueError(
-            "Can't use auto with OD calibrations. Change ir_led_intensity in your config.ini to a numeric value (50 is good default)."
-        )
-
     initial_od600 = prompt(
         green("Provide the OD600 measurement of your initial, high density, culture"),
         type=click.FloatRange(min=0.01, clamp=False),
     )
 
     minimum_od600 = prompt(
         green("Provide the minimum OD600 measurement you wish to calibrate to"),
@@ -192,25 +187,21 @@
     if highlight_recent_point:
         plt.scatter([x[-1]], [y[-1]], color=204, marker="hd")
 
     plt.theme("pro")
     plt.title(title)
     plt.xlabel("OD600")
     plt.ylabel("OD Reading (Raw)")
-
     plt.plot_size(105, 22)
 
     if interpolation_curve:
         plt.plot(x, [interpolation_curve(x_) for x_ in x], color=204)
         plt.plot_size(145, 26)
 
     plt.xlim(x_min, x_max)
-    plt.yfrequency(6)
-    plt.xfrequency(6)
-
     plt.show()
 
 
 def start_recording_and_diluting(
     st: Stirrer,
     initial_od600: pt.OD,
     minimum_od600: pt.OD,
```

## pioreactor/actions/pump_calibration.py

```diff
@@ -255,17 +255,14 @@
 
     plt.theme("pro")
     plt.title(title)
     plt.plot_size(105, 20)
     plt.xlabel("Duration")
     plt.ylabel("Volume")
     plt.xlim(x_min, x_max)
-    plt.yfrequency(6)
-    plt.xfrequency(6)
-
     plt.show()
 
 
 def run_tests(
     execute_pump: Callable,
     hz: float,
     dc: float,
```

## pioreactor/actions/leader/experiment_profile.py

```diff
@@ -17,15 +17,14 @@
 from pioreactor.experiment_profiles import profile_struct as struct
 from pioreactor.logging import create_logger
 from pioreactor.logging import CustomLogger
 from pioreactor.mureq import put
 from pioreactor.pubsub import publish
 from pioreactor.utils import ClusterJobManager
 from pioreactor.utils import managed_lifecycle
-from pioreactor.utils.timing import current_utc_timestamp
 from pioreactor.whoami import get_assigned_experiment_name
 from pioreactor.whoami import get_unit_name
 
 bool_expression = str | bool
 
 
 def wrap_in_try_except(func, logger: CustomLogger) -> Callable:
@@ -586,19 +585,14 @@
             raise e
 
         state.mqtt_client.publish(
             f"pioreactor/{unit}/{experiment}/{action_name}/experiment_profile_name",
             profile.experiment_profile_name,
             retain=True,
         )
-        state.mqtt_client.publish(
-            f"pioreactor/{unit}/{experiment}/{action_name}/start_time_utc",
-            current_utc_timestamp(),
-            retain=True,
-        )
 
         if dry_run:
             logger.notice(  # type: ignore
                 f"Executing DRY-RUN of profile {profile.experiment_profile_name}, sourced from {Path(profile_filename).name}. See logs."
             )
         else:
             logger.notice(  # type: ignore
@@ -608,97 +602,93 @@
         try:
             check_plugins(profile.plugins)
         except Exception as e:
             logger.debug(e, exc_info=True)
             logger.error(e)
             raise e
 
-        sched = scheduler()
+        s = scheduler()
 
         # process common
         for job_name, job in profile.common.jobs.items():
             for action in job.actions:
-                sched.enter(
+                s.enter(
                     delay=hours_to_seconds(action.hours_elapsed),
                     priority=get_simple_priority(action),
                     action=common_wrapped_execute_action(
                         experiment,
                         job_name,
                         logger,
-                        sched,
+                        s,
                         action,
                         dry_run,
                     ),
                 )
 
         # process specific pioreactors
         for unit_ in profile.pioreactors:
             pioreactor_specific_block = profile.pioreactors[unit_]
             if pioreactor_specific_block.label is not None:
                 label = pioreactor_specific_block.label
                 push_labels_to_ui(experiment, {unit_: label})
 
             for job_name, job in pioreactor_specific_block.jobs.items():
                 for action in job.actions:
-                    sched.enter(
+                    s.enter(
                         delay=hours_to_seconds(action.hours_elapsed),
                         priority=get_simple_priority(action),
                         action=wrapped_execute_action(
                             unit_,
                             experiment,
                             job_name,
                             logger,
-                            sched,
+                            s,
                             action,
                             dry_run,
                         ),
                     )
 
         logger.debug("Starting execution of actions.")
 
         try:
             # try / finally to handle keyboard interrupts
 
             # the below is so the schedule can be canceled by setting the event.
             while not state.exit_event.wait(timeout=0):
-                next_event_in = sched.run(blocking=False)
+                next_event_in = s.run(blocking=False)
                 if next_event_in is not None:
-                    time.sleep(min(0.25, next_event_in))
+                    time.sleep(min(0.5, next_event_in))
                 else:
                     break
         finally:
             if state.exit_event.is_set():
                 # ended early
 
-                logger.notice(f"Stopping profile {profile.experiment_profile_name} early: {len(sched.queue)} actions not started, and stopping all started actions.")  # type: ignore
                 # stop all jobs started
                 # we can use active workers in experiment, since if a worker leaves an experiment or goes inactive, it's jobs are stopped
                 workers = get_active_workers_in_experiment(experiment)
                 with ClusterJobManager(workers) as jm:
                     jm.kill_jobs(experiment=experiment, job_source="experiment_profile")
 
+                logger.notice(f"Stopping profile {profile.experiment_profile_name} early: {len(s.queue)} actions not started, and stopping all started actions.")  # type: ignore
+
             else:
                 if dry_run:
                     logger.notice(  # type: ignore
                         f"Finished executing DRY-RUN of profile {profile.experiment_profile_name}."
                     )
 
                 else:
                     logger.notice(f"Finished executing profile {profile.experiment_profile_name}.")  # type: ignore
 
             state.mqtt_client.publish(
                 f"pioreactor/{unit}/{experiment}/{action_name}/experiment_profile_name",
                 None,
                 retain=True,
             )
-            state.mqtt_client.publish(
-                f"pioreactor/{unit}/{experiment}/{action_name}/start_time_utc",
-                None,
-                retain=True,
-            )
 
             logger.clean_up()
 
 
 @click.group(name="experiment_profile")
 def click_experiment_profile():
     """
```

## pioreactor/automations/dosing/base.py

```diff
@@ -200,19 +200,20 @@
     )
 
     # dosing metrics that are available, and published to MQTT
     alt_media_fraction: float  # fraction of the vial that is alt-media (vs regular media).
     media_throughput: float  # amount of media that has been expelled
     alt_media_throughput: float  # amount of alt-media that has been expelled
     vial_volume: float  # amount in the vial
+    MAX_VIAL_VOLUME_TO_WARN: float = config.getfloat(
+        "dosing_automation.config", "max_volume_to_warn", fallback=17.0
+    )
     MAX_VIAL_VOLUME_TO_STOP: float = config.getfloat(
         "dosing_automation.config", "max_volume_to_stop", fallback=18.0
     )
-    MAX_VIAL_VOLUME_TO_WARN: float = 0.9 * MAX_VIAL_VOLUME_TO_STOP
-
     MAX_SUBDOSE = config.getfloat(
         "dosing_automation.config", "max_subdose", fallback=1.0
     )  # arbitrary, but should be some value that the pump is well calibrated for.
 
     def __init_subclass__(cls, **kwargs) -> None:
         super().__init_subclass__(**kwargs)
```

## pioreactor/automations/dosing/turbidostat.py

```diff
@@ -3,15 +3,14 @@
 
 from typing import Optional
 
 from pioreactor.automations import events
 from pioreactor.automations.dosing.base import DosingAutomationJob
 from pioreactor.exc import CalibrationError
 from pioreactor.utils import local_persistant_storage
-from pioreactor.utils.streaming_calculations import ExponentialMovingAverage
 
 
 class Turbidostat(DosingAutomationJob):
     """
     Turbidostat mode - try to keep cell density constant by dosing whenever the target is surpassed
     """
 
@@ -47,15 +46,14 @@
 
         if target_normalized_od is not None:
             self.target_normalized_od = float(target_normalized_od)
         elif target_od is not None:
             self.target_od = float(target_od)
 
         self.volume = float(volume)
-        self.ema_od = ExponentialMovingAverage(0.5)  # strong bias to recent observations
 
     @property
     def is_targeting_nOD(self) -> bool:
         return self.target_normalized_od is not None
 
     def execute(self) -> Optional[events.DilutionEvent]:
         if self.is_targeting_nOD:
@@ -73,18 +71,16 @@
         if self.is_targeting_nOD:
             self.logger.warning("You are currently targeting nOD, and can only change that.")
         else:
             self.target_od = float(new_target)
 
     def _execute_target_od(self) -> Optional[events.DilutionEvent]:
         assert self.target_od is not None
-        smoothed_od = self.ema_od.update(self.latest_od["2"])
-        if smoothed_od >= self.target_od:
-            self.ema_od.clear()  # clear the ema so that we don't cause a second dosing to occur right after.
-            latest_od_before_dosing = smoothed_od
+        if self.latest_od["2"] >= self.target_od:
+            latest_od_before_dosing = self.latest_od["2"]
             target_od_before_dosing = self.target_od
             results = self.execute_io_action(media_ml=self.volume, waste_ml=self.volume)
             media_moved = results["media_ml"]
             return events.DilutionEvent(
                 f"Latest OD = {latest_od_before_dosing:.2f} ≥ Target OD = {target_od_before_dosing:.2f}; cycled {media_moved:.2f} mL",
                 {
                     "latest_od": latest_od_before_dosing,
```

## pioreactor/automations/temperature/thermostat.py

```diff
@@ -3,27 +3,22 @@
 
 from pioreactor.automations.events import UpdatedHeaterDC
 from pioreactor.automations.temperature.base import TemperatureAutomationJob
 from pioreactor.config import config
 from pioreactor.utils import clamp
 from pioreactor.utils import is_pio_job_running
 from pioreactor.utils.streaming_calculations import PID
-from pioreactor.whoami import get_pioreactor_version
 
 
 class Thermostat(TemperatureAutomationJob):
     """
     Uses a PID controller to change the DC% to match a target temperature.
     """
 
-    if get_pioreactor_version() == (1, 0):
-        MAX_TARGET_TEMP = 50
-    else:
-        MAX_TARGET_TEMP = 70
-
+    MAX_TARGET_TEMP = 50
     automation_name = "thermostat"
     published_settings = {"target_temperature": {"datatype": "float", "unit": "℃", "settable": True}}
 
     def __init__(self, target_temperature: float | str, **kwargs) -> None:
         super().__init__(**kwargs)
         assert target_temperature is not None, "target_temperature must be set"
         self.target_temperature = float(target_temperature)
```

## pioreactor/background_jobs/base.py

```diff
@@ -307,16 +307,16 @@
 
         try:
             # this is one function in the __init__ that we may deliberately raise an error
             # if we do raise an error, the class needs to be cleaned up correctly
             # (hence the _cleanup bit, don't use set_state)
             # but we still raise the error afterwards.
             self._check_published_settings(self.published_settings)
-            self._publish_properties_string_to_broker(self.published_settings)
-            self._publish_settings_metadata_to_broker(self.published_settings)
+            self._publish_properties_to_broker(self.published_settings)
+            self._publish_settings_to_broker(self.published_settings)
 
         except ValueError as e:
             self.logger.debug(e, exc_info=True)
             self.logger.error(e)
             self._clean_up_resources()
             raise e
 
@@ -536,16 +536,16 @@
         """
         Add a pair to self.published_settings.
         """
         new_setting_pair = {setting: props}
         self._check_published_settings(new_setting_pair)
         # we need create a new dict (versus just a key update), since published_settings is a class level prop, and editing this would have effects for other BackgroundJob classes.
         self.published_settings = self.published_settings | new_setting_pair
-        self._publish_properties_string_to_broker(self.published_settings)
-        self._publish_settings_metadata_to_broker(new_setting_pair)
+        self._publish_properties_to_broker(self.published_settings)
+        self._publish_settings_to_broker(new_setting_pair)
 
     ########### Private #############
 
     @staticmethod
     def _check_published_settings(published_settings: dict[str, pt.PublishableSetting]) -> None:
         necessary_properies = {"datatype", "settable"}
         optional_properties = {"unit", "persist"}
@@ -581,18 +581,16 @@
         # see note above as to why we split pub and sub.
 
         # the client will try to automatically reconnect if something bad happens
         # when we reconnect to the broker, we want to republish our state
         # to overwrite potential last-will losts...
         # also reconnect to our old topics.
         def reconnect_protocol(client: Client, userdata, flags, rc: int, properties=None):
-            self.logger.info("Reconnected to the MQTT broker on leader.")
-            self._publish_properties_string_to_broker(self.published_settings)
-            self._publish_settings_metadata_to_broker(self.published_settings)
-            self._publish_defined_settings_to_broker(self.published_settings)
+            self.logger.info("Reconnected to the MQTT broker on leader.")  # type: ignore
+            self._publish_attr("state")
             self._start_general_passive_listeners()
             self.start_passive_listeners()
 
         def on_disconnect(client, userdata, rc: int) -> None:
             self._on_mqtt_disconnect(client, rc)
 
         # we give the last_will to this sub client because when it reconnects, it
@@ -802,29 +800,24 @@
         self._remove_from_cache()
         # Explicitly cleanup MQTT resources...
         self._disconnect_from_mqtt_clients()
         self._disconnect_from_loggers()
 
         self._clean = True
 
-    def _publish_properties_string_to_broker(
-        self, published_settings: dict[str, pt.PublishableSetting]
-    ) -> None:
-        # publishes a comma seperated list of settings available to $properties. ex: state,rpm,duty_cycle
+    def _publish_properties_to_broker(self, published_settings: dict[str, pt.PublishableSetting]) -> None:
         # this follows some of the Homie convention: https://homieiot.github.io/specification/
         self.publish(
             f"pioreactor/{self.unit}/{self.experiment}/{self.job_name}/$properties",
             ",".join(published_settings),
             qos=QOS.AT_LEAST_ONCE,
             retain=True,
         )
 
-    def _publish_settings_metadata_to_broker(
-        self, published_settings: dict[str, pt.PublishableSetting]
-    ) -> None:
+    def _publish_settings_to_broker(self, published_settings: dict[str, pt.PublishableSetting]) -> None:
         # this follows some of the Homie convention: https://homieiot.github.io/specification/
         for setting, props in published_settings.items():
             self.publish(
                 f"pioreactor/{self.unit}/{self.experiment}/{self.job_name}/{setting}/$settable",
                 props["settable"],
                 qos=QOS.AT_LEAST_ONCE,
                 retain=True,
@@ -839,21 +832,14 @@
                 self.publish(
                     f"pioreactor/{self.unit}/{self.experiment}/{self.job_name}/{setting}/$unit",
                     props["unit"],
                     qos=QOS.AT_LEAST_ONCE,
                     retain=True,
                 )
 
-    def _publish_defined_settings_to_broker(
-        self, published_settings: dict[str, pt.PublishableSetting]
-    ) -> None:
-        for name in published_settings.keys():
-            if hasattr(self, name):
-                self._publish_attr(name)
-
     def _log_state(self, state: pt.JobState) -> None:
         if state == self.READY or state == self.DISCONNECTED:
             self.logger.info(state.capitalize() + ".")
         else:
             self.logger.debug(state.capitalize() + ".")
 
     def _set_attr_from_message(self, message: pt.MQTTMessage) -> None:
@@ -1149,15 +1135,14 @@
                 f"Your {pre_delay=} or {post_delay=} is too high for the samples_per_second={1/ads_interval}. Either decrease pre_delay or post_delay, or decrease samples_per_second"
             )
             self.clean_up()
 
         self.sneak_in_timer = RepeatedTimer(
             ads_interval,
             sneak_in,
-            job_name=self.job_name,
             args=(ads_interval, post_delay, pre_delay),
             run_immediately=False,
         )
 
         time_to_next_ads_reading = ads_interval - ((time() - ads_start_time) % ads_interval)
 
         sleep(time_to_next_ads_reading + (post_delay + self.OD_READING_DURATION))
```

## pioreactor/background_jobs/growth_rate_calculating.py

```diff
@@ -385,15 +385,17 @@
             )
             for channel, raw_signal in observations.items()
         }
 
         if any(v <= 0.0 for v in scaled_signals.values()):
             self.logger.debug(f"od_normalization_factors: {self.od_normalization_factors}")
             self.logger.debug(f"od_blank: {dict(self.od_blank)}")
-            raise ValueError(f"Negative normalized value(s) observed: {scaled_signals}.")
+            raise ValueError(
+                f"Negative normalized value(s) observed: {scaled_signals}. Did your blank have inoculant in it?"
+            )
 
         return scaled_signals
 
     def respond_to_od_readings_from_mqtt(self, message: pt.MQTTMessage) -> None:
         if self.state != self.READY:
             return
```

## pioreactor/background_jobs/monitor.py

```diff
@@ -7,14 +7,15 @@
 from threading import Thread
 from time import sleep
 from typing import Any
 from typing import Callable
 from typing import Optional
 
 import click
+import lgpio
 from msgspec.json import decode as loads
 
 from pioreactor import error_codes
 from pioreactor import utils
 from pioreactor import version
 from pioreactor import whoami
 from pioreactor.background_jobs.base import LongRunningBackgroundJob
@@ -78,21 +79,15 @@
             led_intensity({'B': 0}, verbose=False, source_of_event="button", unit="demo", experiment="demo")
 
         Monitor.add_pre_button_callback(on)
         Monitor.add_post_button_callback(off)
 
     """
 
-    if whoami.get_pioreactor_version() == (1, 0):
-        # made from PLA
-        MAX_TEMP_TO_SHUTDOWN = 66.0
-    elif whoami.get_pioreactor_version() >= (1, 1):
-        # made from PC-CF
-        MAX_TEMP_TO_SHUTDOWN = 85.0  # risk damaging PCB components
-
+    MAX_TEMP_TO_SHUTDOWN = 66.0
     job_name = "monitor"
     published_settings = {
         "computer_statistics": {"datatype": "json", "settable": False},
         "button_down": {"datatype": "boolean", "settable": False},
         "versions": {"datatype": "json", "settable": True},
         "voltage_on_pwm_rail": {"datatype": "Voltage", "settable": False},
         "ipv4": {"datatype": "string", "settable": False},
@@ -113,26 +108,21 @@
         self.versions = {
             "app": pretty_version(version.software_version_info),
             "hat": pretty_version(version.hardware_version_info),
             "firmware": pretty_version(version.get_firmware_version()),
             "hat_serial": version.serial_number,
             "rpi_machine": version.rpi_version_info,
             "timestamp": current_utc_timestamp(),
-            "pioreactor_version": version.tuple_to_text(whoami.get_pioreactor_version()),
-            "pioreactor_model": whoami.get_pioreactor_model(),
         }
 
         self.logger.debug(f"Pioreactor software version: {self.versions['app']}")
         self.logger.debug(f"Raspberry Pi: {self.versions['rpi_machine']}")
         self.logger.debug(f"Pioreactor HAT version: {self.versions['hat']}")
         self.logger.debug(f"Pioreactor firmware version: {self.versions['firmware']}")
         self.logger.debug(f"Pioreactor HAT serial number: {self.versions['hat_serial']}")
-        self.logger.debug(
-            f"Pioreactor: {self.versions['pioreactor_model']} v{self.versions['pioreactor_version']}"
-        )
 
         self.button_down = False
         # set up GPIO for accessing the button and changing the LED
 
         try:
             # if these fail, don't kill the entire job - sucks for onboarding.
             self._setup_GPIO()
@@ -166,16 +156,14 @@
         cls._pre_button.append(function)
 
     @classmethod
     def add_post_button_callback(cls, function: Callable) -> None:
         cls._post_button.append(function)
 
     def _setup_GPIO(self) -> None:
-        import lgpio
-
         set_gpio_availability(BUTTON_PIN, False)
         set_gpio_availability(LED_PIN, False)
 
         if not whoami.is_testing_env():
             self._handle = lgpio.gpiochip_open(GPIOCHIP)
 
             # Set LED_PIN as output and initialize to low
@@ -258,17 +246,17 @@
 
         from pathlib import Path
 
         storage_path = Path(config.get("storage", "database")).parent
 
         for file in [
             storage_path / "pioreactor.sqlite",
-            # shm and wal sometimes aren't present at when monitor starts - removed too many false positives
-            # storage_path / "pioreactor.sqlite-shm",
-            # storage_path / "pioreactor.sqlite-wal",
+            # shm and wal sometimes aren't present at when monitor starts
+            storage_path / "pioreactor.sqlite-shm",
+            storage_path / "pioreactor.sqlite-wal",
         ]:
             if file.exists() and (file.owner() != "pioreactor" or file.group() != "www-data"):
                 self.logger.warning(
                     f"Pioreactor sqlite database file {file} has the wrong permissions / does not exist."
                 )
                 break
 
@@ -428,44 +416,36 @@
 
     def check_for_last_backup(self) -> None:
         with utils.local_persistant_storage("database_backups") as cache:
             if cache.get("latest_backup_timestamp"):
                 latest_backup_at = to_datetime(cache["latest_backup_timestamp"])
 
                 if (current_utc_datetime() - latest_backup_at).days > 30:
-                    self.logger.warning(
-                        "Database hasn't been backed up in over 30 days. Try running `pio run backup_database` between experiments."
-                    )
+                    self.logger.warning("Database hasn't been backed up in over 30 days.")
 
     def on_ready(self) -> None:
         self.flicker_led_response_okay()
         self.logger.notice(f"{self.unit} is online and ready.")  # type: ignore
 
         # we can delay this check until ready.
 
     def on_disconnected(self) -> None:
-        import lgpio
-
         self.led_off()
         with suppress(AttributeError):
             self._button_callback.cancel()
             lgpio.gpiochip_close(self._handle)
 
         set_gpio_availability(BUTTON_PIN, True)
         set_gpio_availability(LED_PIN, True)
 
     def led_on(self) -> None:
-        import lgpio
-
         if not whoami.is_testing_env():
             lgpio.gpio_write(self._handle, LED_PIN, 1)
 
     def led_off(self) -> None:
-        import lgpio
-
         if not whoami.is_testing_env():
             lgpio.gpio_write(self._handle, LED_PIN, 0)
 
     def button_down_and_up(self, chip, gpio, level, tick) -> None:
         # Warning: this might be called twice
         # don't put anything that is not idempotent in here.
         if level == 1:
```

## pioreactor/background_jobs/od_reading.py

```diff
@@ -695,17 +695,15 @@
                     # confirm that PD channel is the same as when calibration was performed
                     elif calibration_data.pd_channel != channel:
                         msg = f"The calibration `{name}` was calibrated with a different PD channel ({calibration_data.pd_channel} vs current: {channel})."
                         self.logger.error(msg)
                         raise exc.CalibrationError(msg)
                     else:
                         models[channel] = self._hydrate_model(calibration_data)
-                        self.logger.debug(
-                            f"Using calibration `{name}` for channel {channel}, {calibration_data.curve_type=}, {calibration_data.curve_data_=}"
-                        )
+                        self.logger.debug(f"Using calibration `{name}` for channel {channel}")
 
                     # confirm that PD channel is the same as when calibration was performed
                     if calibration_data.pd_channel != channel:
                         msg = f"The calibration `{name}` was calibrated with a different PD channel ({calibration_data.pd_channel} vs current: {channel})."
                         self.logger.error(msg)
                         raise exc.CalibrationError(msg)
 
@@ -831,19 +829,15 @@
     }
 
     _pre_read: list[Callable] = []
     _post_read: list[Callable] = []
     od1: structs.ODReading
     od2: structs.ODReading
     ods: structs.ODReadings
-
-    if whoami.get_pioreactor_version() == (1, 0):
-        TARGET_REF_VOLTAGE = 0.10
-    elif whoami.get_pioreactor_version() >= (1, 1):
-        TARGET_REF_VOLTAGE = 0.03
+    TARGET_REF_VOLTAGE = 0.1
 
     def __init__(
         self,
         channel_angle_map: dict[pt.PdChannel, pt.PdAngle],
         interval: Optional[float],
         adc_reader: ADCReader,
         unit: str,
@@ -953,32 +947,34 @@
             culture_on_signal = on_reading.pop(pd_channel)
             blank_on_signal = blank_reading.pop(pd_channel)
 
             # if the blank signal is too close to the culture signal, its possible the culture is very sparse
             # this could create poor lower sensitivity, so we bump up the IR LED slightly.
             # 1.5 and 0.1 are arbitrary!
             if culture_on_signal / blank_on_signal < 1.5:
-                sparse_signal_factor = 1.1
+                sparse_signal_factor = 0.1
             else:
-                sparse_signal_factor = 1.0
+                sparse_signal_factor = 0.0
 
         if len(on_reading) == 0:
             # no op, didn't specify a REF, so we can't do much.
             return self.ir_led_intensity
         elif len(on_reading) > 1:
             raise ValueError("Too many REFs?")
         else:
             # only element of the dict is our REF signal
             _, signal_voltage = on_reading.popitem()
             return clamp(
                 20.0,
                 round(
-                    self.TARGET_REF_VOLTAGE * (self.ir_led_intensity / signal_voltage) * sparse_signal_factor,
-                    0,
-                ),  # round for a nice number to display in the UI
+                    self.TARGET_REF_VOLTAGE
+                    * (self.ir_led_intensity / signal_voltage)
+                    * (1 + sparse_signal_factor),
+                    2,
+                ),
                 80.0,
             )  # more than 80% is a bad idea for IR LED
 
     def _prepare_post_callbacks(self) -> list[Callable]:
         callbacks: list[Callable] = []
 
         # user created callbacks, this binds the callback to the instance so def cb(self, ... ) makes sense.
```

## pioreactor/background_jobs/stirring.py

```diff
@@ -6,14 +6,15 @@
 from time import perf_counter
 from time import sleep
 from time import time
 from typing import Callable
 from typing import Optional
 
 import click
+import lgpio
 
 import pioreactor.types as pt
 from pioreactor import error_codes
 from pioreactor import exc
 from pioreactor import hardware
 from pioreactor import structs
 from pioreactor.background_jobs.base import BackgroundJob
@@ -51,16 +52,14 @@
 
     """
 
     def __init__(self) -> None:
         pass
 
     def setup(self) -> None:
-        import lgpio
-
         # we delay the setup so that when all other checks are done (like in stirring's uniqueness), we can start to
         # use the GPIO for this.
         set_gpio_availability(hardware.HALL_SENSOR_PIN, False)
 
         if not is_testing_env():
             self._handle = lgpio.gpiochip_open(hardware.GPIOCHIP)
             lgpio.gpio_claim_input(self._handle, hardware.HALL_SENSOR_PIN, lgpio.SET_PULL_UP)
@@ -76,26 +75,22 @@
         self.turn_off_collection()
 
     def turn_off_collection(self) -> None:
         self.collecting = False
         self._edge_callback.cancel()
 
     def turn_on_collection(self) -> None:
-        import lgpio
-
         self.collecting = True
 
         if not is_testing_env():
             self._edge_callback = lgpio.callback(
                 self._handle, hardware.HALL_SENSOR_PIN, lgpio.FALLING_EDGE, self.callback
             )
 
     def clean_up(self) -> None:
-        import lgpio
-
         with suppress(AttributeError):
             self._edge_callback.cancel()
             lgpio.gpiochip_close(self._handle)
 
         set_gpio_availability(hardware.HALL_SENSOR_PIN, True)
 
     def estimate(self, seconds_to_observe: float) -> float:
@@ -306,21 +301,18 @@
         self.set_duty_cycle(self.duty_cycle)
         sleep(0.50)
         if self.rpm_calculator is not None:
             self.rpm_check_repeated_thread.start()  # .start is idempotent
 
     def kick_stirring(self) -> None:
         self.logger.debug("Kicking stirring")
-        _existing_duty_cycle = self.duty_cycle
-        self.set_duty_cycle(0)
-        sleep(0.25)
         self.set_duty_cycle(100)
-        sleep(0.15)
+        sleep(0.25)
         self.set_duty_cycle(
-            min(1.01 * _existing_duty_cycle, 50)
+            min(1.01 * self._previous_duty_cycle, 50)
         )  # DC should never need to be above 50 - simply not realistic. We want to avoid the death spiral to 100%.
 
     def kick_stirring_but_avoid_od_reading(self) -> None:
         """
         This will determine when the next od reading occurs (if possible), and
         wait until it completes before kicking stirring.
         """
```

## pioreactor/background_jobs/temperature_control.py

```diff
@@ -62,34 +62,24 @@
         }
 
     Parameters
     ------------
 
     """
 
-    INFERENCE_SAMPLES_EVERY_T_SECONDS: float = 5.0
-
-    if whoami.get_pioreactor_version() == (1, 0):
-        # made from PLA
-        MAX_TEMP_TO_REDUCE_HEATING = 63.0
-        MAX_TEMP_TO_DISABLE_HEATING = 65.0  # probably okay, but can't stay here for too long
-        MAX_TEMP_TO_SHUTDOWN = 66.0
-        INFERENCE_N_SAMPLES: int = 29
-        INFERENCE_EVERY_N_SECONDS: float = 225.0
-
-    elif whoami.get_pioreactor_version() >= (1, 1):
-        # made from PC-CF
-        MAX_TEMP_TO_REDUCE_HEATING = 78.0
-        MAX_TEMP_TO_DISABLE_HEATING = 80.0
-        MAX_TEMP_TO_SHUTDOWN = 85.0  # risk damaging PCB components
-        INFERENCE_N_SAMPLES = 21
-        INFERENCE_EVERY_N_SECONDS = 200.0
+    MAX_TEMP_TO_REDUCE_HEATING = (
+        63.0  # ~PLA glass transition temp, and I've gone safely above this an it's not a problem.
+    )
+    MAX_TEMP_TO_DISABLE_HEATING = 65.0  # probably okay, but can't stay here for too long
+    MAX_TEMP_TO_SHUTDOWN = 66.0
 
-    inference_total_time = INFERENCE_SAMPLES_EVERY_T_SECONDS * INFERENCE_N_SAMPLES
-    assert INFERENCE_EVERY_N_SECONDS > inference_total_time
+    INFERENCE_SAMPLES_EVERY_T_SECONDS: float = 5.0
+    INFERENCE_N_SAMPLES: int = 29
+    INFERENCE_EVERY_N_SECONDS: float = 225.0
+    inference_total_time: float = INFERENCE_SAMPLES_EVERY_T_SECONDS * INFERENCE_N_SAMPLES
     # PWM is on for (INFERENCE_EVERY_N_SECONDS - inference_total_time) seconds
     # the ratio of time a PWM is on is equal to (INFERENCE_EVERY_N_SECONDS - inference_total_time) / INFERENCE_EVERY_N_SECONDS
 
     job_name = "temperature_control"
 
     available_automations = {}  # type: ignore
 
@@ -122,22 +112,20 @@
         self.heater_duty_cycle = 0.0
         self.pwm = self.setup_pwm()
 
         self.heating_pcb_tmp_driver = TMP1075(address=hardware.TEMP)
         self.read_external_temperature_timer = RepeatedTimer(
             53,
             self.read_external_temperature,
-            job_name=self.job_name,
             run_immediately=False,
         ).start()
 
         self.publish_temperature_timer = RepeatedTimer(
             int(self.INFERENCE_EVERY_N_SECONDS),
             self.infer_temperature,
-            job_name=self.job_name,
             run_after=self.INFERENCE_EVERY_N_SECONDS
             - self.inference_total_time,  # This gives an automation a "full" PWM cycle to be on before an inference starts.
             run_immediately=True,
         ).start()
 
         try:
             automation_class = self.available_automations[automation_name]
@@ -194,15 +182,15 @@
         Update heater's duty cycle. This function checks for the PWM lock, and will not
         update if the PWM is locked.
 
         Returns true if the update was made (eg: no lock), else returns false
         """
 
         if not self.pwm.is_locked():
-            return self._update_heater(new_duty_cycle)
+            return self._update_heater(clamp(0.0, new_duty_cycle, 100.0))
         else:
             return False
 
     def update_heater_with_delta(self, delta_duty_cycle: float) -> bool:
         """
         Update heater's duty cycle by `delta_duty_cycle` amount. This function checks for the PWM lock, and will not
         update if the PWM is locked.
@@ -358,25 +346,23 @@
         self.automation_job.set_state(self.SLEEPING)
 
     def on_sleeping_to_ready(self) -> None:
         self.automation_job.set_state(self.READY)
 
     def on_disconnected(self) -> None:
         with suppress(AttributeError):
-            self._update_heater(0)
-
-        with suppress(AttributeError):
             self.read_external_temperature_timer.cancel()
             self.publish_temperature_timer.cancel()
 
         with suppress(AttributeError):
-            self.automation_job.clean_up()
+            self._update_heater(0)
+            self.pwm.clean_up()
 
         with suppress(AttributeError):
-            self.turn_off_heater()
+            self.automation_job.clean_up()
 
     def setup_pwm(self) -> PWM:
         hertz = 8  # technically this doesn't need to be high: it could even be 1hz. However, we want to smooth it's
         # impact (mainly: current sink), over the second. Ex: imagine freq=1hz, dc=40%, and the pump needs to run for
         # 0.3s. The influence of when the heat is one on the pump can be significant in a power-constrained system.
         pin = hardware.PWM_TO_PIN[hardware.HEATER_PWM_TO_PIN]
         pwm = PWM(pin, hertz, unit=self.unit, experiment=self.experiment)
@@ -438,30 +424,24 @@
                 # We also want to remove the lock first, so close this context early.
                 self._update_heater(previous_heater_dc)
 
         features["time_series_of_temp"] = time_series_of_temp
         self.logger.debug(f"{features=}")
 
         try:
-            if whoami.get_pioreactor_version() == (1, 0):
-                inferred_temperature = self.approximate_temperature_1_0(features)
-            elif whoami.get_pioreactor_version() >= (1, 1):
-                inferred_temperature = self.approximate_temperature_2_0(features)
-
             self.temperature = Temperature(
-                temperature=round(inferred_temperature, 2),
+                temperature=round(self.approximate_temperature(features), 2),
                 timestamp=current_utc_datetime(),
             )
 
         except Exception as e:
             self.logger.debug(e, exc_info=True)
             self.logger.error(e)
 
-    @staticmethod
-    def approximate_temperature_1_0(features: dict[str, Any]) -> float:
+    def approximate_temperature(self, features: dict[str, Any]) -> float:
         """
         models
 
             temp = b * exp(p * t) + c * exp(q * t) + room_temp
 
         Reference
         -------------
@@ -522,19 +502,27 @@
                 y.sum(),
             ]
         )
 
         try:
             A, B, _, _ = np.linalg.solve(M1, Y1)
         except np.linalg.LinAlgError:
-            raise ValueError(f"Error in temperature inference. {x=}, {y=}")
+            self.logger.error("Error in temperature inference.")
+            self.logger.debug("Error in temperature inference", exc_info=True)
+            self.logger.debug(f"x={x}")
+            self.logger.debug(f"y={y}")
+            raise ValueError()
 
         if (B**2 + 4 * A) < 0:
             # something when wrong in the data collection - the data doesn't look enough like a sum of two expos
-            raise ValueError(f"Error in temperature inference. {x=}, {y=}")
+            self.logger.error("Error in temperature inference.")
+            self.logger.debug(f"Error in temperature inference: {(B ** 2 + 4 * A)=} < 0")
+            self.logger.debug(f"x={x}")
+            self.logger.debug(f"y={y}")
+            raise ValueError()
 
         p = 0.5 * (
             B + np.sqrt(B**2 + 4 * A)
         )  # usually p ~= -0.0000 to -0.0100, but is a function of the temperature (Recall it describes the heat loss to ambient)
         q = 0.5 * (
             B - np.sqrt(B**2 + 4 * A)
         )  # usually q ~= -0.130 to -0.160, but is a not really a function of the temperature. Oddly enough, it looks periodic with freq ~1hr...
@@ -546,75 +534,27 @@
                 [exp((q + p) * x).sum(), exp(2 * q * x).sum()],
             ]
         )
         Y2 = np.array([(y * exp(p * x)).sum(), (y * exp(q * x)).sum()])
         try:
             b, c = np.linalg.solve(M2, Y2)
         except np.linalg.LinAlgError:
-            raise ValueError(f"Error in temperature inference. {x=}, {y=}")
+            self.logger.error("Error in temperature inference.")
+            self.logger.debug("Error in temperature inference's second regression.", exc_info=True)
+            self.logger.debug(f"x={x}")
+            self.logger.debug(f"y={y}")
+            raise ValueError()
 
         alpha, beta = b, p
 
         # this weighting is from evaluating the "average" temp over the period: 1/n int_0^n R + a*exp(b*s) ds
         # cast from numpy float to python float
         return float(room_temp + alpha * exp(beta * n))
         # return float(room_temp + alpha * (exp(beta * n) - 1)/(beta * n))
 
-    @staticmethod
-    def approximate_temperature_2_0(features: dict[str, Any]) -> float:
-        """
-        This uses linear regression from historical data
-        """
-        if features["previous_heater_dc"] == 0:
-            return features["time_series_of_temp"][-1]
-
-        X = features["time_series_of_temp"]
-
-        # normalize to ~1.0, as we do this in training.
-        X = [x / 35.0 for x in X]
-
-        # add in non-linear features
-        X.append(X[0] ** 2)
-        X.append(X[0] ** 0.5)
-
-        coefs = [
-            22.44950549,
-            -47.26707134,
-            -31.07494909,
-            -41.36629363,
-            -12.17348368,
-            55.03067504,
-            22.91692162,
-            35.96733783,
-            37.86185926,
-            49.00325047,
-            43.72159562,
-            47.12556322,
-            30.780167,
-            34.25574632,
-            21.12142635,
-            1.77795003,
-            -0.74499359,
-            -46.5411805,
-            -38.20418079,
-            -59.83658558,
-            -65.3550903,
-            -3.36141664,
-            -34.61894608,
-        ]
-
-        intercept = 13.358217809582857
-
-        def dot_product(vec1: list, vec2: list) -> float:
-            if len(vec1) != len(vec2):
-                raise ValueError(f"Vectors must be of the same length. Got {len(vec1)=}, {len(vec2)=}")
-            return sum(x * y for x, y in zip(vec1, vec2))
-
-        return dot_product(coefs, X) + intercept
-
 
 def start_temperature_control(
     automation_name: str,
     unit: Optional[str] = None,
     experiment: Optional[str] = None,
     **kwargs,
 ) -> TemperatureController:
```

## pioreactor/background_jobs/leader/mqtt_to_db_streaming.py

```diff
@@ -110,17 +110,17 @@
             if not message.payload:
                 # filter out empty payloads
                 return
 
             try:
                 new_rows = parser(message.topic, message.payload)
             except Exception as e:
-                self.logger.warning(f"Encountered error in saving to DB: {e}. See logs.")
+                self.logger.error(f"Encountered error in saving to DB: {e}. See logs.")
                 self.logger.debug(
-                    f"Error in {parser.__name__}. Payload that caused error: `{message.payload.decode()}`",
+                    f"Error in {parser.__name__}. message.payload that caused error: `{message.payload.decode()}`",
                     exc_info=True,
                 )
                 return
 
             if new_rows is None:
                 # parsers can return None to exit out.
                 return
@@ -132,15 +132,15 @@
                 cols_placeholder = ", ".join(new_row.keys())
                 values_placeholder = ", ".join(":" + c for c in new_row.keys())
                 SQL = f"""INSERT INTO {table} ({cols_placeholder}) VALUES ({values_placeholder})"""
 
                 try:
                     self.sqliteworker.execute(SQL, new_row)  # type: ignore
                 except Exception as e:
-                    self.logger.warning(e)
+                    self.logger.error(e)
                     self.logger.debug(f"SQL that caused error: `{SQL}`")
                     return
                 self._inserts_in_last_60s += 1
 
         return callback
 
     def initialize_callbacks(self, topics_and_callbacks: list[TopicToCallback]) -> None:
```

## pioreactor/background_jobs/leader/watchdog.py

```diff
@@ -74,15 +74,15 @@
                 f"pioreactor/{unit}/{UNIVERSAL_EXPERIMENT}/monitor/$state/set", self.SLEEPING
             )
             time.sleep(1)
             self.pub_client.publish(
                 f"pioreactor/{unit}/{UNIVERSAL_EXPERIMENT}/monitor/$state/set", self.READY
             )
             ###
-            time.sleep(10)
+            time.sleep(20)
 
             if self.state != self.READY:
                 # when the entire Rpi shuts down, ex via sudo reboot, monitor can publish a lost. This code will halt the shutdown.
                 # let's return early.
                 return
 
             msg = subscribe(  # I don't think this can be self.sub_client because we are in a callback.
```

## pioreactor/cli/pio.py

```diff
@@ -3,55 +3,43 @@
 cmd line interface for running individual pioreactor units (including leader)
 
 > pio run stirring --ignore-rpm
 > pio logs
 """
 from __future__ import annotations
 
+import subprocess
 from os import geteuid
 from shlex import quote
 from time import sleep
 from typing import Optional
 
 import click
 from msgspec.json import decode as loads
 from msgspec.json import encode as dumps
 
 import pioreactor
+from pioreactor import actions
+from pioreactor import background_jobs as jobs
 from pioreactor import config
 from pioreactor import exc
+from pioreactor import plugin_management
+from pioreactor import pubsub
 from pioreactor import whoami
-from pioreactor.cli.lazy_group import LazyGroup
 from pioreactor.logging import create_logger
 from pioreactor.mureq import get
 from pioreactor.mureq import HTTPException
 from pioreactor.utils import JobManager
 from pioreactor.utils import local_intermittent_storage
 from pioreactor.utils import local_persistant_storage
 from pioreactor.utils.networking import is_using_local_access_point
 from pioreactor.utils.timing import current_utc_timestamp
-from pioreactor.whoami import am_I_leader
 
-if am_I_leader():
-    lazy_subcommands = {
-        "run": "pioreactor.cli.run.run",
-        "workers": "pioreactor.cli.workers.workers",
-        "plugins": "pioreactor.cli.plugins.plugins",
-    }
-else:
-    lazy_subcommands = {
-        "run": "pioreactor.cli.run.run",
-    }
-
-
-@click.group(
-    cls=LazyGroup,
-    lazy_subcommands=lazy_subcommands,
-    invoke_without_command=True,
-)
+
+@click.group(invoke_without_command=True)
 @click.pass_context
 def pio(ctx) -> None:
     """
     Execute commands on this Pioreactor.
 
     Configuration available: /home/pioreactor/.pioreactor/config.ini
 
@@ -121,15 +109,15 @@
 
 @pio.command(name="log", short_help="logs a message from the CLI")
 @click.option("-m", "--message", required=True, type=str, help="the message to append to the log")
 @click.option(
     "-l",
     "--level",
     default="debug",
-    type=click.Choice(["debug", "info", "notice", "warning", "error", "critical"], case_sensitive=False),
+    type=click.Choice(["debug", "info", "notice", "warning", "critical"], case_sensitive=False),
 )
 @click.option(
     "-n",
     "--name",
     default="CLI",
     type=str,
 )
@@ -150,39 +138,41 @@
 
 
 @pio.command(name="blink", short_help="blink LED")
 def blink() -> None:
     """
     monitor job is required to be running.
     """
-    from pioreactor.pubsub import publish
-
-    publish(
+    pubsub.publish(
         f"pioreactor/{whoami.get_unit_name()}/{whoami.UNIVERSAL_EXPERIMENT}/monitor/flicker_led_response_okay",
         1,
     )
 
 
 @pio.command(name="kill", short_help="kill job(s)")
 @click.option("--name", type=click.STRING)
 @click.option("--experiment", type=click.STRING)
 @click.option("--job-source", type=click.STRING)
 @click.option("--all-jobs", is_flag=True, help="kill all Pioreactor jobs running")
 def kill(name: str | None, experiment: str | None, job_source: str | None, all_jobs: bool) -> None:
     """
     stop job(s).
     """
-    if not (name or experiment or job_source or all_jobs):
-        raise click.Abort("Provide an option to kill.")
     with JobManager() as jm:
         count = jm.count_jobs(all_jobs=all_jobs, name=name, experiment=experiment, job_source=job_source)
         jm.kill_jobs(all_jobs=all_jobs, name=name, experiment=experiment, job_source=job_source)
     click.echo(f"Killed {count} job(s).")
 
 
+@pio.group(short_help="run a job")
+@click.option("--source", "-s", default="user", help="source of command")
+def run(source) -> None:
+    pass
+
+
 @pio.command(name="version", short_help="print the Pioreactor software version")
 @click.option("--verbose", "-v", is_flag=True, help="show more system information")
 def version(verbose: bool) -> None:
     if verbose:
         import platform
         from pioreactor.version import hardware_version_info
         from pioreactor.version import software_version_info
@@ -287,26 +277,24 @@
     ----------
 
     > pio update-settings stirring --target_rpm 500
     > pio update-settings stirring --target-rpm 500
     > pio update-settings dosing_control --automation '{"type": "dosing", "automation_name": "silent", "args": {}}
 
     """
-    from pioreactor.pubsub import publish
-
     unit = whoami.get_unit_name()
     exp = whoami.get_assigned_experiment_name(unit)
 
     extra_args = {ctx.args[i][2:]: ctx.args[i + 1] for i in range(0, len(ctx.args), 2)}
 
     assert len(extra_args) > 0
 
     for setting, value in extra_args.items():
         setting = setting.replace("-", "_")
-        publish(f"pioreactor/{unit}/{exp}/{job}/{setting}/set", value)
+        pubsub.publish(f"pioreactor/{unit}/{exp}/{job}/{setting}/set", value, qos=pubsub.QOS.EXACTLY_ONCE)
 
 
 @pio.group()
 def update() -> None:
     """
     update software for the app and UI
     """
@@ -392,50 +380,43 @@
     repo: str,
     source: Optional[str],
     version: Optional[str],
 ) -> None:
     """
     Update the Pioreactor core software
     """
-    import subprocess
-
     logger = create_logger("update-app", unit=whoami.get_unit_name(), experiment=whoami.UNIVERSAL_EXPERIMENT)
 
     commands_and_priority: list[tuple[str, float]] = []
 
     if source is not None:
         source = quote(source)
         import re
         import tempfile
 
         if re.search(r"release_\d{0,2}\.\d{0,2}\.\d{0,2}\w{0,6}\.zip$", source):
             # provided a release archive
             version_installed = re.search(r"release_(.*).zip$", source).groups()[0]  # type: ignore
             tmp_dir = tempfile.gettempdir()
-            tmp_rlse_dir = f"{tmp_dir}/release_{version_installed}"
+            tmp_release_folder = f"{tmp_dir}/release_{version_installed}"
             # fmt: off
             commands_and_priority.extend(
                 [
-                    (f"rm -rf {tmp_rlse_dir}", -99),
-                    (f"unzip {source} -d {tmp_rlse_dir}", 0),
-                    (f"unzip {tmp_rlse_dir}/wheels_{version_installed}.zip -d {tmp_rlse_dir}/wheels", 1),
-                    (f"sudo bash {tmp_rlse_dir}/pre_update.sh", 2),
-                    (f"sudo pip install --no-index --find-links={tmp_rlse_dir}/wheels/ {tmp_rlse_dir}/pioreactor-{version_installed}-py3-none-any.whl", 3),
-                    (f"sudo bash {tmp_rlse_dir}/update.sh", 4),
-                    (f"sudo bash {tmp_rlse_dir}/post_update.sh", 20),
-                    (f"rm -rf {tmp_rlse_dir}", 99),
+                    (f"rm -rf {tmp_release_folder}", -3),
+                    (f"unzip {source} -d {tmp_release_folder}", -2),
+                    (f"unzip {tmp_release_folder}/wheels_{version_installed}.zip -d {tmp_release_folder}/wheels", 0),
+                    (f"mv {tmp_release_folder}/pioreactorui_*.tar.gz {tmp_dir}/pioreactorui_archive || :", 0.5),  # move ui folder to be accessed by a `pio update ui`
+                    (f"sudo bash {tmp_release_folder}/pre_update.sh || :", 1),
+                    (f"sudo pip install --no-index --find-links={tmp_release_folder}/wheels/ {tmp_release_folder}/pioreactor-{version_installed}-py3-none-any.whl", 2),
+                    (f"sudo bash {tmp_release_folder}/update.sh || :", 3),
+                    (f'sudo sqlite3 {config.config["storage"]["database"]} < {tmp_release_folder}/update.sql || :', 4),
+                    (f"sudo bash {tmp_release_folder}/post_update.sh || :", 5),
+                    (f"rm -rf {tmp_release_folder}", 6),
                 ]
             )
-
-            if whoami.am_I_leader():
-                commands_and_priority.extend([
-                    (f"mv {tmp_rlse_dir}/pioreactorui_*.tar.gz {tmp_dir}/pioreactorui_archive", 98),  # move ui folder to be accessed by a `pio update ui`
-                    (f'sudo sqlite3 {config.config["storage"]["database"]} < {tmp_rlse_dir}/update.sql', 10)
-                ])
-
             # fmt: on
         elif source.endswith(".whl"):
             # provided a whl
             version_installed = source
             commands_and_priority.append((f"sudo pip3 install --force-reinstall --no-index {source}", 1))
         else:
             click.echo("Not a valid source file. Should be either a whl or release archive.")
@@ -497,22 +478,19 @@
             elif asset_name == "update.sh":
                 commands_and_priority.extend(
                     [
                         (f"wget -O /tmp/update.sh {url}", 3),
                         ("sudo bash /tmp/update.sh", 4),
                     ]
                 )
-            elif asset_name == "update.sql" and whoami.am_I_leader():
+            elif asset_name == "update.sql":
                 commands_and_priority.extend(
                     [
                         (f"wget -O /tmp/update.sql {url}", 5),
-                        (
-                            f'sudo sqlite3 {config.config["storage"]["database"]} < /tmp/update.sql || :',
-                            6,
-                        ),  # or True at the end, since this may run on workers, that's okay.
+                        (f'sudo sqlite3 {config.config["storage"]["database"]} < /tmp/update.sql', 6),
                     ]
                 )
             elif asset_name == "post_update.sh":
                 commands_and_priority.extend(
                     [
                         (f"wget -O /tmp/post_update.sh {url}", 99),
                         ("sudo bash /tmp/post_update.sh", 100),
@@ -536,32 +514,28 @@
             # end early
             raise click.Abort()
         else:
             logger.debug(p.stdout)
 
     logger.notice(f"Updated {whoami.get_unit_name()} to version {version_installed}.")  # type: ignore
     # everything work? Let's publish to MQTT. This is a terrible hack, as monitor should do this.
-    from pioreactor.pubsub import publish
-
-    publish(
+    pubsub.publish(
         f"pioreactor/{whoami.get_unit_name()}/{whoami.UNIVERSAL_EXPERIMENT}/monitor/versions/set",
         dumps({"app": version_installed, "timestamp": current_utc_timestamp()}),
     )
 
 
 @update.command(name="firmware")
 @click.option("-v", "--version", help="install a specific version, default is latest")
 def update_firmware(version: Optional[str]) -> None:
     """
     Update the RP2040 firmware.
 
     # TODO: this needs accept a --source arg
     """
-    import subprocess
-
     logger = create_logger("update-app", unit=whoami.get_unit_name(), experiment=whoami.UNIVERSAL_EXPERIMENT)
     commands_and_priority: list[tuple[str, int]] = []
 
     if version is None:
         version = "latest"
     else:
         version = quote(version)
@@ -598,15 +572,72 @@
             logger.error("Update failed. See logs.")
             # end early
             raise click.Abort()
 
     logger.notice(f"Updated Pioreactor firmware to version {version_installed}.")  # type: ignore
 
 
+pio.add_command(plugin_management.click_install_plugin)
+pio.add_command(plugin_management.click_uninstall_plugin)
+pio.add_command(plugin_management.click_list_plugins)
+
+# this runs on both leader and workers
+run.add_command(jobs.monitor.click_monitor)
+
+
+run.add_command(jobs.growth_rate_calculating.click_growth_rate_calculating)
+run.add_command(jobs.stirring.click_stirring)
+run.add_command(jobs.od_reading.click_od_reading)
+run.add_command(jobs.dosing_control.click_dosing_control)
+run.add_command(jobs.led_control.click_led_control)
+run.add_command(jobs.temperature_control.click_temperature_control)
+
+run.add_command(actions.led_intensity.click_led_intensity)
+run.add_command(actions.pump.click_add_alt_media)
+run.add_command(actions.pump.click_add_media)
+run.add_command(actions.pump.click_remove_waste)
+run.add_command(actions.od_blank.click_od_blank)
+run.add_command(actions.self_test.click_self_test)
+run.add_command(actions.stirring_calibration.click_stirring_calibration)
+run.add_command(actions.pump_calibration.click_pump_calibration)
+run.add_command(actions.od_calibration.click_od_calibration)
+
+# TODO: this only adds to `pio run` - what if users want to add a high level command? Examples?
+for plugin in pioreactor.plugin_management.get_plugins().values():
+    for possible_entry_point in dir(plugin.module):
+        if possible_entry_point.startswith("click_"):
+            run.add_command(getattr(plugin.module, possible_entry_point))
+
+
 if whoami.am_I_leader():
+    from pioreactor.cluster_management import add_worker
+    from pioreactor.cluster_management import remove_worker
+    from pioreactor.cluster_management import assign_worker_to_experiment
+    from pioreactor.cluster_management import unassign_worker_from_experiment
+    from pioreactor.cluster_management import update_active
+    from pioreactor.cluster_management import discover_workers
+    from pioreactor.cluster_management import cluster_status
+
+    run.add_command(jobs.mqtt_to_db_streaming.click_mqtt_to_db_streaming)
+    run.add_command(jobs.watchdog.click_watchdog)
+    run.add_command(actions.export_experiment_data.click_export_experiment_data)
+    run.add_command(actions.backup_database.click_backup_database)
+    run.add_command(actions.experiment_profile.click_experiment_profile)
+
+    @pio.group(short_help="manage workers")
+    def workers():
+        pass
+
+    workers.add_command(add_worker)
+    workers.add_command(remove_worker)
+    workers.add_command(assign_worker_to_experiment)
+    workers.add_command(unassign_worker_from_experiment)
+    workers.add_command(update_active)
+    workers.add_command(discover_workers)
+    workers.add_command(cluster_status)
 
     @pio.command(short_help="access the db CLI")
     def db() -> None:
         import os
 
         os.system(f"sqlite3 {config.config['storage']['database']} -column -header")
 
@@ -630,16 +661,14 @@
     def update_ui(branch: Optional[str], repo: str, source: Optional[str], version: Optional[str]) -> None:
         """
         Update the PioreactorUI
 
         Source, if provided, should be a .tar.gz with a top-level dir like pioreactorui-{version}/
         This is what is provided from Github releases.
         """
-        import subprocess
-
         logger = create_logger(
             "update-ui", unit=whoami.get_unit_name(), experiment=whoami.UNIVERSAL_EXPERIMENT
         )
         commands = []
 
         if version is None:
             version = "latest"
```

## pioreactor/cli/pios.py

```diff
@@ -1,54 +1,52 @@
 # -*- coding: utf-8 -*-
 """
 CLI for running the commands on workers, or otherwise interacting with the workers.
 
 general API:
 
- - All `pios` commands should have a -y to confirm the execution.
+ - All `pios` commands should have a -y to confirm the execution. (there are exceptions for no good reason)
+
 
 """
 from __future__ import annotations
 
 from concurrent.futures import ThreadPoolExecutor
+from typing import Optional
 
 import click
 
 from pioreactor.cluster_management import get_active_workers_in_inventory
 from pioreactor.cluster_management import get_workers_in_inventory
 from pioreactor.config import config
 from pioreactor.config import get_leader_hostname
 from pioreactor.logging import create_logger
+from pioreactor.pubsub import create_client
 from pioreactor.utils import ClusterJobManager
 from pioreactor.utils.networking import add_local
 from pioreactor.utils.networking import cp_file_across_cluster
 from pioreactor.utils.timing import current_utc_timestamp
 from pioreactor.whoami import am_I_leader
 from pioreactor.whoami import get_assigned_experiment_name
 from pioreactor.whoami import get_unit_name
+from pioreactor.whoami import is_testing_env
 from pioreactor.whoami import UNIVERSAL_EXPERIMENT
 from pioreactor.whoami import UNIVERSAL_IDENTIFIER
 
 
-@click.group(invoke_without_command=True)
-@click.pass_context
-def pios(ctx) -> None:
+@click.group()
+def pios() -> None:
     """
     Command each of the worker Pioreactors with the `pios` command.
 
     See full documentation here: https://docs.pioreactor.com/user-guide/cli#leader-only-commands-to-control-workers
 
     Report errors or feedback here: https://github.com/Pioreactor/pioreactor/issues
     """
-
-    if ctx.invoked_subcommand is None:
-        click.echo(ctx.get_help())
-
-    # this is run even if workers run `pios plugins etc.`
-    if not am_I_leader():
+    if not am_I_leader() and not is_testing_env():
         click.echo("workers cannot run `pios` commands. Try `pio` instead.", err=True)
         raise click.Abort()
 
 
 if am_I_leader():
 
     def universal_identifier_to_all_active_workers(units: tuple[str, ...]) -> tuple[str, ...]:
@@ -147,15 +145,15 @@
             if confirm != "Y":
                 raise click.Abort()
 
         logger = create_logger("cp", unit=get_unit_name(), experiment=UNIVERSAL_EXPERIMENT)
         units = remove_leader(universal_identifier_to_all_workers(units))
 
         def _thread_function(unit: str) -> bool:
-            logger.debug(f"Copying {filepath} to {unit}:{filepath}...")
+            logger.debug(f"Moving {filepath} to {unit}:{filepath}...")
             try:
                 cp_file_across_cluster(unit, filepath, filepath, timeout=30)
                 return True
             except Exception as e:
                 logger.error(f"Error occurred: {e}. See logs for more.")
                 logger.debug(f"Error occurred: {e}.", exc_info=True)
                 return False
@@ -224,28 +222,30 @@
         help="install from a repo on github. Format: username/project",
     )
     @click.option("-v", "--version", help="install a specific version, default is latest")
     @click.option("--source", help="install from a source, whl or release archive")
     @click.option("-y", is_flag=True, help="Skip asking for confirmation.")
     def update(
         units: tuple[str, ...],
-        branch: str | None,
-        repo: str | None,
-        version: str | None,
-        source: str | None,
+        branch: Optional[str],
+        repo: Optional[str],
+        version: Optional[str],
+        source: Optional[str],
         y: bool,
     ) -> None:
         """
         Pulls and installs a Pioreactor software version across the cluster
         """
         from sh import ssh  # type: ignore
         from sh import ErrorReturnCode_255  # type: ignore
         from sh import ErrorReturnCode_1
         from shlex import join
 
+        # type: ignore
+
         logger = create_logger("update", unit=get_unit_name(), experiment=UNIVERSAL_EXPERIMENT)
         if version is not None:
             commands = ["pio", "update", "app", "-v", version]
         elif branch is not None:
             commands = ["pio", "update", "app", "-b", branch]
         elif source is not None:
             commands = ["pio", "update", "app", "--source", source]
@@ -280,46 +280,34 @@
 
         with ThreadPoolExecutor(max_workers=len(units)) as executor:
             results = executor.map(_thread_function, units)
 
         if not all(results):
             raise click.Abort()
 
-    @pios.group()
-    def plugins():
-        pass
-
-    @plugins.command("install", short_help="install a plugin on workers")
+    @pios.command("install-plugin", short_help="install a plugin on workers")
     @click.argument("plugin")
     @click.option(
         "--units",
         multiple=True,
         default=(UNIVERSAL_IDENTIFIER,),
         type=click.STRING,
         help="specify a Pioreactor name, default is all active units",
     )
-    @click.option("-y", is_flag=True, help="skip asking for confirmation")
-    def install_plugin(plugin: str, units: tuple[str, ...], y: bool) -> None:
+    def install_plugin(plugin: str, units: tuple[str, ...]) -> None:
         """
         Installs a plugin to worker and leader
         """
         from sh import ssh  # type: ignore
         from sh import ErrorReturnCode_255  # type: ignore
         from sh import ErrorReturnCode_1  # type: ignore
-        from shlex import quote
 
         logger = create_logger("install_plugin", unit=get_unit_name(), experiment=UNIVERSAL_EXPERIMENT)
 
-        command = f"pio plugins install {quote(plugin)}"
-        units = add_leader(universal_identifier_to_all_workers(units))
-
-        if not y:
-            confirm = input(f"Confirm installing {quote(plugin)} on {units}? Y/n: ").strip()
-            if confirm != "Y":
-                raise click.Abort()
+        command = f"pio install-plugin {plugin}"
 
         def _thread_function(unit: str):
             logger.debug(f"Executing `{command}` on {unit}...")
             try:
                 ssh(add_local(unit), command)
                 return True
             except ErrorReturnCode_255 as e:
@@ -327,49 +315,42 @@
                 logger.debug(e, exc_info=True)
                 return False
             except ErrorReturnCode_1 as e:
                 logger.error(f"Error occurred: {e}. See logs for more.")
                 logger.debug(e.stderr, exc_info=True)
                 return False
 
+        units = add_leader(universal_identifier_to_all_workers(units))
         with ThreadPoolExecutor(max_workers=len(units)) as executor:
             results = executor.map(_thread_function, units)
 
         if not all(results):
             raise click.Abort()
 
-    @plugins.command("uninstall", short_help="uninstall a plugin on workers")
+    @pios.command("uninstall-plugin", short_help="uninstall a plugin on workers")
     @click.argument("plugin")
     @click.option(
         "--units",
         multiple=True,
         default=(UNIVERSAL_IDENTIFIER,),
         type=click.STRING,
         help="specify a Pioreactor name, default is all active units",
     )
-    @click.option("-y", is_flag=True, help="skip asking for confirmation")
-    def uninstall_plugin(plugin: str, units: tuple[str, ...], y: bool) -> None:
+    def uninstall_plugin(plugin: str, units: tuple[str, ...]) -> None:
         """
         Uninstalls a plugin from worker and leader
         """
 
         from sh import ssh  # type: ignore
         from sh import ErrorReturnCode_255  # type: ignore
         from sh import ErrorReturnCode_1  # type: ignore
-        from shlex import quote
 
         logger = create_logger("uninstall_plugin", unit=get_unit_name(), experiment=UNIVERSAL_EXPERIMENT)
 
-        command = f"pio plugin uninstall {quote(plugin)}"
-        units = add_leader(universal_identifier_to_all_workers(units))
-
-        if not y:
-            confirm = input(f"Confirm uninstalling {quote(plugin)} on {units}? Y/n: ").strip()
-            if confirm != "Y":
-                raise click.Abort()
+        command = f"pio uninstall-plugin {plugin}"
 
         def _thread_function(unit: str):
             logger.debug(f"Executing `{command}` on {unit}...")
             try:
                 ssh(add_local(unit), command)
                 return True
             except ErrorReturnCode_255 as e:
@@ -377,14 +358,15 @@
                 logger.debug(e, exc_info=True)
                 return False
             except ErrorReturnCode_1 as e:
                 logger.error(f"Error occurred: {e}. See logs for more.")
                 logger.debug(e.stderr, exc_info=True)
                 return False
 
+        units = add_leader(universal_identifier_to_all_workers(units))
         with ThreadPoolExecutor(max_workers=len(units)) as executor:
             results = executor.map(_thread_function, units)
 
         if not all(results):
             raise click.Abort()
 
     @pios.command(name="sync-configs", short_help="sync config")
@@ -406,16 +388,15 @@
         help="sync the worker specific config.ini(s)",
     )
     @click.option(
         "--skip-save",
         is_flag=True,
         help="don't save to db",
     )
-    @click.option("-y", is_flag=True, help="(does nothing currently)")
-    def sync_configs(units: tuple[str, ...], shared: bool, specific: bool, skip_save: bool, y: bool) -> None:
+    def sync_configs(units: tuple[str, ...], shared: bool, specific: bool, skip_save: bool) -> None:
         """
         Deploys the shared config.ini and worker specific config.inis to the workers.
 
         If neither `--shared` not `--specific` are specified, both are set to true.
         """
         logger = create_logger("sync_configs", unit=get_unit_name(), experiment=UNIVERSAL_EXPERIMENT)
         units = universal_identifier_to_all_workers(units)
@@ -700,21 +681,20 @@
         help="specify a hostname, default is all active units",
     )
     @click.option("-y", is_flag=True, help="Skip asking for confirmation.")
     @click.pass_context
     def update_settings(ctx, job: str, units: tuple[str, ...], y: bool) -> None:
         """
 
-        Examples:
-
+        Examples
+        ---------
         > pios update-settings stirring --target_rpm 500 --units worker1
         > pios update-settings dosing_control --automation '{"type": "dosing", "automation_name": "silent", "args": {}}
 
         """
-        from pioreactor.pubsub import create_client
 
         extra_args = {ctx.args[i][2:]: ctx.args[i + 1] for i in range(0, len(ctx.args), 2)}
 
         assert len(extra_args) > 0
 
         if not y:
             confirm = input(f"Confirm updating {job}'s {extra_args} on {units}? Y/n: ").strip()
@@ -723,13 +703,12 @@
 
         units = universal_identifier_to_all_active_workers(units)
 
         with create_client() as client:
             for unit in units:
                 experiment = get_assigned_experiment_name(unit)
                 for setting, value in extra_args.items():
-                    setting = setting.replace("-", "_")
                     client.publish(f"pioreactor/{unit}/{experiment}/{job}/{setting}/set", value)
 
 
 if __name__ == "__main__":
     pios()
```

## pioreactor/cluster_management/__init__.py

```diff
@@ -5,53 +5,52 @@
 from concurrent.futures import ThreadPoolExecutor
 from time import sleep
 
 import click
 from msgspec.json import decode as loads
 from msgspec.json import encode as dumps
 
+from pioreactor import config
+from pioreactor import pubsub
 from pioreactor import whoami
-from pioreactor.config import leader_address
 from pioreactor.exc import BashScriptError
 from pioreactor.logging import create_logger
 from pioreactor.mureq import delete
 from pioreactor.mureq import get
 from pioreactor.mureq import HTTPErrorStatus
 from pioreactor.mureq import HTTPException
 from pioreactor.mureq import put
 from pioreactor.utils import networking
 from pioreactor.utils.timing import catchtime
 
 
 def get_workers_in_inventory() -> tuple[str, ...]:
-    result = get(f"http://{leader_address}/api/workers")
+    result = get(f"http://{config.leader_address}/api/workers")
     return tuple(worker["pioreactor_unit"] for worker in result.json())
 
 
 def get_active_workers_in_inventory() -> tuple[str, ...]:
-    result = get(f"http://{leader_address}/api/workers")
+    result = get(f"http://{config.leader_address}/api/workers")
     return tuple(worker["pioreactor_unit"] for worker in result.json() if bool(worker["is_active"]))
 
 
 def get_workers_in_experiment(experiment: str) -> tuple[str, ...]:
-    result = get(f"http://{leader_address}/api/experiments/{experiment}/workers")
+    result = get(f"http://{config.leader_address}/api/experiments/{experiment}/workers")
     return tuple(worker["pioreactor_unit"] for worker in result.json())
 
 
 def get_active_workers_in_experiment(experiment: str) -> tuple[str, ...]:
-    result = get(f"http://{leader_address}/api/experiments/{experiment}/workers")
+    result = get(f"http://{config.leader_address}/api/experiments/{experiment}/workers")
     return tuple(worker["pioreactor_unit"] for worker in result.json() if bool(worker["is_active"]))
 
 
 @click.command(name="add", short_help="add a pioreactor worker")
 @click.argument("hostname")
 @click.option("--password", "-p", default="raspberry")
-@click.option("--version", "-v", default="1.1")
-@click.option("--model", "-m", default="pioreactor_20ml")
-def add_worker(hostname: str, password: str, version: str, model: str) -> None:
+def add_worker(hostname: str, password: str) -> None:
     """
     Add a new pioreactor worker to the cluster. The pioreactor should already have the worker image installed and is turned on.
     """
 
     import socket
 
     logger = create_logger(
@@ -60,16 +59,14 @@
         experiment=whoami.UNIVERSAL_EXPERIMENT,
     )
     logger.info(f"Adding new pioreactor {hostname} to cluster.")
 
     hostname = hostname.removesuffix(".local")
     hostname_dot_local = hostname + ".local"
 
-    assert model == "pioreactor_20ml"
-
     # check to make sure <hostname>.local is on network
     checks, max_checks = 0, 15
     sleep_time = 3
 
     if not whoami.is_testing_env():
         with catchtime() as elapsed:
             while not networking.is_hostname_on_network(hostname_dot_local):
@@ -82,32 +79,25 @@
                     if checks >= max_checks:
                         logger.error(
                             f"`{hostname}` not found on network after {round(elapsed())} seconds. Check that you provided the right i) WiFi credentials to the network, ii) the hostname is correct, the iii) worker is turned on."
                         )
                         raise click.Abort()
 
         res = subprocess.run(
-            [
-                "bash",
-                "/usr/local/bin/add_new_pioreactor_worker_from_leader.sh",
-                hostname,
-                password,
-                version,
-                model,
-            ],
+            ["bash", "/usr/local/bin/add_new_pioreactor_worker_from_leader.sh", hostname, password],
             capture_output=True,
             text=True,
         )
         if res.returncode > 0:
             logger.error(res.stderr)
             raise BashScriptError(res.stderr)
 
     try:
         result = put(
-            f"http://{leader_address}/api/workers",
+            f"http://{config.leader_address}/api/workers",
             dumps({"pioreactor_unit": hostname}),
             headers={"Content-Type": "application/json"},
         )
         result.raise_for_status()
     except HTTPErrorStatus:
         logger.error("Did not add Pioreactor to backend")
         raise HTTPException("Did not add Pioreactor to backend")
@@ -118,15 +108,15 @@
     logger.notice(f"New pioreactor {hostname} successfully added to cluster.")  # type: ignore
 
 
 @click.command(name="remove", short_help="remove a pioreactor worker")
 @click.argument("hostname")
 def remove_worker(hostname: str) -> None:
     try:
-        r = delete(f"http://{leader_address}/api/workers/{hostname}")
+        r = delete(f"http://{config.leader_address}/api/workers/{hostname}")
         r.raise_for_status()
     except HTTPErrorStatus:
         click.echo(f"Worker {hostname} not present to be removed. Check hostname.")
         click.Abort()
     except HTTPException:
         click.echo("Not able to connect to leader's backend.")
         click.Abort()
@@ -136,15 +126,15 @@
 
 @click.command(name="assign", short_help="assign a pioreactor worker")
 @click.argument("hostname")
 @click.argument("experiment")
 def assign_worker_to_experiment(hostname: str, experiment: str) -> None:
     try:
         r = put(
-            f"http://{leader_address}/api/experiments/{experiment}/workers",
+            f"http://{config.leader_address}/api/experiments/{experiment}/workers",
             json={"pioreactor_unit": hostname},
         )
         r.raise_for_status()
     except HTTPErrorStatus:
         click.echo("Not valid data. Check hostname or experiment.")
         click.Abort()
     except HTTPException:
@@ -156,15 +146,15 @@
 
 @click.command(name="unassign", short_help="unassign a pioreactor worker")
 @click.argument("hostname")
 @click.argument("experiment")
 def unassign_worker_from_experiment(hostname: str, experiment: str) -> None:
     try:
         r = delete(
-            f"http://{leader_address}/api/experiments/{experiment}/workers/{hostname}",
+            f"http://{config.leader_address}/api/experiments/{experiment}/workers/{hostname}",
         )
         r.raise_for_status()
     except HTTPErrorStatus:
         click.echo("Error")
         click.Abort()
     except HTTPException:
         click.echo("Not able to connect to leader's backend.")
@@ -175,15 +165,15 @@
 
 @click.command(name="update-active", short_help="change active of worker")
 @click.argument("hostname")
 @click.argument("active", type=int)
 def update_active(hostname: str, active: int) -> None:
     try:
         r = delete(
-            f"http://{leader_address}/api//workers/{hostname}/is_active",
+            f"http://{config.leader_address}/api//workers/{hostname}/is_active",
             json={"is_active": active},
         )
         r.raise_for_status()
     except HTTPException:
         click.echo("Not able to connect to leader's backend.")
         click.Abort()
     else:
@@ -209,15 +199,14 @@
 
 @click.command(name="status", short_help="report information on the cluster")
 def cluster_status() -> None:
     """
     Note that this only looks at the current cluster as defined in config.ini.
     """
     import socket
-    from pioreactor import pubsub
 
     def get_metadata(hostname):
         # get ip
         if whoami.get_unit_name() == hostname:
             ip = networking.get_ip()
         else:
             try:
@@ -248,42 +237,42 @@
             app_version = "unknown"
 
         # is reachable?
         reachable = networking.is_reachable(networking.add_local(hostname))
 
         # get experiment
         try:
-            result = get(f"http://{leader_address}/api/workers/{hostname}/experiment")
+            result = get(f"http://{config.leader_address}/api/workers/{hostname}/experiment")
             experiment = result.json()["experiment"]
         except Exception:
             experiment = ""
 
         return ip, state, reachable, app_version, experiment
 
     def display_data_for(worker: dict[str, str]) -> bool:
         hostname, is_active = worker["pioreactor_unit"], worker["is_active"]
 
         ip, state, reachable, version, experiment = get_metadata(hostname)
 
         statef = click.style(f"{state:15s}", fg="green" if state in ("ready", "init") else "red")
         ipf = f"{ip if (ip is not None) else 'unknown':20s}"
 
-        is_leaderf = f"{('Y' if hostname==leader_address else 'N'):15s}"
+        is_leaderf = f"{('Y' if hostname==config.get_leader_hostname() else 'N'):15s}"
         hostnamef = f"{hostname:20s}"
         reachablef = f"{(click.style('Y', fg='green') if reachable else click.style('N', fg='red')):23s}"
         versionf = f"{version:15s}"
         is_activef = f"{(click.style('Y', fg='green') if is_active else click.style('N', fg='red')):24s}"
         experimentf = f"{experiment:15s}"
 
         click.echo(
             f"{hostnamef} {is_leaderf} {ipf} {statef} {is_activef} {reachablef} {versionf} {experimentf}"
         )
         return reachable & (state == "ready")
 
-    workers = get(f"http://{leader_address}/api/workers").json()
+    workers = get(f"http://{config.leader_address}/api/workers").json()
     n_workers = len(workers)
 
     click.secho(
         f"{'Unit / hostname':20s} {'Is leader?':15s} {'IP address':20s} {'State':15s} {'Active?':15s} {'Reachable?':14s} {'Version':15s} {'Experiment':15s}",
         bold=True,
     )
     if n_workers == 0:
```

## pioreactor/plugin_management/install_plugin.py

```diff
@@ -29,15 +29,15 @@
     else:
         logger.error(f"Failed to install plugin {name_of_plugin}. See logs.")
         logger.debug(result.stdout)
         logger.debug(result.stderr)
         raise BashScriptError(f"Failed to install plugin {name_of_plugin}. See logs.")
 
 
-@click.command(name="install", short_help="install a plugin")
+@click.command(name="install-plugin", short_help="install a plugin")
 @click.argument("name-of-plugin")
 @click.option(
     "--source",
     type=str,
     help="Install from a url, ex: https://github.com/user/repository/archive/branch.zip, or wheel file",
 )
 def click_install_plugin(name_of_plugin: str, source: str | None):
```

## pioreactor/plugin_management/list_plugins.py

```diff
@@ -2,15 +2,15 @@
 from __future__ import annotations
 
 from json import dumps
 
 import click
 
 
-@click.command(name="list", short_help="list the installed plugins")
+@click.command(name="list-plugins", short_help="list the installed plugins")
 @click.option("--json", is_flag=True, help="output as json")
 def click_list_plugins(json: bool) -> None:
     from pioreactor.plugin_management import get_plugins
 
     if not json:
         for plugin, metadata in get_plugins().items():
             click.echo(f"{plugin}=={metadata.version}")
@@ -18,15 +18,17 @@
     else:
         click.echo(
             dumps(
                 [
                     {
                         "name": plugin,
                         "version": metadata.version,
-                        "description": metadata.description if metadata.description != "UNKNOWN" else None,
+                        "description": metadata.description
+                        if metadata.description != "UNKNOWN"
+                        else None,
                         "homepage": metadata.homepage if metadata.homepage != "UNKNOWN" else None,
                         "source": metadata.source,
                         "author": metadata.author if metadata.author != "UNKNOWN" else None,
                     }
                     for plugin, metadata in get_plugins().items()
                 ]
             )
```

## pioreactor/plugin_management/uninstall_plugin.py

```diff
@@ -40,11 +40,11 @@
         logger.debug(result.stdout)
         logger.debug(result.stderr)
         raise BashScriptError(f"Failed to uninstall plugin {name_of_plugin}. See logs.")
 
     return
 
 
-@click.command(name="uninstall", short_help="uninstall an existing plugin")
+@click.command(name="uninstall-plugin", short_help="uninstall an existing plugin")
 @click.argument("name-of-plugin")
 def click_uninstall_plugin(name_of_plugin: str) -> None:
     uninstall_plugin(name_of_plugin)
```

## pioreactor/utils/__init__.py

```diff
@@ -13,28 +13,29 @@
 from threading import Event
 from typing import Any
 from typing import Callable
 from typing import cast
 from typing import Generator
 from typing import overload
 from typing import Sequence
-from typing import TYPE_CHECKING
 
 from diskcache import Cache  # type: ignore
 
 from pioreactor import structs
 from pioreactor import types as pt
 from pioreactor import whoami
 from pioreactor.exc import NotActiveWorkerError
 from pioreactor.exc import RoleError
+from pioreactor.pubsub import Client
+from pioreactor.pubsub import create_client
+from pioreactor.pubsub import QOS
+from pioreactor.pubsub import subscribe_and_callback
 from pioreactor.utils.networking import add_local
 from pioreactor.utils.timing import current_utc_timestamp
 
-if TYPE_CHECKING:
-    from pioreactor.pubsub import Client
 
 JobMetadataKey = int
 
 
 class callable_stack:
     """
     A class for managing a stack of callable objects in Python.
@@ -141,31 +142,29 @@
         mqtt_client: Client | None = None,
         exit_on_mqtt_disconnect: bool = False,
         mqtt_client_kwargs: dict | None = None,
         ignore_is_active_state=False,  # hack and kinda gross
         source: str = "app",
         job_source: str | None = None,
     ) -> None:
-        from pioreactor.pubsub import create_client
-
         if not ignore_is_active_state and not whoami.is_active(unit):
             raise NotActiveWorkerError(f"{unit} is not active.")
 
         self.unit = unit
         self.experiment = experiment
         self.name = name
         self.state = "init"
         self.exit_event = Event()
         self._source = source
         self._job_source = job_source or os.environ.get("JOB_SOURCE") or "user"
 
         last_will = {
             "topic": f"pioreactor/{self.unit}/{self.experiment}/{self.name}/$state",
             "payload": b"lost",
-            "qos": 2,
+            "qos": QOS.EXACTLY_ONCE,
             "retain": True,
         }
 
         default_mqtt_client_kwargs = {
             "keepalive": 5 * 60,
             "client_id": f"{self.name}-{self.unit}-{self.experiment}",
         }
@@ -198,15 +197,15 @@
         except ValueError:
             pass
 
         self.state = "ready"
         self.mqtt_client.publish(
             f"pioreactor/{self.unit}/{self.experiment}/{self.name}/$state",
             self.state,
-            qos=1,
+            qos=QOS.AT_LEAST_ONCE,
             retain=True,
         )
 
         with JobManager() as jm:
             self._jm_key = jm.register_and_set_running(
                 self.unit, self.experiment, self.name, self._job_source, getpid(), ""
             )
@@ -214,15 +213,15 @@
         return self
 
     def __exit__(self, *args) -> None:
         self.state = "disconnected"
         self.mqtt_client.publish(
             f"pioreactor/{self.unit}/{self.experiment}/{self.name}/$state",
             b"disconnected",
-            qos=1,
+            qos=QOS.AT_LEAST_ONCE,
             retain=True,
         )
         if not self._externally_provided_client:
             self.mqtt_client.loop_stop()
             self.mqtt_client.disconnect()
 
         with JobManager() as jm:
@@ -231,16 +230,14 @@
         return
 
     def exit_from_mqtt(self, message: pt.MQTTMessage) -> None:
         if message.payload == b"disconnected":
             self._exit()
 
     def start_passive_listeners(self) -> None:
-        from pioreactor.pubsub import subscribe_and_callback
-
         subscribe_and_callback(
             self.exit_from_mqtt,
             [
                 f"pioreactor/{self.unit}/{self.experiment}/{self.name}/$state/set",
                 f"pioreactor/{whoami.UNIVERSAL_IDENTIFIER}/{self.experiment}/{self.name}/$state/set",
                 f"pioreactor/{whoami.UNIVERSAL_IDENTIFIER}/{whoami.UNIVERSAL_EXPERIMENT}/{self.name}/$state/set",
                 f"pioreactor/{self.unit}/{whoami.UNIVERSAL_EXPERIMENT}/{self.name}/$state/set",
@@ -499,26 +496,24 @@
     def __init__(self):
         self.list_of_job_names = []
 
     def append(self, name):
         self.list_of_job_names.append(name)
 
     def kill(self):
-        from pioreactor.pubsub import create_client
-
         with create_client() as client:
             for i, name in enumerate(self.list_of_job_names):
                 msg = client.publish(
                     f"pioreactor/{whoami.get_unit_name()}/{whoami.UNIVERSAL_EXPERIMENT}/{name}/$state/set",
                     "disconnected",
-                    qos=1,
+                    qos=QOS.AT_LEAST_ONCE,
                 )
 
                 if (i + 1) == len(self.list_of_job_names):
-                    # last one
+                    # list one
                     msg.wait_for_publish(2)
 
 
 class JobManager:
     AUTOMATION_JOBS = ("temperature_automation", "dosing_automation", "led_automation")
     PUMPING_JOBS = (
         "add_media",
@@ -586,15 +581,15 @@
     def _get_jobs(self, all_jobs: bool = False, **query) -> list[tuple[str, int]]:
         if not all_jobs:
             # Construct the WHERE clause based on the query parameters
             where_clause = " AND ".join([f"{key} = :{key}" for key in query.keys() if query[key] is not None])
 
             # Construct the SELECT query
             select_query = f"""
-                SELECT
+            SELECT
                     name, pid
                 FROM pio_job_metadata
                 WHERE is_running=1
                 AND name NOT IN {self.LONG_RUNNING_JOBS}
                 AND {where_clause};
             """
```

## pioreactor/utils/pwm.py

```diff
@@ -5,14 +5,16 @@
 from contextlib import suppress
 from json import dumps
 from os import getpid
 from typing import Any
 from typing import Iterator
 from typing import Optional
 
+import lgpio
+
 from pioreactor import types as pt
 from pioreactor.exc import PWMError
 from pioreactor.hardware import GPIOCHIP
 from pioreactor.logging import create_logger
 from pioreactor.logging import CustomLogger
 from pioreactor.pubsub import Client
 from pioreactor.pubsub import create_client
@@ -75,58 +77,49 @@
         pass
 
 
 class SoftwarePWMOutputDevice:
     _started = False
 
     def __init__(self, pin: GpioPin, frequency: float = 100) -> None:
-        import lgpio
-
         self.pin = pin
         self.frequency = frequency
         self._handle = lgpio.gpiochip_open(GPIOCHIP)
 
         lgpio.gpio_claim_output(self._handle, self.pin)
         lgpio.tx_pwm(self._handle, self.pin, self.frequency, 0)
 
     def start(self, initial_dc: pt.FloatBetween0and100) -> None:
-        import lgpio
-
         self._started = True
         self.dc = initial_dc
         lgpio.tx_pwm(self._handle, self.pin, self.frequency, self.dc)
 
     def off(self) -> None:
         self.dc = 0.0
 
     @property
     def dc(self) -> pt.FloatBetween0and100:
         return self._dc
 
     @dc.setter
     def dc(self, dc: pt.FloatBetween0and100) -> None:
-        import lgpio
-
         dc = clamp(0.0, dc, 100.0)
         self._dc = dc
         if self._started:
             try:
                 lgpio.tx_pwm(self._handle, self.pin, self.frequency, self.dc)
-            except lgpio.error as e:
-                print(e)
+            except lgpio.error:
+                # see issue #435
                 pass
 
         else:
             raise ValueError("must call .start() first!")
 
     def close(self):
-        import lgpio
-
         lgpio.gpiochip_close(self._handle)
-        lgpio.gpio_free(self._handle, self.pin)
 
 
 class PWM:
     """
     This class abstracts out the Rpi's PWM library details
 
 
@@ -176,19 +169,19 @@
         unit: Optional[str] = None,
         experiment: Optional[str] = None,
         always_use_software: bool = False,
         pubsub_client: Optional[Client] = None,
         logger: Optional[CustomLogger] = None,
     ) -> None:
         self.unit = unit or get_unit_name()
-        self.experiment = experiment or get_assigned_experiment_name(self.unit)
+        self.experiment = experiment or get_assigned_experiment_name(unit)
 
         if pubsub_client is None:
             self._external_client = False
-            self.pubsub_client = create_client(client_id=f"pwm-{self.unit}-{experiment}-{pin}")
+            self.pubsub_client = create_client(client_id=f"pwm-{unit}-{experiment}-{pin}")
         else:
             self._external_client = True
             self.pubsub_client = pubsub_client
 
         if logger is None:
             self.logger = create_logger(f"PWM@GPIO-{pin}", experiment=self.experiment, unit=self.unit)
         else:
```

## Comparing `pioreactor-24.4.30rc0.dist-info/LICENSE` & `pioreactor-24.4.3rc0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `pioreactor-24.4.30rc0.dist-info/METADATA` & `pioreactor-24.4.3rc0.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: pioreactor
-Version: 24.4.30rc0
+Version: 24.4.3rc0
 Summary: The core Python app of the Pioreactor. Control your bioreactor through Python.
 Home-page: https://github.com/pioreactor/pioreactor
 Author: Pioreactor
 Author-email: hello@pioreactor.com
 License: MIT
 Keywords: microbiology,bioreactor,turbidostat,raspberry pi,education,research
 Classifier: Topic :: Scientific/Engineering
@@ -53,15 +53,15 @@
 
 <img src="https://user-images.githubusercontent.com/884032/101398418-08e1c700-389c-11eb-8cf2-592c20383a19.png" width="250">
 <br />
 
 
 [![CI](https://github.com/Pioreactor/pioreactor/actions/workflows/ci.yaml/badge.svg)](https://github.com/Pioreactor/pioreactor/actions/workflows/ci.yaml)
 
-The Pioreactor is a *mostly* open source, affordable, and extensible bioreactor platform. The goal is to enable biologists, educators, DIYers, biohackers, and enthusiasts to be able to reliably control and study microorganisms.
+The Pioreactor is an open-source, affordable, and extensible bioreactor platform. The goal is to enable biologists, educators, DIYers, biohackers, and enthusiasts to be able to reliably control and study microorganisms.
 
 We hope to empower the next generation of builders, similar to the Raspberry Pi's influence on our imagination (in fact, at the core of our hardware _is_ a Raspberry Pi). However, the builders in mind are those who are looking to use biology, or computer science, or both, to achieve their goals. For research, the affordable price point enables fleets of Pioreactors to study large experiment spaces. For educators and students, the Pioreactor is a learning tool to study a wide variety of microbiology, electrical engineering, and computer science principles. For enthusiasts, the control and extensibility of the Pioreactor gives them a platform to build their next project on-top of.
 
 
 
 ### Where can I get one?
```

## Comparing `pioreactor-24.4.30rc0.dist-info/RECORD` & `pioreactor-24.4.3rc0.dist-info/RECORD`

 * *Files 20% similar despite different names*

```diff
@@ -1,92 +1,88 @@
 pioreactor/__init__.py,sha256=YBDDaFMxxsG_1Dg9ss9llZcW95gAh8WqpcdCjhF0T-E,117
 pioreactor/config.py,sha256=QqeRVVJoqMOtMszp6M5nnbEPkjM1pCO7yrI1uFcgqas,5868
 pioreactor/error_codes.py,sha256=XDfT3fPTVKN9wIGM9DdrXdvrEUn7lQkf6CJd8Xj_vFo,265
 pioreactor/exc.py,sha256=9fnJVIpg9Yyxq2e1qoWrE1ekMu7QcMHkjdRRkc7Pk3w,958
 pioreactor/hardware.py,sha256=9kdFrdLxgNPMFgXZSijV8zjVJy26zPET0K9axVb-tmI,3854
-pioreactor/logging.py,sha256=8c5TZMQMQ1rIjxWX3BPxr7jHKrZhl__A6rUAeFWDuMY,6588
-pioreactor/mureq.py,sha256=HazeoeohPwmWKCMO2PlUYfJXxD9ukaAmnnXzILrLYtw,15631
-pioreactor/pubsub.py,sha256=vtox-oh0RtasA2hGAx3heS6J2KWN_toOYWx3xwnoSJU,10903
+pioreactor/logging.py,sha256=7-x_45gucfCXZVGt2A1vngwoqICAnXVxWR1N0RN-sOc,6824
+pioreactor/mureq.py,sha256=l3upU3z_6FRw2ddAdLprKfcm72ygoT7pkfoeo_tN2P4,15621
+pioreactor/pubsub.py,sha256=psqCl4R2DeOLeZmgHo-pZ3lJgzwEs2tvb9WGNmDO30E,12014
 pioreactor/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-pioreactor/structs.py,sha256=UIYVXEJEz80cHdjiqFOhWzwFoOaBv6-9zllGBfOlJXw,6361
+pioreactor/structs.py,sha256=Z6mr5s9T6rSrhPAVKjSbKJJmc3oFZs8tfYY0_PrGjgw,6386
 pioreactor/types.py,sha256=Dh5nDPrqQQ4maMtMeqrUeXRzwHsJIzKFM2QfR9ZPLQ8,3304
-pioreactor/version.py,sha256=qY-eBbtrh1ZEPbNO4-Ro97CxXfcEVty99XXDFN--6dk,3023
-pioreactor/whoami.py,sha256=JRko2UvKgPkLACo9om2UiuInqY6vviuuYSB1NL_Ou8A,5844
+pioreactor/version.py,sha256=Bbo8d_XUEZdIQ_tutc1llQuDenwDsY7P013alayZytg,2912
+pioreactor/whoami.py,sha256=tkUJb0pcY_Bq2XXQH1VwA8TKm7dUjg_dce8KVjZHSTw,5462
 pioreactor/actions/__init__.py,sha256=VuwIL8llFFqBspvBRgC9yNm-Blu9tsE2kwgIJEs786o,540
 pioreactor/actions/led_intensity.py,sha256=_qhvooLA1mdGTSW3Z9dcxAXbR7hD6ZQqKg7MWi7PEEY,8810
 pioreactor/actions/od_blank.py,sha256=flKxWK0BySZzdJwW8oqn4RPiALIVRScI2yy5lpwlC2E,9013
-pioreactor/actions/od_calibration.py,sha256=LYZeQ217hw001RIDyHXeSMbQWItMMQqohbROD3hoAAA,24592
+pioreactor/actions/od_calibration.py,sha256=xIvjnWYivquED1DTDzk_iyZGC9mP24WyHOGWBpI5kyM,24316
 pioreactor/actions/pump.py,sha256=6seq-0Do6CZSh25kaCKOhfs6RDGYmNWtcv72U9tbjeA,19799
-pioreactor/actions/pump_calibration.py,sha256=pRUlESvtvr1AhmKqr3HO50cRF5KTi4AixztxoHJvLow,22445
+pioreactor/actions/pump_calibration.py,sha256=yKvc-pi1OQZejZRkenA2_LebLRu4B7nG5w_PTAKRLw0,22400
 pioreactor/actions/self_test.py,sha256=AeUspX_wQAvtFw_Jw-yDjvFJm-yvnIlII4rPbD6zZLU,20149
 pioreactor/actions/stirring_calibration.py,sha256=i2IGq2pUfKC6l63MNFgEwopouuy-ts7sJxuaGmCWpA4,5339
 pioreactor/actions/leader/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 pioreactor/actions/leader/backup_database.py,sha256=G3SMLyMgR9Hrfo7qyjvfEVtVc9EcfcimuvsYBKfoAEI,4902
-pioreactor/actions/leader/experiment_profile.py,sha256=XmWcZlWrN6IBdrcGg5pAMKOEItptpnKI49swCiPKeFU,25244
+pioreactor/actions/leader/experiment_profile.py,sha256=Zp1kT0aB2-Yli0FtrbrfFQrWhN_Rmkq5gKCS2frglAk,24791
 pioreactor/actions/leader/export_experiment_data.py,sha256=qU-ZTC8RXtZZp6mzqjcyMM9JdKS5bP2zHmmF6cySZ8M,6544
 pioreactor/automations/__init__.py,sha256=PTQQNnA-xrcDLHa0a0ZVM1fYw--rwRSrcoXRvJDHSN0,146
 pioreactor/automations/base.py,sha256=ZCRXAMvz7rtER8zT6wFLxuw6KfimsMhf9f1G9k3y24o,1000
 pioreactor/automations/dosing/__init__.py,sha256=dqTWOveaUiOvaWZ_U90UtN2w_pqDbM1qBIn5X9dat_E,459
-pioreactor/automations/dosing/base.py,sha256=Cf-poCPOW67_43uVMbWK_boQAtpqmMUXBzQXnkpVQKI,29432
+pioreactor/automations/dosing/base.py,sha256=rxWhJ4GqjPlLGnMm-vjfl_HphYGMXEFK4EaAJ0aarFc,29496
 pioreactor/automations/dosing/chemostat.py,sha256=bf3a3gAe_6OZztB7RsNuYFinimdZty5tR5WwJhYGBks,1424
 pioreactor/automations/dosing/fed_batch.py,sha256=YZv5h0PHRwXT4dpEELWGQnNbvgKypzE1CuxiUWuVl_k,1497
 pioreactor/automations/dosing/pid_morbidostat.py,sha256=obaEebppEb_ZUW0UUMc_I68XN8WA2Hp4gLm603URs4I,4962
 pioreactor/automations/dosing/silent.py,sha256=UfYL7mVBMH71rqd35eZ9pDDWikz7DmCnkJGfiSXy6qA,476
-pioreactor/automations/dosing/turbidostat.py,sha256=94ZkKocVsLfv2kPjOg1BUz9_LKe85bYAJyN4nDUrneg,4936
+pioreactor/automations/dosing/turbidostat.py,sha256=jIrAtK6cs5ABHDtWdKI6-Z3upaxCTNgzRXguBQsYT_U,4613
 pioreactor/automations/events/__init__.py,sha256=WxPoBeae7fD2SGOLEZ-rQf3IM83Je4SS4CztddADqlw,510
 pioreactor/automations/led/__init__.py,sha256=BhqlUc01Kj2Wbm5tf5C9y7X8AHo4XZv6eDixeakQNLc,567
 pioreactor/automations/led/base.py,sha256=YeVMwzeWthExN7Boxd2cetkrKIgq57fDgtGY6g8spY8,12023
 pioreactor/automations/led/light_dark_cycle.py,sha256=GX50pON5HbZxIUxQMl_WfeYKV_ERtyiJjxQIgbfzNsE,3875
 pioreactor/automations/temperature/__init__.py,sha256=rxAitEYRWPQqFWvGUl_XIe9FwyzwRVQTQmaReafOfBM,154
 pioreactor/automations/temperature/base.py,sha256=jYxG-uG5VFtsyYmPp_HuVbCxemYnmgedaYQusxLPTew,9317
 pioreactor/automations/temperature/only_record_temperature.py,sha256=DB-6Dxn_CQ54YoNKsD46F6EnKi2o5kJDKkhfqB0ekKI,561
-pioreactor/automations/temperature/thermostat.py,sha256=dM6lOTffSGSP4Ow8rvqWFjOMaebde7h84CAWrDhISZE,4375
+pioreactor/automations/temperature/thermostat.py,sha256=ziOOEH2ghX2MnuLT9-vArUrBRV722gYpQgUUJs3XrG0,4235
 pioreactor/background_jobs/__init__.py,sha256=pn23vImMyfiHjbdKObOWpAwzNUbE1xnHWUYk4j4KSJM,715
-pioreactor/background_jobs/base.py,sha256=dAaNirpR8Nxkg2_5heWgmDOXU1_OZryBdm6nmA0IxAM,45137
+pioreactor/background_jobs/base.py,sha256=CpMxUFyh5wBuUX1-qXTzKB289-23HHFXFSVDaugiJkw,44487
 pioreactor/background_jobs/dosing_control.py,sha256=PSohU2cgQANjMJbpS2i7Z5lobQUPgzBD-AB9Ordfma4,7043
-pioreactor/background_jobs/growth_rate_calculating.py,sha256=UYspbPYWQ6nH-hxvQr_NI3jLVlWj2jYzSzrkxHG_F0g,22053
+pioreactor/background_jobs/growth_rate_calculating.py,sha256=Ls-DdmcQA9QEjQFqUA9J58MeYUD6WTsLo_KIr97SSt0,22120
 pioreactor/background_jobs/led_control.py,sha256=oS2rZtHlq8Ct2WZ_3y2L_coqbtIJGvQeqBdmwiYeG4o,5806
-pioreactor/background_jobs/monitor.py,sha256=PCkgOn7beLD4lVr7So6Dsr2yDPv5RUY2FgAmVpKowpw,29820
-pioreactor/background_jobs/od_reading.py,sha256=JTL0XZkeFqk0rVUrZ1UYqPVLhbOAfJbidFYaoWZWjkw,52952
-pioreactor/background_jobs/stirring.py,sha256=2xXIup_mC54bNfVM9-P6qIR6yKIiA3nUK3lvkIE7CDM,18124
-pioreactor/background_jobs/temperature_control.py,sha256=YBBrCn9av-bHVze3NMP621aPPKUmR0mJrN8S4qB_MpY,26075
+pioreactor/background_jobs/monitor.py,sha256=6_bs0A3u-7T8-KfDQh-DfqoUC5gHrCI9OtuzrDr6KC8,29084
+pioreactor/background_jobs/od_reading.py,sha256=59vcJZgZaewFZv7wvpclcHLyinXOodCgEeWARF3HUEc,52689
+pioreactor/background_jobs/stirring.py,sha256=syCS5abapM3y1OVDDS02kmvsL2rSTZLvwWbMkkR4Syw,17978
+pioreactor/background_jobs/temperature_control.py,sha256=os8uN0zfE4Wnfs9xpZ_JjXpOHEgf8CIIdEWZ2r8JvlQ,24449
 pioreactor/background_jobs/leader/__init__.py,sha256=Uhl2Xksfkf06lmfmz2scTxmBWDBnwkA9rSil_V94aWQ,605
-pioreactor/background_jobs/leader/mqtt_to_db_streaming.py,sha256=IfYLPKM4CyaVdDlvx_DtL90bCdaRdCddxzWxdjCWkwk,16997
-pioreactor/background_jobs/leader/watchdog.py,sha256=yBY9lYoiAJI4K7b4OpEHTyaJDQNIDXn7Ug7d6u1a_GU,4573
+pioreactor/background_jobs/leader/mqtt_to_db_streaming.py,sha256=ZYGNrf281NvtAQCVRQ20RNS3efVktWl7SSehyItHEMw,17001
+pioreactor/background_jobs/leader/watchdog.py,sha256=Lh7ZUp7M5rxGmbSSCykSZEJBgXF6Um-Ur7KwsipkNco,4573
 pioreactor/background_jobs/subjobs/__init__.py,sha256=RP7U5Q5cWqmmlmiVwAbVnwGyEnhqJM6fk71VP-3Y0c0,1094
 pioreactor/cli/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-pioreactor/cli/lazy_group.py,sha256=yVmwvXO1dInCcFbY13vFsH0lvYQozDHeWfr-7rlMYBE,1408
-pioreactor/cli/pio.py,sha256=af0TkVADm_z79OspGrZXHg6q1h0IGzksXDiYN3aHOjA,24433
-pioreactor/cli/pios.py,sha256=TGDqZZCOr2SKOyVQ8xIY57MKVGwkKy3ZyidOxyiUmgw,26918
-pioreactor/cli/plugins.py,sha256=ETiDAZscou6bCtpD9zPG2_5IYSKohqFlyvJh5xjA-bE,365
-pioreactor/cli/run.py,sha256=quWPHpNBZ2npTvPv29RuEiiUonc9pEA3-zx2cRhEflY,1949
-pioreactor/cli/workers.py,sha256=2I_NmtyvIDlkEYPO0Q8tU5EIwDpYoZGJAtoxWbkZqtk,700
-pioreactor/cluster_management/__init__.py,sha256=WJ_AUvY_jqTaWKUajlW3HtC1qZTC4DiZfXHcEzUN8lc,10403
+pioreactor/cli/pio.py,sha256=XFgXJl1gg-z2GHmwFcV435EmWDNcfGYNaKi2zkBvOj0,26493
+pioreactor/cli/pios.py,sha256=0M6nbgbuTvcxUY_w-LOEu_rABXzsuSdUPw6avbeXjRs,26132
+pioreactor/cluster_management/__init__.py,sha256=QKl9pA6Pws5DJM2wanMxSWMCMztHQ4gtTiFikd7ac3Y,10177
 pioreactor/experiment_profiles/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 pioreactor/experiment_profiles/parser.py,sha256=lYDWjhTirYWiWAx6o7T_K044FwQsmPNGmqQYmXT50sg,5488
 pioreactor/experiment_profiles/profile_struct.py,sha256=OIok66XPpbba8ghUqzQL9EkT9OqbAzO5gcXSohHP6oY,2896
 pioreactor/experiment_profiles/sly/__init__.py,sha256=Z7rV-XpX5Nz29NqaaJ7ln8hHgY6WYqC5t-59YYt8xqs,197
 pioreactor/experiment_profiles/sly/lex.py,sha256=Dwt9dJqVw92BpmfwWR0PzqduLpD5qE-ILgSj_vXUlRg,16273
 pioreactor/experiment_profiles/sly/yacc.py,sha256=EfzAO8Wg4Cb8wOPBaf8pK37MDsk0KFjTEN8BHgDMXi0,83015
 pioreactor/plugin_management/__init__.py,sha256=ivql-g9QTAWn_xvFCoFYj0BzUBcWxYp-AQKKifUdNXQ,3807
-pioreactor/plugin_management/install_plugin.py,sha256=7BCWXWfirkF71uJHwnjEeoRWKdbeldgUQVAG6OVyvGg,1439
-pioreactor/plugin_management/list_plugins.py,sha256=MM5eNvVO4ibbOwcj3B6yMkDnlrwAF912I2nO51chLVw,1123
-pioreactor/plugin_management/uninstall_plugin.py,sha256=S8x3nqQ2euSbhiBPTYVHtpQeuw3fqYxwB7M0XNYCCW4,1782
+pioreactor/plugin_management/install_plugin.py,sha256=o6LDEjw2PLZpaH4hqfGdNnFx7hxChsSv4AQ4m4F1ljw,1446
+pioreactor/plugin_management/list_plugins.py,sha256=oXTY0zfPkTR-PjZiCyuil9DAnPjQ9Z-GsFQev3b-5ak,1179
+pioreactor/plugin_management/uninstall_plugin.py,sha256=cIwFK6WUGU2k4jwAywttXWGsxARYagE1x9CQtPbjtCg,1789
 pioreactor/plugin_management/utils.py,sha256=Cferq4vLR0JuXjZY135tm_fcszm5_8bNP4eToOH2Slw,1194
-pioreactor/utils/__init__.py,sha256=eg6BigGHepUYYj2qMegu8bLdBZryq6kNu9WdN4dUDoc,21578
+pioreactor/utils/__init__.py,sha256=iO3S5uFZWBP9AnUc3TCtm-RH4h5Rzy3I6pwRgv4PjMA,21545
 pioreactor/utils/adcs.py,sha256=8tLRJuZFUB0JFLCnQ7WFkx171DlYgigLcCzo3xy-pwQ,4240
 pioreactor/utils/dacs.py,sha256=gPAEjRseVA3-Ta5MTHpwi0HRdbWVd47pD21FcCaQwFY,1930
 pioreactor/utils/gpio_helpers.py,sha256=9lAKuEMuLIqXtTk6wRisKABo_Ab0n-zGcBjtN8gjX2I,976
 pioreactor/utils/math_helpers.py,sha256=lHAaO2X6tH8oP5Znk7CoO5l-phdPpgAR1AQTecVZr88,3311
 pioreactor/utils/mock.py,sha256=o5tNfE40supfTBDurMCgbXp2dqtsCsXeK3Hl6LotJow,5211
 pioreactor/utils/networking.py,sha256=6I3sykzSFPfrS1erIRFu33Cq8x-25I_UFdJTdsn9KOg,3622
-pioreactor/utils/pwm.py,sha256=OMsTjNEn-JwoM9jMnW4uoJ6BCbJQNZFJucNmevLWSoo,10278
+pioreactor/utils/pwm.py,sha256=33tYIbip7C6XILNw6y8wM2F7R70llepO4CirWx3Gpyw,10149
 pioreactor/utils/rpi_bad_power.py,sha256=CbtzIi9x8pvtVAX6aID8MG5YXNzkeIRFYfhri4qI-Xo,3393
 pioreactor/utils/sqlite_worker.py,sha256=TKgohPrZu3HsttrzH7HDmwkk5KWSEkFT1sFTB7jQkBc,7889
 pioreactor/utils/streaming_calculations.py,sha256=RP2ZIG7oylkJipXRvCn8uxd2JO979MSrI1U6jFxHM80,18416
 pioreactor/utils/timing.py,sha256=x_CPXqm4pkaaz5I3XUkTM49XJbjTETXKya3YRkbCwSk,5827
-pioreactor-24.4.30rc0.dist-info/LICENSE,sha256=V9lTmv9cMeiSZ_9ezl7s5LVGXkZ4t7PUzVxIeVqkk7k,1067
-pioreactor-24.4.30rc0.dist-info/METADATA,sha256=arDadZE7ke0lkd9d-DdIc-e0XaPanyFTCDj_RDqcoe8,3722
-pioreactor-24.4.30rc0.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
-pioreactor-24.4.30rc0.dist-info/entry_points.txt,sha256=1vQa-58PTH44hOQBeYFJdO3Tdfzea7_pYDxv5KQWvZ4,79
-pioreactor-24.4.30rc0.dist-info/top_level.txt,sha256=xhd14Ee_KR74whX88OzvljqlGXmfpBUHOSIqDrbs9_0,11
-pioreactor-24.4.30rc0.dist-info/RECORD,,
+pioreactor-24.4.3rc0.dist-info/LICENSE,sha256=V9lTmv9cMeiSZ_9ezl7s5LVGXkZ4t7PUzVxIeVqkk7k,1067
+pioreactor-24.4.3rc0.dist-info/METADATA,sha256=lZ4PSceRFzy-bZtAPcY1QDPWjiMR5JhrAVs9l4BY-pk,3713
+pioreactor-24.4.3rc0.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+pioreactor-24.4.3rc0.dist-info/entry_points.txt,sha256=1vQa-58PTH44hOQBeYFJdO3Tdfzea7_pYDxv5KQWvZ4,79
+pioreactor-24.4.3rc0.dist-info/top_level.txt,sha256=xhd14Ee_KR74whX88OzvljqlGXmfpBUHOSIqDrbs9_0,11
+pioreactor-24.4.3rc0.dist-info/RECORD,,
```

