# Comparing `tmp/snowflake_core-0.7.0.tar.gz` & `tmp/snowflake_core-0.8.0.tar.gz`

## Comparing `snowflake_core-0.7.0.tar` & `snowflake_core-0.8.0.tar`

### file list

```diff
@@ -1,211 +1,275 @@
--rw-r--r--   0        0        0     1852 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/CHANGELOG.md
--rw-r--r--   0        0        0     1923 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/codegen/README.md
--rw-r--r--   0        0        0      492 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/__init__.py
--rw-r--r--   0        0        0     8651 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/_common.py
--rw-r--r--   0        0        0     3732 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/_http_requests.py
--rw-r--r--   0        0        0     4055 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/_root.py
--rw-r--r--   0        0        0     5445 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/exceptions.py
--rw-r--r--   0        0        0     1607 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/paging.py
--rw-r--r--   0        0        0      740 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/rest.py
--rw-r--r--   0        0        0       95 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/version.py
--rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/_internal/__init__.py
--rw-r--r--   0        0        0      444 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/_internal/pydantic_compatibility.py
--rw-r--r--   0        0        0     3187 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/_internal/telemetry.py
--rw-r--r--   0        0        0     3295 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/_internal/utils.py
--rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/__init__.py
--rw-r--r--   0        0        0     9003 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/executor.py
--rw-r--r--   0        0        0     3286 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/rest_errors.py
--rw-r--r--   0        0        0     7859 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/snow_bridge.py
--rw-r--r--   0        0        0      283 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/snow_execute.py
--rw-r--r--   0        0        0     1728 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/snow_request.py
--rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/resources/__init__.py
--rw-r--r--   0        0        0     8723 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/resources/computepools_resource.py
--rw-r--r--   0        0        0    16111 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/resources/database_resource.py
--rw-r--r--   0        0        0     5338 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/resources/imagerepo_resource.py
--rw-r--r--   0        0        0     1128 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/resources/resource_base.py
--rw-r--r--   0        0        0    13323 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/resources/schema_resource.py
--rw-r--r--   0        0        0    10600 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/resources/services_resource.py
--rw-r--r--   0        0        0    39124 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/resources/table_resource.py
--rw-r--r--   0        0        0    28034 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/resources/task_resource.py
--rw-r--r--   0        0        0    13060 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/resources/warehouse_resource.py
--rw-r--r--   0        0        0      927 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/compute_pool/__init__.py
--rw-r--r--   0        0        0     4546 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/compute_pool/_compute_pool.py
--rw-r--r--   0        0        0     1009 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/compute_pool/_generated/__init__.py
--rw-r--r--   0        0        0    30563 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/compute_pool/_generated/api_client.py
--rw-r--r--   0        0        0      891 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/compute_pool/_generated/api_response.py
--rw-r--r--   0        0        0    13274 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/compute_pool/_generated/configuration.py
--rw-r--r--   0        0        0    16386 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/compute_pool/_generated/rest.py
--rw-r--r--   0        0        0      212 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/compute_pool/_generated/api/__init__.py
--rw-r--r--   0        0        0    56043 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/compute_pool/_generated/api/compute_pool_api.py
--rw-r--r--   0        0        0      775 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/compute_pool/_generated/models/__init__.py
--rw-r--r--   0        0        0     7726 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/compute_pool/_generated/models/compute_pool.py
--rw-r--r--   0        0        0     3511 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/compute_pool/_generated/models/error_response.py
--rw-r--r--   0        0        0     2886 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/compute_pool/_generated/models/success_response.py
--rw-r--r--   0        0        0      214 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/database/__init__.py
--rw-r--r--   0        0        0    10336 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/database/_database.py
--rw-r--r--   0        0        0     1516 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/database/_generated/__init__.py
--rw-r--r--   0        0        0    30545 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/database/_generated/api_client.py
--rw-r--r--   0        0        0      891 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/database/_generated/api_response.py
--rw-r--r--   0        0        0    13263 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/database/_generated/configuration.py
--rw-r--r--   0        0        0    16384 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/database/_generated/rest.py
--rw-r--r--   0        0        0      198 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/database/_generated/api/__init__.py
--rw-r--r--   0        0        0    98882 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/database/_generated/api/database_api.py
--rw-r--r--   0        0        0     1445 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/database/_generated/models/__init__.py
--rw-r--r--   0        0        0     2927 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/database/_generated/models/account_identifiers.py
--rw-r--r--   0        0        0    10811 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/database/_generated/models/database.py
--rw-r--r--   0        0        0    11550 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/database/_generated/models/database_clone.py
--rw-r--r--   0        0        0     3509 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/database/_generated/models/error_response.py
--rw-r--r--   0        0        0     4726 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/database/_generated/models/point_of_time.py
--rw-r--r--   0        0        0     3566 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/database/_generated/models/point_of_time_offset.py
--rw-r--r--   0        0        0     3650 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/database/_generated/models/point_of_time_statement.py
--rw-r--r--   0        0        0     3650 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/database/_generated/models/point_of_time_timestamp.py
--rw-r--r--   0        0        0     2884 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/database/_generated/models/success_response.py
--rw-r--r--   0        0        0      893 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/image_repository/__init__.py
--rw-r--r--   0        0        0     3991 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/image_repository/_image_repository.py
--rw-r--r--   0        0        0     1071 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/image_repository/_generated/__init__.py
--rw-r--r--   0        0        0    30601 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/image_repository/_generated/api_client.py
--rw-r--r--   0        0        0      891 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/image_repository/_generated/api_response.py
--rw-r--r--   0        0        0    13303 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/image_repository/_generated/configuration.py
--rw-r--r--   0        0        0    16408 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/image_repository/_generated/rest.py
--rw-r--r--   0        0        0      228 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/image_repository/_generated/api/__init__.py
--rw-r--r--   0        0        0    32050 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/image_repository/_generated/api/image_repository_api.py
--rw-r--r--   0        0        0      821 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/image_repository/_generated/models/__init__.py
--rw-r--r--   0        0        0     3533 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/image_repository/_generated/models/error_response.py
--rw-r--r--   0        0        0     5838 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/image_repository/_generated/models/image_repository.py
--rw-r--r--   0        0        0     2908 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/image_repository/_generated/models/success_response.py
--rw-r--r--   0        0        0      194 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/schema/__init__.py
--rw-r--r--   0        0        0     6318 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/schema/_schema.py
--rw-r--r--   0        0        0     1394 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/schema/_generated/__init__.py
--rw-r--r--   0        0        0    30531 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/schema/_generated/api_client.py
--rw-r--r--   0        0        0      891 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/schema/_generated/api_response.py
--rw-r--r--   0        0        0    13253 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/schema/_generated/configuration.py
--rw-r--r--   0        0        0    16378 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/schema/_generated/rest.py
--rw-r--r--   0        0        0      190 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/schema/_generated/api/__init__.py
--rw-r--r--   0        0        0    51515 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/schema/_generated/api/schema_api.py
--rw-r--r--   0        0        0     1308 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/schema/_generated/models/__init__.py
--rw-r--r--   0        0        0     3503 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/schema/_generated/models/error_response.py
--rw-r--r--   0        0        0    11176 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/schema/_generated/models/model_schema.py
--rw-r--r--   0        0        0     4714 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/schema/_generated/models/point_of_time.py
--rw-r--r--   0        0        0     3556 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/schema/_generated/models/point_of_time_offset.py
--rw-r--r--   0        0        0     3640 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/schema/_generated/models/point_of_time_statement.py
--rw-r--r--   0        0        0     3640 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/schema/_generated/models/point_of_time_timestamp.py
--rw-r--r--   0        0        0    11831 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/schema/_generated/models/schema_clone.py
--rw-r--r--   0        0        0     2878 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/schema/_generated/models/success_response.py
--rw-r--r--   0        0        0     1351 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/service/__init__.py
--rw-r--r--   0        0        0     5778 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/service/_service.py
--rw-r--r--   0        0        0     1474 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/service/_generated/__init__.py
--rw-r--r--   0        0        0    30552 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/service/_generated/api_client.py
--rw-r--r--   0        0        0      891 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/service/_generated/api_response.py
--rw-r--r--   0        0        0    13273 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/service/_generated/configuration.py
--rw-r--r--   0        0        0    16395 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/service/_generated/rest.py
--rw-r--r--   0        0        0      194 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/service/_generated/api/__init__.py
--rw-r--r--   0        0        0    62981 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/service/_generated/api/service_api.py
--rw-r--r--   0        0        0     1408 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/service/_generated/models/__init__.py
--rw-r--r--   0        0        0     3520 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/service/_generated/models/error_response.py
--rw-r--r--   0        0        0     3273 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/service/_generated/models/fetch_service_logs200_response.py
--rw-r--r--   0        0        0     3331 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/service/_generated/models/fetch_service_status200_response.py
--rw-r--r--   0        0        0     9687 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/service/_generated/models/service.py
--rw-r--r--   0        0        0     4258 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/service/_generated/models/service_spec.py
--rw-r--r--   0        0        0     3300 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/service/_generated/models/service_spec_inline_text.py
--rw-r--r--   0        0        0     3467 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/service/_generated/models/service_spec_stage_file.py
--rw-r--r--   0        0        0     2895 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/service/_generated/models/success_response.py
--rw-r--r--   0        0        0      347 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/table/__init__.py
--rw-r--r--   0        0        0     8009 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/table/_table.py
--rw-r--r--   0        0        0     1311 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/table/_generated/__init__.py
--rw-r--r--   0        0        0    30536 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/table/_generated/api_client.py
--rw-r--r--   0        0        0      891 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/table/_generated/api_response.py
--rw-r--r--   0        0        0    13262 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/table/_generated/configuration.py
--rw-r--r--   0        0        0    16387 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/table/_generated/rest.py
--rw-r--r--   0        0        0      186 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/table/_generated/api/__init__.py
--rw-r--r--   0        0        0    77322 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/table/_generated/api/table_api.py
--rw-r--r--   0        0        0     1195 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/table/_generated/models/__init__.py
--rw-r--r--   0        0        0     4654 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/table/_generated/models/constraint.py
--rw-r--r--   0        0        0     3512 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/table/_generated/models/error_response.py
--rw-r--r--   0        0        0     4091 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/table/_generated/models/foreign_key.py
--rw-r--r--   0        0        0     3260 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/table/_generated/models/primary_key.py
--rw-r--r--   0        0        0     2887 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/table/_generated/models/success_response.py
--rw-r--r--   0        0        0    11659 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/table/_generated/models/table.py
--rw-r--r--   0        0        0     6051 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/table/_generated/models/table_column.py
--rw-r--r--   0        0        0     3243 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/table/_generated/models/unique_key.py
--rw-r--r--   0        0        0      925 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/task/__init__.py
--rw-r--r--   0        0        0    31058 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/task/_task.py
--rw-r--r--   0        0        0     8563 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/task/context.py
--rw-r--r--   0        0        0    29476 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/task/dagv1.py
--rw-r--r--   0        0        0     1233 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/task/_generated/__init__.py
--rw-r--r--   0        0        0    30529 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/task/_generated/api_client.py
--rw-r--r--   0        0        0      891 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/task/_generated/api_response.py
--rw-r--r--   0        0        0    13255 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/task/_generated/configuration.py
--rw-r--r--   0        0        0    16384 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/task/_generated/rest.py
--rw-r--r--   0        0        0      182 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/task/_generated/api/__init__.py
--rw-r--r--   0        0        0    84663 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/task/_generated/api/task_api.py
--rw-r--r--   0        0        0     1109 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/task/_generated/models/__init__.py
--rw-r--r--   0        0        0     3371 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/task/_generated/models/cron_schedule.py
--rw-r--r--   0        0        0     3509 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/task/_generated/models/error_response.py
--rw-r--r--   0        0        0     3188 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/task/_generated/models/minutes_schedule.py
--rw-r--r--   0        0        0     2884 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/task/_generated/models/success_response.py
--rw-r--r--   0        0        0    11939 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/task/_generated/models/task.py
--rw-r--r--   0        0        0     7899 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/task/_generated/models/task_run.py
--rw-r--r--   0        0        0     4209 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/task/_generated/models/task_schedule.py
--rw-r--r--   0        0        0       72 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/task/_internal/__init__.py
--rw-r--r--   0        0        0      307 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/warehouse/__init__.py
--rw-r--r--   0        0        0     8493 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/warehouse/_warehouse.py
--rw-r--r--   0        0        0      973 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/warehouse/_generated/__init__.py
--rw-r--r--   0        0        0    30543 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/warehouse/_generated/api_client.py
--rw-r--r--   0        0        0      891 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/warehouse/_generated/api_response.py
--rw-r--r--   0        0        0    13259 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/warehouse/_generated/configuration.py
--rw-r--r--   0        0        0    16378 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/warehouse/_generated/rest.py
--rw-r--r--   0        0        0      202 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/warehouse/_generated/api/__init__.py
--rw-r--r--   0        0        0    69865 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/warehouse/_generated/api/warehouse_api.py
--rw-r--r--   0        0        0      751 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/warehouse/_generated/models/__init__.py
--rw-r--r--   0        0        0     3503 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/warehouse/_generated/models/error_response.py
--rw-r--r--   0        0        0     2878 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/warehouse/_generated/models/success_response.py
--rw-r--r--   0        0        0    18561 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/src/snowflake/core/warehouse/_generated/models/warehouse.py
--rw-r--r--   0        0        0       15 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/.gitignore
--rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/__init__.py
--rw-r--r--   0        0        0      660 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/utils.py
--rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/integ/__init__.py
--rw-r--r--   0        0        0     9239 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/integ/conftest.py
--rw-r--r--   0        0        0     3346 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/integ/test_compute_pool.py
--rw-r--r--   0        0        0     4462 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/integ/test_database.py
--rw-r--r--   0        0        0     1475 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/integ/test_image_repository.py
--rw-r--r--   0        0        0      346 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/integ/test_root.py
--rw-r--r--   0        0        0     3814 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/integ/test_schema.py
--rw-r--r--   0        0        0     4940 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/integ/test_service.py
--rw-r--r--   0        0        0    12696 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/integ/test_table.py
--rw-r--r--   0        0        0    12944 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/integ/test_warehouse.py
--rw-r--r--   0        0        0      584 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/integ/utils.py
--rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/integ/task/__init__.py
--rw-r--r--   0        0        0      568 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/integ/task/conftest.py
--rw-r--r--   0        0        0     7718 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/integ/task/test_create_or_update_task.py
--rw-r--r--   0        0        0     9726 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/integ/task/test_create_task.py
--rw-r--r--   0        0        0     1531 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/integ/task/test_drop_task.py
--rw-r--r--   0        0        0     1559 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/integ/task/test_execute_task.py
--rw-r--r--   0        0        0     4348 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/integ/task/test_load_task.py
--rw-r--r--   0        0        0    10684 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/integ/task/test_python_function.py
--rw-r--r--   0        0        0     3105 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/integ/task/test_show_task.py
--rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/integ/task/dag/__init__.py
--rw-r--r--   0        0        0    25996 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/integ/task/dag/test_dag.py
--rw-r--r--   0        0        0       34 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/resources/testCSVheader.csv
--rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/unit/__init__.py
--rw-r--r--   0        0        0     2301 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/unit/common.py
--rw-r--r--   0        0        0      695 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/unit/conftest.py
--rw-r--r--   0        0        0     7533 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/unit/test_database.py
--rw-r--r--   0        0        0     2619 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/unit/test_schema.py
--rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/unit/api/__init__.py
--rw-r--r--   0        0        0     4168 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/unit/api/general_api_test.py
--rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/unit/bridge/__init__.py
--rw-r--r--   0        0        0     6954 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/unit/bridge/test_database.py
--rw-r--r--   0        0        0     7069 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/unit/bridge/test_executor.py
--rw-r--r--   0        0        0     1768 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/unit/bridge/test_rest_errors.py
--rw-r--r--   0        0        0     4302 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/unit/bridge/test_schema.py
--rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/unit/resources/__init__.py
--rw-r--r--   0        0        0     1106 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/unit/resources/test_computepool_resource.py
--rw-r--r--   0        0        0     1396 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/unit/resources/test_task_resource.py
--rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/unit/task/__init__.py
--rw-r--r--   0        0        0     1825 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/unit/task/test_dagv1.py
--rw-r--r--   0        0        0     4392 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/unit/task/test_task_context.py
--rw-r--r--   0        0        0      660 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/tests/unit/task/test_task_reference.py
--rw-r--r--   0        0        0     1317 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/.gitignore
--rw-r--r--   0        0        0      405 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/README.md
--rw-r--r--   0        0        0     4067 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/pyproject.toml
--rw-r--r--   0        0        0     1786 2020-02-02 00:00:00.000000 snowflake_core-0.7.0/PKG-INFO
+-rw-r--r--   0        0        0     2992 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/CHANGELOG.md
+-rw-r--r--   0        0        0     1915 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/codegen/README.md
+-rw-r--r--   0        0        0      492 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/__init__.py
+-rw-r--r--   0        0        0     8890 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_common.py
+-rw-r--r--   0        0        0      117 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_constants.py
+-rw-r--r--   0        0        0     5463 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_http_requests.py
+-rw-r--r--   0        0        0     4865 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_root.py
+-rw-r--r--   0        0        0     5956 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/exceptions.py
+-rw-r--r--   0        0        0      740 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/rest.py
+-rw-r--r--   0        0        0       95 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/version.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/__init__.py
+-rw-r--r--   0        0        0      444 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/pydantic_compatibility.py
+-rw-r--r--   0        0        0     1035 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/snowapi_parameters.py
+-rw-r--r--   0        0        0     4197 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/telemetry.py
+-rw-r--r--   0        0        0     3692 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/utils.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/__init__.py
+-rw-r--r--   0        0        0     9003 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/executor.py
+-rw-r--r--   0        0        0     3286 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/rest_errors.py
+-rw-r--r--   0        0        0     7859 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/snow_bridge.py
+-rw-r--r--   0        0        0      283 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/snow_execute.py
+-rw-r--r--   0        0        0     1728 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/snow_request.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/__init__.py
+-rw-r--r--   0        0        0     8714 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/computepools_resource.py
+-rw-r--r--   0        0        0    16158 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/database_resource.py
+-rw-r--r--   0        0        0     5458 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/imagerepo_resource.py
+-rw-r--r--   0        0        0     1128 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/resource_base.py
+-rw-r--r--   0        0        0    13516 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/schema_resource.py
+-rw-r--r--   0        0        0    10828 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/services_resource.py
+-rw-r--r--   0        0        0    40719 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/table_resource.py
+-rw-r--r--   0        0        0    28172 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/task_resource.py
+-rw-r--r--   0        0        0    13474 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/warehouse_resource.py
+-rw-r--r--   0        0        0      927 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/__init__.py
+-rw-r--r--   0        0        0     4617 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/_compute_pool.py
+-rw-r--r--   0        0        0     1046 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/__init__.py
+-rw-r--r--   0        0        0    37790 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/api_client.py
+-rw-r--r--   0        0        0      905 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/api_response.py
+-rw-r--r--   0        0        0    13311 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/configuration.py
+-rw-r--r--   0        0        0     1674 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/paging.py
+-rw-r--r--   0        0        0      444 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/pydantic_compatibility.py
+-rw-r--r--   0        0        0    22715 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/rest.py
+-rw-r--r--   0        0        0      212 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/api/__init__.py
+-rw-r--r--   0        0        0    62546 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/api/compute_pool_api.py
+-rw-r--r--   0        0        0      812 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/models/__init__.py
+-rw-r--r--   0        0        0     7777 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/models/compute_pool.py
+-rw-r--r--   0        0        0     3638 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/models/error_response.py
+-rw-r--r--   0        0        0     2881 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/models/success_response.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/__init__.py
+-rw-r--r--   0        0        0      533 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/__init__.py
+-rw-r--r--   0        0        0     2202 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_search_service.py
+-rw-r--r--   0        0        0     1030 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/__init__.py
+-rw-r--r--   0        0        0    37756 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/api_client.py
+-rw-r--r--   0        0        0      914 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/api_response.py
+-rw-r--r--   0        0        0    13163 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/configuration.py
+-rw-r--r--   0        0        0     1674 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/paging.py
+-rw-r--r--   0        0        0      444 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/pydantic_compatibility.py
+-rw-r--r--   0        0        0    22630 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/rest.py
+-rw-r--r--   0        0        0      246 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/api/__init__.py
+-rw-r--r--   0        0        0    13020 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/api/cortex_search_service_api.py
+-rw-r--r--   0        0        0      751 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/models/__init__.py
+-rw-r--r--   0        0        0     3562 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/models/error_response.py
+-rw-r--r--   0        0        0     3511 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/models/query_request.py
+-rw-r--r--   0        0        0     3083 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/models/query_response.py
+-rw-r--r--   0        0        0      214 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/__init__.py
+-rw-r--r--   0        0        0    10388 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_database.py
+-rw-r--r--   0        0        0     1553 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/__init__.py
+-rw-r--r--   0        0        0    37756 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/api_client.py
+-rw-r--r--   0        0        0      901 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/api_response.py
+-rw-r--r--   0        0        0    13300 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/configuration.py
+-rw-r--r--   0        0        0     1674 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/paging.py
+-rw-r--r--   0        0        0      444 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/pydantic_compatibility.py
+-rw-r--r--   0        0        0    22713 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/rest.py
+-rw-r--r--   0        0        0      198 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/api/__init__.py
+-rw-r--r--   0        0        0   108817 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/api/database_api.py
+-rw-r--r--   0        0        0     1482 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/__init__.py
+-rw-r--r--   0        0        0     2974 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/account_identifiers.py
+-rw-r--r--   0        0        0    10472 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/database.py
+-rw-r--r--   0        0        0    11211 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/database_clone.py
+-rw-r--r--   0        0        0     3632 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/error_response.py
+-rw-r--r--   0        0        0     4660 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/point_of_time.py
+-rw-r--r--   0        0        0     3555 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/point_of_time_offset.py
+-rw-r--r--   0        0        0     3636 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/point_of_time_statement.py
+-rw-r--r--   0        0        0     3636 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/point_of_time_timestamp.py
+-rw-r--r--   0        0        0     2875 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/success_response.py
+-rw-r--r--   0        0        0      893 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/__init__.py
+-rw-r--r--   0        0        0     4078 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/_image_repository.py
+-rw-r--r--   0        0        0     1108 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/__init__.py
+-rw-r--r--   0        0        0    37844 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/api_client.py
+-rw-r--r--   0        0        0      909 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/api_response.py
+-rw-r--r--   0        0        0    13340 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/configuration.py
+-rw-r--r--   0        0        0     1674 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/paging.py
+-rw-r--r--   0        0        0      444 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/pydantic_compatibility.py
+-rw-r--r--   0        0        0    22737 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/rest.py
+-rw-r--r--   0        0        0      228 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/api/__init__.py
+-rw-r--r--   0        0        0    39684 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/api/image_repository_api.py
+-rw-r--r--   0        0        0      858 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/models/__init__.py
+-rw-r--r--   0        0        0     3664 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/models/error_response.py
+-rw-r--r--   0        0        0     5893 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/models/image_repository.py
+-rw-r--r--   0        0        0     2907 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/models/success_response.py
+-rw-r--r--   0        0        0      194 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/__init__.py
+-rw-r--r--   0        0        0     6584 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_schema.py
+-rw-r--r--   0        0        0     1431 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/__init__.py
+-rw-r--r--   0        0        0    37734 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/api_client.py
+-rw-r--r--   0        0        0      899 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/api_response.py
+-rw-r--r--   0        0        0    13290 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/configuration.py
+-rw-r--r--   0        0        0     1674 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/paging.py
+-rw-r--r--   0        0        0      444 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/pydantic_compatibility.py
+-rw-r--r--   0        0        0    22707 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/rest.py
+-rw-r--r--   0        0        0      190 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/api/__init__.py
+-rw-r--r--   0        0        0    61166 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/api/schema_api.py
+-rw-r--r--   0        0        0     1345 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/__init__.py
+-rw-r--r--   0        0        0     3624 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/error_response.py
+-rw-r--r--   0        0        0    10773 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/model_schema.py
+-rw-r--r--   0        0        0     4646 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/point_of_time.py
+-rw-r--r--   0        0        0     3543 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/point_of_time_offset.py
+-rw-r--r--   0        0        0     3624 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/point_of_time_statement.py
+-rw-r--r--   0        0        0     3624 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/point_of_time_timestamp.py
+-rw-r--r--   0        0        0    11428 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/schema_clone.py
+-rw-r--r--   0        0        0     2867 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/success_response.py
+-rw-r--r--   0        0        0     1397 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/__init__.py
+-rw-r--r--   0        0        0     7275 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_service.py
+-rw-r--r--   0        0        0     1597 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/__init__.py
+-rw-r--r--   0        0        0    37759 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/api_client.py
+-rw-r--r--   0        0        0      900 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/api_response.py
+-rw-r--r--   0        0        0    13310 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/configuration.py
+-rw-r--r--   0        0        0     1674 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/paging.py
+-rw-r--r--   0        0        0      444 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/pydantic_compatibility.py
+-rw-r--r--   0        0        0    22724 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/rest.py
+-rw-r--r--   0        0        0      194 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/api/__init__.py
+-rw-r--r--   0        0        0    84995 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/api/service_api.py
+-rw-r--r--   0        0        0     1554 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/__init__.py
+-rw-r--r--   0        0        0     3642 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/error_response.py
+-rw-r--r--   0        0        0     3319 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/fetch_service_logs200_response.py
+-rw-r--r--   0        0        0     3377 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/fetch_service_status200_response.py
+-rw-r--r--   0        0        0     9733 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/service.py
+-rw-r--r--   0        0        0     3922 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/service_endpoint.py
+-rw-r--r--   0        0        0     4304 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/service_spec.py
+-rw-r--r--   0        0        0     3346 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/service_spec_inline_text.py
+-rw-r--r--   0        0        0     3513 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/service_spec_stage_file.py
+-rw-r--r--   0        0        0     2885 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/success_response.py
+-rw-r--r--   0        0        0      111 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/__init__.py
+-rw-r--r--   0        0        0     1429 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_session.py
+-rw-r--r--   0        0        0      958 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/__init__.py
+-rw-r--r--   0        0        0    37706 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/api_client.py
+-rw-r--r--   0        0        0      900 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/api_response.py
+-rw-r--r--   0        0        0    13307 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/configuration.py
+-rw-r--r--   0        0        0     1674 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/paging.py
+-rw-r--r--   0        0        0      444 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/pydantic_compatibility.py
+-rw-r--r--   0        0        0    22671 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/rest.py
+-rw-r--r--   0        0        0      194 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/api/__init__.py
+-rw-r--r--   0        0        0    10986 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/api/session_api.py
+-rw-r--r--   0        0        0      746 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/models/__init__.py
+-rw-r--r--   0        0        0     2947 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/models/create_session_request.py
+-rw-r--r--   0        0        0     4699 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/models/create_session_response.py
+-rw-r--r--   0        0        0     3589 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/models/error_response.py
+-rw-r--r--   0        0        0     4077 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/models/parameter.py
+-rw-r--r--   0        0        0     2832 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/models/success_response.py
+-rw-r--r--   0        0        0     2871 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/models/token_request.py
+-rw-r--r--   0        0        0      347 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/__init__.py
+-rw-r--r--   0        0        0    10201 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_table.py
+-rw-r--r--   0        0        0     1781 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/__init__.py
+-rw-r--r--   0        0        0    37735 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/api_client.py
+-rw-r--r--   0        0        0      898 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/api_response.py
+-rw-r--r--   0        0        0    13299 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/configuration.py
+-rw-r--r--   0        0        0     1674 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/paging.py
+-rw-r--r--   0        0        0      444 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/pydantic_compatibility.py
+-rw-r--r--   0        0        0    22716 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/rest.py
+-rw-r--r--   0        0        0      186 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/api/__init__.py
+-rw-r--r--   0        0        0   130412 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/api/table_api.py
+-rw-r--r--   0        0        0     1783 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/__init__.py
+-rw-r--r--   0        0        0     4698 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/constraint.py
+-rw-r--r--   0        0        0     3632 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/error_response.py
+-rw-r--r--   0        0        0     4135 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/foreign_key.py
+-rw-r--r--   0        0        0     4651 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/point_of_time.py
+-rw-r--r--   0        0        0     3549 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/point_of_time_offset.py
+-rw-r--r--   0        0        0     3630 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/point_of_time_statement.py
+-rw-r--r--   0        0        0     3630 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/point_of_time_timestamp.py
+-rw-r--r--   0        0        0     3297 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/primary_key.py
+-rw-r--r--   0        0        0     2875 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/success_response.py
+-rw-r--r--   0        0        0    11896 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/table.py
+-rw-r--r--   0        0        0    12629 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/table_clone.py
+-rw-r--r--   0        0        0     6275 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/table_column.py
+-rw-r--r--   0        0        0     3280 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/unique_key.py
+-rw-r--r--   0        0        0      925 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/__init__.py
+-rw-r--r--   0        0        0    31115 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_task.py
+-rw-r--r--   0        0        0     8563 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/context.py
+-rw-r--r--   0        0        0    29476 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/dagv1.py
+-rw-r--r--   0        0        0     1270 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/__init__.py
+-rw-r--r--   0        0        0    37724 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/api_client.py
+-rw-r--r--   0        0        0      897 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/api_response.py
+-rw-r--r--   0        0        0    13292 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/configuration.py
+-rw-r--r--   0        0        0     1674 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/paging.py
+-rw-r--r--   0        0        0      444 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/pydantic_compatibility.py
+-rw-r--r--   0        0        0    22713 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/rest.py
+-rw-r--r--   0        0        0      182 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/api/__init__.py
+-rw-r--r--   0        0        0   103843 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/api/task_api.py
+-rw-r--r--   0        0        0     1146 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/__init__.py
+-rw-r--r--   0        0        0     3414 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/cron_schedule.py
+-rw-r--r--   0        0        0     3628 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/error_response.py
+-rw-r--r--   0        0        0     3231 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/minutes_schedule.py
+-rw-r--r--   0        0        0     2871 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/success_response.py
+-rw-r--r--   0        0        0    11882 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/task.py
+-rw-r--r--   0        0        0     7942 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/task_run.py
+-rw-r--r--   0        0        0     4252 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/task_schedule.py
+-rw-r--r--   0        0        0       72 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_internal/__init__.py
+-rw-r--r--   0        0        0      307 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/__init__.py
+-rw-r--r--   0        0        0     8596 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/_warehouse.py
+-rw-r--r--   0        0        0     1010 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/__init__.py
+-rw-r--r--   0        0        0    37758 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/api_client.py
+-rw-r--r--   0        0        0      902 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/api_response.py
+-rw-r--r--   0        0        0    13296 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/configuration.py
+-rw-r--r--   0        0        0     1674 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/paging.py
+-rw-r--r--   0        0        0      444 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/pydantic_compatibility.py
+-rw-r--r--   0        0        0    22707 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/rest.py
+-rw-r--r--   0        0        0      202 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/api/__init__.py
+-rw-r--r--   0        0        0    77524 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/api/warehouse_api.py
+-rw-r--r--   0        0        0      788 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/models/__init__.py
+-rw-r--r--   0        0        0     3627 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/models/error_response.py
+-rw-r--r--   0        0        0     2870 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/models/success_response.py
+-rw-r--r--   0        0        0    16326 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/models/warehouse.py
+-rw-r--r--   0        0        0       15 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/.gitignore
+-rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/__init__.py
+-rw-r--r--   0        0        0      138 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/conftest.py
+-rw-r--r--   0        0        0      660 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/utils.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/__init__.py
+-rw-r--r--   0        0        0    15745 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/conftest.py
+-rw-r--r--   0        0        0     2365 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/setup_manually.py
+-rw-r--r--   0        0        0     5305 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/test_compute_pool.py
+-rw-r--r--   0        0        0     2158 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/test_cortex_search_service.py
+-rw-r--r--   0        0        0     6708 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/test_database.py
+-rw-r--r--   0        0        0     1903 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/test_image_repository.py
+-rw-r--r--   0        0        0      381 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/test_root.py
+-rw-r--r--   0        0        0     4004 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/test_schema.py
+-rw-r--r--   0        0        0     6043 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/test_service.py
+-rw-r--r--   0        0        0    15936 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/test_table.py
+-rw-r--r--   0        0        0    13804 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/test_warehouse.py
+-rw-r--r--   0        0        0      920 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/utils.py
+-rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/task/__init__.py
+-rw-r--r--   0        0        0      568 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/task/conftest.py
+-rw-r--r--   0        0        0     7767 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/task/test_create_or_update_task.py
+-rw-r--r--   0        0        0     9724 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/task/test_create_task.py
+-rw-r--r--   0        0        0     1580 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/task/test_drop_task.py
+-rw-r--r--   0        0        0     1608 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/task/test_execute_task.py
+-rw-r--r--   0        0        0     4397 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/task/test_load_task.py
+-rw-r--r--   0        0        0    10923 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/task/test_python_function.py
+-rw-r--r--   0        0        0     3154 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/task/test_show_task.py
+-rw-r--r--   0        0        0     1396 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/task/test_task_parameters.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/task/dag/__init__.py
+-rw-r--r--   0        0        0    25597 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/task/dag/test_dag.py
+-rw-r--r--   0        0        0       34 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/resources/testCSVheader.csv
+-rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/__init__.py
+-rw-r--r--   0        0        0     2349 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/conftest.py
+-rw-r--r--   0        0        0     2350 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/test_common.py
+-rw-r--r--   0        0        0     8851 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/test_database.py
+-rw-r--r--   0        0        0     2451 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/test_schema.py
+-rw-r--r--   0        0        0     6199 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/test_table.py
+-rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/api/__init__.py
+-rw-r--r--   0        0        0     4214 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/api/general_api_test.py
+-rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/bridge/__init__.py
+-rw-r--r--   0        0        0     7517 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/bridge/test_database.py
+-rw-r--r--   0        0        0     7104 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/bridge/test_executor.py
+-rw-r--r--   0        0        0     1803 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/bridge/test_rest_errors.py
+-rw-r--r--   0        0        0     4838 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/bridge/test_schema.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/resources/__init__.py
+-rw-r--r--   0        0        0     1141 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/resources/test_computepool_resource.py
+-rw-r--r--   0        0        0     2990 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/resources/test_service.py
+-rw-r--r--   0        0        0     1431 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/resources/test_task_resource.py
+-rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/task/__init__.py
+-rw-r--r--   0        0        0     1875 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/task/test_dagv1.py
+-rw-r--r--   0        0        0     4427 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/task/test_task_context.py
+-rw-r--r--   0        0        0      710 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/task/test_task_reference.py
+-rw-r--r--   0        0        0     1315 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/.gitignore
+-rw-r--r--   0        0        0    11339 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/LICENSE
+-rw-r--r--   0        0        0      405 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/README.md
+-rw-r--r--   0        0        0     4355 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/pyproject.toml
+-rw-r--r--   0        0        0     1808 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/PKG-INFO
```

### Comparing `snowflake_core-0.7.0/codegen/README.md` & `snowflake_core-0.8.0/codegen/README.md`

 * *Files 3% similar despite different names*

```diff
@@ -14,15 +14,15 @@
 `./generate.py` is the script that generates the code from the OpenAPI specs
 in that repository.  It handles both cloning that repository locally, and
 running the OpenAPI spec generator with our custom templates.
 
 Try `./generate.py --help` for options and details.
 
 You can generate the code against a commit other than `HEAD` on the spec repo
-`main` branch by using the `-b`/`--branch` option.
+`main` branch by using the `--ref` option.
 
 You can generate a subset of resources with the `-r`/`--resources` option, by
 specifying a comma-separated list of resources, or by using `:all:` (the
 default) to generate all supported resources.
 
 ## Generation history
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/_common.py` & `snowflake_core-0.8.0/src/snowflake/core/_common.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 # Copyright (c) 2012-2023 Snowflake Computing Inc. All rights reserved.
 
 import json
+import os
 import sys
 
 from abc import ABC, abstractmethod
 from enum import Enum, EnumMeta
 from typing import (
     TYPE_CHECKING,
     Any,
@@ -43,14 +44,27 @@
 
 UNALTERABLE_PARAMETERS = {
     "name",
     "tag"
 }
 
 
+def check_env_parameter_enabled(param: str, default: str = "False") -> bool:
+    return os.getenv(
+        param,
+        default,
+    ).lower() in (
+        "true",
+        "t",
+        "yes",
+        "y",
+        "on",
+    )
+
+
 def _is_an_update(parameters: Iterable[str]) -> bool:
     """Decide whether the parameters contain update-relevant values.
 
     Parameters:
         parameters: an iterable of parameters in the request
     """
     return len(set(parameters) - UNALTERABLE_PARAMETERS) > 0
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/_root.py` & `snowflake_core-0.8.0/src/snowflake/core/_root.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,19 @@
-import os
 
 from typing import Optional, Union
 
 from snowflake.connector import SnowflakeConnection
 from snowflake.snowpark.session import Session, _active_sessions
 
+from ._common import check_env_parameter_enabled
+from ._internal.snowapi_parameters import SnowApiParameters
 from ._internal.telemetry import ApiTelemetryClient
 from .compute_pool import ComputePoolCollection
 from .database import DatabaseCollection
+from .session import SnowAPISession
 from .warehouse import WarehouseCollection
 
 
 class Root:
     """The entry point of the Snowflake Core Python APIs that manage the Snowflake objects.
 
     Args:
@@ -60,29 +62,36 @@
             ).create()
             _active_sessions.remove(
                 self._session
             )  # This is tentatively to avoid a user has two active sessions.
         else:
             self._session = connection
             self._connection = connection._conn._conn
+
+        self._snowapi_session = SnowAPISession(self)
+        self._refresh_parameters()
+
         self._databases = DatabaseCollection(self)
         self._compute_pools = ComputePoolCollection(self)
         self._telemetry_client = ApiTelemetryClient(self._connection)
         self._warehouses = WarehouseCollection(self)
-        self._can_use_rest_api = os.getenv(
+        self._can_use_rest_api = check_env_parameter_enabled(
             "_SNOWFLAKE_CAN_USE_REST_API",
-            "False",
-        ).lower() in (
-            "true",
-            "t",
-            "yes",
-            "y",
-            "on",
+            "True"
+        )
+        self._enable_long_running_polling = check_env_parameter_enabled(
+            "_SNOWFLAKE_ENABLE_LONG_RUNNING_POLLING"
         )
 
+    def effective_parameters(self, refresh: bool = True) -> SnowApiParameters:
+        if refresh:
+            self._refresh_parameters()
+
+        return self._effective_parameters
+
     @property
     def connection(self) -> SnowflakeConnection:
         """Return the connection in use.
 
         This is the connection used to create this Root instance, or the
         Snowpark session's connection if this root is created from a
         session.
@@ -114,7 +123,13 @@
         # TODO: this needs to be fixed in the connector
         return self._connection.rest.token  # type: ignore[union-attr]
 
     @property
     def _master_token(self) -> Optional[str]:
         # TODO: this needs to be fixed in the connector
         return self._connection.rest.master_token  # type: ignore[union-attr]
+
+    def _refresh_parameters(self) -> None:
+        # In principle, self._effective_parameters should/can contain a lot of relevant parameters,
+        # but for now, we don't want so many and only care about the enablement ones.
+        self._effective_parameters = SnowApiParameters(
+            params_map=self._snowapi_session._get_api_enablement_parameters())
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/exceptions.py` & `snowflake_core-0.8.0/src/snowflake/core/exceptions.py`

 * *Files 4% similar despite different names*

```diff
@@ -178,7 +178,32 @@
     if path_to_item:
         for pth in path_to_item:
             if isinstance(pth, int):
                 result += f"[{pth}]"
             else:
                 result += f"['{pth}']"
     return result
+
+
+@public
+class InvalidResponseError(Exception):
+    """Raised when the api response is invalid."""
+
+    def __init__(
+        self,
+        reason: typing.Optional[str] = None
+    ) -> None:
+        super().__init__(reason)
+        self.reason = reason
+
+
+@public
+class LongRunningQueryTimeout(Exception):
+    """Raised when long running query timeout."""
+
+    def __init__(
+        self,
+        reason: typing.Optional[str] = None
+    ) -> None:
+        super().__init__(reason)
+        self.reason = reason
+
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/paging.py` & `snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/paging.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,24 +1,25 @@
-"""Defines an Iterator to represent a certain resource instances fetched from the Snowflake database."""
+"""Defines an Iterator to represent certain resource instances fetched from the Snowflake database."""
 
 from typing import Callable, Generic, Iterable, Iterator, Optional, TypeVar, Union, overload
-
+from functools import partial
 from public import public
 
-
 T = TypeVar("T")
 S = TypeVar("S")
 
-
 @public
-class PagedIter(Iterator[T], Generic[T]):
+class PagedIter(Iterable[T], Generic[T]):
     """A page-by-page iterator.
 
     Data fetched from the server is iterated over page by page, yielding items one by
-    one.  For PrPr, we won't have real paging. More for future use.
+    one.
+
+    This iterator works by accepting a closure/partial function, which it will delegate to
+    in order to fetch the next page, passing in only the chunk/page index it wants to get.
 
     Example:
         >>> from snowflake.core import Root
         >>> root = Root(connection)
         >>> tasks: TaskCollection = root.databases["mydb"].schemas["myschema"].tasks
         >>> task_iter = tasks.iter(like="my%")  # returns a PagedIter[Task]
         >>> for task_obj in task_iter:
@@ -34,24 +35,18 @@
         ...
 
     @overload
     def __init__(self, data: Iterable[S], map_: Callable[[S], T]) -> None:
         ...
 
     def __init__(
-        self,
-        data: Union[Iterable[T], Iterable[S]],
-        map_: Optional[Callable[[S], T]] = None,
+            self,
+            page_fetch_closure_,
+            number_of_chunks_=1,
     ) -> None:
-        self._data = data
-        if map_ is None:
-            self._map = lambda e: e
-        else:
-            self._map = map_
-        iterator = iter(self._data)
-        self._iter: Iterator[T] = map(self._map, iterator)
+        self._page_fetch_closure = page_fetch_closure_
+        self._number_of_chunks = number_of_chunks_
+        self._iter = iter(self)
 
     def __iter__(self) -> Iterator[T]:
-        return self._iter
-
-    def __next__(self) -> T:
-        return next(self._iter)
+        for chunk in range(self._number_of_chunks):
+            yield from self._page_fetch_closure(chunk_index=chunk)
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/rest.py` & `snowflake_core-0.8.0/src/snowflake/core/rest.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.7.0/src/snowflake/core/_internal/utils.py` & `snowflake_core-0.8.0/src/snowflake/core/_internal/utils.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,11 +1,13 @@
 from enum import Enum
 from re import compile
 from typing import Any, Dict, Optional, Union
 
+from snowflake.connector.description import PLATFORM
+
 
 # The following code is copied from snowpark's code /snowflake/snowpark/_internal/utils.py to avoid being broken
 # when snowpark changes the code.
 # We'll need to move the code to a common place.
 # Another solution is to move snowpark to the mono repo so the merge gate will find the breaking changes.
 # To address later.
 
@@ -23,20 +25,31 @@
     f"^(({SNOWFLAKE_ID_PATTERN}\\.){{0,2}}|({SNOWFLAKE_ID_PATTERN}\\.\\.)){SNOWFLAKE_ID_PATTERN}$"
 )
 
 class ApiClientType(Enum):
     NONE = 0
     BRIDGE = 1
     REST = 2
+    STORED_PROC = 3
 
 def validate_object_name(name: str) -> None:
     if not SNOWFLAKE_OBJECT_RE_PATTERN.match(name):
         raise ValueError(f"The object name '{name}' is invalid.")
 
 
+def is_running_inside_stored_procedure() -> bool:
+    """
+    Check if snowpy is running inside a stored procedure.
+
+    Returns:
+        bool: True if snowpy is running inside a stored procedure, False otherwise.
+    """
+    return PLATFORM == "XP"
+
+
 def validate_quoted_name(name: str) -> str:
     if DOUBLE_QUOTE in name[1:-1].replace(DOUBLE_QUOTE + DOUBLE_QUOTE, EMPTY_STRING):
         raise ValueError(f"Invalid Identifier {name}. "
                          f"The inside double quotes need to be escaped when the name itself is double quoted.")
     else:
         return name
 
@@ -60,16 +73,18 @@
     return name
 
 
 def try_single_quote_value(value: Any) -> str:
     """Single quote the value if the value is a string and not single quoted yet."""
     if value is None:
         return ""
-    if (not isinstance(value, str)) or (value[0] == "'" and value[-1] == "'"):
+    if not isinstance(value, str):
         return str(value)
+    if value[0] == "'" and value[-1] == "'": # quote wrapped the string
+        value = "".join(list(value)[1:-1])
     return f"""'{value.replace("'", "''")}'"""
 
 
 def double_quote_name(name: str) -> str:
     return DOUBLE_QUOTE + escape_quotes(name) + DOUBLE_QUOTE if name else name
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/executor.py` & `snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/executor.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/rest_errors.py` & `snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/rest_errors.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/snow_bridge.py` & `snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/snow_bridge.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/snow_request.py` & `snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/snow_request.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/resources/computepools_resource.py` & `snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/computepools_resource.py`

 * *Files 0% similar despite different names*

```diff
@@ -199,15 +199,15 @@
         return sql_str, self.snow_exec.execute(sql_str)[0]
 
     def resume_cp(self) -> tuple[str, Dict[str, Any]]:
         sql_str = f"ALTER COMPUTE POOL {self._pool_name} RESUME"
         return sql_str, self.snow_exec.execute(sql_str)[0]
 
     def stopallservices_cp(self) -> tuple[str, Dict[str, Any]]:
-        sql_str = f"ALTER COMPUTE POOL {self._pool_name} STOP ALL SERVICES"
+        sql_str = f"ALTER COMPUTE POOL {self._pool_name} STOP ALL"
         return sql_str, self.snow_exec.execute(sql_str)[0]
 
     def drop_cp(self) -> tuple[str, Dict[str, Any]]:
         if "ifExists" in self._query_params and self._query_params["ifExists"]:
             sql_str = f"DROP COMPUTE POOL IF EXISTS {self._pool_name}"
         else:
             sql_str = f"DROP COMPUTE POOL {self._pool_name} "
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/resources/database_resource.py` & `snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/database_resource.py`

 * *Files 5% similar despite different names*

```diff
@@ -105,21 +105,20 @@
             _, ret = self.create_or_alter_db()
         elif self._method == "GET":
             if self._is_collection:
                 _, ret = self.show_db()
             else:
                 _, ret = self.desc_db()
         elif self._method == "POST":
-            if self._action == "":
-                if self._is_collection:
-                    _, ret = self.create_db()
-                elif self._property == "clone":
+            if self._action == "" and self._is_collection:
+                _, ret = self.create_db()
+            elif self._action == "clone":
                     _, ret = self.clone_db()
-                else:
-                    _, ret = self.create_db_from_share()
+            elif self._action == 'from_share':
+                _, ret = self.create_db_from_share()
             elif self._action == "enable":
                 if self._property == "replication":
                     _, ret = self.enable_replication()
                 elif self._property == "failover":
                     _, ret = self.enable_failover()
                 else:
                     raise BadRequest(
@@ -188,14 +187,17 @@
                 "default_ddl_collation",
             ) and prop_v:
                 prop_v = try_single_quote_value(prop_v)
             coa_sql.append(f"{prop} = {prop_v}")
         # TODO: should other props be unset if they're missing?
         if "comment" not in self._prop or self._prop["comment"] is None:
             coa_sql.append("comment=null")
+        if len(coa_sql) == 1:
+            # Nothing is being updated, skip executing anything
+            return ("", dict())
         coa_sql_s = " ".join(coa_sql)
         return coa_sql_s, self.snow_exec.execute(coa_sql_s)[0]
 
     def show_db(self) -> tuple[str, List[Dict[str, Any]]]:
         sql_str = "SHOW DATABASES "
         if "like" in self._query_params:
             sql_str = sql_str + "LIKE '{}' ".format(self._query_params["like"])
@@ -329,17 +331,15 @@
         if createMode is not None:
             if createMode == "orReplace":
                 sql_str += "OR REPLACE "
             elif createMode == "ifNotExists":
                 sql_str += "IF NOT EXISTS "
         options = self._prop.get("options")
         sql_str += "DATABASE "
-        if "name" not in self._query_params:
-            raise BadRequest("Name is a required field for Creating a Compute Pool")
-        sql_str += f"{self._query_params['name']} FROM SHARE {self._query_params['share']} "
+        sql_str += f"{self._db_name} FROM SHARE {self._query_params['share']} "
 
         return sql_str, self.snow_exec.execute(sql_str)[0]
 
     def drop_db(self) -> tuple[str, Dict[str, Any]]:
         sql_str = "DROP DATABASE "
         createMode = self._query_params.get("createMode")
         if self._query_params.get("createMode", "") == "ifExists":
@@ -391,13 +391,15 @@
         for k in (
             "data_retention_time_in_days",
             "max_data_extension_time_in_days",
             "suspend_task_after_num_failures",
             "user_task_timeout_ms",
         ):
             resp[k] = None if k not in resp else int(resp[k])
+        if resp["comment"] == "":
+            resp["comment"] = None
         resp["name"] = normalize_name(resp["name"])
         return resp
 
     @staticmethod
     def _transform_show_responses(resp: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
         return list(map(DatabaseResource._transform_show_response, resp))
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/resources/imagerepo_resource.py` & `snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/imagerepo_resource.py`

 * *Files 2% similar despite different names*

```diff
@@ -111,17 +111,18 @@
             _, ret = self._drop_image_repo()
         else:
             raise BadRequest("Unsupported REST Verb used")
 
         return ret
 
     def _desc_image_repo(self) -> tuple[str, dict[str, Any]]:
-
         self._query_params["like"] = self._repo_name
         sql_str, resp = self._show_image_repo()
+        if not resp:
+            raise NotFound(f"Image repository {self._repo_name} does not exist or not authorized.")
         return sql_str, resp[0]
 
     def _show_image_repo(self) -> tuple[str, list[dict[str, Any]]]:
         sql_str = "SHOW IMAGE REPOSITORIES "
         if "like" in self._query_params.keys():
             sql_str = sql_str + " LIKE '%{}%' ".format(self._query_params["like"])
         sql_str = sql_str + f"in SCHEMA {self._database}.{self._schema} "
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/resources/resource_base.py` & `snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/resource_base.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/resources/schema_resource.py` & `snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/schema_resource.py`

 * *Files 1% similar despite different names*

```diff
@@ -112,18 +112,18 @@
             _, ret = self.create_or_alter_schema()
         elif self._method == "GET":
             if self._is_collection:
                 _, ret = self.show_schemas()
             else:
                 _, ret = self.desc_schema()
         elif self._method == "POST":
-            if self._is_collection:
-                _, ret = self.create_schema()
-            elif self._property == "clone":
+            if self._action == "clone":
                 _, ret = self.clone_schema()
+            elif self._is_collection:
+                _, ret = self.create_schema()
             else:
                 raise BadRequest(
                     f"Unsupported property '{self._property}' for action''"
                 )
         elif self._method == "DELETE":
             _, ret = self.drop_schema()
         else:
@@ -168,14 +168,17 @@
                 "default_ddl_collation",
             ) and prop_v:
                 prop_v = try_single_quote_value(prop_v)
             coa_sql.append(f"{prop} = {prop_v}")
         # TODO: should other props be unset if they're missing?
         if "comment" not in self._prop or self._prop["comment"] is None:
             coa_sql.append("comment=null")
+        if len(coa_sql) == 1:
+            # Nothing is being updated, skip executing anything
+            return ("", dict())
         coa_sql_s = " ".join(coa_sql)
         return coa_sql_s, self.snow_exec.execute(coa_sql_s)[0]
 
     def show_schemas(self) -> tuple[str, List[Dict[str, Any]]]:
         sql_str = "SHOW SCHEMAS "
         if "history" in self._query_params:
             sql_str = sql_str + "HISTORY "
@@ -337,13 +340,15 @@
         for k in (
             "data_retention_time_in_days",
             "max_data_extension_time_in_days",
             "suspend_task_after_num_failures",
             "user_task_timeout_ms",
         ):
             resp[k] = None if k not in resp else int(resp[k])
+        if resp["comment"] == "":
+            resp["comment"] = None
         resp["name"] = normalize_name(resp["name"])
         return resp
 
     @staticmethod
     def _transform_show_responses(resp: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
         return list(map(SchemaResource._transform_show_response, resp))
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/resources/services_resource.py` & `snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/services_resource.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 import operator
 
 from typing import Any, Dict, List, Optional, Tuple, Union
 from urllib.parse import unquote
 
 from snowflake.connector import SnowflakeConnection
 
-from ...utils import normalize_name
+from ...utils import normalize_name, try_single_quote_value
 from ..rest_errors import BadRequest
 from ..snow_request import SnowRequest
 from .resource_base import ResourceBase
 
 
 Results = Union[List[Dict[str, Any]], Dict[str, Any], str, None]
 
@@ -180,14 +180,16 @@
             }
             result_spec = {
                 "spec_type": "from_inline",
                 "spec_text": s["spec"],
             }
             service["spec"] = result_spec
             service["auto_resume"] = (s["auto_resume"] == "true")
+            if service["comment"] == "":
+                service["comment"] = None
             new_services.append(service)
         return new_services
 
     def show_status(self) -> Tuple[str, Dict[str, Optional[str]]]:
         # TODO Validate that all information is present in the call.
         sql_str = "CALL SYSTEM$GET_SERVICE_STATUS('{}.{}.{}', {})".format(
             self._database,
@@ -235,14 +237,16 @@
             sql_str = sql_str + " MIN_INSTANCES = {}".format(
                 self._prop["min_instances"]
             )
         if "max_instances" in self._prop:
             sql_str = sql_str + " MAX_INSTANCES = {}".format(
                 self._prop["max_instances"]
             )
+        if "comment" in self._prop:
+            sql_str += f" COMMENT = {try_single_quote_value(self._prop['comment'])}"
 
         return sql_str, self.snow_exec.execute(sql_str)[0]
 
     def suspend_service(self) -> Tuple[str, Dict[str, Any]]:
         if "ifExists" in self._query_params and self._query_params["ifExists"]:
             sql_str = f"ALTER SERVICE IF EXISTS {self._service_full_name} SUSPEND"
         else:
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/resources/table_resource.py` & `snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/table_resource.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,70 +20,66 @@
         "api",
         "v2",
         "databases",
         "database_name",
         "schemas",
         "schema_name",
         "tables",
-        "table_name",
-        "parameters",
-        "effective",
+        "table_name"
     ]
 
     def __init__(self, req: SnowRequest, conn_ob: SnowflakeConnection):
         super().__init__(conn_ob)
         self._database = ""
         self._dependents = False
-        self._is_collection = False
+        self._is_create_or_show = False
         self._method = req.method
         self._parameter_key = ""
         self._prop = req.body if req.body is not None else dict()
         self._query_params = req.query_params
         self._schema = ""
         self._full_table_name = ""
         self._table_name = ""
-        self._effective_parameter = False
 
         self._action, path = self._parse_url(req.url)
         self._init_resource_metadata(path)
 
     def _init_resource_metadata(self, path: str) -> None:
         """
         Resource action metadata initializer
 
         This function will validate the URL and extract
         any metadata required to route to the right
         sql translate function.
         """
         path_parts = path.strip("/").split("/")
-        self._is_collection = False
+        self._is_create_or_show = False
         self._database = normalize_name(
             unquote(path_parts[TableResource.table_components.index("database_name")])
         )
         self._schema = normalize_name(
             unquote(path_parts[TableResource.table_components.index("schema_name")])
         )
-        if len(path_parts) < TableResource.table_components.index("tables") + 1:
+        index_of_table_name_in_url = TableResource.table_components.index("table_name")
+
+        if len(path_parts) < TableResource.table_components.index("tables") + 1\
+            or len(path_parts) > index_of_table_name_in_url + 1:
             raise BadRequest("Malformed Resource URL")
-        elif len(path_parts) >= TableResource.table_components.index("table_name") + 1:
+
+        path_parts_contains_table_name = len(path_parts) >= index_of_table_name_in_url + 1
+        if path_parts_contains_table_name:
+            table_name = path_parts[index_of_table_name_in_url]
             self._table_name = normalize_name(
-                unquote(path_parts[TableResource.table_components.index("table_name")])
+                unquote(table_name)
             )
             self._full_table_name = f"{self._database}.{self._schema}.{self._table_name}"
-            if len(path_parts) > TableResource.table_components.index("table_name") + 1:
-                parameters = path_parts[
-                    TableResource.table_components.index("parameters")
-                ]
-                effective_parameter = path_parts[
-                    TableResource.table_components.index("effective")
-                ]
-                if parameters == "parameters" and effective_parameter == "effective":
-                    self._effective_parameter = True
-        elif len(path_parts) == TableResource.table_components.index("tables") + 1:
-            self._is_collection = True
+
+        self._is_create_or_show = (not path_parts_contains_table_name) or (
+            self._action in ('create_like', 'using_template', 'as_select')
+        )
 
     def execute(self) -> Union[List[Dict[str, Any]], Dict[str, Any]]:
         """
         Routing function
 
         Using the VERB from the Rest request and the
         metadata collected from the call route to the
@@ -94,22 +90,22 @@
         testability of individual functions.
         """
         ret: Union[List[Dict[str, Any]], Dict[str, Any]] = [{}]
         if self._method == "PUT":
             if self._full_table_name != "":
                 _, ret = self.create_or_alter_table()
         elif self._method == "GET":
-            # if self._effective_parameter:
-            #     _, ret = self.fetch_effective_parameters()
-            if self._is_collection:
+            if self._is_create_or_show:
                 _, ret = self.show_tables()
             elif self._full_table_name != "":
                 _, ret = self.desc_table()
         elif self._method == "POST":
-            if self._is_collection:
+            if self._action == 'clone':
+                _, ret = self.clone_table()
+            elif self._is_create_or_show:
                 _, ret = self.create_table()
             elif self._action != "":
                 if self._action == "undelete":
                     _, ret = self.undelete_table()
                 elif self._action == "suspend_recluster":
                     _, ret = self.suspend_recluster()
                 elif self._action == "resume_recluster":
@@ -125,32 +121,31 @@
                 raise BadRequest("Incorrect Path")
         else:
             raise BadRequest("REST VERB not supported")
 
         return ret
 
     def desc_table(self) -> Tuple[str, Dict[str, Any]]:
-        deep: bool = self._query_params["deep"]  # type: ignore
-        return self._desc_table(deep)
+        return self._desc_table()
 
-    def _desc_table(self, deep: bool = False) -> Tuple[str, Dict[str, Any]]:
+    def _desc_table(self) -> Tuple[str, Dict[str, Any]]:
         sql_str = f"SHOW tables like '{unquote_name(self._table_name)}' in schema {self._database}.{self._schema}"
         tables = self.snow_exec.execute(sql_str)
         if not tables:
             raise NotFound(f"Table {self._table_name} doesn't exist.")
         for table in tables:
             if normalize_name(table["name"]) == self._table_name:
-                self._validate_table([table], deep)
+                self._validate_table([table], True)
                 return sql_str, tables[0]
         raise NotFound(f"Table {self._table_name} doesn't exist.")
 
     def show_tables(self) -> Tuple[str, List[Dict[str, Any]]]:
         deep: bool = self._query_params["deep"]  # type: ignore
         sql_str = "SHOW "
-        if "terse" in self._query_params:
+        if not deep:
             sql_str += "TERSE "
 
         if self._query_params.get("history") is True:  # type: ignore
             sql_str += "HISTORY "
 
         sql_str += "TABLES "
 
@@ -199,22 +194,17 @@
         return sql_str, self.snow_exec.execute(sql_str)[0]
 
     def resume_recluster(self) -> Tuple[str, Dict[str, Any]]:
         sql_str = f"ALTER table {self._full_table_name} resume recluster "
         return sql_str, self.snow_exec.execute(sql_str)[0]
 
     def swap_with(self) -> Tuple[str, Dict[str, Any]]:
-        sql_str = f"ALTER table {self._full_table_name} SWAP WITH {self._query_params['to_swap_table_name']}"
+        sql_str = f"ALTER table {self._full_table_name} SWAP WITH {self._query_params['targetTableName']}"
         return sql_str, self.snow_exec.execute(sql_str)[0]
 
-    # def fetch_effective_parameters(self) -> Tuple[str, List[Dict[str, Any]]]:
-    #     sql = f"show parameters in table {self._full_table_name}"
-    #     parameters = self.snow_exec.execute(sql)
-    #     return sql, parameters
-
     def create_or_alter_table(self) -> Tuple[str, Dict[str, Any]]:
         """
         columns = t.get("columns")
         constraints = t.get("constraints")
         cluster_by = t.get("cluster_by")
         enable_schema_evolution: bool = t.get("enable_schema_evolution")  # type: ignore
         stage_file_format_name = t.get("stage_file_format_name")
@@ -227,15 +217,15 @@
         default_ddl_collation = t.get("default_ddl_collation")
         comment = t.get("comment")
         """
         if normalize_name(self._table_name) != normalize_name(self._prop["name"]):
             raise BadRequest(
                 f"Table name {self._table_name} in path doesn't match input Table object's name {self._prop['name']}")
         try:
-            _, original = self._desc_table(deep=True)
+            _, original = self._desc_table()
         except NotFound:
             return self.create_table()
         kind = self._prop.get("kind", "TABLE")
         if kind:
             kind = kind.lower()
         original_kind = original["kind"].lower()
         if kind != original_kind.lower() and not (kind == "temp" and original_kind == "temporary"):
@@ -297,19 +287,19 @@
                     column_sqls.append(f""" {normalized_column_name} comment '{new_column["comment"]}'""")
                 else:
                     column_sqls.append(f" {normalized_column_name} unset comment")
             new_collate = new_column.get("collate")
             if new_collate and old_column.get("collate", "").lower() != new_collate.lower():
                 raise BadRequest("Can't update a column collate.")
 
-            new_identity = bool(new_column.get("identity"))
-            old_identity = bool(old_column.get("identity"))
+            new_identity = bool(new_column.get("autoincrement"))
+            old_identity = bool(old_column.get("autoincrement"))
             if new_identity != old_identity:
-                raise BadRequest(f"'identity' of Column {column_name} can't be updated.")
-            for prop in ("identity_start", "identity_increment"):
+                raise BadRequest(f"'autoincrement' of Column {column_name} can't be updated.")
+            for prop in ("autoincrement_start", "autoincrement_increment"):
                 if old_column.get(prop) != new_column.get(prop):
                     raise BadRequest(f"'{prop}' of Column {column_name} can't be updated.")
             return ",".join(column_sqls)
 
         # process columns
         length = min(len(new_columns), len(original_columns))
         for i in range(length):
@@ -409,32 +399,45 @@
         # process cluster by
         new_cluster_by = new.get("cluster_by")
         if original.get("cluster_by") != new_cluster_by:
             if new_cluster_by:
                 sqls.append(f"alter table {full_table_name} cluster by ({','.join(new_cluster_by)})")
             else:
                 sqls.append(f"alter table {full_table_name} drop clustering key")
+
         # end of processing
         try:
             for query in sqls:
                 self.snow_exec.execute(query)
         except RestError as re:
             raise InternalServerError(
                 "Could not successfully put the table on Snowflake. "
                 "Kindly check for data inconsistencies"
             ) from re
 
         # We send one success message for the entire batch of SQL statements.
         return str(sqls), {"description": "successful"}
 
-    def create_table(self) -> Tuple[str, Dict[str, Any]]:
+    def get_new_table_name(self) -> str:
+        if self._action in ('using_template', 'as_select'):
+            table_name = self._table_name
+        elif self._action == 'create_like':
+            table_name = self._query_params["newTableName"]
+        else:
+            table_name = self._prop['name']
+
+        _, _, table_name = table_name.rpartition('.')
+        return table_name
+
+    def table_creation_prefix(self) -> str:
         kind = self._prop.get("kind", "")
         if kind and kind.lower().strip(" ") == "table":
             kind = ""
-        table_start_sql = f'{kind}  table {self._database}.{self._schema}.{normalize_name(self._prop["name"])}'
+        table_start_sql = f'{kind}  table {self._database}.{self._schema}.{normalize_name(self.get_new_table_name())}'
+
         sql_str = "CREATE "
         if "createMode" in self._query_params:
             createMode = self._query_params["createMode"]
             # No Op for errorIfExists as that is default behavior
             if createMode == "orReplace":
                 sql_str += f"OR REPLACE {table_start_sql} "
             elif createMode == "ifNotExists":
@@ -445,39 +448,83 @@
                 raise BadRequest(
                     "Unsupported createMode mentioned {}".format(
                         self._query_params["createMode"]
                     )
                 )
         else:
             sql_str += table_start_sql
+        sql_str += " "
+        return sql_str
 
-        template_query = self._query_params.get("template_query")
-        template_query = f" using template ({template_query})" if template_query else ""
-        clone_table = self._query_params.get("clone_table")
-        clone_table = f' clone {clone_table}' if clone_table else ""
-        like_table = self._query_params.get("like_table")
-        like_table = f' like {like_table}' if like_table else ""
-        as_select = self._query_params.get("as_select")
-        as_select = f' as {as_select}' if as_select else ""
+    def clone_table(self) -> Tuple[str, Dict[str, Any]]:
+        sql_str = self.table_creation_prefix()
+        if "name" not in self._prop:
+            raise BadRequest("Name is a required field for cloning a table")
+
+        clone: Union[str, None] = self._prop.get("name")
+        if clone is not None:
+            sql_str += f"CLONE {normalize_name(self._table_name)} "
+            pot = self._prop.get("point_of_time")
+            if pot is not None:
+                sql_str += f"{pot['reference'].upper()} ({pot['point_of_time_type'].upper()} => {pot[pot['point_of_time_type']]}) "
+        if "data_retention_time_in_days" in self._prop:
+            sql_str = sql_str + "DATA_RETENTION_TIME_IN_DAYS = {} ".format(
+                self._prop["data_retention_time_in_days"]
+            )
+        if "max_data_extension_time_in_days" in self._prop:
+            sql_str = sql_str + "MAX_DATA_EXTENSION_TIME_IN_DAYS = {} ".format(
+                self._prop["max_data_extension_time_in_days"]
+            )
+        if "default_ddl_collation" in self._prop and self._prop["default_ddl_collation"]:
+            sql_str = sql_str + "DEFAULT_DDL_COLLATION = {} ".format(
+                try_single_quote_value(self._prop["default_ddl_collation"])
+            )
+
+        if "comment" in self._prop:
+            sql_str = sql_str + "COMMENT = {} ".format(
+                try_single_quote_value(self._prop["comment"])
+            )
+
+        return sql_str, self.snow_exec.execute(sql_str)[0]
+
+    def create_table(self) -> Tuple[str, Dict[str, Any]]:
+        sql_str = self.table_creation_prefix()
+
+        create_table_query = self._get_create_table_query()
 
         copy_grants = self._query_params.get("copy_grants")
         copy_grants = " copy grants" if copy_grants else ""
 
         # TODO: Add policy, tags, search_optimization_targets
-        sql_str = f"{sql_str} {table_to_sql(self._prop)}{copy_grants}{template_query}{clone_table}{like_table}{as_select}"
+        sql_str = f"{sql_str} {table_to_sql(self._prop)}{copy_grants}{create_table_query}"
         return sql_str, self.snow_exec.execute(sql_str)[0]
 
+    def _get_create_table_query(self) -> str:
+        query = ""
+        if self._action == 'clone':
+            query += f' clone {self._prop}'
+        elif self._action == 'create_like':
+            query += f' like {self._full_table_name}'
+        elif self._action == 'as_select':
+            query += f' as {self._query_params.get("query")}'
+        elif self._action == 'using_template':
+            query += f' using template ({self._query_params.get("query")})'
+
+        return query
+
     def _validate_table(self, tables: List[Dict[str, Any]], deep: bool = False) -> List[Dict[str, Any]]:
         for t in tables:
             t["search_optimization"] = True if t.get("search_optimization") == "ON" else False
-            t["change_tracking"] = True if t["change_tracking"] == "ON" else False
+            t["change_tracking"] = True if t.get("change_tracking") == "ON" else False
             t["automatic_clustering"] = True if t.get("automatic_clustering") == "ON" else False
             t["enable_schema_evolution"] = True if t.get("enable_schema_evolution") == "Y" else False
-            t["data_retention_time_in_days"] = int(t["retention_time"])
-            cluster_by = t["cluster_by"]
+            retention_time = t.get("retention_time")
+            if retention_time:
+                t["data_retention_time_in_days"] = int(retention_time)
+            cluster_by = t.get("cluster_by")
             if cluster_by and cluster_by.startswith("LINEAR"):
                 cluster_by = cluster_by[7:-1]  # remove LINEAR( and ) to retrieve the value
             t["cluster_by"] = cluster_by.split(",") if cluster_by else None
             full_table_name = f"{double_quote_name(t['database_name'])}.{double_quote_name(t['schema_name'])}.{double_quote_name(t['name'])}"
             object_parameters = self._fetch_object_parameters(full_table_name)
             t["data_retention_time_in_days"] = object_parameters.get("DATA_RETENTION_TIME_IN_DAYS")
             t["max_data_extension_time_in_days"] = object_parameters.get("MAX_DATA_EXTENSION_TIME_IN_DAYS")
@@ -486,52 +533,54 @@
             delete_dict_key(t, "retention_time")
             delete_dict_key(t, "is_external")
             delete_dict_key(t, "is_event")
             delete_dict_key(t, "is_hybrid")
             if deep:
                 t["columns"] = self._fetch_columns(t["name"])
                 t["constraints"] = self._fetch_constraints(t["name"])
+            if t.get("comment") == "":
+                t["comment"] = None
         return tables
 
     def _fetch_object_parameters(self, table_name: str) -> Dict[str, Any]:
         sql = f"show parameters in table {table_name}"
         parameters = self.snow_exec.execute(sql)
         d = {}
         for table_level_parameter in [p for p in parameters if p["level"] == "TABLE"]:
             d[table_level_parameter["key"]] = _retrieve_parameter_value(table_level_parameter)
         return d
 
     def _fetch_columns(self, table_name: str) -> List[Dict[str, Any]]:
         sql = f"select COLUMN_NAME, DATA_TYPE, IS_NULLABLE, COLLATION_NAME, COLUMN_DEFAULT, " \
               f"IS_IDENTITY, IDENTITY_START, IDENTITY_INCREMENT, COMMENT " \
-              f"from information_schema.columns " \
+              f"from {self._database}.information_schema.columns " \
               f"where table_catalog='{self._database}' " \
               f"and table_schema='{self._schema}' and table_name= '{table_name}' order by ORDINAL_POSITION"
         # inline constraints can't be obtained.
         columns_data = self.snow_exec.execute(sql)
         columns = []
         for item in columns_data:
             column = {
                 "name": item["COLUMN_NAME"],
                 "datatype": item["DATA_TYPE"],
-                "nullable": True if item["IS_NULLABLE"] == "YES" else False,
+                "nullable": item["IS_NULLABLE"] == "YES",
                 "collate": item["COLLATION_NAME"],
                 "default": item["COLUMN_DEFAULT"],
-                "identity": True if item["IS_IDENTITY"] == "YES" else False,
-                "identity_start": item["IDENTITY_START"],
-                "identity_increment": item["IDENTITY_INCREMENT"],
+                "autoincrement": item["IS_IDENTITY"] == "YES",
+                "autoincrement_start": item["IDENTITY_START"],
+                "autoincrement_increment": item["IDENTITY_INCREMENT"],
                 "comment": item["COMMENT"],
             }
             columns.append(column)
         return columns
 
     def _fetch_constraints(self, table_name: str) -> List[Dict[str, Any]]:
         result = []
         constraints = self.snow_exec.execute(
-            f"select CONSTRAINT_NAME, CONSTRAINT_TYPE from information_schema.table_constraints where CONSTRAINT_CATALOG='{self._database}' and "
+            f"select CONSTRAINT_NAME, CONSTRAINT_TYPE from {self._database}.information_schema.table_constraints where CONSTRAINT_CATALOG='{self._database}' and "
             f"CONSTRAINT_SCHEMA = '{self._schema}' and TABLE_NAME = '{table_name}' order by CONSTRAINT_NAME"
         )
         primary_keys = self.snow_exec.execute(
             f"show primary keys in table {self._database}.{self._schema}.{double_quote_name(table_name)}"
         )
         unique_keys = self.snow_exec.execute(
             f"show unique keys in table {self._database}.{self._schema}.{double_quote_name(table_name)}"
@@ -628,24 +677,24 @@
 
 def column_to_sql(c: Dict[str, Any]) -> str:
     name = c["name"]
     datatype = c.get("datatype")
     nullable = c.get("nullable")
     collate = c.get("collate")
     default = c.get("default")
-    identity = c.get("identity")
-    identity_start = c.get("identity_start")
-    identity_increment = c.get("identity_increment")
+    autoincrement = c.get("autoincrement")
+    autoincrement_start = c.get("autoincrement_start")
+    autoincrement_increment = c.get("autoincrement_increment")
     constraint = c.get("constraint")
     comment = c.get("comment")
     cs = f"""{normalize_name(name)} {datatype}\
 {' not null' if not nullable else ''}\
 {name_value_to_sql("collate", collate, False, True)}\
 {' default' if default is not None else ""} {default if default is not None else ""}\
-{" identity" if identity else ""} {f"start {identity_start}" if identity_start is not None else ""} {f"increment {identity_increment}" if identity_increment else ""}\
+{" autoincrement" if autoincrement else ""} {f"start {autoincrement_start}" if autoincrement_start is not None else ""} {f"increment {autoincrement_increment}" if autoincrement_increment else ""}\
 {constraint_to_sql(constraint) if constraint is not None else ""}\
 {f" comment '{comment}'" if comment else ""}\
 """
     return cs
 
 
 def table_to_sql(t: Dict[str, Any]) -> str:
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/resources/task_resource.py` & `snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/task_resource.py`

 * *Files 0% similar despite different names*

```diff
@@ -292,15 +292,19 @@
                 "suspend_task_after_num_failures",
             ):
                 if self._prop.get(key) is None:
                     if desc_task.get(key) is not None:
                         coa_unset_prop_list.append(key)
                 elif self._prop[key] != desc_task.get(key):
                     value = self._prop[key]
-                    value = try_single_quote_value(value)
+                    if key in (
+                        "comment",
+                        "error_integration",
+                    ):
+                        value = try_single_quote_value(value)
                     coa_set_prop_list.append(f"{key.upper()} = {value}")
             elif key == "user_task_managed_initial_warehouse_size" and self._prop.get(
                 key
             ) != desc_task.get(key):
                 if key in self._prop:
                     raise BadRequest(
                         "Managed Warehouse cannot be changed on an existing resource"
@@ -450,15 +454,15 @@
             sql_str += "TASK "
 
         sql_str += "{}.{}.{} ".format(
             self._database, self._schema, normalize_name(self._prop["name"])
         )
 
         if "warehouse" in self._prop:
-            sql_str += "WAREHOUSE= {}, ".format(self._prop["warehouse"])
+            sql_str += "WAREHOUSE={}, ".format(self._prop["warehouse"])
         else:
             if "user_task_managed_initial_warehouse_size" in self._prop:
                 sql_str += "USER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE= '{}', ".format(
                     self._prop["user_task_managed_initial_warehouse_size"]
                 )
         schedule = self._prop.get("schedule", None) if self._prop is not None else None
         if schedule is not None:
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/_internal/bridge/resources/warehouse_resource.py` & `snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/warehouse_resource.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 
 from typing import Any, Dict, List, Union
 from urllib.parse import unquote
 
 from snowflake.connector import SnowflakeConnection
 from snowflake.core._common import _is_an_update
 
-from ...utils import normalize_name
+from ...utils import normalize_name, try_single_quote_value
 from ..rest_errors import BadRequest, NotFound
 from ..snow_request import SnowRequest
 from .resource_base import ResourceBase
 
 
 class WarehouseResource(ResourceBase):
     warehouse_prop_list = {
@@ -132,15 +132,18 @@
         if not _is_an_update(self._prop):
             raise BadRequest("Can not alter warehouse set with no parameters")
         sql_str = "ALTER WAREHOUSE "
         sql_str += self._prop["name"] + " "
         sql_str += "SET "
         for key in WarehouseResource.warehouse_prop_list["optional"]:
             if key in self._prop:
-                sql_str += f"{key.upper()} = {self._prop[key]} "
+                prop_v = self._prop[key]
+                if key in ("comment",) and prop_v:
+                    prop_v = try_single_quote_value(prop_v)
+                sql_str += f"{key.upper()} = {prop_v} "
 
         return sql_str, self.snow_exec.execute(sql_str)[0]
 
     def update_and_unset_warehouse(self) -> tuple[str, Dict[str, Any]]:
         for key in WarehouseResource.warehouse_prop_list["required"]:
             if key not in self._prop:
                 raise BadRequest(f"{key} is a required field for Updating a Warehouse")
@@ -191,14 +194,16 @@
     @staticmethod
     def _transform_warehouses(warehouses: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
         for w in warehouses:
             # Turn is_default and is_current to booleans
             for e in ('is_default', 'is_current'):
                 if e in w:
                     w[e] = (w[e] == 'Y')
+            if w["comment"] == "":
+                w["comment"] = None
         return warehouses
 
     def describe_warehouse(self) -> tuple[str, Dict[str, Any]]:
         sql_str = f"DESC WAREHOUSE {self._warehouse_name}"
         res = self.snow_exec.execute(sql_str)[0]
         obj_para_sql = f"SHOW PARAMETERS IN WAREHOUSE {self._warehouse_name}"
         object_parameters = self.snow_exec.execute(obj_para_sql)
@@ -241,17 +246,23 @@
         else:
             sql_str += "WAREHOUSE "
 
         if "name" not in self._prop:
             raise BadRequest("Name is a required field for Creating a Warehouse")
         sql_str += self._prop["name"] + " "
 
-        for key in WarehouseResource.warehouse_prop_list["optional"]:
-            if key in self._prop:
-                sql_str += f"{key.upper()} = {self._prop[key]} "
+        for key in filter(
+            lambda e: e in self._prop,
+            WarehouseResource.warehouse_prop_list["optional"],
+        ):
+            v = self._prop[key]
+            if key == "comment":
+                sql_str += f" COMMENT = {try_single_quote_value(v)}, "
+            else:
+                sql_str += f"{key.upper()} = {v} "
         return sql_str, self.snow_exec.execute(sql_str)[0]
 
     def create_or_update_warehouse(self) -> tuple[str, Dict[str, Any]]:
         show_sql = "SHOW WAREHOUSES LIKE '{}'".format(self._prop["name"])
         show_result = self.snow_exec.execute(show_sql)
         exist = False
         for exist_warehouse in show_result:
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/compute_pool/__init__.py` & `snowflake_core-0.8.0/src/snowflake/core/compute_pool/__init__.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.7.0/src/snowflake/core/compute_pool/_compute_pool.py` & `snowflake_core-0.8.0/src/snowflake/core/compute_pool/_compute_pool.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,16 +1,15 @@
-from typing import TYPE_CHECKING, Optional
+from typing import TYPE_CHECKING, Iterator, Optional
 
 from snowflake.core._common import AccountObjectCollectionParent, CreateMode, ObjectReferenceMixin
-from snowflake.core._internal.pydantic_compatibility import StrictStr
 from snowflake.core._internal.telemetry import api_telemetry
 from snowflake.core.compute_pool._generated.api import ComputePoolApi
-from snowflake.core.compute_pool._generated.api_client import BridgeApiClient
+from snowflake.core.compute_pool._generated.api_client import BridgeApiClient, StoredProcApiClient
 from snowflake.core.compute_pool._generated.models.compute_pool import ComputePoolModel as ComputePool
-from snowflake.core.paging import PagedIter
+from snowflake.core.compute_pool._generated.pydantic_compatibility import StrictStr
 
 
 if TYPE_CHECKING:
     from snowflake.core import Root
 
 
 class ComputePoolCollection(AccountObjectCollectionParent["ComputePoolResource"]):
@@ -20,15 +19,16 @@
         super().__init__(root, ref_class=ComputePoolResource)
         self._api = ComputePoolApi(
             root=root,
             resource_class=self._ref_class,
             bridge_client=BridgeApiClient(
                 root=root,
                 snowflake_connection=root.connection,
-            )
+            ),
+            sproc_client=StoredProcApiClient(root=self.root)
         )
 
     @api_telemetry
     def create(
         self,
         compute_pool: ComputePool,
         *,
@@ -61,29 +61,30 @@
     @api_telemetry
     def iter(
         self,
         *,
         like: Optional[str] = None,
         starts_with: Optional[str] = None,
         limit: Optional[int] = None,
-    ) -> PagedIter[ComputePool]:
+    ) -> Iterator[ComputePool]:
         """Look up compute pools in Snowflake."""
-        return PagedIter(
-            data=self._api.fetch_compute_pools(
-                StrictStr(like) if like is not None else None,
-                StrictStr(starts_with) if starts_with else None,
-                limit,
-                async_req=False,
-            ), map_=ComputePool._from_model,
-        )
+        compute_pools = self._api.fetch_compute_pools(
+            StrictStr(like) if like is not None else None,
+            StrictStr(starts_with) if starts_with else None,
+            limit,
+            async_req=False, )
+
+        return map(ComputePool._from_model, iter(compute_pools))
 
 
 class ComputePoolResource(ObjectReferenceMixin[ComputePoolCollection]):
     """A reference to a Compute Pool in Snowflake."""
 
+    _supports_rest_api = True
+
     def __init__(self, name: str, collection: ComputePoolCollection) -> None:
         self.name = name
         self.collection = collection
 
     @property
     def _api(self) -> ComputePoolApi:
         return self.collection._api
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/compute_pool/_generated/__init__.py` & `snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -6,14 +6,16 @@
     Snowflake Compute Pools API
 
     The Snowflake Compute Pools API is a REST API that you can use to access, update, and perform certain actions on Compute Pool resources.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 __version__ = "1.0.0"
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/compute_pool/_generated/api_client.py` & `snowflake_core-0.8.0/src/snowflake/core/session/_generated/api_client.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,37 +1,44 @@
 # coding: utf-8
 """
-    Snowflake Compute Pools API
+    Snowflake Session API
 
-    The Snowflake Compute Pools API is a REST API that you can use to access, update, and perform certain actions on Compute Pool resources.  # noqa: E501
+    The Snowflake Session API is a REST API that you can use to query your current session properties.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 from __future__ import absolute_import
 
 import atexit
 import datetime
+import time
 import typing
 from dateutil.parser import parse
 import json
 import mimetypes
 from multiprocessing.pool import ThreadPool
 import os
 import re
 import tempfile
 
 from urllib.parse import quote
 
-from snowflake.core.compute_pool._generated.configuration import Configuration
-import snowflake.core.compute_pool._generated.models
-from snowflake.core.compute_pool._generated import rest
-from snowflake.core.exceptions import _APIValueError, APIError
+from functools import partial
+
+from snowflake.core.session._generated.configuration import Configuration
+import snowflake.core.session._generated.models
+from snowflake.core.session._generated import rest
+from snowflake.core.session._generated.paging import PagedIter
+from snowflake.core.exceptions import _APIValueError, APIError, InvalidResponseError, LongRunningQueryTimeout
+from snowflake.core.version import __version__ as VERSION
 
 if typing.TYPE_CHECKING:
     from snowflake.core._root import Root
 
 
 class ApiClient(object):
     """Generic API client for OpenAPI client library builds.
@@ -62,41 +69,48 @@
         'float': float,
         'str': str,
         'bool': bool,
         'date': datetime.date,
         'datetime': datetime.datetime,
         'object': object,
     }
+    DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING = 600.0 # default 10 minutes for long running queries
     _pool = None
 
     def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
                  cookie=None, pool_threads=1):
         # use default configuraiton if none is provided
         if configuration is None:
             configuration = Configuration.get_default()
         self.configuration = configuration
         if (
             hasattr(root, "_connection")
+            and root._connection is not None
             and hasattr(root._connection, "_rest")
+            and root._connection._rest is not None
+            and hasattr(root._connection._rest, "_protocol")
+            and hasattr(root._connection._rest, "_host")
+            and hasattr(root._connection._rest, "_port")
         ):
             self.configuration.host = (
                 f"{root._connection._rest._protocol}://"
                 + root._connection._rest._host
                 + f":{root._connection._rest._port}"
             )
         self.pool_threads = pool_threads
 
         self.rest_client = rest.RESTClientObject(root, configuration)
         self.default_headers = {}
         if header_name is not None:
             self.default_headers[header_name] = header_value
         self.cookie = cookie
         # Set default User-Agent.
-        self.user_agent = 'OpenAPI-Generator/1.0.0/python'
+        self.user_agent = 'python_api/' + VERSION + ''
         self.client_side_validation = configuration.client_side_validation
+        self._enable_long_running_polling = getattr(root, "_enable_long_running_polling", False)
 
     def __enter__(self):
         return self
 
     def __exit__(self, exc_type, exc_value, traceback):
         self.close()
 
@@ -154,15 +168,15 @@
         It stores default ApiClient.
 
         :param default: object of ApiClient.
         """
         cls._default = default
 
     def __call_api(
-            self, resource_path, method, path_params=None,
+            self, root, resource_path, method, path_params=None,
             query_params=None, header_params=None, body=None, post_params=None,
             files=None, response_types_map=None, auth_settings=None,
             _return_http_data_only=None, collection_formats=None,
             _preload_content=True, _request_timeout=None, _host=None,
             _request_auth=None):
 
         config = self.configuration
@@ -218,22 +232,25 @@
         if query_params:
             query_params = self.sanitize_for_serialization(query_params)
             url_query = self.parameters_to_url_query(query_params,
                                                      collection_formats)
             url += "?" + url_query
 
         try:
-            # perform request and return response
-            response_data = self.request(
-                method, url,
+            # perform request and return response, maybe with retry
+            response_data = self.request_with_retry(
+                root,
+                method,
+                url,
                 query_params=query_params,
                 headers=header_params,
                 post_params=post_params, body=body,
                 _preload_content=_preload_content,
-                _request_timeout=_request_timeout)
+                _request_timeout=_request_timeout
+            )
         except APIError as e:
             if e.body:
                 e.body = e.body.decode('utf-8')
             raise e
 
         self.last_response = response_data
 
@@ -251,15 +268,52 @@
         #         match = re.search(r"charset=([a-zA-Z\-\d]+)[\s;]?", content_type)
         #     encoding = match.group(1) if match else "utf-8"
         #     response_data.data = response_data.data.decode(encoding)
 
         # deserialize response data
 
         if response_type:
-            return_data = self.deserialize(response_data, response_type)
+            large_results_resp = self.large_results(response_data)
+            if large_results_resp is None:
+                # regular, non-large results use case
+                return_data = self.deserialize(response_data, response_type)
+            else:
+                # This should be the normal way in which we figure out where to get the results from,
+                # as well as how many chunks there are to get. Due to a bug, we use the alternate logic
+                # (in the "else" clause) to infer the URL from the UUID
+                if "Link" in response_data.getheaders():
+                    results_path, num_chunks = self.get_path_and_chunk_count_from_header(response_data.getheaders()["Link"])
+                else:
+                    handler_id = large_results_resp['result_handler']
+                    results_path = '/api/v2/results/' + handler_id
+
+                    # If there is no "Link" header, there is just one chunk
+                    num_chunks = 1
+
+                # Closure for fetching the next chunk in the PagedIter iterator
+                def _fetch_next_chunk(chunk_index, deserialize_type):
+                    # For now, do this because query_params is not actually being used properly in self.request
+                    chunk_url = f'{self.configuration.host}{results_path}?page={chunk_index}'
+
+                    chunk_response_data = self.request(
+                        root,
+                        "GET",
+                        chunk_url,
+                        headers=header_params,
+                        _preload_content=True,
+                        _request_timeout=_request_timeout)
+
+                    return self.deserialize(chunk_response_data, deserialize_type)
+
+                if 'Iterable' in response_type:
+                    return PagedIter(partial(_fetch_next_chunk, deserialize_type=response_type), num_chunks)
+                else:
+                    # At most, we should only need to fetch one chunk if it's a point lookup,
+                    # i.e., one row return
+                    return_data = _fetch_next_chunk(0, response_type)
         else:
             return_data = None
 
         if _return_http_data_only:
             return (return_data)
         else:
             return (return_data, response_data.status,
@@ -335,42 +389,42 @@
 
         :return: object.
         """
         if data is None:
             return None
 
         if type(klass) == str:
-            if klass.startswith('List['):
-                sub_kls = re.match(r'List\[(.*)]', klass).group(1)
+            if klass.startswith('Iterable['):
+                sub_kls = re.match(r'Iterable\[(.*)]', klass).group(1)
                 return [self.__deserialize(sub_data, sub_kls)
                         for sub_data in data]
 
             if klass.startswith('Dict['):
                 sub_kls = re.match(r'Dict\[([^,]*), (.*)]', klass).group(2)
                 return {k: self.__deserialize(v, sub_kls)
                         for k, v in data.items()}
 
             # convert str to class
             if klass in self.NATIVE_TYPES_MAPPING:
                 klass = self.NATIVE_TYPES_MAPPING[klass]
             else:
-                klass = getattr(snowflake.core.compute_pool._generated.models, klass)
+                klass = getattr(snowflake.core.session._generated.models, klass)
 
         if klass in self.PRIMITIVE_TYPES:
             return self.__deserialize_primitive(data, klass)
         elif klass == object:
             return self.__deserialize_object(data)
         elif klass == datetime.date:
             return self.__deserialize_date(data)
         elif klass == datetime.datetime:
             return self.__deserialize_datetime(data)
         else:
             return self.__deserialize_model(data, klass)
 
-    def call_api(self, resource_path, method,
+    def call_api(self, root, resource_path, method,
                  path_params=None, query_params=None, header_params=None,
                  body=None, post_params=None, files=None,
                  response_types_map=None, auth_settings=None,
                  async_req=None, _return_http_data_only=None,
                  collection_formats=None,_preload_content=True,
                   _request_timeout=None, _host=None, _request_auth=None):
         """Makes the HTTP request (synchronous) and returns deserialized data.
@@ -410,88 +464,198 @@
             If async_req parameter is True,
             the request will be called asynchronously.
             The method will return the request thread.
             If parameter async_req is False or missing,
             then the method will return the response directly.
         """
         if not async_req:
-            return self.__call_api(resource_path, method,
-                                   path_params, query_params, header_params,
-                                   body, post_params, files,
-                                   response_types_map, auth_settings,
-                                   _return_http_data_only, collection_formats,
-                                   _preload_content, _request_timeout, _host,
-                                   _request_auth)
-
-        return self.pool.apply_async(self.__call_api, (resource_path,
-                                                       method, path_params,
-                                                       query_params,
-                                                       header_params, body,
-                                                       post_params, files,
-                                                       response_types_map,
-                                                       auth_settings,
-                                                       _return_http_data_only,
-                                                       collection_formats,
-                                                       _preload_content,
-                                                       _request_timeout,
-                                                       _host, _request_auth))
+            return self.__call_api(
+                root,
+                resource_path,
+                method,
+                path_params,
+                query_params,
+                header_params,
+                body,
+                post_params,
+                files,
+                response_types_map,
+                auth_settings,
+                _return_http_data_only,
+                collection_formats,
+                _preload_content,
+                _request_timeout,
+                _host,
+                _request_auth,
+            )
+
+        return self.pool.apply_async(
+            self.__call_api,
+            (
+                root,
+                resource_path,
+                method,
+                path_params,
+                query_params,
+                header_params,
+                body,
+                post_params,
+                files,
+                response_types_map,
+                auth_settings,
+                _return_http_data_only,
+                collection_formats,
+                _preload_content,
+                _request_timeout,
+                _host,
+                _request_auth,
+            )
+        )
 
-    def request(self, method, url, query_params=None, headers=None,
+
+    def request_with_retry(
+                self, root, method, url, query_params=None, headers=None,
+                post_params=None, body=None, _preload_content=True,
+                _request_timeout=None):
+        """
+            Response time by default one hour
+        """
+        enter_timing = time.time()
+        response_data = self.request(
+                root,
+                method,
+                url,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params, body=body,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout)
+
+        if response_data.status != 202 or not self._enable_long_running_polling:
+            return response_data
+
+        result_endpoint = response_data.getheader('Location')
+        if result_endpoint is None:
+            raise InvalidResponseError("Long Running Queries result endpoint is missing")
+
+        if _request_timeout is None:
+            _request_timeout = self.DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING
+        wait_for_results_timeout = enter_timing + _request_timeout
+
+        exponential_wait_time = 1 # wait time increases exponentially, 30% more everytime
+        while True:
+            time_remaining = wait_for_results_timeout - time.time()
+            if time_remaining <= 0:
+                break
+            wait_time = min(exponential_wait_time, time_remaining)
+            time.sleep(wait_time)
+            response_data = self.request(
+                root,
+                'GET',
+                self.configuration.host + result_endpoint,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params, body=body,
+                _preload_content=_preload_content,
+                _request_timeout=max(time_remaining - wait_time, 1)
+                # request_timeout can never be zero
+            )
+
+            if response_data.status != 202:
+                return response_data
+
+            exponential_wait_time *= 1.3
+
+        raise LongRunningQueryTimeout("Long running queries timeout")
+
+
+    def request(self, root, method, url, query_params=None, headers=None,
                 post_params=None, body=None, _preload_content=True,
                 _request_timeout=None):
         """Makes the HTTP request using RESTClient."""
         if method == "GET":
-            return self.rest_client.get_request(url,
-                                        query_params=query_params,
-                                        _preload_content=_preload_content,
-                                        _request_timeout=_request_timeout,
-                                        headers=headers)
+            return self.rest_client.get_request(
+                root,
+                url,
+                query_params=query_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                headers=headers,
+            )
         elif method == "HEAD":
-            return self.rest_client.head_request(url,
-                                         query_params=query_params,
-                                         _preload_content=_preload_content,
-                                         _request_timeout=_request_timeout,
-                                         headers=headers)
+            return self.rest_client.head_request(
+                root,
+                url,
+                query_params=query_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                headers=headers,
+            )
         elif method == "OPTIONS":
-            return self.rest_client.options_request(url,
-                                            query_params=query_params,
-                                            headers=headers,
-                                            _preload_content=_preload_content,
-                                            _request_timeout=_request_timeout)
+            return self.rest_client.options_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+            )
         elif method == "POST":
-            return self.rest_client.post_request(url,
-                                         query_params=query_params,
-                                         headers=headers,
-                                         post_params=post_params,
-                                         _preload_content=_preload_content,
-                                         _request_timeout=_request_timeout,
-                                         body=body)
+            return self.rest_client.post_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                body=body,
+            )
         elif method == "PUT":
-            return self.rest_client.put_request(url,
-                                        query_params=query_params,
-                                        headers=headers,
-                                        post_params=post_params,
-                                        _preload_content=_preload_content,
-                                        _request_timeout=_request_timeout,
-                                        body=body)
+            try:
+                return self.rest_client.put_request(
+                    root,
+                    url,
+                    query_params=query_params,
+                    headers=headers,
+                    post_params=post_params,
+                    _preload_content=_preload_content,
+                    _request_timeout=_request_timeout,
+                    body=body,
+                )
+            except APIError as error:
+                # Raise a more helpful user error if CoA is not supported for this resource;
+                # this is represented as either 405 or 501 on the server.
+                if error.status in (405, 501):
+                    raise NotImplementedError(
+                        'create_or_update is not yet supported for session. Updating session '
+                        'objects is not supported yet; use create() for creating a session.')
+                raise
+
         elif method == "PATCH":
-            return self.rest_client.patch_request(url,
-                                          query_params=query_params,
-                                          headers=headers,
-                                          post_params=post_params,
-                                          _preload_content=_preload_content,
-                                          _request_timeout=_request_timeout,
-                                          body=body)
+            return self.rest_client.patch_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                body=body,
+            )
         elif method == "DELETE":
-            return self.rest_client.delete_request(url,
-                                           query_params=query_params,
-                                           headers=headers,
-                                           _preload_content=_preload_content,
-                                           _request_timeout=_request_timeout,
-                                           body=body)
+            return self.rest_client.delete_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                body=body,
+            )
         else:
             raise _APIValueError(
                 "http method must be `GET`, `HEAD`, `OPTIONS`,"
                 " `POST`, `PATCH`, `PUT` or `DELETE`."
             )
 
     def parameters_to_tuples(self, params, collection_formats):
@@ -759,13 +923,73 @@
         :param data: dict, list.
         :param klass: class literal.
         :return: model object.
         """
 
         return klass.from_dict(data)
 
+    @staticmethod
+    def large_results(response):
+        try:
+            result = json.loads(response.data)
+            if ("result_handler" in result
+                    and "message" in result and
+                    'Large result set. Use provided Link' in result['message']):
+                return result
+            else:
+                return None
+        except ValueError:
+            pass
+
+        return None
+
+
+    @staticmethod
+    def get_path_and_chunk_count_from_header(links_str):
+        links_list = links_str.split(",")
+
+        def parse_links(s):
+            import re
+            # Use regex to extract necessary parts
+            #
+            # Explanation:
+            # The result links are provided to us in the form:
+            # '</api/v2/results/01b39664-0100-0001-0000-0000000430391?page=0>; rel="first"'
+            #
+            # We wish to find how many chunks there are by finding the one that has rel="last",
+            # therefore we find page index corresponding to the link with that rel value.
+            #
+            # 1. <(.*?)> matches and captures the URL inside the angle brackets
+            # 2. page=(\d+) matches 'page=' followed by one or more digits to find the page number
+            # 3. rel="([^"]*)" matches 'rel="'
+            pattern = r'<(.*?)\?page=(\d+)>; rel="([^"]*)"'
+
+            # Search using the regular expression
+            match = re.search(pattern, s)
+            if match:
+                parse_result = dict()
+                parse_result['url'], parse_result['page_number'], parse_result['rel_value'] = match.groups()
+                return parse_result
+
+            return None
+
+        parsed_links = [parse_links(link) for link in links_list]
+
+        # Find the last one
+        last_link = list(filter(lambda link: link['rel_value'].lower() == 'last', parsed_links)).pop()
+
+        # Return the URL; the number of chunks is the chunk index of the last page plus one
+        return last_link['url'], int(last_link['page_number']) + 1
+
 
 class BridgeApiClient(ApiClient):
     def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
                  cookie=None, pool_threads=1, snowflake_connection=None):
         ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
         self.rest_client = rest.BridgeClientObject(snowflake_connection)
+
+
+class StoredProcApiClient(ApiClient):
+    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
+                 cookie=None, pool_threads=1):
+        ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
+        self.rest_client = rest.StoredProcClientObject()
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/compute_pool/_generated/api_response.py` & `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/api_response.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 """API response object."""
 
 from __future__ import annotations
 from typing import Any, Dict, Optional
-from snowflake.core._internal.pydantic_compatibility import Field, StrictInt, StrictStr
+from snowflake.core.schema._generated.pydantic_compatibility import Field, StrictInt, StrictStr
 
 class ApiResponse:
     """
     API response object
     """
 
     status_code: Optional[StrictInt] = Field(None, description="HTTP status code")
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/compute_pool/_generated/configuration.py` & `snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/configuration.py`

 * *Files 0% similar despite different names*

```diff
@@ -4,14 +4,16 @@
     Snowflake Compute Pools API
 
     The Snowflake Compute Pools API is a REST API that you can use to access, update, and perform certain actions on Compute Pool resources.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 import copy
 import logging
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/compute_pool/_generated/rest.py` & `snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/rest.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,17 +1,19 @@
 # coding: utf-8
 
 """
-    Snowflake Compute Pools API
+    Snowflake Image Repository API
 
-    The Snowflake Compute Pools API is a REST API that you can use to access, update, and perform certain actions on Compute Pool resources.  # noqa: E501
+    The Snowflake Image Repository API is a REST API that you can use to access, update, and perform certain actions on Image Repository resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 import json
 import logging
@@ -49,17 +51,26 @@
     def __init__(self, root: "Root", *args, **kwargs):
         self.root = root
         self.pool_manager = create_connection_pool(
             *args,
             **kwargs,
         )
 
-    def request(self, method, url, query_params=None, headers=None,
-                body=None, post_params=None, _preload_content=True,
-                _request_timeout=None):
+    def request(
+        self,
+        root,
+        method,
+        url,
+        query_params=None,
+        headers=None,
+        body=None,
+        post_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
         """Perform requests.
 
         :param method: http request method
         :param url: http request url
         :param query_params: query parameters in the url
         :param headers: http request headers
         :param body: request json body, for `application/json`
@@ -104,64 +115,64 @@
 
                 # no content type provided or payload is json
                 if not headers.get('Content-Type') or re.search('json', headers['Content-Type'], re.IGNORECASE):
                     request_body = None
                     if body is not None:
                         request_body = json.dumps(body)
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 elif headers['Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         fields=post_params,
                         encode_multipart=False,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 elif headers['Content-Type'] == 'multipart/form-data':
                     # must del headers['Content-Type'], or the correct
                     # Content-Type which generated by urllib3 will be
                     # overwritten.
                     del headers['Content-Type']
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         fields=post_params,
                         encode_multipart=True,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 # Pass a `string` parameter directly in the body to support
                 # other content types than Json when `body` argument is
                 # provided in serialized form
                 elif isinstance(body, str) or isinstance(body, bytes):
                     request_body = body
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 else:
                     # Cannot generate the request from given parameters
                     msg = """Cannot prepare a request message for provided
                              arguments. Please check that your arguments match
                              declared content type."""
                     raise APIError(status=0, reason=msg)
             # For `GET`, `HEAD`
             else:
                 r = self.pool_manager.request(
-                    self.root._session_token,
+                    root,
                     method,
                     url,
                     fields={},
                     preload_content=_preload_content,
                     timeout=timeout,
                     headers=headers,
                 )
@@ -191,88 +202,139 @@
             if 500 <= r.status <= 599:
                 raise ServerError(http_resp=r)
 
             raise APIError(http_resp=r)
 
         return r
 
-    def get_request(self, url, headers=None, query_params=None, _preload_content=True,
-            _request_timeout=None):
-        return self.request("GET", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
-
-    def head_request(self, url, headers=None, query_params=None, _preload_content=True,
-             _request_timeout=None):
-        return self.request("HEAD", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
+    def get_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "GET",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def head_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "HEAD",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
 
-    def options_request(self, url, headers=None, query_params=None, post_params=None,
+    def options_request(self, root, url, headers=None, query_params=None, post_params=None,
                 body=None, _preload_content=True, _request_timeout=None):
-        return self.request("OPTIONS", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "OPTIONS",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def delete_request(self, url, headers=None, query_params=None, body=None,
+    def delete_request(self, root, url, headers=None, query_params=None, body=None,
                _preload_content=True, _request_timeout=None):
-        return self.request("DELETE", url,
-                            headers=headers,
-                            query_params=query_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "DELETE",
+            url,
+            headers=headers,
+            query_params=query_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def post_request(self, url, headers=None, query_params=None, post_params=None,
+    def post_request(self, root, url, headers=None, query_params=None, post_params=None,
              body=None, _preload_content=True, _request_timeout=None):
-        return self.request("POST", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "POST",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def put_request(self, url, headers=None, query_params=None, post_params=None,
+    def put_request(self, root, url, headers=None, query_params=None, post_params=None,
             body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PUT", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "PUT",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def patch_request(self, url, headers=None, query_params=None, post_params=None,
+    def patch_request(self, root, url, headers=None, query_params=None, post_params=None,
               body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PATCH", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "PATCH",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
 
 class BridgeClientObject(object):
 
     def __init__(self, snowflake_connection: SnowflakeConnection):
         self.bridge = SnowBridge(snowflake_connection)
 
-    def request(self, method, url, query_params=None, headers=None,
-                body=None, post_params=None, _preload_content=True,
-                _request_timeout=None):
+    def request(
+        self,
+        root,
+        method,
+        url,
+        query_params=None,
+        headers=None,
+        body=None,
+        post_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
         """Perform requests.
 
         :param method: http request method
         :param url: http request url
         :param query_params: query parameters in the url
         :param headers: http request headers
         :param body: request json body, for `application/json`
@@ -315,71 +377,378 @@
             if 500 <= r.status <= 599:
                 raise ServerError(http_resp=r)
 
             raise APIError(http_resp=r)
 
         return r
 
-    def get_request(self, url, headers=None, query_params=None, _preload_content=True,
-                    _request_timeout=None):
-        return self.request("GET", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
-
-    def head_request(self, url, headers=None, query_params=None, _preload_content=True,
-                     _request_timeout=None):
-        return self.request("HEAD", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
-
-    def options_request(self, url, headers=None, query_params=None, post_params=None,
-                        body=None, _preload_content=True, _request_timeout=None):
-        return self.request("OPTIONS", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def delete_request(self, url, headers=None, query_params=None, body=None,
-                       _preload_content=True, _request_timeout=None):
-        return self.request("DELETE", url,
-                            headers=headers,
-                            query_params=query_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def post_request(self, url, headers=None, query_params=None, post_params=None,
-                     body=None, _preload_content=True, _request_timeout=None):
-        return self.request("POST", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def put_request(self, url, headers=None, query_params=None, post_params=None,
-                    body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PUT", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def patch_request(self, url, headers=None, query_params=None, post_params=None,
-                      body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PATCH", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+    def get_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "GET",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def head_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "HEAD",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def options_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "OPTIONS",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def delete_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "DELETE",
+            url,
+            headers=headers,
+            query_params=query_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def post_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "POST",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def put_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PUT",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def patch_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PATCH",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+
+class StoredProcClientObject(object):
+
+    def request(
+        self,
+        root,
+        method,
+        url,
+        query_params={},
+        headers={},
+        body={},
+        post_params={},
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        """Perform requests.
+        :param method: http request method
+        :param url: http request url
+        :param query_params: query parameters in the url
+        :param headers: http request headers
+        :param body: request json body, for `application/json`
+        :param post_params: request post parameters,
+                            `application/x-www-form-urlencoded`
+                            and `multipart/form-data`
+        :param _preload_content: if False, the urllib3.HTTPResponse object will
+                                 be returned without reading/decoding response
+                                 data. Default is True.
+        :param _request_timeout: timeout setting for this request. If one
+                                 number provided, it will be total request
+                                 timeout. It can also be a pair (tuple) of
+                                 (connection, read) timeouts.
+        """
+        method = method.upper()
+        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
+                          'PATCH', 'OPTIONS']
+        import _snowflake
+        parsed_url = urllib3.util.parse_url(url)
+        response_dict = _snowflake.send_snow_api_request(method, parsed_url.path, dict(query_params), headers, body,
+                                                         post_params, _request_timeout)
+        json_content = json.loads(response_dict["content"])
+        if "data" in json_content:
+            r = urllib3.HTTPResponse(body=json.dumps(json_content["data"]))
+        else:
+            r = urllib3.HTTPResponse(body=json.dumps(json_content).encode("utf-8"))
+        r.status = response_dict["status"]
+        if _preload_content:
+            r = RESTResponse(r)
+            # log response body
+            logger.debug("response body: %s", r.data)
+
+        if not 200 <= r.status <= 299:
+            if r.status == 401:
+                raise UnauthorizedError(http_resp=r)
+
+            if r.status == 403:
+                raise ForbiddenError(http_resp=r)
+
+            if r.status == 404:
+                raise NotFoundError(http_resp=r)
+
+            if r.status == 409:
+                raise ConflictError(http_resp=r)
+
+            if 500 <= r.status <= 599:
+                raise ServerError(http_resp=r)
+
+            raise APIError(http_resp=r)
+
+        return r
+
+    def get_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "GET",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def head_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "HEAD",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def options_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "OPTIONS",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def delete_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "DELETE",
+            url,
+            headers=headers,
+            query_params=query_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def post_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "POST",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def put_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PUT",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def patch_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PATCH",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/compute_pool/_generated/api/compute_pool_api.py` & `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/api/schema_api.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,95 +1,125 @@
 # coding: utf-8
 
 """
-    Snowflake Compute Pools API
+    Snowflake Schema API
 
-    The Snowflake Compute Pools API is a REST API that you can use to access, update, and perform certain actions on Compute Pool resources.  # noqa: E501
+    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 import logging
 
 from typing_extensions import Annotated
-
-from typing_extensions import Annotated
 from pydantic import Field, StrictBool, StrictInt, StrictStr, constr, validator
 
 from typing import List, Optional
 
-from snowflake.core.compute_pool._generated.models.compute_pool import ComputePool
-from snowflake.core.compute_pool._generated.models.success_response import SuccessResponse
+from snowflake.core.schema._generated.models.model_schema import ModelSchema
+from snowflake.core.schema._generated.models.schema_clone import SchemaClone
+from snowflake.core.schema._generated.models.success_response import SuccessResponse
+from typing import Iterable
 
-from snowflake.core._internal.pydantic_compatibility import StrictBool, StrictInt, StrictStr, constr, validate_arguments, ValidationError, validator
-from snowflake.core._internal.utils import ApiClientType
 
-from snowflake.core.compute_pool._generated.api_client import ApiClient
+from snowflake.core.schema._generated.pydantic_compatibility import StrictBool, StrictInt, StrictStr, constr, validate_arguments, ValidationError, validator
+from snowflake.core._internal.snowapi_parameters import SnowApiParameters
+from snowflake.core._internal.utils import ApiClientType, is_running_inside_stored_procedure
+
 from snowflake.core.exceptions import (  # noqa: F401
     _APITypeError,
     _APIValueError
 )
 
 logger  = logging.getLogger(__name__)
 
-class ComputePoolApi(object):
+class SchemaApi(object):
     """NOTE: This class is auto generated by OpenAPI Generator
     Ref: https://openapi-generator.tech
 
     Do not edit the class manually.
     """
 
-    def __init__(self, root, resource_class, bridge_client):
+    def __init__(self, root, resource_class, bridge_client, sproc_client):
         self._root = root
-        self._rest_client = ApiClient.get_default(root)
+        self._resource_name = 'schema'
         self._resource_class = resource_class
         self._bridge_client = bridge_client
+        self._sproc_client = sproc_client
         self._chosen_client_type = ApiClientType.NONE
 
     @property
     def api_client(self):
         """
             chosen_client is the client we chose , either bridge or rest
-            new_chosen_client is the client we want to choose under the current situation ( value of _supports_rest_api + _can_use_rest_api )
+            new_chosen_client is the client we want to choose under the current situation ( value of
+            _supports_rest_api + _can_use_rest_api, and the server-controlled flag )
             We will log the change if we want to choose another client instead of the current one
         """
-        if self._resource_class._supports_rest_api and self._root._can_use_rest_api:
-            chosen_client = self._rest_client
-            new_chosen_client = ApiClientType.REST
+        from snowflake.core.schema._generated.api_client import ApiClient
+
+        # Small helper function for figuring out the correct 'REST' client to use if in stored proc or not
+        def _get_rest_client():
+            if is_running_inside_stored_procedure():
+                return self._sproc_client, ApiClientType.STORED_PROC
+            else:
+                return ApiClient.get_default(self._root), ApiClientType.REST
+
+        use_bridge_override = False
+
+        # We can force use of the bridge if the server dictates it so
+        # But, don't check it for non-resources; _resource_class is not set for non-resources.
+        if self._resource_class is not None:
+            use_bridge_override = self._root.effective_parameters(refresh = False).resource_should_use_client_bridge('schema')
+
+        # if the _resource_class is None (such as Session, which is not a resource), then it is implied
+        # that we use REST (or the stored_proc client)
+        if self._resource_class is None:
+            chosen_client, new_chosen_client = _get_rest_client()
+        elif use_bridge_override:
+            # Bridge override is in effect. Use the client bridge.
+            chosen_client = self._bridge_client
+            new_chosen_client = ApiClientType.BRIDGE
+        # Check if it supports REST before choosing the REST client.
+        elif self._resource_class._supports_rest_api and self._root._can_use_rest_api:
+            chosen_client, new_chosen_client = _get_rest_client()
+        # If all else fails, use the BRIDGE (if there is no REST support for this resource)
         else:
             chosen_client = self._bridge_client
             new_chosen_client = ApiClientType.BRIDGE
 
         if new_chosen_client != self._chosen_client_type:
             self._chosen_client_type = new_chosen_client
             logger.info("Going to use client-%s for this resource", new_chosen_client.name)
         return chosen_client
 
     @validate_arguments
-    def create_compute_pool(self, compute_pool : ComputePool, create_mode : Optional[StrictStr] = None, initially_suspended : Annotated[Optional[StrictBool], Field(description="Specifies whether the compute pool is created initially in the suspended state.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Create a compute pool  # noqa: E501
+    def create_or_alter_schema(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], model_schema : ModelSchema, **kwargs) -> SuccessResponse:  # noqa: E501
+        """Create a (or alter an existing) schema.  # noqa: E501
 
-        Create a compute pool, with standard create modifiers as query parameters. See the Compute Pool component definition for what is required to be provided in the request body.  # noqa: E501
+        Create a (or alter an existing) schema. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_compute_pool(compute_pool, create_mode, initially_suspended, async_req=True)
+        >>> thread = api.create_or_alter_schema(database, name, model_schema, async_req=True)
         >>> result = thread.get()
 
-        :param compute_pool: (required)
-        :type compute_pool: ComputePool
-        :param create_mode:
-        :type create_mode: str
-        :param initially_suspended: Specifies whether the compute pool is created initially in the suspended state.
-        :type initially_suspended: bool
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :type database: str
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :type name: str
+        :param model_schema: (required)
+        :type model_schema: ModelSchema
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
@@ -98,33 +128,33 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.create_compute_pool_with_http_info(compute_pool, create_mode, initially_suspended, **kwargs)  # noqa: E501
+        return self.create_or_alter_schema_with_http_info(database, name, model_schema, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def create_compute_pool_with_http_info(self, compute_pool : ComputePool, create_mode : Optional[StrictStr] = None, initially_suspended : Annotated[Optional[StrictBool], Field(description="Specifies whether the compute pool is created initially in the suspended state.")] = None, **kwargs):  # noqa: E501
-        """Create a compute pool  # noqa: E501
+    def create_or_alter_schema_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], model_schema : ModelSchema, **kwargs):  # noqa: E501
+        """Create a (or alter an existing) schema.  # noqa: E501
 
-        Create a compute pool, with standard create modifiers as query parameters. See the Compute Pool component definition for what is required to be provided in the request body.  # noqa: E501
+        Create a (or alter an existing) schema. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_compute_pool_with_http_info(compute_pool, create_mode, initially_suspended, async_req=True)
+        >>> thread = api.create_or_alter_schema_with_http_info(database, name, model_schema, async_req=True)
         >>> result = thread.get()
 
-        :param compute_pool: (required)
-        :type compute_pool: ComputePool
-        :param create_mode:
-        :type create_mode: str
-        :param initially_suspended: Specifies whether the compute pool is created initially in the suspended state.
-        :type initially_suspended: bool
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :type database: str
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :type name: str
+        :param model_schema: (required)
+        :type model_schema: ModelSchema
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -144,17 +174,17 @@
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
-            'compute_pool',
-            'create_mode',
-            'initially_suspended'
+            'database',
+            'name',
+            'model_schema'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -165,42 +195,42 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method create_compute_pool" % _key
+                    " to method create_or_alter_schema" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+        if _params['database']:
+            _path_params['database'] = _params['database']
+        if _params['name']:
+            _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
-        if _params.get('create_mode') is not None:  # noqa: E501
-            _query_params.append(('createMode', _params['create_mode']))
-        if _params.get('initially_suspended') is not None:  # noqa: E501
-            _query_params.append(('initiallySuspended', _params['initially_suspended']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
-        if _params['compute_pool']:
-            _body_params = _params['compute_pool']
+        if _params['model_schema']:
+            _body_params = _params['model_schema']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # set the HTTP header `Content-Type`
         _content_types_list = _params.get('_content_type',
@@ -215,22 +245,22 @@
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
-            '409': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/compute-pools', 'POST',
+            self._root,
+            '/api/v2/databases/{database}/schemas/{name}', 'PUT',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -239,28 +269,34 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def create_or_alter_compute_pool(self, name : constr(strict=True), compute_pool : ComputePool, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Create a (or alter an existing) compute pool.  # noqa: E501
+    def create_schema(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], model_schema : ModelSchema, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of schema. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, with_managed_access : Annotated[Optional[StrictBool], Field(description="Specifies a managed schema. Managed access schemas centralize privilege management with the schema owner.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+        """Create a schema  # noqa: E501
 
-        Create a (or alter an existing) compute pool. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
+        Create a schema, with modifiers as query parameters. See the schema definition for what is required to be provided in the request body. (Cloning not currently supported)  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_or_alter_compute_pool(name, compute_pool, async_req=True)
+        >>> thread = api.create_schema(database, model_schema, create_mode, kind, with_managed_access, async_req=True)
         >>> result = thread.get()
 
-        :param name: (required)
-        :type name: str
-        :param compute_pool: (required)
-        :type compute_pool: ComputePool
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :type database: str
+        :param model_schema: (required)
+        :type model_schema: ModelSchema
+        :param create_mode: A query parameter allowing support for different modes of resource creation.
+        :type create_mode: str
+        :param kind: Type of schema. At the time of writing this transient and permanent (represented by the empty string) are supported.
+        :type kind: str
+        :param with_managed_access: Specifies a managed schema. Managed access schemas centralize privilege management with the schema owner.
+        :type with_managed_access: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
@@ -269,31 +305,37 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.create_or_alter_compute_pool_with_http_info(name, compute_pool, **kwargs)  # noqa: E501
+        return self.create_schema_with_http_info(database, model_schema, create_mode, kind, with_managed_access, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def create_or_alter_compute_pool_with_http_info(self, name : constr(strict=True), compute_pool : ComputePool, **kwargs):  # noqa: E501
-        """Create a (or alter an existing) compute pool.  # noqa: E501
+    def create_schema_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], model_schema : ModelSchema, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of schema. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, with_managed_access : Annotated[Optional[StrictBool], Field(description="Specifies a managed schema. Managed access schemas centralize privilege management with the schema owner.")] = None, **kwargs):  # noqa: E501
+        """Create a schema  # noqa: E501
 
-        Create a (or alter an existing) compute pool. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
+        Create a schema, with modifiers as query parameters. See the schema definition for what is required to be provided in the request body. (Cloning not currently supported)  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_or_alter_compute_pool_with_http_info(name, compute_pool, async_req=True)
+        >>> thread = api.create_schema_with_http_info(database, model_schema, create_mode, kind, with_managed_access, async_req=True)
         >>> result = thread.get()
 
-        :param name: (required)
-        :type name: str
-        :param compute_pool: (required)
-        :type compute_pool: ComputePool
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :type database: str
+        :param model_schema: (required)
+        :type model_schema: ModelSchema
+        :param create_mode: A query parameter allowing support for different modes of resource creation.
+        :type create_mode: str
+        :param kind: Type of schema. At the time of writing this transient and permanent (represented by the empty string) are supported.
+        :type kind: str
+        :param with_managed_access: Specifies a managed schema. Managed access schemas centralize privilege management with the schema owner.
+        :type with_managed_access: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -313,16 +355,19 @@
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
-            'name',
-            'compute_pool'
+            'database',
+            'model_schema',
+            'create_mode',
+            'kind',
+            'with_managed_access'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -333,40 +378,46 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method create_or_alter_compute_pool" % _key
+                    " to method create_schema" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['name']:
-            _path_params['name'] = _params['name']
+        if _params['database']:
+            _path_params['database'] = _params['database']
 
         # process the query parameters
         _query_params = []
+        if _params.get('create_mode') is not None:  # noqa: E501
+            _query_params.append(('createMode', _params['create_mode']))
+        if _params.get('kind') is not None:  # noqa: E501
+            _query_params.append(('kind', _params['kind']))
+        if _params.get('with_managed_access') is not None:  # noqa: E501
+            _query_params.append(('with_managed_access', _params['with_managed_access']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
-        if _params['compute_pool']:
-            _body_params = _params['compute_pool']
+        if _params['model_schema']:
+            _body_params = _params['model_schema']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # set the HTTP header `Content-Type`
         _content_types_list = _params.get('_content_type',
@@ -381,21 +432,23 @@
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '409': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/compute-pools/{name}', 'PUT',
+            self._root,
+            '/api/v2/databases/{database}/schemas', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -404,28 +457,36 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def delete_compute_pool(self, name : constr(strict=True), if_exists : Optional[StrictBool] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Delete a compute pool  # noqa: E501
+    def clone_schema(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], schema_clone : SchemaClone, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of schema. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, with_managed_access : Annotated[Optional[StrictBool], Field(description="Specifies a managed schema. Managed access schemas centralize privilege management with the schema owner.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+        """Clone a schema  # noqa: E501
 
-        Delete a compute pool with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a 404 failure if the drop is unsuccessful.  # noqa: E501
+        Clone an existing schema, with modifiers as query parameters. See the schema definition for what is required to be provided in the request body. (Cloning not currently supported)  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.delete_compute_pool(name, if_exists, async_req=True)
+        >>> thread = api.clone_schema(database, name, schema_clone, create_mode, kind, with_managed_access, async_req=True)
         >>> result = thread.get()
 
-        :param name: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :type database: str
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists:
-        :type if_exists: bool
+        :param schema_clone: (required)
+        :type schema_clone: SchemaClone
+        :param create_mode: A query parameter allowing support for different modes of resource creation.
+        :type create_mode: str
+        :param kind: Type of schema. At the time of writing this transient and permanent (represented by the empty string) are supported.
+        :type kind: str
+        :param with_managed_access: Specifies a managed schema. Managed access schemas centralize privilege management with the schema owner.
+        :type with_managed_access: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
@@ -434,31 +495,39 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.delete_compute_pool_with_http_info(name, if_exists, **kwargs)  # noqa: E501
+        return self.clone_schema_with_http_info(database, name, schema_clone, create_mode, kind, with_managed_access, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def delete_compute_pool_with_http_info(self, name : constr(strict=True), if_exists : Optional[StrictBool] = None, **kwargs):  # noqa: E501
-        """Delete a compute pool  # noqa: E501
+    def clone_schema_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], schema_clone : SchemaClone, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of schema. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, with_managed_access : Annotated[Optional[StrictBool], Field(description="Specifies a managed schema. Managed access schemas centralize privilege management with the schema owner.")] = None, **kwargs):  # noqa: E501
+        """Clone a schema  # noqa: E501
 
-        Delete a compute pool with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a 404 failure if the drop is unsuccessful.  # noqa: E501
+        Clone an existing schema, with modifiers as query parameters. See the schema definition for what is required to be provided in the request body. (Cloning not currently supported)  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.delete_compute_pool_with_http_info(name, if_exists, async_req=True)
+        >>> thread = api.clone_schema_with_http_info(database, name, schema_clone, create_mode, kind, with_managed_access, async_req=True)
         >>> result = thread.get()
 
-        :param name: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :type database: str
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists:
-        :type if_exists: bool
+        :param schema_clone: (required)
+        :type schema_clone: SchemaClone
+        :param create_mode: A query parameter allowing support for different modes of resource creation.
+        :type create_mode: str
+        :param kind: Type of schema. At the time of writing this transient and permanent (represented by the empty string) are supported.
+        :type kind: str
+        :param with_managed_access: Specifies a managed schema. Managed access schemas centralize privilege management with the schema owner.
+        :type with_managed_access: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -478,16 +547,20 @@
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
+            'database',
             'name',
-            'if_exists'
+            'schema_clone',
+            'create_mode',
+            'kind',
+            'with_managed_access'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -498,62 +571,79 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method delete_compute_pool" % _key
+                    " to method clone_schema" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+        if _params['database']:
+            _path_params['database'] = _params['database']
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
-        if _params.get('if_exists') is not None:  # noqa: E501
-            _query_params.append(('ifExists', _params['if_exists']))
+        if _params.get('create_mode') is not None:  # noqa: E501
+            _query_params.append(('createMode', _params['create_mode']))
+        if _params.get('kind') is not None:  # noqa: E501
+            _query_params.append(('kind', _params['kind']))
+        if _params.get('with_managed_access') is not None:  # noqa: E501
+            _query_params.append(('with_managed_access', _params['with_managed_access']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
+        if _params['schema_clone']:
+            _body_params = _params['schema_clone']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
+        # set the HTTP header `Content-Type`
+        _content_types_list = _params.get('_content_type',
+            self.api_client.select_header_content_type(
+                ['application/json']))
+        if _content_types_list:
+                _header_params['Content-Type'] = _content_types_list
+
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '409': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/compute-pools/{name}', 'DELETE',
+            self._root,
+            '/api/v2/databases/{database}/schemas/{name}:clone', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -562,56 +652,60 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def fetch_compute_pool(self, name : constr(strict=True), **kwargs) -> ComputePool:  # noqa: E501
-        """Fetch a compute pool.  # noqa: E501
+    def fetch_schema(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> ModelSchema:  # noqa: E501
+        """fetch_schema  # noqa: E501
 
-        Fetch a compute pool using the SHOW command output.  # noqa: E501
+        Fetch a schema.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_compute_pool(name, async_req=True)
+        >>> thread = api.fetch_schema(database, name, async_req=True)
         >>> result = thread.get()
 
-        :param name: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :type database: str
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: ComputePool
+        :rtype: ModelSchema
         """
         kwargs['_return_http_data_only'] = True
-        return self.fetch_compute_pool_with_http_info(name, **kwargs)  # noqa: E501
+        return self.fetch_schema_with_http_info(database, name, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def fetch_compute_pool_with_http_info(self, name : constr(strict=True), **kwargs):  # noqa: E501
-        """Fetch a compute pool.  # noqa: E501
+    def fetch_schema_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
+        """fetch_schema  # noqa: E501
 
-        Fetch a compute pool using the SHOW command output.  # noqa: E501
+        Fetch a schema.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_compute_pool_with_http_info(name, async_req=True)
+        >>> thread = api.fetch_schema_with_http_info(database, name, async_req=True)
         >>> result = thread.get()
 
-        :param name: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :type database: str
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -626,20 +720,21 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(ComputePool, status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(ModelSchema, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
+            'database',
             'name'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
@@ -651,23 +746,25 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method fetch_compute_pool" % _key
+                    " to method fetch_schema" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+        if _params['database']:
+            _path_params['database'] = _params['database']
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
@@ -684,27 +781,28 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "ComputePool",
+            '200': "ModelSchema",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/compute-pools/{name}', 'GET',
+            self._root,
+            '/api/v2/databases/{database}/schemas/{name}', 'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -713,65 +811,77 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def fetch_compute_pools(self, like : Optional[StrictStr] = None, starts_with : Optional[StrictStr] = None, show_limit : Optional[StrictInt] = None, **kwargs) -> List[ComputePool]:  # noqa: E501
-        """List compute pools  # noqa: E501
+    def list_schemas(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, starts_with : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.")] = None, show_limit : Annotated[Optional[StrictInt], Field(description="A query parameter that limits the maximum number of rows returned by a command.")] = None, from_name : Annotated[Optional[StrictStr], Field(description="A query parameter enables fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name.")] = None, history : Annotated[Optional[StrictBool], Field(description="Includes dropped schemas that have not yet been purged.")] = None, **kwargs) -> Iterable[ModelSchema]:  # noqa: E501
+        """List schemas  # noqa: E501
 
-        Lists the compute pools under the account.  # noqa: E501
+        Lists the accessible schemas.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_compute_pools(like, starts_with, show_limit, async_req=True)
+        >>> thread = api.list_schemas(database, like, starts_with, show_limit, from_name, history, async_req=True)
         >>> result = thread.get()
 
-        :param like:
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :type database: str
+        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
         :type like: str
-        :param starts_with:
+        :param starts_with: A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
         :type starts_with: str
-        :param show_limit:
+        :param show_limit: A query parameter that limits the maximum number of rows returned by a command.
         :type show_limit: int
+        :param from_name: A query parameter enables fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name.
+        :type from_name: str
+        :param history: Includes dropped schemas that have not yet been purged.
+        :type history: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: List[ComputePool]
+        :rtype: Iterable[ModelSchema]
         """
         kwargs['_return_http_data_only'] = True
-        return self.fetch_compute_pools_with_http_info(like, starts_with, show_limit, **kwargs)  # noqa: E501
+        return self.list_schemas_with_http_info(database, like, starts_with, show_limit, from_name, history, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def fetch_compute_pools_with_http_info(self, like : Optional[StrictStr] = None, starts_with : Optional[StrictStr] = None, show_limit : Optional[StrictInt] = None, **kwargs):  # noqa: E501
-        """List compute pools  # noqa: E501
+    def list_schemas_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, starts_with : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.")] = None, show_limit : Annotated[Optional[StrictInt], Field(description="A query parameter that limits the maximum number of rows returned by a command.")] = None, from_name : Annotated[Optional[StrictStr], Field(description="A query parameter enables fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name.")] = None, history : Annotated[Optional[StrictBool], Field(description="Includes dropped schemas that have not yet been purged.")] = None, **kwargs):  # noqa: E501
+        """List schemas  # noqa: E501
 
-        Lists the compute pools under the account.  # noqa: E501
+        Lists the accessible schemas.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_compute_pools_with_http_info(like, starts_with, show_limit, async_req=True)
+        >>> thread = api.list_schemas_with_http_info(database, like, starts_with, show_limit, from_name, history, async_req=True)
         >>> result = thread.get()
 
-        :param like:
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :type database: str
+        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
         :type like: str
-        :param starts_with:
+        :param starts_with: A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
         :type starts_with: str
-        :param show_limit:
+        :param show_limit: A query parameter that limits the maximum number of rows returned by a command.
         :type show_limit: int
+        :param from_name: A query parameter enables fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name.
+        :type from_name: str
+        :param history: Includes dropped schemas that have not yet been purged.
+        :type history: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -785,23 +895,26 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(List[ComputePool], status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(Iterable[ModelSchema], status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
+            'database',
             'like',
             'starts_with',
-            'show_limit'
+            'show_limit',
+            'from_name',
+            'history'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -812,32 +925,38 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method fetch_compute_pools" % _key
+                    " to method list_schemas" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+        if _params['database']:
+            _path_params['database'] = _params['database']
 
         # process the query parameters
         _query_params = []
         if _params.get('like') is not None:  # noqa: E501
             _query_params.append(('like', _params['like']))
         if _params.get('starts_with') is not None:  # noqa: E501
             _query_params.append(('startsWith', _params['starts_with']))
         if _params.get('show_limit') is not None:  # noqa: E501
             _query_params.append(('showLimit', _params['show_limit']))
+        if _params.get('from_name') is not None:  # noqa: E501
+            _query_params.append(('fromName', _params['from_name']))
+        if _params.get('history') is not None:  # noqa: E501
+            _query_params.append(('history', _params['history']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -849,329 +968,28 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "List[ComputePool]",
-            '400': "ErrorResponse",
-            '401': "ErrorResponse",
-            '403': "ErrorResponse",
-            '404': "ErrorResponse",
-            '405': "ErrorResponse",
-            '500': "ErrorResponse",
-            '503': "ErrorResponse",
-            '504': "ErrorResponse",
-        }
-
-        return self.api_client.call_api(
-            '/api/v2/compute-pools', 'GET',
-            _path_params,
-            _query_params,
-            _header_params,
-            body=_body_params,
-            post_params=_form_params,
-            files=_files,
-            response_types_map=_response_types_map,
-            auth_settings=_auth_settings,
-            async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
-            _preload_content=_params.get('_preload_content', True),
-            _request_timeout=_params.get('_request_timeout'),
-            collection_formats=_collection_formats,
-            _request_auth=_params.get('_request_auth'))
-
-    @validate_arguments
-    def resume_compute_pool(self, name : constr(strict=True), **kwargs) -> SuccessResponse:  # noqa: E501
-        """Resume a compute pool  # noqa: E501
-
-        Resume a compute pool, if suspended. This is a no-op if it is already running.  # noqa: E501
-        This method makes a synchronous HTTP request by default. To make an
-        asynchronous HTTP request, please pass async_req=True
-
-        >>> thread = api.resume_compute_pool(name, async_req=True)
-        >>> result = thread.get()
-
-        :param name: (required)
-        :type name: str
-        :param async_req: Whether to execute the request asynchronously.
-        :type async_req: bool, optional
-        :param _preload_content: if False, the urllib3.HTTPResponse object will
-                                 be returned without reading/decoding response
-                                 data. Default is True.
-        :type _preload_content: bool, optional
-        :param _request_timeout: timeout setting for this request. If one
-                                 number provided, it will be total request
-                                 timeout. It can also be a pair (tuple) of
-                                 (connection, read) timeouts.
-        :return: Returns the result object.
-                 If the method is called asynchronously,
-                 returns the request thread.
-        :rtype: SuccessResponse
-        """
-        kwargs['_return_http_data_only'] = True
-        return self.resume_compute_pool_with_http_info(name, **kwargs)  # noqa: E501
-
-    @validate_arguments
-    def resume_compute_pool_with_http_info(self, name : constr(strict=True), **kwargs):  # noqa: E501
-        """Resume a compute pool  # noqa: E501
-
-        Resume a compute pool, if suspended. This is a no-op if it is already running.  # noqa: E501
-        This method makes a synchronous HTTP request by default. To make an
-        asynchronous HTTP request, please pass async_req=True
-
-        >>> thread = api.resume_compute_pool_with_http_info(name, async_req=True)
-        >>> result = thread.get()
-
-        :param name: (required)
-        :type name: str
-        :param async_req: Whether to execute the request asynchronously.
-        :type async_req: bool, optional
-        :param _return_http_data_only: response data without head status code
-                                       and headers
-        :type _return_http_data_only: bool, optional
-        :param _preload_content: if False, the urllib3.HTTPResponse object will
-                                 be returned without reading/decoding response
-                                 data. Default is True.
-        :type _preload_content: bool, optional
-        :param _request_timeout: timeout setting for this request. If one
-                                 number provided, it will be total request
-                                 timeout. It can also be a pair (tuple) of
-                                 (connection, read) timeouts.
-        :param _request_auth: set to override the auth_settings for an a single
-                              request; this effectively ignores the authentication
-                              in the spec for a single request.
-        :type _request_auth: dict, optional
-        :type _content_type: string, optional: force content-type for the request
-        :return: Returns the result object.
-                 If the method is called asynchronously,
-                 returns the request thread.
-        :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
-        """
-
-        _params = locals()
-
-        _all_params = [
-            'name'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
-
-        # validate the arguments
-        for _key, _val in _params['kwargs'].items():
-            if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method resume_compute_pool" % _key
-                )
-            _params[_key] = _val
-        del _params['kwargs']
-
-        _collection_formats = {}
-
-        # process the path parameters
-        _path_params = {}
-        if _params['name']:
-            _path_params['name'] = _params['name']
-
-        # process the query parameters
-        _query_params = []
-
-        # process the header parameters
-        _header_params = dict(_params.get('_headers', {}))
-
-        # process the form parameters
-        _form_params = []
-        _files = {}
-
-        # process the body parameter
-        _body_params = None
-
-        # set the HTTP header `Accept`
-        _header_params['Accept'] = self.api_client.select_header_accept(
-            ['application/json'])  # noqa: E501
-
-        # authentication setting
-        _auth_settings = []  # noqa: E501
-
-        _response_types_map = {
-            '200': "SuccessResponse",
-            '400': "ErrorResponse",
-            '401': "ErrorResponse",
-            '403': "ErrorResponse",
-            '404': "ErrorResponse",
-            '405': "ErrorResponse",
-            '500': "ErrorResponse",
-            '503': "ErrorResponse",
-            '504': "ErrorResponse",
-        }
-
-        return self.api_client.call_api(
-            '/api/v2/compute-pools/{name}:resume', 'POST',
-            _path_params,
-            _query_params,
-            _header_params,
-            body=_body_params,
-            post_params=_form_params,
-            files=_files,
-            response_types_map=_response_types_map,
-            auth_settings=_auth_settings,
-            async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
-            _preload_content=_params.get('_preload_content', True),
-            _request_timeout=_params.get('_request_timeout'),
-            collection_formats=_collection_formats,
-            _request_auth=_params.get('_request_auth'))
-
-    @validate_arguments
-    def stop_all_services_in_compute_pool(self, name : constr(strict=True), **kwargs) -> SuccessResponse:  # noqa: E501
-        """Stops all services on the compute pool.  # noqa: E501
-
-        Stop all services in the compute pool.  # noqa: E501
-        This method makes a synchronous HTTP request by default. To make an
-        asynchronous HTTP request, please pass async_req=True
-
-        >>> thread = api.stop_all_services_in_compute_pool(name, async_req=True)
-        >>> result = thread.get()
-
-        :param name: (required)
-        :type name: str
-        :param async_req: Whether to execute the request asynchronously.
-        :type async_req: bool, optional
-        :param _preload_content: if False, the urllib3.HTTPResponse object will
-                                 be returned without reading/decoding response
-                                 data. Default is True.
-        :type _preload_content: bool, optional
-        :param _request_timeout: timeout setting for this request. If one
-                                 number provided, it will be total request
-                                 timeout. It can also be a pair (tuple) of
-                                 (connection, read) timeouts.
-        :return: Returns the result object.
-                 If the method is called asynchronously,
-                 returns the request thread.
-        :rtype: SuccessResponse
-        """
-        kwargs['_return_http_data_only'] = True
-        return self.stop_all_services_in_compute_pool_with_http_info(name, **kwargs)  # noqa: E501
-
-    @validate_arguments
-    def stop_all_services_in_compute_pool_with_http_info(self, name : constr(strict=True), **kwargs):  # noqa: E501
-        """Stops all services on the compute pool.  # noqa: E501
-
-        Stop all services in the compute pool.  # noqa: E501
-        This method makes a synchronous HTTP request by default. To make an
-        asynchronous HTTP request, please pass async_req=True
-
-        >>> thread = api.stop_all_services_in_compute_pool_with_http_info(name, async_req=True)
-        >>> result = thread.get()
-
-        :param name: (required)
-        :type name: str
-        :param async_req: Whether to execute the request asynchronously.
-        :type async_req: bool, optional
-        :param _return_http_data_only: response data without head status code
-                                       and headers
-        :type _return_http_data_only: bool, optional
-        :param _preload_content: if False, the urllib3.HTTPResponse object will
-                                 be returned without reading/decoding response
-                                 data. Default is True.
-        :type _preload_content: bool, optional
-        :param _request_timeout: timeout setting for this request. If one
-                                 number provided, it will be total request
-                                 timeout. It can also be a pair (tuple) of
-                                 (connection, read) timeouts.
-        :param _request_auth: set to override the auth_settings for an a single
-                              request; this effectively ignores the authentication
-                              in the spec for a single request.
-        :type _request_auth: dict, optional
-        :type _content_type: string, optional: force content-type for the request
-        :return: Returns the result object.
-                 If the method is called asynchronously,
-                 returns the request thread.
-        :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
-        """
-
-        _params = locals()
-
-        _all_params = [
-            'name'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
-
-        # validate the arguments
-        for _key, _val in _params['kwargs'].items():
-            if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method stop_all_services_in_compute_pool" % _key
-                )
-            _params[_key] = _val
-        del _params['kwargs']
-
-        _collection_formats = {}
-
-        # process the path parameters
-        _path_params = {}
-        if _params['name']:
-            _path_params['name'] = _params['name']
-
-        # process the query parameters
-        _query_params = []
-
-        # process the header parameters
-        _header_params = dict(_params.get('_headers', {}))
-
-        # process the form parameters
-        _form_params = []
-        _files = {}
-
-        # process the body parameter
-        _body_params = None
-
-        # set the HTTP header `Accept`
-        _header_params['Accept'] = self.api_client.select_header_accept(
-            ['application/json'])  # noqa: E501
-
-        # authentication setting
-        _auth_settings = []  # noqa: E501
-
-        _response_types_map = {
-            '200': "SuccessResponse",
+            '200': "Iterable[ModelSchema]",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/compute-pools/{name}:stopallservices', 'POST',
+            self._root,
+            '/api/v2/databases/{database}/schemas', 'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -1180,26 +998,32 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def suspend_compute_pool(self, name : constr(strict=True), **kwargs) -> SuccessResponse:  # noqa: E501
-        """Perform an action on a compute pool  # noqa: E501
+    def delete_schema(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, restrict : Annotated[Optional[StrictBool], Field(description="Specifies whether the schema should not be droppped if there are existing foreign key references. Returns a warning instead.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+        """Delete a schema.  # noqa: E501
 
-        Suspend a compute pool.  # noqa: E501
+        Delete a schema with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.suspend_compute_pool(name, async_req=True)
+        >>> thread = api.delete_schema(database, name, if_exists, restrict, async_req=True)
         >>> result = thread.get()
 
-        :param name: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :type database: str
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
+        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :type if_exists: bool
+        :param restrict: Specifies whether the schema should not be droppped if there are existing foreign key references. Returns a warning instead.
+        :type restrict: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
@@ -1208,29 +1032,35 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.suspend_compute_pool_with_http_info(name, **kwargs)  # noqa: E501
+        return self.delete_schema_with_http_info(database, name, if_exists, restrict, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def suspend_compute_pool_with_http_info(self, name : constr(strict=True), **kwargs):  # noqa: E501
-        """Perform an action on a compute pool  # noqa: E501
+    def delete_schema_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, restrict : Annotated[Optional[StrictBool], Field(description="Specifies whether the schema should not be droppped if there are existing foreign key references. Returns a warning instead.")] = None, **kwargs):  # noqa: E501
+        """Delete a schema.  # noqa: E501
 
-        Suspend a compute pool.  # noqa: E501
+        Delete a schema with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.suspend_compute_pool_with_http_info(name, async_req=True)
+        >>> thread = api.delete_schema_with_http_info(database, name, if_exists, restrict, async_req=True)
         >>> result = thread.get()
 
-        :param name: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :type database: str
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
+        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :type if_exists: bool
+        :param restrict: Specifies whether the schema should not be droppped if there are existing foreign key references. Returns a warning instead.
+        :type restrict: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -1250,15 +1080,18 @@
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
-            'name'
+            'database',
+            'name',
+            'if_exists',
+            'restrict'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -1269,28 +1102,34 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method suspend_compute_pool" % _key
+                    " to method delete_schema" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+        if _params['database']:
+            _path_params['database'] = _params['database']
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
+        if _params.get('if_exists') is not None:  # noqa: E501
+            _query_params.append(('ifExists', _params['if_exists']))
+        if _params.get('restrict') is not None:  # noqa: E501
+            _query_params.append(('restrict', _params['restrict']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -1314,15 +1153,16 @@
             '405': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/compute-pools/{name}:suspend', 'POST',
+            self._root,
+            '/api/v2/databases/{database}/schemas/{name}', 'DELETE',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/compute_pool/_generated/models/__init__.py` & `snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/models/__init__.py`

 * *Files 22% similar despite different names*

```diff
@@ -5,14 +5,16 @@
     Snowflake Compute Pools API
 
     The Snowflake Compute Pools API is a REST API that you can use to access, update, and perform certain actions on Compute Pool resources.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 # import models into model package
 from snowflake.core.compute_pool._generated.models.compute_pool import ComputePool
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/compute_pool/_generated/models/compute_pool.py` & `snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/models/compute_pool.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,26 +4,28 @@
     Snowflake Compute Pools API
 
     The Snowflake Compute Pools API is a REST API that you can use to access, update, and perform certain actions on Compute Pool resources.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 from datetime import datetime
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, constr, validator
+from snowflake.core.compute_pool._generated.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, constr, validator
 
 class ComputePool(BaseModel):
     name: constr(strict=True) = Field(...)
     min_nodes: StrictInt = Field(...)
     max_nodes: StrictInt = Field(...)
     instance_family: StrictStr = Field(...)
     auto_resume: Optional[StrictBool] = None
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/compute_pool/_generated/models/error_response.py` & `snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/models/error_response.py`

 * *Files 6% similar despite different names*

```diff
@@ -4,32 +4,35 @@
     Snowflake Compute Pools API
 
     The Snowflake Compute Pools API is a REST API that you can use to access, update, and perform certain actions on Compute Pool resources.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictStr
+from snowflake.core.compute_pool._generated.pydantic_compatibility import BaseModel, StrictStr
 
 class ErrorResponse(BaseModel):
-    message: Optional[StrictStr] = Field(None, description="Error message returned by server")
-    error_code: Optional[StrictStr] = Field(None, description="Error code")
-    request_id: Optional[StrictStr] = Field(None, description="Unique request id")
-    __properties = ["message", "error_code", "request_id"]
+    message: Optional[StrictStr] = None
+    code: Optional[StrictStr] = None
+    error_code: Optional[StrictStr] = None
+    request_id: Optional[StrictStr] = None
+    __properties = ["message", "code", "error_code", "request_id"]
 
 
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
@@ -61,14 +64,16 @@
 
         if type(obj) is not dict:
             return ErrorResponse.parse_obj(obj)
 
         _obj = ErrorResponse.parse_obj({
             "message": obj.get("message"),
 
+            "code": obj.get("code"),
+
             "error_code": obj.get("error_code"),
 
             "request_id": obj.get("request_id"),
 
         })
         return _obj
 
@@ -76,37 +81,43 @@
 from typing import Optional, List, Dict
 
 class ErrorResponseModel():
     def __init__(
         self,
         # optional properties
         message: Optional[str] = None,
+        code: Optional[str] = None,
         error_code: Optional[str] = None,
         request_id: Optional[str] = None,
     ):
         self.message = message
+        self.code = code
         self.error_code = error_code
         self.request_id = request_id
-    __properties = ["message", "error_code", "request_id"]
+    __properties = ["message", "code", "error_code", "request_id"]
 
     def _to_model(self):
         return ErrorResponse(
             message=self.message,
 
+            code=self.code,
+
             error_code=self.error_code,
 
             request_id=self.request_id,
 
         )
 
     @classmethod
     def _from_model(cls, model) -> ErrorResponseModel:
         return ErrorResponseModel(
             message=model.message,
 
+            code=model.code,
+
             error_code=model.error_code,
 
             request_id=model.request_id,
 
         )
 
     def to_dict(self):
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/compute_pool/_generated/models/success_response.py` & `snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/success_response.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,32 +1,34 @@
 # coding: utf-8
 
 """
-    Snowflake Compute Pools API
+    Snowflake Services API
 
-    The Snowflake Compute Pools API is a REST API that you can use to access, update, and perform certain actions on Compute Pool resources.  # noqa: E501
+    The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictStr
+from snowflake.core.service._generated.pydantic_compatibility import BaseModel, StrictStr
 
 class SuccessResponse(BaseModel):
-    status: Optional[StrictStr] = Field(None, description="Message returned by server")
+    status: Optional[StrictStr] = None
     __properties = ["status"]
 
 
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/database/_database.py` & `snowflake_core-0.8.0/src/snowflake/core/database/_database.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,20 +1,19 @@
 from functools import cached_property
-from typing import TYPE_CHECKING, List, Optional, Union
+from typing import TYPE_CHECKING, Iterator, List, Optional, Union
 
 from snowflake.core._common import AccountObjectCollectionParent, Clone, CreateMode, ObjectReferenceMixin, PointOfTime
-from snowflake.core._internal.pydantic_compatibility import StrictStr
 from snowflake.core._internal.telemetry import api_telemetry
 from snowflake.core.database._generated.api import DatabaseApi
-from snowflake.core.database._generated.api_client import BridgeApiClient
+from snowflake.core.database._generated.api_client import BridgeApiClient, StoredProcApiClient
 from snowflake.core.database._generated.models.account_identifiers import AccountIdentifiers
 from snowflake.core.database._generated.models.database import DatabaseModel as Database
 from snowflake.core.database._generated.models.database_clone import DatabaseClone
 from snowflake.core.database._generated.models.point_of_time import PointOfTime as DatabasePointOfTime
-from snowflake.core.paging import PagedIter
+from snowflake.core.database._generated.pydantic_compatibility import StrictStr
 from snowflake.core.schema import SchemaCollection
 
 
 if TYPE_CHECKING:
     from snowflake.core import Root
 
 
@@ -23,15 +22,16 @@
         super().__init__(root, ref_class=DatabaseResource)
         self._api = DatabaseApi(
             root=root,
             resource_class=self._ref_class,
             bridge_client=BridgeApiClient(
                 root=root,
                 snowflake_connection=root.connection,
-            )
+            ),
+            sproc_client=StoredProcApiClient(root=self.root)
         )
 
     @api_telemetry
     def create(
         self,
         database: Database,
         *,
@@ -113,29 +113,29 @@
     def iter(
         self,
         *,
         like: Optional[str] = None,
         starts_with: Optional[str] = None,
         limit: Optional[int] = None,
         from_name: Optional[str] = None
-    ) -> PagedIter[Database]:
+    ) -> Iterator[Database]:
         """Look up databases in Snowflake."""
-        return PagedIter(
-            data=self._api.list_databases(
-                StrictStr(like) if like is not None else None,
-                StrictStr(starts_with) if starts_with else None,
-                limit,
-                from_name=from_name,
-                async_req=False,
-            ), map_=Database._from_model,
-        )
+        databases = self._api.list_databases(
+            StrictStr(like) if like is not None else None,
+            StrictStr(starts_with) if starts_with else None,
+            limit,
+            from_name=from_name,
+            async_req=False,)
 
+        return map(Database._from_model, iter(databases))
 
 class DatabaseResource(ObjectReferenceMixin[DatabaseCollection]):
 
+    _supports_rest_api = True
+
     def __init__(self, name: str, collection: DatabaseCollection) -> None:
         self.name = name
         self.collection: DatabaseCollection = collection
 
     @property
     def _api(self) -> DatabaseApi:
         return self.collection._api
@@ -157,15 +157,15 @@
 
     @api_telemetry
     def create_or_update(
         self,
         database: Database,
     ) -> None:
         """Create or update a database in Snowflake."""
-        self._api.create_or_update_database(
+        self._api.create_or_alter_database(
             database.name, database._to_model(), async_req=False
         )
 
     @api_telemetry
     def enable_replication(self, accounts: List[str], ignore_edition_check: bool = False) -> None:
         """Promotes a local database to serve as a primary database for replication.
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/database/_generated/__init__.py` & `snowflake_core-0.8.0/src/snowflake/core/database/_generated/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -6,14 +6,16 @@
     Snowflake Database API
 
     The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 __version__ = "1.0.0"
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/database/_generated/api_client.py` & `snowflake_core-0.8.0/src/snowflake/core/table/_generated/api_client.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,37 +1,44 @@
 # coding: utf-8
 """
-    Snowflake Database API
+    Snowflake Table API
 
-    The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
+    The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 from __future__ import absolute_import
 
 import atexit
 import datetime
+import time
 import typing
 from dateutil.parser import parse
 import json
 import mimetypes
 from multiprocessing.pool import ThreadPool
 import os
 import re
 import tempfile
 
 from urllib.parse import quote
 
-from snowflake.core.database._generated.configuration import Configuration
-import snowflake.core.database._generated.models
-from snowflake.core.database._generated import rest
-from snowflake.core.exceptions import _APIValueError, APIError
+from functools import partial
+
+from snowflake.core.table._generated.configuration import Configuration
+import snowflake.core.table._generated.models
+from snowflake.core.table._generated import rest
+from snowflake.core.table._generated.paging import PagedIter
+from snowflake.core.exceptions import _APIValueError, APIError, InvalidResponseError, LongRunningQueryTimeout
+from snowflake.core.version import __version__ as VERSION
 
 if typing.TYPE_CHECKING:
     from snowflake.core._root import Root
 
 
 class ApiClient(object):
     """Generic API client for OpenAPI client library builds.
@@ -62,41 +69,48 @@
         'float': float,
         'str': str,
         'bool': bool,
         'date': datetime.date,
         'datetime': datetime.datetime,
         'object': object,
     }
+    DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING = 600.0 # default 10 minutes for long running queries
     _pool = None
 
     def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
                  cookie=None, pool_threads=1):
         # use default configuraiton if none is provided
         if configuration is None:
             configuration = Configuration.get_default()
         self.configuration = configuration
         if (
             hasattr(root, "_connection")
+            and root._connection is not None
             and hasattr(root._connection, "_rest")
+            and root._connection._rest is not None
+            and hasattr(root._connection._rest, "_protocol")
+            and hasattr(root._connection._rest, "_host")
+            and hasattr(root._connection._rest, "_port")
         ):
             self.configuration.host = (
                 f"{root._connection._rest._protocol}://"
                 + root._connection._rest._host
                 + f":{root._connection._rest._port}"
             )
         self.pool_threads = pool_threads
 
         self.rest_client = rest.RESTClientObject(root, configuration)
         self.default_headers = {}
         if header_name is not None:
             self.default_headers[header_name] = header_value
         self.cookie = cookie
         # Set default User-Agent.
-        self.user_agent = 'OpenAPI-Generator/1.0.0/python'
+        self.user_agent = 'python_api/' + VERSION + ''
         self.client_side_validation = configuration.client_side_validation
+        self._enable_long_running_polling = getattr(root, "_enable_long_running_polling", False)
 
     def __enter__(self):
         return self
 
     def __exit__(self, exc_type, exc_value, traceback):
         self.close()
 
@@ -154,15 +168,15 @@
         It stores default ApiClient.
 
         :param default: object of ApiClient.
         """
         cls._default = default
 
     def __call_api(
-            self, resource_path, method, path_params=None,
+            self, root, resource_path, method, path_params=None,
             query_params=None, header_params=None, body=None, post_params=None,
             files=None, response_types_map=None, auth_settings=None,
             _return_http_data_only=None, collection_formats=None,
             _preload_content=True, _request_timeout=None, _host=None,
             _request_auth=None):
 
         config = self.configuration
@@ -218,22 +232,25 @@
         if query_params:
             query_params = self.sanitize_for_serialization(query_params)
             url_query = self.parameters_to_url_query(query_params,
                                                      collection_formats)
             url += "?" + url_query
 
         try:
-            # perform request and return response
-            response_data = self.request(
-                method, url,
+            # perform request and return response, maybe with retry
+            response_data = self.request_with_retry(
+                root,
+                method,
+                url,
                 query_params=query_params,
                 headers=header_params,
                 post_params=post_params, body=body,
                 _preload_content=_preload_content,
-                _request_timeout=_request_timeout)
+                _request_timeout=_request_timeout
+            )
         except APIError as e:
             if e.body:
                 e.body = e.body.decode('utf-8')
             raise e
 
         self.last_response = response_data
 
@@ -251,15 +268,52 @@
         #         match = re.search(r"charset=([a-zA-Z\-\d]+)[\s;]?", content_type)
         #     encoding = match.group(1) if match else "utf-8"
         #     response_data.data = response_data.data.decode(encoding)
 
         # deserialize response data
 
         if response_type:
-            return_data = self.deserialize(response_data, response_type)
+            large_results_resp = self.large_results(response_data)
+            if large_results_resp is None:
+                # regular, non-large results use case
+                return_data = self.deserialize(response_data, response_type)
+            else:
+                # This should be the normal way in which we figure out where to get the results from,
+                # as well as how many chunks there are to get. Due to a bug, we use the alternate logic
+                # (in the "else" clause) to infer the URL from the UUID
+                if "Link" in response_data.getheaders():
+                    results_path, num_chunks = self.get_path_and_chunk_count_from_header(response_data.getheaders()["Link"])
+                else:
+                    handler_id = large_results_resp['result_handler']
+                    results_path = '/api/v2/results/' + handler_id
+
+                    # If there is no "Link" header, there is just one chunk
+                    num_chunks = 1
+
+                # Closure for fetching the next chunk in the PagedIter iterator
+                def _fetch_next_chunk(chunk_index, deserialize_type):
+                    # For now, do this because query_params is not actually being used properly in self.request
+                    chunk_url = f'{self.configuration.host}{results_path}?page={chunk_index}'
+
+                    chunk_response_data = self.request(
+                        root,
+                        "GET",
+                        chunk_url,
+                        headers=header_params,
+                        _preload_content=True,
+                        _request_timeout=_request_timeout)
+
+                    return self.deserialize(chunk_response_data, deserialize_type)
+
+                if 'Iterable' in response_type:
+                    return PagedIter(partial(_fetch_next_chunk, deserialize_type=response_type), num_chunks)
+                else:
+                    # At most, we should only need to fetch one chunk if it's a point lookup,
+                    # i.e., one row return
+                    return_data = _fetch_next_chunk(0, response_type)
         else:
             return_data = None
 
         if _return_http_data_only:
             return (return_data)
         else:
             return (return_data, response_data.status,
@@ -335,42 +389,42 @@
 
         :return: object.
         """
         if data is None:
             return None
 
         if type(klass) == str:
-            if klass.startswith('List['):
-                sub_kls = re.match(r'List\[(.*)]', klass).group(1)
+            if klass.startswith('Iterable['):
+                sub_kls = re.match(r'Iterable\[(.*)]', klass).group(1)
                 return [self.__deserialize(sub_data, sub_kls)
                         for sub_data in data]
 
             if klass.startswith('Dict['):
                 sub_kls = re.match(r'Dict\[([^,]*), (.*)]', klass).group(2)
                 return {k: self.__deserialize(v, sub_kls)
                         for k, v in data.items()}
 
             # convert str to class
             if klass in self.NATIVE_TYPES_MAPPING:
                 klass = self.NATIVE_TYPES_MAPPING[klass]
             else:
-                klass = getattr(snowflake.core.database._generated.models, klass)
+                klass = getattr(snowflake.core.table._generated.models, klass)
 
         if klass in self.PRIMITIVE_TYPES:
             return self.__deserialize_primitive(data, klass)
         elif klass == object:
             return self.__deserialize_object(data)
         elif klass == datetime.date:
             return self.__deserialize_date(data)
         elif klass == datetime.datetime:
             return self.__deserialize_datetime(data)
         else:
             return self.__deserialize_model(data, klass)
 
-    def call_api(self, resource_path, method,
+    def call_api(self, root, resource_path, method,
                  path_params=None, query_params=None, header_params=None,
                  body=None, post_params=None, files=None,
                  response_types_map=None, auth_settings=None,
                  async_req=None, _return_http_data_only=None,
                  collection_formats=None,_preload_content=True,
                   _request_timeout=None, _host=None, _request_auth=None):
         """Makes the HTTP request (synchronous) and returns deserialized data.
@@ -410,88 +464,198 @@
             If async_req parameter is True,
             the request will be called asynchronously.
             The method will return the request thread.
             If parameter async_req is False or missing,
             then the method will return the response directly.
         """
         if not async_req:
-            return self.__call_api(resource_path, method,
-                                   path_params, query_params, header_params,
-                                   body, post_params, files,
-                                   response_types_map, auth_settings,
-                                   _return_http_data_only, collection_formats,
-                                   _preload_content, _request_timeout, _host,
-                                   _request_auth)
-
-        return self.pool.apply_async(self.__call_api, (resource_path,
-                                                       method, path_params,
-                                                       query_params,
-                                                       header_params, body,
-                                                       post_params, files,
-                                                       response_types_map,
-                                                       auth_settings,
-                                                       _return_http_data_only,
-                                                       collection_formats,
-                                                       _preload_content,
-                                                       _request_timeout,
-                                                       _host, _request_auth))
+            return self.__call_api(
+                root,
+                resource_path,
+                method,
+                path_params,
+                query_params,
+                header_params,
+                body,
+                post_params,
+                files,
+                response_types_map,
+                auth_settings,
+                _return_http_data_only,
+                collection_formats,
+                _preload_content,
+                _request_timeout,
+                _host,
+                _request_auth,
+            )
+
+        return self.pool.apply_async(
+            self.__call_api,
+            (
+                root,
+                resource_path,
+                method,
+                path_params,
+                query_params,
+                header_params,
+                body,
+                post_params,
+                files,
+                response_types_map,
+                auth_settings,
+                _return_http_data_only,
+                collection_formats,
+                _preload_content,
+                _request_timeout,
+                _host,
+                _request_auth,
+            )
+        )
 
-    def request(self, method, url, query_params=None, headers=None,
+
+    def request_with_retry(
+                self, root, method, url, query_params=None, headers=None,
+                post_params=None, body=None, _preload_content=True,
+                _request_timeout=None):
+        """
+            Response time by default one hour
+        """
+        enter_timing = time.time()
+        response_data = self.request(
+                root,
+                method,
+                url,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params, body=body,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout)
+
+        if response_data.status != 202 or not self._enable_long_running_polling:
+            return response_data
+
+        result_endpoint = response_data.getheader('Location')
+        if result_endpoint is None:
+            raise InvalidResponseError("Long Running Queries result endpoint is missing")
+
+        if _request_timeout is None:
+            _request_timeout = self.DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING
+        wait_for_results_timeout = enter_timing + _request_timeout
+
+        exponential_wait_time = 1 # wait time increases exponentially, 30% more everytime
+        while True:
+            time_remaining = wait_for_results_timeout - time.time()
+            if time_remaining <= 0:
+                break
+            wait_time = min(exponential_wait_time, time_remaining)
+            time.sleep(wait_time)
+            response_data = self.request(
+                root,
+                'GET',
+                self.configuration.host + result_endpoint,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params, body=body,
+                _preload_content=_preload_content,
+                _request_timeout=max(time_remaining - wait_time, 1)
+                # request_timeout can never be zero
+            )
+
+            if response_data.status != 202:
+                return response_data
+
+            exponential_wait_time *= 1.3
+
+        raise LongRunningQueryTimeout("Long running queries timeout")
+
+
+    def request(self, root, method, url, query_params=None, headers=None,
                 post_params=None, body=None, _preload_content=True,
                 _request_timeout=None):
         """Makes the HTTP request using RESTClient."""
         if method == "GET":
-            return self.rest_client.get_request(url,
-                                        query_params=query_params,
-                                        _preload_content=_preload_content,
-                                        _request_timeout=_request_timeout,
-                                        headers=headers)
+            return self.rest_client.get_request(
+                root,
+                url,
+                query_params=query_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                headers=headers,
+            )
         elif method == "HEAD":
-            return self.rest_client.head_request(url,
-                                         query_params=query_params,
-                                         _preload_content=_preload_content,
-                                         _request_timeout=_request_timeout,
-                                         headers=headers)
+            return self.rest_client.head_request(
+                root,
+                url,
+                query_params=query_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                headers=headers,
+            )
         elif method == "OPTIONS":
-            return self.rest_client.options_request(url,
-                                            query_params=query_params,
-                                            headers=headers,
-                                            _preload_content=_preload_content,
-                                            _request_timeout=_request_timeout)
+            return self.rest_client.options_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+            )
         elif method == "POST":
-            return self.rest_client.post_request(url,
-                                         query_params=query_params,
-                                         headers=headers,
-                                         post_params=post_params,
-                                         _preload_content=_preload_content,
-                                         _request_timeout=_request_timeout,
-                                         body=body)
+            return self.rest_client.post_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                body=body,
+            )
         elif method == "PUT":
-            return self.rest_client.put_request(url,
-                                        query_params=query_params,
-                                        headers=headers,
-                                        post_params=post_params,
-                                        _preload_content=_preload_content,
-                                        _request_timeout=_request_timeout,
-                                        body=body)
+            try:
+                return self.rest_client.put_request(
+                    root,
+                    url,
+                    query_params=query_params,
+                    headers=headers,
+                    post_params=post_params,
+                    _preload_content=_preload_content,
+                    _request_timeout=_request_timeout,
+                    body=body,
+                )
+            except APIError as error:
+                # Raise a more helpful user error if CoA is not supported for this resource;
+                # this is represented as either 405 or 501 on the server.
+                if error.status in (405, 501):
+                    raise NotImplementedError(
+                        'create_or_update is not yet supported for table. Updating table '
+                        'objects is not supported yet; use create() for creating a table.')
+                raise
+
         elif method == "PATCH":
-            return self.rest_client.patch_request(url,
-                                          query_params=query_params,
-                                          headers=headers,
-                                          post_params=post_params,
-                                          _preload_content=_preload_content,
-                                          _request_timeout=_request_timeout,
-                                          body=body)
+            return self.rest_client.patch_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                body=body,
+            )
         elif method == "DELETE":
-            return self.rest_client.delete_request(url,
-                                           query_params=query_params,
-                                           headers=headers,
-                                           _preload_content=_preload_content,
-                                           _request_timeout=_request_timeout,
-                                           body=body)
+            return self.rest_client.delete_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                body=body,
+            )
         else:
             raise _APIValueError(
                 "http method must be `GET`, `HEAD`, `OPTIONS`,"
                 " `POST`, `PATCH`, `PUT` or `DELETE`."
             )
 
     def parameters_to_tuples(self, params, collection_formats):
@@ -759,13 +923,73 @@
         :param data: dict, list.
         :param klass: class literal.
         :return: model object.
         """
 
         return klass.from_dict(data)
 
+    @staticmethod
+    def large_results(response):
+        try:
+            result = json.loads(response.data)
+            if ("result_handler" in result
+                    and "message" in result and
+                    'Large result set. Use provided Link' in result['message']):
+                return result
+            else:
+                return None
+        except ValueError:
+            pass
+
+        return None
+
+
+    @staticmethod
+    def get_path_and_chunk_count_from_header(links_str):
+        links_list = links_str.split(",")
+
+        def parse_links(s):
+            import re
+            # Use regex to extract necessary parts
+            #
+            # Explanation:
+            # The result links are provided to us in the form:
+            # '</api/v2/results/01b39664-0100-0001-0000-0000000430391?page=0>; rel="first"'
+            #
+            # We wish to find how many chunks there are by finding the one that has rel="last",
+            # therefore we find page index corresponding to the link with that rel value.
+            #
+            # 1. <(.*?)> matches and captures the URL inside the angle brackets
+            # 2. page=(\d+) matches 'page=' followed by one or more digits to find the page number
+            # 3. rel="([^"]*)" matches 'rel="'
+            pattern = r'<(.*?)\?page=(\d+)>; rel="([^"]*)"'
+
+            # Search using the regular expression
+            match = re.search(pattern, s)
+            if match:
+                parse_result = dict()
+                parse_result['url'], parse_result['page_number'], parse_result['rel_value'] = match.groups()
+                return parse_result
+
+            return None
+
+        parsed_links = [parse_links(link) for link in links_list]
+
+        # Find the last one
+        last_link = list(filter(lambda link: link['rel_value'].lower() == 'last', parsed_links)).pop()
+
+        # Return the URL; the number of chunks is the chunk index of the last page plus one
+        return last_link['url'], int(last_link['page_number']) + 1
+
 
 class BridgeApiClient(ApiClient):
     def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
                  cookie=None, pool_threads=1, snowflake_connection=None):
         ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
         self.rest_client = rest.BridgeClientObject(snowflake_connection)
+
+
+class StoredProcApiClient(ApiClient):
+    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
+                 cookie=None, pool_threads=1):
+        ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
+        self.rest_client = rest.StoredProcClientObject()
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/database/_generated/api_response.py` & `snowflake_core-0.8.0/src/snowflake/core/database/_generated/api_response.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 """API response object."""
 
 from __future__ import annotations
 from typing import Any, Dict, Optional
-from snowflake.core._internal.pydantic_compatibility import Field, StrictInt, StrictStr
+from snowflake.core.database._generated.pydantic_compatibility import Field, StrictInt, StrictStr
 
 class ApiResponse:
     """
     API response object
     """
 
     status_code: Optional[StrictInt] = Field(None, description="HTTP status code")
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/database/_generated/configuration.py` & `snowflake_core-0.8.0/src/snowflake/core/database/_generated/configuration.py`

 * *Files 1% similar despite different names*

```diff
@@ -4,14 +4,16 @@
     Snowflake Database API
 
     The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 import copy
 import logging
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/database/_generated/rest.py` & `snowflake_core-0.8.0/src/snowflake/core/service/_generated/rest.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,17 +1,19 @@
 # coding: utf-8
 
 """
-    Snowflake Database API
+    Snowflake Services API
 
-    The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
+    The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 import json
 import logging
@@ -49,17 +51,26 @@
     def __init__(self, root: "Root", *args, **kwargs):
         self.root = root
         self.pool_manager = create_connection_pool(
             *args,
             **kwargs,
         )
 
-    def request(self, method, url, query_params=None, headers=None,
-                body=None, post_params=None, _preload_content=True,
-                _request_timeout=None):
+    def request(
+        self,
+        root,
+        method,
+        url,
+        query_params=None,
+        headers=None,
+        body=None,
+        post_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
         """Perform requests.
 
         :param method: http request method
         :param url: http request url
         :param query_params: query parameters in the url
         :param headers: http request headers
         :param body: request json body, for `application/json`
@@ -104,64 +115,64 @@
 
                 # no content type provided or payload is json
                 if not headers.get('Content-Type') or re.search('json', headers['Content-Type'], re.IGNORECASE):
                     request_body = None
                     if body is not None:
                         request_body = json.dumps(body)
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 elif headers['Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         fields=post_params,
                         encode_multipart=False,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 elif headers['Content-Type'] == 'multipart/form-data':
                     # must del headers['Content-Type'], or the correct
                     # Content-Type which generated by urllib3 will be
                     # overwritten.
                     del headers['Content-Type']
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         fields=post_params,
                         encode_multipart=True,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 # Pass a `string` parameter directly in the body to support
                 # other content types than Json when `body` argument is
                 # provided in serialized form
                 elif isinstance(body, str) or isinstance(body, bytes):
                     request_body = body
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 else:
                     # Cannot generate the request from given parameters
                     msg = """Cannot prepare a request message for provided
                              arguments. Please check that your arguments match
                              declared content type."""
                     raise APIError(status=0, reason=msg)
             # For `GET`, `HEAD`
             else:
                 r = self.pool_manager.request(
-                    self.root._session_token,
+                    root,
                     method,
                     url,
                     fields={},
                     preload_content=_preload_content,
                     timeout=timeout,
                     headers=headers,
                 )
@@ -191,88 +202,139 @@
             if 500 <= r.status <= 599:
                 raise ServerError(http_resp=r)
 
             raise APIError(http_resp=r)
 
         return r
 
-    def get_request(self, url, headers=None, query_params=None, _preload_content=True,
-            _request_timeout=None):
-        return self.request("GET", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
-
-    def head_request(self, url, headers=None, query_params=None, _preload_content=True,
-             _request_timeout=None):
-        return self.request("HEAD", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
+    def get_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "GET",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def head_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "HEAD",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
 
-    def options_request(self, url, headers=None, query_params=None, post_params=None,
+    def options_request(self, root, url, headers=None, query_params=None, post_params=None,
                 body=None, _preload_content=True, _request_timeout=None):
-        return self.request("OPTIONS", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "OPTIONS",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def delete_request(self, url, headers=None, query_params=None, body=None,
+    def delete_request(self, root, url, headers=None, query_params=None, body=None,
                _preload_content=True, _request_timeout=None):
-        return self.request("DELETE", url,
-                            headers=headers,
-                            query_params=query_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "DELETE",
+            url,
+            headers=headers,
+            query_params=query_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def post_request(self, url, headers=None, query_params=None, post_params=None,
+    def post_request(self, root, url, headers=None, query_params=None, post_params=None,
              body=None, _preload_content=True, _request_timeout=None):
-        return self.request("POST", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "POST",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def put_request(self, url, headers=None, query_params=None, post_params=None,
+    def put_request(self, root, url, headers=None, query_params=None, post_params=None,
             body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PUT", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "PUT",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def patch_request(self, url, headers=None, query_params=None, post_params=None,
+    def patch_request(self, root, url, headers=None, query_params=None, post_params=None,
               body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PATCH", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "PATCH",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
 
 class BridgeClientObject(object):
 
     def __init__(self, snowflake_connection: SnowflakeConnection):
         self.bridge = SnowBridge(snowflake_connection)
 
-    def request(self, method, url, query_params=None, headers=None,
-                body=None, post_params=None, _preload_content=True,
-                _request_timeout=None):
+    def request(
+        self,
+        root,
+        method,
+        url,
+        query_params=None,
+        headers=None,
+        body=None,
+        post_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
         """Perform requests.
 
         :param method: http request method
         :param url: http request url
         :param query_params: query parameters in the url
         :param headers: http request headers
         :param body: request json body, for `application/json`
@@ -315,71 +377,378 @@
             if 500 <= r.status <= 599:
                 raise ServerError(http_resp=r)
 
             raise APIError(http_resp=r)
 
         return r
 
-    def get_request(self, url, headers=None, query_params=None, _preload_content=True,
-                    _request_timeout=None):
-        return self.request("GET", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
-
-    def head_request(self, url, headers=None, query_params=None, _preload_content=True,
-                     _request_timeout=None):
-        return self.request("HEAD", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
-
-    def options_request(self, url, headers=None, query_params=None, post_params=None,
-                        body=None, _preload_content=True, _request_timeout=None):
-        return self.request("OPTIONS", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def delete_request(self, url, headers=None, query_params=None, body=None,
-                       _preload_content=True, _request_timeout=None):
-        return self.request("DELETE", url,
-                            headers=headers,
-                            query_params=query_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def post_request(self, url, headers=None, query_params=None, post_params=None,
-                     body=None, _preload_content=True, _request_timeout=None):
-        return self.request("POST", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def put_request(self, url, headers=None, query_params=None, post_params=None,
-                    body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PUT", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def patch_request(self, url, headers=None, query_params=None, post_params=None,
-                      body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PATCH", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+    def get_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "GET",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def head_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "HEAD",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def options_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "OPTIONS",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def delete_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "DELETE",
+            url,
+            headers=headers,
+            query_params=query_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def post_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "POST",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def put_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PUT",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def patch_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PATCH",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+
+class StoredProcClientObject(object):
+
+    def request(
+        self,
+        root,
+        method,
+        url,
+        query_params={},
+        headers={},
+        body={},
+        post_params={},
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        """Perform requests.
+        :param method: http request method
+        :param url: http request url
+        :param query_params: query parameters in the url
+        :param headers: http request headers
+        :param body: request json body, for `application/json`
+        :param post_params: request post parameters,
+                            `application/x-www-form-urlencoded`
+                            and `multipart/form-data`
+        :param _preload_content: if False, the urllib3.HTTPResponse object will
+                                 be returned without reading/decoding response
+                                 data. Default is True.
+        :param _request_timeout: timeout setting for this request. If one
+                                 number provided, it will be total request
+                                 timeout. It can also be a pair (tuple) of
+                                 (connection, read) timeouts.
+        """
+        method = method.upper()
+        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
+                          'PATCH', 'OPTIONS']
+        import _snowflake
+        parsed_url = urllib3.util.parse_url(url)
+        response_dict = _snowflake.send_snow_api_request(method, parsed_url.path, dict(query_params), headers, body,
+                                                         post_params, _request_timeout)
+        json_content = json.loads(response_dict["content"])
+        if "data" in json_content:
+            r = urllib3.HTTPResponse(body=json.dumps(json_content["data"]))
+        else:
+            r = urllib3.HTTPResponse(body=json.dumps(json_content).encode("utf-8"))
+        r.status = response_dict["status"]
+        if _preload_content:
+            r = RESTResponse(r)
+            # log response body
+            logger.debug("response body: %s", r.data)
+
+        if not 200 <= r.status <= 299:
+            if r.status == 401:
+                raise UnauthorizedError(http_resp=r)
+
+            if r.status == 403:
+                raise ForbiddenError(http_resp=r)
+
+            if r.status == 404:
+                raise NotFoundError(http_resp=r)
+
+            if r.status == 409:
+                raise ConflictError(http_resp=r)
+
+            if 500 <= r.status <= 599:
+                raise ServerError(http_resp=r)
+
+            raise APIError(http_resp=r)
+
+        return r
+
+    def get_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "GET",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def head_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "HEAD",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def options_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "OPTIONS",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def delete_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "DELETE",
+            url,
+            headers=headers,
+            query_params=query_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def post_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "POST",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def put_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PUT",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def patch_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PATCH",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/database/_generated/api/database_api.py` & `snowflake_core-0.8.0/src/snowflake/core/database/_generated/api/database_api.py`

 * *Files 7% similar despite different names*

```diff
@@ -4,271 +4,120 @@
     Snowflake Database API
 
     The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 import logging
 
 from typing_extensions import Annotated
-
-from typing_extensions import Annotated
 from pydantic import Field, StrictBool, StrictInt, StrictStr, constr, validator
 
 from typing import List, Optional
 
 from snowflake.core.database._generated.models.account_identifiers import AccountIdentifiers
 from snowflake.core.database._generated.models.database import Database
 from snowflake.core.database._generated.models.database_clone import DatabaseClone
 from snowflake.core.database._generated.models.success_response import SuccessResponse
+from typing import Iterable
+
 
-from snowflake.core._internal.pydantic_compatibility import StrictBool, StrictInt, StrictStr, constr, validate_arguments, ValidationError, validator
-from snowflake.core._internal.utils import ApiClientType
+from snowflake.core.database._generated.pydantic_compatibility import StrictBool, StrictInt, StrictStr, constr, validate_arguments, ValidationError, validator
+from snowflake.core._internal.snowapi_parameters import SnowApiParameters
+from snowflake.core._internal.utils import ApiClientType, is_running_inside_stored_procedure
 
-from snowflake.core.database._generated.api_client import ApiClient
 from snowflake.core.exceptions import (  # noqa: F401
     _APITypeError,
     _APIValueError
 )
 
 logger  = logging.getLogger(__name__)
 
 class DatabaseApi(object):
     """NOTE: This class is auto generated by OpenAPI Generator
     Ref: https://openapi-generator.tech
 
     Do not edit the class manually.
     """
 
-    def __init__(self, root, resource_class, bridge_client):
+    def __init__(self, root, resource_class, bridge_client, sproc_client):
         self._root = root
-        self._rest_client = ApiClient.get_default(root)
+        self._resource_name = 'database'
         self._resource_class = resource_class
         self._bridge_client = bridge_client
+        self._sproc_client = sproc_client
         self._chosen_client_type = ApiClientType.NONE
 
     @property
     def api_client(self):
         """
             chosen_client is the client we chose , either bridge or rest
-            new_chosen_client is the client we want to choose under the current situation ( value of _supports_rest_api + _can_use_rest_api )
+            new_chosen_client is the client we want to choose under the current situation ( value of
+            _supports_rest_api + _can_use_rest_api, and the server-controlled flag )
             We will log the change if we want to choose another client instead of the current one
         """
-        if self._resource_class._supports_rest_api and self._root._can_use_rest_api:
-            chosen_client = self._rest_client
-            new_chosen_client = ApiClientType.REST
+        from snowflake.core.database._generated.api_client import ApiClient
+
+        # Small helper function for figuring out the correct 'REST' client to use if in stored proc or not
+        def _get_rest_client():
+            if is_running_inside_stored_procedure():
+                return self._sproc_client, ApiClientType.STORED_PROC
+            else:
+                return ApiClient.get_default(self._root), ApiClientType.REST
+
+        use_bridge_override = False
+
+        # We can force use of the bridge if the server dictates it so
+        # But, don't check it for non-resources; _resource_class is not set for non-resources.
+        if self._resource_class is not None:
+            use_bridge_override = self._root.effective_parameters(refresh = False).resource_should_use_client_bridge('database')
+
+        # if the _resource_class is None (such as Session, which is not a resource), then it is implied
+        # that we use REST (or the stored_proc client)
+        if self._resource_class is None:
+            chosen_client, new_chosen_client = _get_rest_client()
+        elif use_bridge_override:
+            # Bridge override is in effect. Use the client bridge.
+            chosen_client = self._bridge_client
+            new_chosen_client = ApiClientType.BRIDGE
+        # Check if it supports REST before choosing the REST client.
+        elif self._resource_class._supports_rest_api and self._root._can_use_rest_api:
+            chosen_client, new_chosen_client = _get_rest_client()
+        # If all else fails, use the BRIDGE (if there is no REST support for this resource)
         else:
             chosen_client = self._bridge_client
             new_chosen_client = ApiClientType.BRIDGE
 
         if new_chosen_client != self._chosen_client_type:
             self._chosen_client_type = new_chosen_client
             logger.info("Going to use client-%s for this resource", new_chosen_client.name)
         return chosen_client
 
     @validate_arguments
-    def clone_database(self, name : constr(strict=True), database_clone : DatabaseClone, create_mode : Optional[StrictStr] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Clone a database  # noqa: E501
-
-        Clone an existing database, with modifiers as query parameters. See the database definition for what is required to be provided in the request body. (Cloning not currently supported)  # noqa: E501
-        This method makes a synchronous HTTP request by default. To make an
-        asynchronous HTTP request, please pass async_req=True
-
-        >>> thread = api.clone_database(name, database_clone, create_mode, kind, async_req=True)
-        >>> result = thread.get()
-
-        :param name: (required)
-        :type name: str
-        :param database_clone: (required)
-        :type database_clone: DatabaseClone
-        :param create_mode:
-        :type create_mode: str
-        :param kind: Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.
-        :type kind: str
-        :param async_req: Whether to execute the request asynchronously.
-        :type async_req: bool, optional
-        :param _preload_content: if False, the urllib3.HTTPResponse object will
-                                 be returned without reading/decoding response
-                                 data. Default is True.
-        :type _preload_content: bool, optional
-        :param _request_timeout: timeout setting for this request. If one
-                                 number provided, it will be total request
-                                 timeout. It can also be a pair (tuple) of
-                                 (connection, read) timeouts.
-        :return: Returns the result object.
-                 If the method is called asynchronously,
-                 returns the request thread.
-        :rtype: SuccessResponse
-        """
-        kwargs['_return_http_data_only'] = True
-        return self.clone_database_with_http_info(name, database_clone, create_mode, kind, **kwargs)  # noqa: E501
-
-    @validate_arguments
-    def clone_database_with_http_info(self, name : constr(strict=True), database_clone : DatabaseClone, create_mode : Optional[StrictStr] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, **kwargs):  # noqa: E501
-        """Clone a database  # noqa: E501
-
-        Clone an existing database, with modifiers as query parameters. See the database definition for what is required to be provided in the request body. (Cloning not currently supported)  # noqa: E501
-        This method makes a synchronous HTTP request by default. To make an
-        asynchronous HTTP request, please pass async_req=True
-
-        >>> thread = api.clone_database_with_http_info(name, database_clone, create_mode, kind, async_req=True)
-        >>> result = thread.get()
-
-        :param name: (required)
-        :type name: str
-        :param database_clone: (required)
-        :type database_clone: DatabaseClone
-        :param create_mode:
-        :type create_mode: str
-        :param kind: Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.
-        :type kind: str
-        :param async_req: Whether to execute the request asynchronously.
-        :type async_req: bool, optional
-        :param _return_http_data_only: response data without head status code
-                                       and headers
-        :type _return_http_data_only: bool, optional
-        :param _preload_content: if False, the urllib3.HTTPResponse object will
-                                 be returned without reading/decoding response
-                                 data. Default is True.
-        :type _preload_content: bool, optional
-        :param _request_timeout: timeout setting for this request. If one
-                                 number provided, it will be total request
-                                 timeout. It can also be a pair (tuple) of
-                                 (connection, read) timeouts.
-        :param _request_auth: set to override the auth_settings for an a single
-                              request; this effectively ignores the authentication
-                              in the spec for a single request.
-        :type _request_auth: dict, optional
-        :type _content_type: string, optional: force content-type for the request
-        :return: Returns the result object.
-                 If the method is called asynchronously,
-                 returns the request thread.
-        :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
-        """
-
-        _params = locals()
-
-        _all_params = [
-            'name',
-            'database_clone',
-            'create_mode',
-            'kind'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
-
-        # validate the arguments
-        for _key, _val in _params['kwargs'].items():
-            if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method clone_database" % _key
-                )
-            _params[_key] = _val
-        del _params['kwargs']
-
-        _collection_formats = {}
-
-        # process the path parameters
-        _path_params = {}
-        if _params['name']:
-            _path_params['name'] = _params['name']
-
-        # process the query parameters
-        _query_params = []
-        if _params.get('create_mode') is not None:  # noqa: E501
-            _query_params.append(('createMode', _params['create_mode']))
-        if _params.get('kind') is not None:  # noqa: E501
-            _query_params.append(('kind', _params['kind']))
-
-        # process the header parameters
-        _header_params = dict(_params.get('_headers', {}))
-
-        # process the form parameters
-        _form_params = []
-        _files = {}
-
-        # process the body parameter
-        _body_params = None
-        if _params['database_clone']:
-            _body_params = _params['database_clone']
-
-        # set the HTTP header `Accept`
-        _header_params['Accept'] = self.api_client.select_header_accept(
-            ['application/json'])  # noqa: E501
-
-        # set the HTTP header `Content-Type`
-        _content_types_list = _params.get('_content_type',
-            self.api_client.select_header_content_type(
-                ['application/json']))
-        if _content_types_list:
-                _header_params['Content-Type'] = _content_types_list
-
-        # authentication setting
-        _auth_settings = []  # noqa: E501
-
-        _response_types_map = {
-            '200': "SuccessResponse",
-            '400': "ErrorResponse",
-            '401': "ErrorResponse",
-            '403': "ErrorResponse",
-            '404': "ErrorResponse",
-            '405': "ErrorResponse",
-            '409': "ErrorResponse",
-            '500': "ErrorResponse",
-            '503': "ErrorResponse",
-            '504': "ErrorResponse",
-        }
-
-        return self.api_client.call_api(
-            '/api/v2/databases/{name}/clone', 'POST',
-            _path_params,
-            _query_params,
-            _header_params,
-            body=_body_params,
-            post_params=_form_params,
-            files=_files,
-            response_types_map=_response_types_map,
-            auth_settings=_auth_settings,
-            async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
-            _preload_content=_params.get('_preload_content', True),
-            _request_timeout=_params.get('_request_timeout'),
-            collection_formats=_collection_formats,
-            _request_auth=_params.get('_request_auth'))
-
-    @validate_arguments
-    def create_database(self, database : Database, create_mode : Optional[StrictStr] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+    def create_database(self, database : Database, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
         """Create a database  # noqa: E501
 
         Create a database, with modifiers as query parameters. See the database definition for what is required to be provided in the request body. (Cloning not currently supported)  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.create_database(database, create_mode, kind, async_req=True)
         >>> result = thread.get()
 
         :param database: (required)
         :type database: Database
-        :param create_mode:
+        :param create_mode: A query parameter allowing support for different modes of resource creation.
         :type create_mode: str
         :param kind: Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.
         :type kind: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -283,27 +132,27 @@
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
         return self.create_database_with_http_info(database, create_mode, kind, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def create_database_with_http_info(self, database : Database, create_mode : Optional[StrictStr] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, **kwargs):  # noqa: E501
+    def create_database_with_http_info(self, database : Database, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, **kwargs):  # noqa: E501
         """Create a database  # noqa: E501
 
         Create a database, with modifiers as query parameters. See the database definition for what is required to be provided in the request body. (Cloning not currently supported)  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.create_database_with_http_info(database, create_mode, kind, async_req=True)
         >>> result = thread.get()
 
         :param database: (required)
         :type database: Database
-        :param create_mode:
+        :param create_mode: A query parameter allowing support for different modes of resource creation.
         :type create_mode: str
         :param kind: Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.
         :type kind: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
@@ -404,14 +253,15 @@
             '409': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
+            self._root,
             '/api/v2/databases', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
@@ -421,28 +271,28 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def create_database_from_share(self, create_mode : Optional[StrictStr] = None, name : Annotated[Optional[StrictStr], Field(description="Name of the database to be created")] = None, share : Annotated[Optional[StrictStr], Field(description="The share the database should be created from. Should be of the form \"<provider_account>.<share_name>\".")] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+    def create_database_from_share(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, share : Annotated[Optional[StrictStr], Field(description="The share the database should be created from. Should be of the form \"<provider_account>.<share_name>\".")] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
         """Create a database from a share.  # noqa: E501
 
         Create a database from a given share  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_database_from_share(create_mode, name, share, kind, async_req=True)
+        >>> thread = api.create_database_from_share(name, create_mode, share, kind, async_req=True)
         >>> result = thread.get()
 
-        :param create_mode:
-        :type create_mode: str
-        :param name: Name of the database to be created
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
+        :param create_mode: A query parameter allowing support for different modes of resource creation.
+        :type create_mode: str
         :param share: The share the database should be created from. Should be of the form \"<provider_account>.<share_name>\".
         :type share: str
         :param kind: Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.
         :type kind: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -455,31 +305,31 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.create_database_from_share_with_http_info(create_mode, name, share, kind, **kwargs)  # noqa: E501
+        return self.create_database_from_share_with_http_info(name, create_mode, share, kind, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def create_database_from_share_with_http_info(self, create_mode : Optional[StrictStr] = None, name : Annotated[Optional[StrictStr], Field(description="Name of the database to be created")] = None, share : Annotated[Optional[StrictStr], Field(description="The share the database should be created from. Should be of the form \"<provider_account>.<share_name>\".")] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, **kwargs):  # noqa: E501
+    def create_database_from_share_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, share : Annotated[Optional[StrictStr], Field(description="The share the database should be created from. Should be of the form \"<provider_account>.<share_name>\".")] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, **kwargs):  # noqa: E501
         """Create a database from a share.  # noqa: E501
 
         Create a database from a given share  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_database_from_share_with_http_info(create_mode, name, share, kind, async_req=True)
+        >>> thread = api.create_database_from_share_with_http_info(name, create_mode, share, kind, async_req=True)
         >>> result = thread.get()
 
-        :param create_mode:
-        :type create_mode: str
-        :param name: Name of the database to be created
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
+        :param create_mode: A query parameter allowing support for different modes of resource creation.
+        :type create_mode: str
         :param share: The share the database should be created from. Should be of the form \"<provider_account>.<share_name>\".
         :type share: str
         :param kind: Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.
         :type kind: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
@@ -503,16 +353,16 @@
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
-            'create_mode',
             'name',
+            'create_mode',
             'share',
             'kind'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
@@ -534,21 +384,21 @@
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+        if _params['name']:
+            _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
         if _params.get('create_mode') is not None:  # noqa: E501
             _query_params.append(('createMode', _params['create_mode']))
-        if _params.get('name') is not None:  # noqa: E501
-            _query_params.append(('name', _params['name']))
         if _params.get('share') is not None:  # noqa: E501
             _query_params.append(('share', _params['share']))
         if _params.get('kind') is not None:  # noqa: E501
             _query_params.append(('kind', _params['kind']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
@@ -577,15 +427,16 @@
             '409': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/from_share', 'POST',
+            self._root,
+            '/api/v2/databases/{name}:from_share', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -594,25 +445,25 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def create_or_update_database(self, name : constr(strict=True), database : Database, **kwargs) -> SuccessResponse:  # noqa: E501
+    def create_or_alter_database(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], database : Database, **kwargs) -> SuccessResponse:  # noqa: E501
         """Create a (or alter an existing) database.  # noqa: E501
 
         Create a (or alter an existing) database. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_or_update_database(name, database, async_req=True)
+        >>> thread = api.create_or_alter_database(name, database, async_req=True)
         >>> result = thread.get()
 
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param database: (required)
         :type database: Database
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -624,28 +475,28 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.create_or_update_database_with_http_info(name, database, **kwargs)  # noqa: E501
+        return self.create_or_alter_database_with_http_info(name, database, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def create_or_update_database_with_http_info(self, name : constr(strict=True), database : Database, **kwargs):  # noqa: E501
+    def create_or_alter_database_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], database : Database, **kwargs):  # noqa: E501
         """Create a (or alter an existing) database.  # noqa: E501
 
         Create a (or alter an existing) database. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_or_update_database_with_http_info(name, database, async_req=True)
+        >>> thread = api.create_or_alter_database_with_http_info(name, database, async_req=True)
         >>> result = thread.get()
 
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param database: (required)
         :type database: Database
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
@@ -688,15 +539,15 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method create_or_update_database" % _key
+                    " to method create_or_alter_database" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
@@ -742,14 +593,15 @@
             '405': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
+            self._root,
             '/api/v2/databases/{name}', 'PUT',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
@@ -759,30 +611,32 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def delete_database(self, name : constr(strict=True), if_exists : Optional[StrictBool] = None, restrict : Annotated[Optional[StrictBool], Field(description="Specifies whether the database should not be droppped if there are existing foreign key references. Returns a warning instead.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Delete a database.  # noqa: E501
+    def clone_database(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], database_clone : DatabaseClone, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+        """Clone a database  # noqa: E501
 
-        Delete a database with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
+        Clone an existing database, with modifiers as query parameters. See the database definition for what is required to be provided in the request body. (Cloning not currently supported)  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.delete_database(name, if_exists, restrict, async_req=True)
+        >>> thread = api.clone_database(name, database_clone, create_mode, kind, async_req=True)
         >>> result = thread.get()
 
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists:
-        :type if_exists: bool
-        :param restrict: Specifies whether the database should not be droppped if there are existing foreign key references. Returns a warning instead.
-        :type restrict: bool
+        :param database_clone: (required)
+        :type database_clone: DatabaseClone
+        :param create_mode: A query parameter allowing support for different modes of resource creation.
+        :type create_mode: str
+        :param kind: Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.
+        :type kind: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
@@ -791,33 +645,35 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.delete_database_with_http_info(name, if_exists, restrict, **kwargs)  # noqa: E501
+        return self.clone_database_with_http_info(name, database_clone, create_mode, kind, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def delete_database_with_http_info(self, name : constr(strict=True), if_exists : Optional[StrictBool] = None, restrict : Annotated[Optional[StrictBool], Field(description="Specifies whether the database should not be droppped if there are existing foreign key references. Returns a warning instead.")] = None, **kwargs):  # noqa: E501
-        """Delete a database.  # noqa: E501
+    def clone_database_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], database_clone : DatabaseClone, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, **kwargs):  # noqa: E501
+        """Clone a database  # noqa: E501
 
-        Delete a database with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
+        Clone an existing database, with modifiers as query parameters. See the database definition for what is required to be provided in the request body. (Cloning not currently supported)  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.delete_database_with_http_info(name, if_exists, restrict, async_req=True)
+        >>> thread = api.clone_database_with_http_info(name, database_clone, create_mode, kind, async_req=True)
         >>> result = thread.get()
 
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists:
-        :type if_exists: bool
-        :param restrict: Specifies whether the database should not be droppped if there are existing foreign key references. Returns a warning instead.
-        :type restrict: bool
+        :param database_clone: (required)
+        :type database_clone: DatabaseClone
+        :param create_mode: A query parameter allowing support for different modes of resource creation.
+        :type create_mode: str
+        :param kind: Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.
+        :type kind: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -838,16 +694,17 @@
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
             'name',
-            'if_exists',
-            'restrict'
+            'database_clone',
+            'create_mode',
+            'kind'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -858,64 +715,75 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method delete_database" % _key
+                    " to method clone_database" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
-        if _params.get('if_exists') is not None:  # noqa: E501
-            _query_params.append(('ifExists', _params['if_exists']))
-        if _params.get('restrict') is not None:  # noqa: E501
-            _query_params.append(('restrict', _params['restrict']))
+        if _params.get('create_mode') is not None:  # noqa: E501
+            _query_params.append(('createMode', _params['create_mode']))
+        if _params.get('kind') is not None:  # noqa: E501
+            _query_params.append(('kind', _params['kind']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
+        if _params['database_clone']:
+            _body_params = _params['database_clone']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
+        # set the HTTP header `Content-Type`
+        _content_types_list = _params.get('_content_type',
+            self.api_client.select_header_content_type(
+                ['application/json']))
+        if _content_types_list:
+                _header_params['Content-Type'] = _content_types_list
+
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '409': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{name}', 'DELETE',
+            self._root,
+            '/api/v2/databases/{name}:clone', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -924,25 +792,25 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def disable_database_failover(self, name : constr(strict=True), account_identifiers : Optional[AccountIdentifiers] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+    def disable_database_failover(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], account_identifiers : Optional[AccountIdentifiers] = None, **kwargs) -> SuccessResponse:  # noqa: E501
         """Disable database failover.  # noqa: E501
 
         Disables failover for this primary database, meaning no replica of this database (i.e. secondary database) can be promoted to serve as the primary database.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.disable_database_failover(name, account_identifiers, async_req=True)
         >>> result = thread.get()
 
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param account_identifiers:
         :type account_identifiers: AccountIdentifiers
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -957,25 +825,25 @@
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
         return self.disable_database_failover_with_http_info(name, account_identifiers, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def disable_database_failover_with_http_info(self, name : constr(strict=True), account_identifiers : Optional[AccountIdentifiers] = None, **kwargs):  # noqa: E501
+    def disable_database_failover_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], account_identifiers : Optional[AccountIdentifiers] = None, **kwargs):  # noqa: E501
         """Disable database failover.  # noqa: E501
 
         Disables failover for this primary database, meaning no replica of this database (i.e. secondary database) can be promoted to serve as the primary database.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.disable_database_failover_with_http_info(name, account_identifiers, async_req=True)
         >>> result = thread.get()
 
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param account_identifiers:
         :type account_identifiers: AccountIdentifiers
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
@@ -1073,14 +941,15 @@
             '409': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
+            self._root,
             '/api/v2/databases/{name}/failover:disable', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
@@ -1090,25 +959,25 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def disable_database_replication(self, name : constr(strict=True), account_identifiers : Optional[AccountIdentifiers] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+    def disable_database_replication(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], account_identifiers : Optional[AccountIdentifiers] = None, **kwargs) -> SuccessResponse:  # noqa: E501
         """Disable database replication.  # noqa: E501
 
         Disables replication for this primary database, meaning no replica of this database (i.e. secondary database) in another account can be refreshed. Any secondary databases remain linked to the primary database, but requests to refresh a secondary database are denied.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.disable_database_replication(name, account_identifiers, async_req=True)
         >>> result = thread.get()
 
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param account_identifiers:
         :type account_identifiers: AccountIdentifiers
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -1123,25 +992,25 @@
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
         return self.disable_database_replication_with_http_info(name, account_identifiers, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def disable_database_replication_with_http_info(self, name : constr(strict=True), account_identifiers : Optional[AccountIdentifiers] = None, **kwargs):  # noqa: E501
+    def disable_database_replication_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], account_identifiers : Optional[AccountIdentifiers] = None, **kwargs):  # noqa: E501
         """Disable database replication.  # noqa: E501
 
         Disables replication for this primary database, meaning no replica of this database (i.e. secondary database) in another account can be refreshed. Any secondary databases remain linked to the primary database, but requests to refresh a secondary database are denied.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.disable_database_replication_with_http_info(name, account_identifiers, async_req=True)
         >>> result = thread.get()
 
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param account_identifiers:
         :type account_identifiers: AccountIdentifiers
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
@@ -1239,14 +1108,15 @@
             '409': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
+            self._root,
             '/api/v2/databases/{name}/replication:disable', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
@@ -1256,25 +1126,25 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def enable_database_failover(self, name : constr(strict=True), account_identifiers : AccountIdentifiers, **kwargs) -> SuccessResponse:  # noqa: E501
+    def enable_database_failover(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], account_identifiers : AccountIdentifiers, **kwargs) -> SuccessResponse:  # noqa: E501
         """Enable database failover.  # noqa: E501
 
         Specifies a comma-separated list of accounts in your organization where a replica of this primary database can be promoted to serve as the primary database.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.enable_database_failover(name, account_identifiers, async_req=True)
         >>> result = thread.get()
 
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param account_identifiers: (required)
         :type account_identifiers: AccountIdentifiers
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -1289,25 +1159,25 @@
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
         return self.enable_database_failover_with_http_info(name, account_identifiers, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def enable_database_failover_with_http_info(self, name : constr(strict=True), account_identifiers : AccountIdentifiers, **kwargs):  # noqa: E501
+    def enable_database_failover_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], account_identifiers : AccountIdentifiers, **kwargs):  # noqa: E501
         """Enable database failover.  # noqa: E501
 
         Specifies a comma-separated list of accounts in your organization where a replica of this primary database can be promoted to serve as the primary database.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.enable_database_failover_with_http_info(name, account_identifiers, async_req=True)
         >>> result = thread.get()
 
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param account_identifiers: (required)
         :type account_identifiers: AccountIdentifiers
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
@@ -1405,14 +1275,15 @@
             '409': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
+            self._root,
             '/api/v2/databases/{name}/failover:enable', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
@@ -1422,25 +1293,25 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def enable_database_replication(self, name : constr(strict=True), account_identifiers : AccountIdentifiers, ignore_edition_check : Annotated[Optional[StrictBool], Field(description="Allows replicating data to accounts on lower editions. Please see https://docs.snowflake.com/en/sql-reference/sql/alter-database for full description.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+    def enable_database_replication(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], account_identifiers : AccountIdentifiers, ignore_edition_check : Annotated[Optional[StrictBool], Field(description="Allows replicating data to accounts on lower editions. Please see https://docs.snowflake.com/en/sql-reference/sql/alter-database for full description.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
         """Enable database replication.  # noqa: E501
 
         Promotes a local database to serve as a primary database for replication. A primary database can be replicated in one or more accounts, allowing users in those accounts to query objects in each secondary (i.e. replica) database.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.enable_database_replication(name, account_identifiers, ignore_edition_check, async_req=True)
         >>> result = thread.get()
 
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param account_identifiers: (required)
         :type account_identifiers: AccountIdentifiers
         :param ignore_edition_check: Allows replicating data to accounts on lower editions. Please see https://docs.snowflake.com/en/sql-reference/sql/alter-database for full description.
         :type ignore_edition_check: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
@@ -1457,25 +1328,25 @@
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
         return self.enable_database_replication_with_http_info(name, account_identifiers, ignore_edition_check, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def enable_database_replication_with_http_info(self, name : constr(strict=True), account_identifiers : AccountIdentifiers, ignore_edition_check : Annotated[Optional[StrictBool], Field(description="Allows replicating data to accounts on lower editions. Please see https://docs.snowflake.com/en/sql-reference/sql/alter-database for full description.")] = None, **kwargs):  # noqa: E501
+    def enable_database_replication_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], account_identifiers : AccountIdentifiers, ignore_edition_check : Annotated[Optional[StrictBool], Field(description="Allows replicating data to accounts on lower editions. Please see https://docs.snowflake.com/en/sql-reference/sql/alter-database for full description.")] = None, **kwargs):  # noqa: E501
         """Enable database replication.  # noqa: E501
 
         Promotes a local database to serve as a primary database for replication. A primary database can be replicated in one or more accounts, allowing users in those accounts to query objects in each secondary (i.e. replica) database.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.enable_database_replication_with_http_info(name, account_identifiers, ignore_edition_check, async_req=True)
         >>> result = thread.get()
 
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param account_identifiers: (required)
         :type account_identifiers: AccountIdentifiers
         :param ignore_edition_check: Allows replicating data to accounts on lower editions. Please see https://docs.snowflake.com/en/sql-reference/sql/alter-database for full description.
         :type ignore_edition_check: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
@@ -1578,14 +1449,15 @@
             '409': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
+            self._root,
             '/api/v2/databases/{name}/replication:enable', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
@@ -1595,25 +1467,25 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def fetch_database(self, name : constr(strict=True), **kwargs) -> Database:  # noqa: E501
+    def fetch_database(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> Database:  # noqa: E501
         """fetch_database  # noqa: E501
 
         Fetch a database.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.fetch_database(name, async_req=True)
         >>> result = thread.get()
 
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -1626,25 +1498,25 @@
                  returns the request thread.
         :rtype: Database
         """
         kwargs['_return_http_data_only'] = True
         return self.fetch_database_with_http_info(name, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def fetch_database_with_http_info(self, name : constr(strict=True), **kwargs):  # noqa: E501
+    def fetch_database_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
         """fetch_database  # noqa: E501
 
         Fetch a database.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.fetch_database_with_http_info(name, async_req=True)
         >>> result = thread.get()
 
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -1729,14 +1601,15 @@
             '405': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
+            self._root,
             '/api/v2/databases/{name}', 'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
@@ -1746,72 +1619,72 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def list_databases(self, like : Optional[StrictStr] = None, starts_with : Optional[StrictStr] = None, show_limit : Optional[StrictInt] = None, from_name : Optional[StrictStr] = None, history : Optional[StrictBool] = None, **kwargs) -> List[Database]:  # noqa: E501
+    def list_databases(self, like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, starts_with : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.")] = None, show_limit : Annotated[Optional[StrictInt], Field(description="A query parameter that limits the maximum number of rows returned by a command.")] = None, from_name : Annotated[Optional[StrictStr], Field(description="A query parameter enables fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name.")] = None, history : Annotated[Optional[StrictBool], Field(description="Optionally includes dropped databases that have not yet been purged.")] = None, **kwargs) -> Iterable[Database]:  # noqa: E501
         """List databases  # noqa: E501
 
         Lists the accessible databases.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.list_databases(like, starts_with, show_limit, from_name, history, async_req=True)
         >>> result = thread.get()
 
-        :param like:
+        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
         :type like: str
-        :param starts_with:
+        :param starts_with: A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
         :type starts_with: str
-        :param show_limit:
+        :param show_limit: A query parameter that limits the maximum number of rows returned by a command.
         :type show_limit: int
-        :param from_name:
+        :param from_name: A query parameter enables fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name.
         :type from_name: str
-        :param history:
+        :param history: Optionally includes dropped databases that have not yet been purged.
         :type history: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: List[Database]
+        :rtype: Iterable[Database]
         """
         kwargs['_return_http_data_only'] = True
         return self.list_databases_with_http_info(like, starts_with, show_limit, from_name, history, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def list_databases_with_http_info(self, like : Optional[StrictStr] = None, starts_with : Optional[StrictStr] = None, show_limit : Optional[StrictInt] = None, from_name : Optional[StrictStr] = None, history : Optional[StrictBool] = None, **kwargs):  # noqa: E501
+    def list_databases_with_http_info(self, like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, starts_with : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.")] = None, show_limit : Annotated[Optional[StrictInt], Field(description="A query parameter that limits the maximum number of rows returned by a command.")] = None, from_name : Annotated[Optional[StrictStr], Field(description="A query parameter enables fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name.")] = None, history : Annotated[Optional[StrictBool], Field(description="Optionally includes dropped databases that have not yet been purged.")] = None, **kwargs):  # noqa: E501
         """List databases  # noqa: E501
 
         Lists the accessible databases.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.list_databases_with_http_info(like, starts_with, show_limit, from_name, history, async_req=True)
         >>> result = thread.get()
 
-        :param like:
+        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
         :type like: str
-        :param starts_with:
+        :param starts_with: A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
         :type starts_with: str
-        :param show_limit:
+        :param show_limit: A query parameter that limits the maximum number of rows returned by a command.
         :type show_limit: int
-        :param from_name:
+        :param from_name: A query parameter enables fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name.
         :type from_name: str
-        :param history:
+        :param history: Optionally includes dropped databases that have not yet been purged.
         :type history: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -1826,15 +1699,15 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(List[Database], status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(Iterable[Database], status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
             'like',
             'starts_with',
@@ -1896,26 +1769,27 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "List[Database]",
+            '200': "Iterable[Database]",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
+            self._root,
             '/api/v2/databases', 'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
@@ -1925,25 +1799,25 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def primary_database_failover(self, name : constr(strict=True), **kwargs) -> SuccessResponse:  # noqa: E501
+    def primary_database_failover(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> SuccessResponse:  # noqa: E501
         """Set database as primary.  # noqa: E501
 
         Promotes the specified secondary (replica) database to serve as the primary database.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.primary_database_failover(name, async_req=True)
         >>> result = thread.get()
 
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -1956,25 +1830,25 @@
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
         return self.primary_database_failover_with_http_info(name, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def primary_database_failover_with_http_info(self, name : constr(strict=True), **kwargs):  # noqa: E501
+    def primary_database_failover_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
         """Set database as primary.  # noqa: E501
 
         Promotes the specified secondary (replica) database to serve as the primary database.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.primary_database_failover_with_http_info(name, async_req=True)
         >>> result = thread.get()
 
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -2060,14 +1934,15 @@
             '409': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
+            self._root,
             '/api/v2/databases/{name}/failover:primary', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
@@ -2077,25 +1952,25 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def refresh_database_replication(self, name : constr(strict=True), **kwargs) -> SuccessResponse:  # noqa: E501
+    def refresh_database_replication(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> SuccessResponse:  # noqa: E501
         """Refresh database replications.  # noqa: E501
 
         Refreshes a secondary database from a snapshot of its primary database. A snapshot includes changes to the objects and data.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.refresh_database_replication(name, async_req=True)
         >>> result = thread.get()
 
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -2108,25 +1983,25 @@
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
         return self.refresh_database_replication_with_http_info(name, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def refresh_database_replication_with_http_info(self, name : constr(strict=True), **kwargs):  # noqa: E501
+    def refresh_database_replication_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
         """Refresh database replications.  # noqa: E501
 
         Refreshes a secondary database from a snapshot of its primary database. A snapshot includes changes to the objects and data.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.refresh_database_replication_with_http_info(name, async_req=True)
         >>> result = thread.get()
 
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -2212,22 +2087,189 @@
             '409': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
+            self._root,
             '/api/v2/databases/{name}/replication:refresh', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
+            auth_settings=_auth_settings,
+            async_req=_params.get('async_req'),
+            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _preload_content=_params.get('_preload_content', True),
+            _request_timeout=_params.get('_request_timeout'),
+            collection_formats=_collection_formats,
+            _request_auth=_params.get('_request_auth'))
+
+    @validate_arguments
+    def delete_database(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, restrict : Annotated[Optional[StrictBool], Field(description="Specifies whether the database should not be droppped if there are existing foreign key references. Returns a warning instead.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+        """Delete a database.  # noqa: E501
+
+        Delete a database with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
+        This method makes a synchronous HTTP request by default. To make an
+        asynchronous HTTP request, please pass async_req=True
+
+        >>> thread = api.delete_database(name, if_exists, restrict, async_req=True)
+        >>> result = thread.get()
+
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :type name: str
+        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :type if_exists: bool
+        :param restrict: Specifies whether the database should not be droppped if there are existing foreign key references. Returns a warning instead.
+        :type restrict: bool
+        :param async_req: Whether to execute the request asynchronously.
+        :type async_req: bool, optional
+        :param _preload_content: if False, the urllib3.HTTPResponse object will
+                                 be returned without reading/decoding response
+                                 data. Default is True.
+        :type _preload_content: bool, optional
+        :param _request_timeout: timeout setting for this request. If one
+                                 number provided, it will be total request
+                                 timeout. It can also be a pair (tuple) of
+                                 (connection, read) timeouts.
+        :return: Returns the result object.
+                 If the method is called asynchronously,
+                 returns the request thread.
+        :rtype: SuccessResponse
+        """
+        kwargs['_return_http_data_only'] = True
+        return self.delete_database_with_http_info(name, if_exists, restrict, **kwargs)  # noqa: E501
+
+    @validate_arguments
+    def delete_database_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, restrict : Annotated[Optional[StrictBool], Field(description="Specifies whether the database should not be droppped if there are existing foreign key references. Returns a warning instead.")] = None, **kwargs):  # noqa: E501
+        """Delete a database.  # noqa: E501
+
+        Delete a database with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
+        This method makes a synchronous HTTP request by default. To make an
+        asynchronous HTTP request, please pass async_req=True
+
+        >>> thread = api.delete_database_with_http_info(name, if_exists, restrict, async_req=True)
+        >>> result = thread.get()
+
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :type name: str
+        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :type if_exists: bool
+        :param restrict: Specifies whether the database should not be droppped if there are existing foreign key references. Returns a warning instead.
+        :type restrict: bool
+        :param async_req: Whether to execute the request asynchronously.
+        :type async_req: bool, optional
+        :param _return_http_data_only: response data without head status code
+                                       and headers
+        :type _return_http_data_only: bool, optional
+        :param _preload_content: if False, the urllib3.HTTPResponse object will
+                                 be returned without reading/decoding response
+                                 data. Default is True.
+        :type _preload_content: bool, optional
+        :param _request_timeout: timeout setting for this request. If one
+                                 number provided, it will be total request
+                                 timeout. It can also be a pair (tuple) of
+                                 (connection, read) timeouts.
+        :param _request_auth: set to override the auth_settings for an a single
+                              request; this effectively ignores the authentication
+                              in the spec for a single request.
+        :type _request_auth: dict, optional
+        :type _content_type: string, optional: force content-type for the request
+        :return: Returns the result object.
+                 If the method is called asynchronously,
+                 returns the request thread.
+        :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
+        """
+
+        _params = locals()
+
+        _all_params = [
+            'name',
+            'if_exists',
+            'restrict'
+        ]
+        _all_params.extend(
+            [
+                'async_req',
+                '_return_http_data_only',
+                '_preload_content',
+                '_request_timeout',
+                '_request_auth',
+                '_content_type',
+                '_headers'
+            ]
+        )
+
+        # validate the arguments
+        for _key, _val in _params['kwargs'].items():
+            if _key not in _all_params:
+                raise _APITypeError(
+                    "Got an unexpected keyword argument '%s'"
+                    " to method delete_database" % _key
+                )
+            _params[_key] = _val
+        del _params['kwargs']
+
+        _collection_formats = {}
+
+        # process the path parameters
+        _path_params = {}
+        if _params['name']:
+            _path_params['name'] = _params['name']
+
+        # process the query parameters
+        _query_params = []
+        if _params.get('if_exists') is not None:  # noqa: E501
+            _query_params.append(('ifExists', _params['if_exists']))
+        if _params.get('restrict') is not None:  # noqa: E501
+            _query_params.append(('restrict', _params['restrict']))
+
+        # process the header parameters
+        _header_params = dict(_params.get('_headers', {}))
+
+        # process the form parameters
+        _form_params = []
+        _files = {}
+
+        # process the body parameter
+        _body_params = None
+
+        # set the HTTP header `Accept`
+        _header_params['Accept'] = self.api_client.select_header_accept(
+            ['application/json'])  # noqa: E501
+
+        # authentication setting
+        _auth_settings = []  # noqa: E501
+
+        _response_types_map = {
+            '200': "SuccessResponse",
+            '400': "ErrorResponse",
+            '401': "ErrorResponse",
+            '403': "ErrorResponse",
+            '404': "ErrorResponse",
+            '405': "ErrorResponse",
+            '500': "ErrorResponse",
+            '503': "ErrorResponse",
+            '504': "ErrorResponse",
+        }
+
+        return self.api_client.call_api(
+            self._root,
+            '/api/v2/databases/{name}', 'DELETE',
+            _path_params,
+            _query_params,
+            _header_params,
+            body=_body_params,
+            post_params=_form_params,
+            files=_files,
+            response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/database/_generated/models/__init__.py` & `snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -5,14 +5,16 @@
     Snowflake Database API
 
     The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 # import models into model package
 from snowflake.core.database._generated.models.account_identifiers import AccountIdentifiers
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/database/_generated/models/account_identifiers.py` & `snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/account_identifiers.py`

 * *Files 6% similar despite different names*

```diff
@@ -4,26 +4,28 @@
     Snowflake Database API
 
     The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 from typing import List
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, conlist, constr
+from snowflake.core.database._generated.pydantic_compatibility import BaseModel, Field, conlist, constr
 
 class AccountIdentifiers(BaseModel):
     accounts: conlist(constr(strict=True, min_length=1)) = Field(...)
     __properties = ["accounts"]
 
 
     class Config:
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/database/_generated/models/database.py` & `snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/database_clone.py`

 * *Files 4% similar despite different names*

```diff
@@ -4,28 +4,32 @@
     Snowflake Database API
 
     The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 from datetime import datetime
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, constr, validator
+from snowflake.core.database._generated.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, constr, validator
+from snowflake.core.database._generated.models.point_of_time import PointOfTime
 
-class Database(BaseModel):
+class DatabaseClone(BaseModel):
+    point_of_time: Optional[PointOfTime] = None
     created_on: Optional[datetime] = None
     name: constr(strict=True) = Field(...)
     is_default: Optional[StrictBool] = None
     is_current: Optional[StrictBool] = None
     origin: Optional[StrictStr] = None
     owner: Optional[StrictStr] = None
     comment: Optional[StrictStr] = None
@@ -33,18 +37,18 @@
     retention_time: Optional[StrictInt] = None
     dropped_on: Optional[datetime] = None
     kind: Optional[StrictStr] = None
     budget: Optional[StrictStr] = None
     owner_role_type: Optional[StrictStr] = None
     data_retention_time_in_days: Optional[StrictInt] = None
     default_ddl_collation: Optional[StrictStr] = None
-    log_level: Optional[StrictStr] = Field(None, description="Specifies the severity level of messages that should be ingested and made available in the active event table. At the time of writing the supported values are TRACE, DEBUG, INFO, WARN, ERROR, FATAL and OFF.")
+    log_level: Optional[StrictStr] = None
     max_data_extension_time_in_days: Optional[StrictInt] = None
     suspend_task_after_num_failures: Optional[StrictInt] = None
-    trace_level: Optional[StrictStr] = Field(None, description="Controls how trace events are ingested into the event table. At the time of writing the supported values are ALWAYS, ON_EVENT and OFF.")
+    trace_level: Optional[StrictStr] = None
     user_task_managed_initial_warehouse_size: Optional[StrictStr] = None
     user_task_timeout_ms: Optional[StrictInt] = None
     __properties = ["created_on", "name", "is_default", "is_current", "origin", "owner", "comment", "options", "retention_time", "dropped_on", "kind", "budget", "owner_role_type", "data_retention_time_in_days", "default_ddl_collation", "log_level", "max_data_extension_time_in_days", "suspend_task_after_num_failures", "trace_level", "user_task_managed_initial_warehouse_size", "user_task_timeout_ms"]
 
 
     @validator('name')
     def name_validate_regular_expression(cls, v):
@@ -61,16 +65,16 @@
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
         """Returns the JSON representation of the model using alias"""
         return json.dumps(self.to_dict())
 
     @classmethod
-    def from_json(cls, json_str: str) -> Database:
-        """Create an instance of Database from a JSON string"""
+    def from_json(cls, json_str: str) -> DatabaseClone:
+        """Create an instance of DatabaseClone from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         _dict = self.dict(by_alias=True,
                           exclude={
                             "created_on",
@@ -89,23 +93,25 @@
         # set to None if dropped_on (nullable) is None
         if self.dropped_on is None:
             _dict['dropped_on'] = None
 
         return _dict
 
     @classmethod
-    def from_dict(cls, obj: dict) -> Database:
-        """Create an instance of Database from a dict"""
+    def from_dict(cls, obj: dict) -> DatabaseClone:
+        """Create an instance of DatabaseClone from a dict"""
         if obj is None:
             return None
 
         if type(obj) is not dict:
-            return Database.parse_obj(obj)
+            return DatabaseClone.parse_obj(obj)
+
+        _obj = DatabaseClone.parse_obj({
+            "point_of_time": PointOfTime.from_dict(obj.get("point_of_time")) if obj.get("point_of_time") is not None else None,
 
-        _obj = Database.parse_obj({
             "created_on": obj.get("created_on"),
 
             "name": obj.get("name"),
 
             "is_default": obj.get("is_default"),
 
             "is_current": obj.get("is_current"),
@@ -145,20 +151,22 @@
             "user_task_timeout_ms": obj.get("user_task_timeout_ms"),
 
         })
         return _obj
 
 
 from typing import Optional, List, Dict
+from snowflake.core.database._generated.models.point_of_time import PointOfTime
 
-class DatabaseModel():
+class DatabaseCloneModel():
     def __init__(
         self,
         name: str,
         # optional properties
+        point_of_time: Optional[PointOfTime] = None,
         created_on: Optional[datetime] = None,
         is_default: Optional[bool] = None,
         is_current: Optional[bool] = None,
         origin: Optional[str] = None,
         owner: Optional[str] = None,
         comment: Optional[str] = None,
         options: Optional[str] = None,
@@ -172,14 +180,15 @@
         log_level: Optional[str] = None,
         max_data_extension_time_in_days: Optional[int] = None,
         suspend_task_after_num_failures: Optional[int] = None,
         trace_level: Optional[str] = None,
         user_task_managed_initial_warehouse_size: Optional[str] = None,
         user_task_timeout_ms: Optional[int] = None,
     ):
+        self.point_of_time = point_of_time
         self.created_on = created_on
         self.name = name
         self.is_default = is_default
         self.is_current = is_current
         self.origin = origin
         self.owner = owner
         self.comment = comment
@@ -196,15 +205,17 @@
         self.suspend_task_after_num_failures = suspend_task_after_num_failures
         self.trace_level = trace_level
         self.user_task_managed_initial_warehouse_size = user_task_managed_initial_warehouse_size
         self.user_task_timeout_ms = user_task_timeout_ms
     __properties = ["created_on", "name", "is_default", "is_current", "origin", "owner", "comment", "options", "retention_time", "dropped_on", "kind", "budget", "owner_role_type", "data_retention_time_in_days", "default_ddl_collation", "log_level", "max_data_extension_time_in_days", "suspend_task_after_num_failures", "trace_level", "user_task_managed_initial_warehouse_size", "user_task_timeout_ms"]
 
     def _to_model(self):
-        return Database(
+        return DatabaseClone(
+            point_of_time=self.point_of_time._to_model() if self.point_of_time is not None else None,
+
             created_on=self.created_on,
 
             name=self.name,
 
             is_default=self.is_default,
 
             is_current=self.is_current,
@@ -242,16 +253,18 @@
             user_task_managed_initial_warehouse_size=self.user_task_managed_initial_warehouse_size,
 
             user_task_timeout_ms=self.user_task_timeout_ms,
 
         )
 
     @classmethod
-    def _from_model(cls, model) -> DatabaseModel:
-        return DatabaseModel(
+    def _from_model(cls, model) -> DatabaseCloneModel:
+        return DatabaseCloneModel(
+            point_of_time=PointOfTimeModel._from_model(model.point_of_time) if model.point_of_time is not None else None,
+
             created_on=model.created_on,
 
             name=model.name,
 
             is_default=model.is_default,
 
             is_current=model.is_current,
@@ -293,13 +306,13 @@
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
-    def from_dict(cls, obj: dict) -> DatabaseModel:
-        """Create an instance of Database from a dict"""
-        return cls._from_model(Database.from_dict(obj))
+    def from_dict(cls, obj: dict) -> DatabaseCloneModel:
+        """Create an instance of DatabaseClone from a dict"""
+        return cls._from_model(DatabaseClone.from_dict(obj))
 
 
-Database._model_class = DatabaseModel
+DatabaseClone._model_class = DatabaseCloneModel
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/database/_generated/models/database_clone.py` & `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/model_schema.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,55 +1,55 @@
 # coding: utf-8
 
 """
-    Snowflake Database API
+    Snowflake Schema API
 
-    The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
+    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 from datetime import datetime
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, constr, validator
-from snowflake.core.database._generated.models.point_of_time import PointOfTime
+from snowflake.core.schema._generated.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, constr, validator
 
-class DatabaseClone(BaseModel):
-    point_of_time: Optional[PointOfTime] = None
+class ModelSchema(BaseModel):
     created_on: Optional[datetime] = None
     name: constr(strict=True) = Field(...)
     is_default: Optional[StrictBool] = None
     is_current: Optional[StrictBool] = None
-    origin: Optional[StrictStr] = None
+    database_name: Optional[StrictStr] = None
     owner: Optional[StrictStr] = None
     comment: Optional[StrictStr] = None
     options: Optional[StrictStr] = None
     retention_time: Optional[StrictInt] = None
     dropped_on: Optional[datetime] = None
-    kind: Optional[StrictStr] = None
-    budget: Optional[StrictStr] = None
     owner_role_type: Optional[StrictStr] = None
+    budget: Optional[StrictStr] = None
     data_retention_time_in_days: Optional[StrictInt] = None
     default_ddl_collation: Optional[StrictStr] = None
-    log_level: Optional[StrictStr] = Field(None, description="Specifies the severity level of messages that should be ingested and made available in the active event table. At the time of writing the supported values are TRACE, DEBUG, INFO, WARN, ERROR, FATAL and OFF.")
+    log_level: Optional[StrictStr] = None
+    pipe_execution_paused: Optional[StrictBool] = None
     max_data_extension_time_in_days: Optional[StrictInt] = None
     suspend_task_after_num_failures: Optional[StrictInt] = None
-    trace_level: Optional[StrictStr] = Field(None, description="Controls how trace events are ingested into the event table. At the time of writing the supported values are ALWAYS, ON_EVENT and OFF.")
+    trace_level: Optional[StrictStr] = None
     user_task_managed_initial_warehouse_size: Optional[StrictStr] = None
     user_task_timeout_ms: Optional[StrictInt] = None
-    __properties = ["created_on", "name", "is_default", "is_current", "origin", "owner", "comment", "options", "retention_time", "dropped_on", "kind", "budget", "owner_role_type", "data_retention_time_in_days", "default_ddl_collation", "log_level", "max_data_extension_time_in_days", "suspend_task_after_num_failures", "trace_level", "user_task_managed_initial_warehouse_size", "user_task_timeout_ms"]
+    __properties = ["created_on", "name", "is_default", "is_current", "database_name", "owner", "comment", "options", "retention_time", "dropped_on", "owner_role_type", "budget", "data_retention_time_in_days", "default_ddl_collation", "log_level", "pipe_execution_paused", "max_data_extension_time_in_days", "suspend_task_after_num_failures", "trace_level", "user_task_managed_initial_warehouse_size", "user_task_timeout_ms"]
 
 
     @validator('name')
     def name_validate_regular_expression(cls, v):
         if not re.match(r"""^\"([^\"]|\"\")+\"|[a-zA-Z_][a-zA-Z0-9_$]*$""", v):
             raise ValueError(r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/""")
         return v
@@ -63,85 +63,82 @@
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
         """Returns the JSON representation of the model using alias"""
         return json.dumps(self.to_dict())
 
     @classmethod
-    def from_json(cls, json_str: str) -> DatabaseClone:
-        """Create an instance of DatabaseClone from a JSON string"""
+    def from_json(cls, json_str: str) -> ModelSchema:
+        """Create an instance of ModelSchema from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         _dict = self.dict(by_alias=True,
                           exclude={
                             "created_on",
                             "is_default",
                             "is_current",
-                            "origin",
+                            "database_name",
                             "owner",
                             "options",
                             "retention_time",
                             "dropped_on",
-                            "kind",
-                            "budget",
                             "owner_role_type",
+                            "budget",
                           },
                           exclude_none=True)
         # set to None if dropped_on (nullable) is None
         if self.dropped_on is None:
             _dict['dropped_on'] = None
 
         return _dict
 
     @classmethod
-    def from_dict(cls, obj: dict) -> DatabaseClone:
-        """Create an instance of DatabaseClone from a dict"""
+    def from_dict(cls, obj: dict) -> ModelSchema:
+        """Create an instance of ModelSchema from a dict"""
         if obj is None:
             return None
 
         if type(obj) is not dict:
-            return DatabaseClone.parse_obj(obj)
-
-        _obj = DatabaseClone.parse_obj({
-            "point_of_time": PointOfTime.from_dict(obj.get("point_of_time")) if obj.get("point_of_time") is not None else None,
+            return ModelSchema.parse_obj(obj)
 
+        _obj = ModelSchema.parse_obj({
             "created_on": obj.get("created_on"),
 
             "name": obj.get("name"),
 
             "is_default": obj.get("is_default"),
 
             "is_current": obj.get("is_current"),
 
-            "origin": obj.get("origin"),
+            "database_name": obj.get("database_name"),
 
             "owner": obj.get("owner"),
 
             "comment": obj.get("comment"),
 
             "options": obj.get("options"),
 
             "retention_time": obj.get("retention_time"),
 
             "dropped_on": obj.get("dropped_on"),
 
-            "kind": obj.get("kind"),
+            "owner_role_type": obj.get("owner_role_type"),
 
             "budget": obj.get("budget"),
 
-            "owner_role_type": obj.get("owner_role_type"),
-
             "data_retention_time_in_days": obj.get("data_retention_time_in_days"),
 
             "default_ddl_collation": obj.get("default_ddl_collation"),
 
             "log_level": obj.get("log_level"),
 
+            "pipe_execution_paused": obj.get("pipe_execution_paused"),
+
             "max_data_extension_time_in_days": obj.get("max_data_extension_time_in_days"),
 
             "suspend_task_after_num_failures": obj.get("suspend_task_after_num_failures"),
 
             "trace_level": obj.get("trace_level"),
 
             "user_task_managed_initial_warehouse_size": obj.get("user_task_managed_initial_warehouse_size"),
@@ -149,152 +146,145 @@
             "user_task_timeout_ms": obj.get("user_task_timeout_ms"),
 
         })
         return _obj
 
 
 from typing import Optional, List, Dict
-from snowflake.core.database._generated.models.point_of_time import PointOfTime
 
-class DatabaseCloneModel():
+class ModelSchemaModel():
     def __init__(
         self,
         name: str,
         # optional properties
-        point_of_time: Optional[PointOfTime] = None,
         created_on: Optional[datetime] = None,
         is_default: Optional[bool] = None,
         is_current: Optional[bool] = None,
-        origin: Optional[str] = None,
+        database_name: Optional[str] = None,
         owner: Optional[str] = None,
         comment: Optional[str] = None,
         options: Optional[str] = None,
         retention_time: Optional[int] = None,
         dropped_on: Optional[datetime] = None,
-        kind: Optional[str] = None,
-        budget: Optional[str] = None,
         owner_role_type: Optional[str] = None,
+        budget: Optional[str] = None,
         data_retention_time_in_days: Optional[int] = None,
         default_ddl_collation: Optional[str] = None,
         log_level: Optional[str] = None,
+        pipe_execution_paused: Optional[bool] = None,
         max_data_extension_time_in_days: Optional[int] = None,
         suspend_task_after_num_failures: Optional[int] = None,
         trace_level: Optional[str] = None,
         user_task_managed_initial_warehouse_size: Optional[str] = None,
         user_task_timeout_ms: Optional[int] = None,
     ):
-        self.point_of_time = point_of_time
         self.created_on = created_on
         self.name = name
         self.is_default = is_default
         self.is_current = is_current
-        self.origin = origin
+        self.database_name = database_name
         self.owner = owner
         self.comment = comment
         self.options = options
         self.retention_time = retention_time
         self.dropped_on = dropped_on
-        self.kind = kind
-        self.budget = budget
         self.owner_role_type = owner_role_type
+        self.budget = budget
         self.data_retention_time_in_days = data_retention_time_in_days
         self.default_ddl_collation = default_ddl_collation
         self.log_level = log_level
+        self.pipe_execution_paused = pipe_execution_paused
         self.max_data_extension_time_in_days = max_data_extension_time_in_days
         self.suspend_task_after_num_failures = suspend_task_after_num_failures
         self.trace_level = trace_level
         self.user_task_managed_initial_warehouse_size = user_task_managed_initial_warehouse_size
         self.user_task_timeout_ms = user_task_timeout_ms
-    __properties = ["created_on", "name", "is_default", "is_current", "origin", "owner", "comment", "options", "retention_time", "dropped_on", "kind", "budget", "owner_role_type", "data_retention_time_in_days", "default_ddl_collation", "log_level", "max_data_extension_time_in_days", "suspend_task_after_num_failures", "trace_level", "user_task_managed_initial_warehouse_size", "user_task_timeout_ms"]
+    __properties = ["created_on", "name", "is_default", "is_current", "database_name", "owner", "comment", "options", "retention_time", "dropped_on", "owner_role_type", "budget", "data_retention_time_in_days", "default_ddl_collation", "log_level", "pipe_execution_paused", "max_data_extension_time_in_days", "suspend_task_after_num_failures", "trace_level", "user_task_managed_initial_warehouse_size", "user_task_timeout_ms"]
 
     def _to_model(self):
-        return DatabaseClone(
-            point_of_time=self.point_of_time._to_model() if self.point_of_time is not None else None,
-
+        return ModelSchema(
             created_on=self.created_on,
 
             name=self.name,
 
             is_default=self.is_default,
 
             is_current=self.is_current,
 
-            origin=self.origin,
+            database_name=self.database_name,
 
             owner=self.owner,
 
             comment=self.comment,
 
             options=self.options,
 
             retention_time=self.retention_time,
 
             dropped_on=self.dropped_on,
 
-            kind=self.kind,
+            owner_role_type=self.owner_role_type,
 
             budget=self.budget,
 
-            owner_role_type=self.owner_role_type,
-
             data_retention_time_in_days=self.data_retention_time_in_days,
 
             default_ddl_collation=self.default_ddl_collation,
 
             log_level=self.log_level,
 
+            pipe_execution_paused=self.pipe_execution_paused,
+
             max_data_extension_time_in_days=self.max_data_extension_time_in_days,
 
             suspend_task_after_num_failures=self.suspend_task_after_num_failures,
 
             trace_level=self.trace_level,
 
             user_task_managed_initial_warehouse_size=self.user_task_managed_initial_warehouse_size,
 
             user_task_timeout_ms=self.user_task_timeout_ms,
 
         )
 
     @classmethod
-    def _from_model(cls, model) -> DatabaseCloneModel:
-        return DatabaseCloneModel(
-            point_of_time=PointOfTimeModel._from_model(model.point_of_time) if model.point_of_time is not None else None,
-
+    def _from_model(cls, model) -> ModelSchemaModel:
+        return ModelSchemaModel(
             created_on=model.created_on,
 
             name=model.name,
 
             is_default=model.is_default,
 
             is_current=model.is_current,
 
-            origin=model.origin,
+            database_name=model.database_name,
 
             owner=model.owner,
 
             comment=model.comment,
 
             options=model.options,
 
             retention_time=model.retention_time,
 
             dropped_on=model.dropped_on,
 
-            kind=model.kind,
+            owner_role_type=model.owner_role_type,
 
             budget=model.budget,
 
-            owner_role_type=model.owner_role_type,
-
             data_retention_time_in_days=model.data_retention_time_in_days,
 
             default_ddl_collation=model.default_ddl_collation,
 
             log_level=model.log_level,
 
+            pipe_execution_paused=model.pipe_execution_paused,
+
             max_data_extension_time_in_days=model.max_data_extension_time_in_days,
 
             suspend_task_after_num_failures=model.suspend_task_after_num_failures,
 
             trace_level=model.trace_level,
 
             user_task_managed_initial_warehouse_size=model.user_task_managed_initial_warehouse_size,
@@ -304,13 +294,13 @@
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
-    def from_dict(cls, obj: dict) -> DatabaseCloneModel:
-        """Create an instance of DatabaseClone from a dict"""
-        return cls._from_model(DatabaseClone.from_dict(obj))
+    def from_dict(cls, obj: dict) -> ModelSchemaModel:
+        """Create an instance of ModelSchema from a dict"""
+        return cls._from_model(ModelSchema.from_dict(obj))
 
 
-DatabaseClone._model_class = DatabaseCloneModel
+ModelSchema._model_class = ModelSchemaModel
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/database/_generated/models/error_response.py` & `snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/error_response.py`

 * *Files 3% similar despite different names*

```diff
@@ -4,32 +4,35 @@
     Snowflake Database API
 
     The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictStr
+from snowflake.core.database._generated.pydantic_compatibility import BaseModel, StrictStr
 
 class ErrorResponse(BaseModel):
-    message: Optional[StrictStr] = Field(None, description="Error message returned by server")
-    error_code: Optional[StrictStr] = Field(None, description="Error code")
-    request_id: Optional[StrictStr] = Field(None, description="Unique request id")
-    __properties = ["message", "error_code", "request_id"]
+    message: Optional[StrictStr] = None
+    code: Optional[StrictStr] = None
+    error_code: Optional[StrictStr] = None
+    request_id: Optional[StrictStr] = None
+    __properties = ["message", "code", "error_code", "request_id"]
 
 
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
@@ -61,14 +64,16 @@
 
         if type(obj) is not dict:
             return ErrorResponse.parse_obj(obj)
 
         _obj = ErrorResponse.parse_obj({
             "message": obj.get("message"),
 
+            "code": obj.get("code"),
+
             "error_code": obj.get("error_code"),
 
             "request_id": obj.get("request_id"),
 
         })
         return _obj
 
@@ -76,37 +81,43 @@
 from typing import Optional, List, Dict
 
 class ErrorResponseModel():
     def __init__(
         self,
         # optional properties
         message: Optional[str] = None,
+        code: Optional[str] = None,
         error_code: Optional[str] = None,
         request_id: Optional[str] = None,
     ):
         self.message = message
+        self.code = code
         self.error_code = error_code
         self.request_id = request_id
-    __properties = ["message", "error_code", "request_id"]
+    __properties = ["message", "code", "error_code", "request_id"]
 
     def _to_model(self):
         return ErrorResponse(
             message=self.message,
 
+            code=self.code,
+
             error_code=self.error_code,
 
             request_id=self.request_id,
 
         )
 
     @classmethod
     def _from_model(cls, model) -> ErrorResponseModel:
         return ErrorResponseModel(
             message=model.message,
 
+            code=model.code,
+
             error_code=model.error_code,
 
             request_id=model.request_id,
 
         )
 
     def to_dict(self):
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/database/_generated/models/point_of_time.py` & `snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/point_of_time.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,32 +4,34 @@
     Snowflake Database API
 
     The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 import snowflake.core.database._generated.models
 from snowflake.core.database._generated.models import *
 
 
 from typing import Optional, Union
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictStr
+from snowflake.core.database._generated.pydantic_compatibility import BaseModel, Field, StrictStr
 
 class PointOfTime(BaseModel):
     point_of_time_type: StrictStr = Field(...)
-    reference: Optional[StrictStr] = Field(None, description="The relation to the point of time. At the time of writing `at` and `before` are supported.")
+    reference: Optional[StrictStr] = None
     __properties = ["point_of_time_type", "reference"]
 
 
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/database/_generated/models/point_of_time_offset.py` & `snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/point_of_time_offset.py`

 * *Files 6% similar despite different names*

```diff
@@ -4,30 +4,32 @@
     Snowflake Database API
 
     The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import Field, StrictStr
+from snowflake.core.database._generated.pydantic_compatibility import StrictStr
 from snowflake.core.database._generated.models.point_of_time import PointOfTime
 
 class PointOfTimeOffset(PointOfTime):
-    offset: Optional[StrictStr] = Field(None, description="Offset of the point of time.")
+    offset: Optional[StrictStr] = None
     __properties = ["point_of_time_type", "reference"]
 
 
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/database/_generated/models/point_of_time_statement.py` & `snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/point_of_time_statement.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,30 +4,32 @@
     Snowflake Database API
 
     The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import Field, StrictStr
+from snowflake.core.database._generated.pydantic_compatibility import StrictStr
 from snowflake.core.database._generated.models.point_of_time import PointOfTime
 
 class PointOfTimeStatement(PointOfTime):
-    statement: Optional[StrictStr] = Field(None, description="Statement of the point of time.")
+    statement: Optional[StrictStr] = None
     __properties = ["point_of_time_type", "reference"]
 
 
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/database/_generated/models/point_of_time_timestamp.py` & `snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/point_of_time_timestamp.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,30 +4,32 @@
     Snowflake Database API
 
     The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import Field, StrictStr
+from snowflake.core.database._generated.pydantic_compatibility import StrictStr
 from snowflake.core.database._generated.models.point_of_time import PointOfTime
 
 class PointOfTimeTimestamp(PointOfTime):
-    timestamp: Optional[StrictStr] = Field(None, description="Timestamp of the point of time.")
+    timestamp: Optional[StrictStr] = None
     __properties = ["point_of_time_type", "reference"]
 
 
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/database/_generated/models/success_response.py` & `snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/success_response.py`

 * *Files 4% similar despite different names*

```diff
@@ -4,29 +4,31 @@
     Snowflake Database API
 
     The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictStr
+from snowflake.core.database._generated.pydantic_compatibility import BaseModel, StrictStr
 
 class SuccessResponse(BaseModel):
-    status: Optional[StrictStr] = Field(None, description="Message returned by server")
+    status: Optional[StrictStr] = None
     __properties = ["status"]
 
 
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/image_repository/__init__.py` & `snowflake_core-0.8.0/src/snowflake/core/image_repository/__init__.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.7.0/src/snowflake/core/image_repository/_image_repository.py` & `snowflake_core-0.8.0/src/snowflake/core/image_repository/_image_repository.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,25 +1,24 @@
-from typing import TYPE_CHECKING, Optional
+from typing import TYPE_CHECKING, Iterator, Optional
 
 from snowflake.core._common import (
     CreateMode,
     SchemaObjectCollectionParent,
     SchemaObjectReferenceMixin,
 )
-from snowflake.core._internal.pydantic_compatibility import StrictStr
 from snowflake.core._internal.telemetry import api_telemetry
-from snowflake.core.paging import PagedIter
+from snowflake.core.image_repository._generated.pydantic_compatibility import StrictStr
 
 
 if TYPE_CHECKING:
     from snowflake.core.schema import SchemaResource
 
 
 from snowflake.core.image_repository._generated import ImageRepositoryApi
-from snowflake.core.image_repository._generated.api_client import BridgeApiClient
+from snowflake.core.image_repository._generated.api_client import BridgeApiClient, StoredProcApiClient
 from snowflake.core.image_repository._generated.models.image_repository import (
     ImageRepositoryModel as ImageRepository,
 )
 
 
 class ImageRepositoryCollection(
     SchemaObjectCollectionParent["ImageRepositoryResource"]
@@ -30,15 +29,16 @@
         super().__init__(schema, ImageRepositoryResource)
         self._api = ImageRepositoryApi(
             root=self.root,
             resource_class=self._ref_class,
             bridge_client=BridgeApiClient(
                 root=self.root,
                 snowflake_connection=self._connection or self._session._conn._conn
-            )
+            ),
+            sproc_client=StoredProcApiClient(root=self.root)
         )
 
     @api_telemetry
     def create(
         self,
         image_repository: ImageRepository,
         mode: CreateMode = CreateMode.error_if_exists,
@@ -73,29 +73,30 @@
         return self[image_repository.name]
 
     @api_telemetry
     def iter(
         self,
         *,
         like: Optional[str] = None,
-    ) -> PagedIter[ImageRepository]:
+    ) -> Iterator[ImageRepository]:
         """Look up image repositories in Snowflake."""
-        return PagedIter(
-            data=self._api.list_image_repositories(
-                self.database.name,
-                self.schema.name,
-                StrictStr(like) if like is not None else None,
-                async_req=False,
-            ), map_=ImageRepository._from_model,
-        )
+        image_respositories = self._api.list_image_repositories(
+            self.database.name,
+            self.schema.name,
+            StrictStr(like) if like is not None else None,
+            async_req=False, )
+
+        return map(ImageRepository._from_model, iter(image_respositories))
 
 
 class ImageRepositoryResource(SchemaObjectReferenceMixin[ImageRepositoryCollection]):
     """A reference to an Image Repository in Snowflake."""
 
+    _supports_rest_api = True
+
     def __init__(self, name: str, collection: ImageRepositoryCollection):
         self.name = name
         self.collection = collection
 
     @api_telemetry
     def fetch(self) -> ImageRepository:
         """Fetch the image repository details from Snowflake."""
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/image_repository/_generated/__init__.py` & `snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/__init__.py`

 * *Files 20% similar despite different names*

```diff
@@ -6,14 +6,16 @@
     Snowflake Image Repository API
 
     The Snowflake Image Repository API is a REST API that you can use to access, update, and perform certain actions on Image Repository resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 __version__ = "1.0.0"
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/image_repository/_generated/api_client.py` & `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/api_client.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,37 +1,44 @@
 # coding: utf-8
 """
-    Snowflake Image Repository API
+    Snowflake Schema API
 
-    The Snowflake Image Repository API is a REST API that you can use to access, update, and perform certain actions on Image Repository resource in Snowflake.  # noqa: E501
+    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 from __future__ import absolute_import
 
 import atexit
 import datetime
+import time
 import typing
 from dateutil.parser import parse
 import json
 import mimetypes
 from multiprocessing.pool import ThreadPool
 import os
 import re
 import tempfile
 
 from urllib.parse import quote
 
-from snowflake.core.image_repository._generated.configuration import Configuration
-import snowflake.core.image_repository._generated.models
-from snowflake.core.image_repository._generated import rest
-from snowflake.core.exceptions import _APIValueError, APIError
+from functools import partial
+
+from snowflake.core.schema._generated.configuration import Configuration
+import snowflake.core.schema._generated.models
+from snowflake.core.schema._generated import rest
+from snowflake.core.schema._generated.paging import PagedIter
+from snowflake.core.exceptions import _APIValueError, APIError, InvalidResponseError, LongRunningQueryTimeout
+from snowflake.core.version import __version__ as VERSION
 
 if typing.TYPE_CHECKING:
     from snowflake.core._root import Root
 
 
 class ApiClient(object):
     """Generic API client for OpenAPI client library builds.
@@ -62,41 +69,48 @@
         'float': float,
         'str': str,
         'bool': bool,
         'date': datetime.date,
         'datetime': datetime.datetime,
         'object': object,
     }
+    DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING = 600.0 # default 10 minutes for long running queries
     _pool = None
 
     def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
                  cookie=None, pool_threads=1):
         # use default configuraiton if none is provided
         if configuration is None:
             configuration = Configuration.get_default()
         self.configuration = configuration
         if (
             hasattr(root, "_connection")
+            and root._connection is not None
             and hasattr(root._connection, "_rest")
+            and root._connection._rest is not None
+            and hasattr(root._connection._rest, "_protocol")
+            and hasattr(root._connection._rest, "_host")
+            and hasattr(root._connection._rest, "_port")
         ):
             self.configuration.host = (
                 f"{root._connection._rest._protocol}://"
                 + root._connection._rest._host
                 + f":{root._connection._rest._port}"
             )
         self.pool_threads = pool_threads
 
         self.rest_client = rest.RESTClientObject(root, configuration)
         self.default_headers = {}
         if header_name is not None:
             self.default_headers[header_name] = header_value
         self.cookie = cookie
         # Set default User-Agent.
-        self.user_agent = 'OpenAPI-Generator/1.0.0/python'
+        self.user_agent = 'python_api/' + VERSION + ''
         self.client_side_validation = configuration.client_side_validation
+        self._enable_long_running_polling = getattr(root, "_enable_long_running_polling", False)
 
     def __enter__(self):
         return self
 
     def __exit__(self, exc_type, exc_value, traceback):
         self.close()
 
@@ -154,15 +168,15 @@
         It stores default ApiClient.
 
         :param default: object of ApiClient.
         """
         cls._default = default
 
     def __call_api(
-            self, resource_path, method, path_params=None,
+            self, root, resource_path, method, path_params=None,
             query_params=None, header_params=None, body=None, post_params=None,
             files=None, response_types_map=None, auth_settings=None,
             _return_http_data_only=None, collection_formats=None,
             _preload_content=True, _request_timeout=None, _host=None,
             _request_auth=None):
 
         config = self.configuration
@@ -218,22 +232,25 @@
         if query_params:
             query_params = self.sanitize_for_serialization(query_params)
             url_query = self.parameters_to_url_query(query_params,
                                                      collection_formats)
             url += "?" + url_query
 
         try:
-            # perform request and return response
-            response_data = self.request(
-                method, url,
+            # perform request and return response, maybe with retry
+            response_data = self.request_with_retry(
+                root,
+                method,
+                url,
                 query_params=query_params,
                 headers=header_params,
                 post_params=post_params, body=body,
                 _preload_content=_preload_content,
-                _request_timeout=_request_timeout)
+                _request_timeout=_request_timeout
+            )
         except APIError as e:
             if e.body:
                 e.body = e.body.decode('utf-8')
             raise e
 
         self.last_response = response_data
 
@@ -251,15 +268,52 @@
         #         match = re.search(r"charset=([a-zA-Z\-\d]+)[\s;]?", content_type)
         #     encoding = match.group(1) if match else "utf-8"
         #     response_data.data = response_data.data.decode(encoding)
 
         # deserialize response data
 
         if response_type:
-            return_data = self.deserialize(response_data, response_type)
+            large_results_resp = self.large_results(response_data)
+            if large_results_resp is None:
+                # regular, non-large results use case
+                return_data = self.deserialize(response_data, response_type)
+            else:
+                # This should be the normal way in which we figure out where to get the results from,
+                # as well as how many chunks there are to get. Due to a bug, we use the alternate logic
+                # (in the "else" clause) to infer the URL from the UUID
+                if "Link" in response_data.getheaders():
+                    results_path, num_chunks = self.get_path_and_chunk_count_from_header(response_data.getheaders()["Link"])
+                else:
+                    handler_id = large_results_resp['result_handler']
+                    results_path = '/api/v2/results/' + handler_id
+
+                    # If there is no "Link" header, there is just one chunk
+                    num_chunks = 1
+
+                # Closure for fetching the next chunk in the PagedIter iterator
+                def _fetch_next_chunk(chunk_index, deserialize_type):
+                    # For now, do this because query_params is not actually being used properly in self.request
+                    chunk_url = f'{self.configuration.host}{results_path}?page={chunk_index}'
+
+                    chunk_response_data = self.request(
+                        root,
+                        "GET",
+                        chunk_url,
+                        headers=header_params,
+                        _preload_content=True,
+                        _request_timeout=_request_timeout)
+
+                    return self.deserialize(chunk_response_data, deserialize_type)
+
+                if 'Iterable' in response_type:
+                    return PagedIter(partial(_fetch_next_chunk, deserialize_type=response_type), num_chunks)
+                else:
+                    # At most, we should only need to fetch one chunk if it's a point lookup,
+                    # i.e., one row return
+                    return_data = _fetch_next_chunk(0, response_type)
         else:
             return_data = None
 
         if _return_http_data_only:
             return (return_data)
         else:
             return (return_data, response_data.status,
@@ -335,42 +389,42 @@
 
         :return: object.
         """
         if data is None:
             return None
 
         if type(klass) == str:
-            if klass.startswith('List['):
-                sub_kls = re.match(r'List\[(.*)]', klass).group(1)
+            if klass.startswith('Iterable['):
+                sub_kls = re.match(r'Iterable\[(.*)]', klass).group(1)
                 return [self.__deserialize(sub_data, sub_kls)
                         for sub_data in data]
 
             if klass.startswith('Dict['):
                 sub_kls = re.match(r'Dict\[([^,]*), (.*)]', klass).group(2)
                 return {k: self.__deserialize(v, sub_kls)
                         for k, v in data.items()}
 
             # convert str to class
             if klass in self.NATIVE_TYPES_MAPPING:
                 klass = self.NATIVE_TYPES_MAPPING[klass]
             else:
-                klass = getattr(snowflake.core.image_repository._generated.models, klass)
+                klass = getattr(snowflake.core.schema._generated.models, klass)
 
         if klass in self.PRIMITIVE_TYPES:
             return self.__deserialize_primitive(data, klass)
         elif klass == object:
             return self.__deserialize_object(data)
         elif klass == datetime.date:
             return self.__deserialize_date(data)
         elif klass == datetime.datetime:
             return self.__deserialize_datetime(data)
         else:
             return self.__deserialize_model(data, klass)
 
-    def call_api(self, resource_path, method,
+    def call_api(self, root, resource_path, method,
                  path_params=None, query_params=None, header_params=None,
                  body=None, post_params=None, files=None,
                  response_types_map=None, auth_settings=None,
                  async_req=None, _return_http_data_only=None,
                  collection_formats=None,_preload_content=True,
                   _request_timeout=None, _host=None, _request_auth=None):
         """Makes the HTTP request (synchronous) and returns deserialized data.
@@ -410,88 +464,198 @@
             If async_req parameter is True,
             the request will be called asynchronously.
             The method will return the request thread.
             If parameter async_req is False or missing,
             then the method will return the response directly.
         """
         if not async_req:
-            return self.__call_api(resource_path, method,
-                                   path_params, query_params, header_params,
-                                   body, post_params, files,
-                                   response_types_map, auth_settings,
-                                   _return_http_data_only, collection_formats,
-                                   _preload_content, _request_timeout, _host,
-                                   _request_auth)
-
-        return self.pool.apply_async(self.__call_api, (resource_path,
-                                                       method, path_params,
-                                                       query_params,
-                                                       header_params, body,
-                                                       post_params, files,
-                                                       response_types_map,
-                                                       auth_settings,
-                                                       _return_http_data_only,
-                                                       collection_formats,
-                                                       _preload_content,
-                                                       _request_timeout,
-                                                       _host, _request_auth))
+            return self.__call_api(
+                root,
+                resource_path,
+                method,
+                path_params,
+                query_params,
+                header_params,
+                body,
+                post_params,
+                files,
+                response_types_map,
+                auth_settings,
+                _return_http_data_only,
+                collection_formats,
+                _preload_content,
+                _request_timeout,
+                _host,
+                _request_auth,
+            )
+
+        return self.pool.apply_async(
+            self.__call_api,
+            (
+                root,
+                resource_path,
+                method,
+                path_params,
+                query_params,
+                header_params,
+                body,
+                post_params,
+                files,
+                response_types_map,
+                auth_settings,
+                _return_http_data_only,
+                collection_formats,
+                _preload_content,
+                _request_timeout,
+                _host,
+                _request_auth,
+            )
+        )
 
-    def request(self, method, url, query_params=None, headers=None,
+
+    def request_with_retry(
+                self, root, method, url, query_params=None, headers=None,
+                post_params=None, body=None, _preload_content=True,
+                _request_timeout=None):
+        """
+            Response time by default one hour
+        """
+        enter_timing = time.time()
+        response_data = self.request(
+                root,
+                method,
+                url,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params, body=body,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout)
+
+        if response_data.status != 202 or not self._enable_long_running_polling:
+            return response_data
+
+        result_endpoint = response_data.getheader('Location')
+        if result_endpoint is None:
+            raise InvalidResponseError("Long Running Queries result endpoint is missing")
+
+        if _request_timeout is None:
+            _request_timeout = self.DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING
+        wait_for_results_timeout = enter_timing + _request_timeout
+
+        exponential_wait_time = 1 # wait time increases exponentially, 30% more everytime
+        while True:
+            time_remaining = wait_for_results_timeout - time.time()
+            if time_remaining <= 0:
+                break
+            wait_time = min(exponential_wait_time, time_remaining)
+            time.sleep(wait_time)
+            response_data = self.request(
+                root,
+                'GET',
+                self.configuration.host + result_endpoint,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params, body=body,
+                _preload_content=_preload_content,
+                _request_timeout=max(time_remaining - wait_time, 1)
+                # request_timeout can never be zero
+            )
+
+            if response_data.status != 202:
+                return response_data
+
+            exponential_wait_time *= 1.3
+
+        raise LongRunningQueryTimeout("Long running queries timeout")
+
+
+    def request(self, root, method, url, query_params=None, headers=None,
                 post_params=None, body=None, _preload_content=True,
                 _request_timeout=None):
         """Makes the HTTP request using RESTClient."""
         if method == "GET":
-            return self.rest_client.get_request(url,
-                                        query_params=query_params,
-                                        _preload_content=_preload_content,
-                                        _request_timeout=_request_timeout,
-                                        headers=headers)
+            return self.rest_client.get_request(
+                root,
+                url,
+                query_params=query_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                headers=headers,
+            )
         elif method == "HEAD":
-            return self.rest_client.head_request(url,
-                                         query_params=query_params,
-                                         _preload_content=_preload_content,
-                                         _request_timeout=_request_timeout,
-                                         headers=headers)
+            return self.rest_client.head_request(
+                root,
+                url,
+                query_params=query_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                headers=headers,
+            )
         elif method == "OPTIONS":
-            return self.rest_client.options_request(url,
-                                            query_params=query_params,
-                                            headers=headers,
-                                            _preload_content=_preload_content,
-                                            _request_timeout=_request_timeout)
+            return self.rest_client.options_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+            )
         elif method == "POST":
-            return self.rest_client.post_request(url,
-                                         query_params=query_params,
-                                         headers=headers,
-                                         post_params=post_params,
-                                         _preload_content=_preload_content,
-                                         _request_timeout=_request_timeout,
-                                         body=body)
+            return self.rest_client.post_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                body=body,
+            )
         elif method == "PUT":
-            return self.rest_client.put_request(url,
-                                        query_params=query_params,
-                                        headers=headers,
-                                        post_params=post_params,
-                                        _preload_content=_preload_content,
-                                        _request_timeout=_request_timeout,
-                                        body=body)
+            try:
+                return self.rest_client.put_request(
+                    root,
+                    url,
+                    query_params=query_params,
+                    headers=headers,
+                    post_params=post_params,
+                    _preload_content=_preload_content,
+                    _request_timeout=_request_timeout,
+                    body=body,
+                )
+            except APIError as error:
+                # Raise a more helpful user error if CoA is not supported for this resource;
+                # this is represented as either 405 or 501 on the server.
+                if error.status in (405, 501):
+                    raise NotImplementedError(
+                        'create_or_update is not yet supported for schema. Updating schema '
+                        'objects is not supported yet; use create() for creating a schema.')
+                raise
+
         elif method == "PATCH":
-            return self.rest_client.patch_request(url,
-                                          query_params=query_params,
-                                          headers=headers,
-                                          post_params=post_params,
-                                          _preload_content=_preload_content,
-                                          _request_timeout=_request_timeout,
-                                          body=body)
+            return self.rest_client.patch_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                body=body,
+            )
         elif method == "DELETE":
-            return self.rest_client.delete_request(url,
-                                           query_params=query_params,
-                                           headers=headers,
-                                           _preload_content=_preload_content,
-                                           _request_timeout=_request_timeout,
-                                           body=body)
+            return self.rest_client.delete_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                body=body,
+            )
         else:
             raise _APIValueError(
                 "http method must be `GET`, `HEAD`, `OPTIONS`,"
                 " `POST`, `PATCH`, `PUT` or `DELETE`."
             )
 
     def parameters_to_tuples(self, params, collection_formats):
@@ -759,13 +923,73 @@
         :param data: dict, list.
         :param klass: class literal.
         :return: model object.
         """
 
         return klass.from_dict(data)
 
+    @staticmethod
+    def large_results(response):
+        try:
+            result = json.loads(response.data)
+            if ("result_handler" in result
+                    and "message" in result and
+                    'Large result set. Use provided Link' in result['message']):
+                return result
+            else:
+                return None
+        except ValueError:
+            pass
+
+        return None
+
+
+    @staticmethod
+    def get_path_and_chunk_count_from_header(links_str):
+        links_list = links_str.split(",")
+
+        def parse_links(s):
+            import re
+            # Use regex to extract necessary parts
+            #
+            # Explanation:
+            # The result links are provided to us in the form:
+            # '</api/v2/results/01b39664-0100-0001-0000-0000000430391?page=0>; rel="first"'
+            #
+            # We wish to find how many chunks there are by finding the one that has rel="last",
+            # therefore we find page index corresponding to the link with that rel value.
+            #
+            # 1. <(.*?)> matches and captures the URL inside the angle brackets
+            # 2. page=(\d+) matches 'page=' followed by one or more digits to find the page number
+            # 3. rel="([^"]*)" matches 'rel="'
+            pattern = r'<(.*?)\?page=(\d+)>; rel="([^"]*)"'
+
+            # Search using the regular expression
+            match = re.search(pattern, s)
+            if match:
+                parse_result = dict()
+                parse_result['url'], parse_result['page_number'], parse_result['rel_value'] = match.groups()
+                return parse_result
+
+            return None
+
+        parsed_links = [parse_links(link) for link in links_list]
+
+        # Find the last one
+        last_link = list(filter(lambda link: link['rel_value'].lower() == 'last', parsed_links)).pop()
+
+        # Return the URL; the number of chunks is the chunk index of the last page plus one
+        return last_link['url'], int(last_link['page_number']) + 1
+
 
 class BridgeApiClient(ApiClient):
     def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
                  cookie=None, pool_threads=1, snowflake_connection=None):
         ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
         self.rest_client = rest.BridgeClientObject(snowflake_connection)
+
+
+class StoredProcApiClient(ApiClient):
+    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
+                 cookie=None, pool_threads=1):
+        ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
+        self.rest_client = rest.StoredProcClientObject()
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/image_repository/_generated/api_response.py` & `snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/api_response.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 """API response object."""
 
 from __future__ import annotations
 from typing import Any, Dict, Optional
-from snowflake.core._internal.pydantic_compatibility import Field, StrictInt, StrictStr
+from snowflake.core.cortex.search_service._generated.pydantic_compatibility import Field, StrictInt, StrictStr
 
 class ApiResponse:
     """
     API response object
     """
 
     status_code: Optional[StrictInt] = Field(None, description="HTTP status code")
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/image_repository/_generated/configuration.py` & `snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/configuration.py`

 * *Files 1% similar despite different names*

```diff
@@ -4,14 +4,16 @@
     Snowflake Image Repository API
 
     The Snowflake Image Repository API is a REST API that you can use to access, update, and perform certain actions on Image Repository resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 import copy
 import logging
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/image_repository/_generated/rest.py` & `snowflake_core-0.8.0/src/snowflake/core/task/_generated/rest.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,17 +1,19 @@
 # coding: utf-8
 
 """
-    Snowflake Image Repository API
+    Snowflake Task API
 
-    The Snowflake Image Repository API is a REST API that you can use to access, update, and perform certain actions on Image Repository resource in Snowflake.  # noqa: E501
+    The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 import json
 import logging
@@ -49,17 +51,26 @@
     def __init__(self, root: "Root", *args, **kwargs):
         self.root = root
         self.pool_manager = create_connection_pool(
             *args,
             **kwargs,
         )
 
-    def request(self, method, url, query_params=None, headers=None,
-                body=None, post_params=None, _preload_content=True,
-                _request_timeout=None):
+    def request(
+        self,
+        root,
+        method,
+        url,
+        query_params=None,
+        headers=None,
+        body=None,
+        post_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
         """Perform requests.
 
         :param method: http request method
         :param url: http request url
         :param query_params: query parameters in the url
         :param headers: http request headers
         :param body: request json body, for `application/json`
@@ -104,64 +115,64 @@
 
                 # no content type provided or payload is json
                 if not headers.get('Content-Type') or re.search('json', headers['Content-Type'], re.IGNORECASE):
                     request_body = None
                     if body is not None:
                         request_body = json.dumps(body)
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 elif headers['Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         fields=post_params,
                         encode_multipart=False,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 elif headers['Content-Type'] == 'multipart/form-data':
                     # must del headers['Content-Type'], or the correct
                     # Content-Type which generated by urllib3 will be
                     # overwritten.
                     del headers['Content-Type']
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         fields=post_params,
                         encode_multipart=True,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 # Pass a `string` parameter directly in the body to support
                 # other content types than Json when `body` argument is
                 # provided in serialized form
                 elif isinstance(body, str) or isinstance(body, bytes):
                     request_body = body
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 else:
                     # Cannot generate the request from given parameters
                     msg = """Cannot prepare a request message for provided
                              arguments. Please check that your arguments match
                              declared content type."""
                     raise APIError(status=0, reason=msg)
             # For `GET`, `HEAD`
             else:
                 r = self.pool_manager.request(
-                    self.root._session_token,
+                    root,
                     method,
                     url,
                     fields={},
                     preload_content=_preload_content,
                     timeout=timeout,
                     headers=headers,
                 )
@@ -191,88 +202,139 @@
             if 500 <= r.status <= 599:
                 raise ServerError(http_resp=r)
 
             raise APIError(http_resp=r)
 
         return r
 
-    def get_request(self, url, headers=None, query_params=None, _preload_content=True,
-            _request_timeout=None):
-        return self.request("GET", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
-
-    def head_request(self, url, headers=None, query_params=None, _preload_content=True,
-             _request_timeout=None):
-        return self.request("HEAD", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
+    def get_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "GET",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def head_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "HEAD",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
 
-    def options_request(self, url, headers=None, query_params=None, post_params=None,
+    def options_request(self, root, url, headers=None, query_params=None, post_params=None,
                 body=None, _preload_content=True, _request_timeout=None):
-        return self.request("OPTIONS", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "OPTIONS",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def delete_request(self, url, headers=None, query_params=None, body=None,
+    def delete_request(self, root, url, headers=None, query_params=None, body=None,
                _preload_content=True, _request_timeout=None):
-        return self.request("DELETE", url,
-                            headers=headers,
-                            query_params=query_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "DELETE",
+            url,
+            headers=headers,
+            query_params=query_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def post_request(self, url, headers=None, query_params=None, post_params=None,
+    def post_request(self, root, url, headers=None, query_params=None, post_params=None,
              body=None, _preload_content=True, _request_timeout=None):
-        return self.request("POST", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "POST",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def put_request(self, url, headers=None, query_params=None, post_params=None,
+    def put_request(self, root, url, headers=None, query_params=None, post_params=None,
             body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PUT", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "PUT",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def patch_request(self, url, headers=None, query_params=None, post_params=None,
+    def patch_request(self, root, url, headers=None, query_params=None, post_params=None,
               body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PATCH", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "PATCH",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
 
 class BridgeClientObject(object):
 
     def __init__(self, snowflake_connection: SnowflakeConnection):
         self.bridge = SnowBridge(snowflake_connection)
 
-    def request(self, method, url, query_params=None, headers=None,
-                body=None, post_params=None, _preload_content=True,
-                _request_timeout=None):
+    def request(
+        self,
+        root,
+        method,
+        url,
+        query_params=None,
+        headers=None,
+        body=None,
+        post_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
         """Perform requests.
 
         :param method: http request method
         :param url: http request url
         :param query_params: query parameters in the url
         :param headers: http request headers
         :param body: request json body, for `application/json`
@@ -315,71 +377,378 @@
             if 500 <= r.status <= 599:
                 raise ServerError(http_resp=r)
 
             raise APIError(http_resp=r)
 
         return r
 
-    def get_request(self, url, headers=None, query_params=None, _preload_content=True,
-                    _request_timeout=None):
-        return self.request("GET", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
-
-    def head_request(self, url, headers=None, query_params=None, _preload_content=True,
-                     _request_timeout=None):
-        return self.request("HEAD", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
-
-    def options_request(self, url, headers=None, query_params=None, post_params=None,
-                        body=None, _preload_content=True, _request_timeout=None):
-        return self.request("OPTIONS", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def delete_request(self, url, headers=None, query_params=None, body=None,
-                       _preload_content=True, _request_timeout=None):
-        return self.request("DELETE", url,
-                            headers=headers,
-                            query_params=query_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def post_request(self, url, headers=None, query_params=None, post_params=None,
-                     body=None, _preload_content=True, _request_timeout=None):
-        return self.request("POST", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def put_request(self, url, headers=None, query_params=None, post_params=None,
-                    body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PUT", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def patch_request(self, url, headers=None, query_params=None, post_params=None,
-                      body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PATCH", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+    def get_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "GET",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def head_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "HEAD",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def options_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "OPTIONS",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def delete_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "DELETE",
+            url,
+            headers=headers,
+            query_params=query_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def post_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "POST",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def put_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PUT",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def patch_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PATCH",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+
+class StoredProcClientObject(object):
+
+    def request(
+        self,
+        root,
+        method,
+        url,
+        query_params={},
+        headers={},
+        body={},
+        post_params={},
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        """Perform requests.
+        :param method: http request method
+        :param url: http request url
+        :param query_params: query parameters in the url
+        :param headers: http request headers
+        :param body: request json body, for `application/json`
+        :param post_params: request post parameters,
+                            `application/x-www-form-urlencoded`
+                            and `multipart/form-data`
+        :param _preload_content: if False, the urllib3.HTTPResponse object will
+                                 be returned without reading/decoding response
+                                 data. Default is True.
+        :param _request_timeout: timeout setting for this request. If one
+                                 number provided, it will be total request
+                                 timeout. It can also be a pair (tuple) of
+                                 (connection, read) timeouts.
+        """
+        method = method.upper()
+        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
+                          'PATCH', 'OPTIONS']
+        import _snowflake
+        parsed_url = urllib3.util.parse_url(url)
+        response_dict = _snowflake.send_snow_api_request(method, parsed_url.path, dict(query_params), headers, body,
+                                                         post_params, _request_timeout)
+        json_content = json.loads(response_dict["content"])
+        if "data" in json_content:
+            r = urllib3.HTTPResponse(body=json.dumps(json_content["data"]))
+        else:
+            r = urllib3.HTTPResponse(body=json.dumps(json_content).encode("utf-8"))
+        r.status = response_dict["status"]
+        if _preload_content:
+            r = RESTResponse(r)
+            # log response body
+            logger.debug("response body: %s", r.data)
+
+        if not 200 <= r.status <= 299:
+            if r.status == 401:
+                raise UnauthorizedError(http_resp=r)
+
+            if r.status == 403:
+                raise ForbiddenError(http_resp=r)
+
+            if r.status == 404:
+                raise NotFoundError(http_resp=r)
+
+            if r.status == 409:
+                raise ConflictError(http_resp=r)
+
+            if 500 <= r.status <= 599:
+                raise ServerError(http_resp=r)
+
+            raise APIError(http_resp=r)
+
+        return r
+
+    def get_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "GET",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def head_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "HEAD",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def options_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "OPTIONS",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def delete_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "DELETE",
+            url,
+            headers=headers,
+            query_params=query_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def post_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "POST",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def put_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PUT",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def patch_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PATCH",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/image_repository/_generated/api/image_repository_api.py` & `snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/api/image_repository_api.py`

 * *Files 20% similar despite different names*

```diff
@@ -4,92 +4,122 @@
     Snowflake Image Repository API
 
     The Snowflake Image Repository API is a REST API that you can use to access, update, and perform certain actions on Image Repository resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 import logging
 
 from typing_extensions import Annotated
-
-from pydantic import StrictBool, StrictStr, constr, validator
+from pydantic import Field, StrictBool, StrictStr, constr, validator
 
 from typing import List, Optional
 
 from snowflake.core.image_repository._generated.models.image_repository import ImageRepository
 from snowflake.core.image_repository._generated.models.success_response import SuccessResponse
+from typing import Iterable
 
-from snowflake.core._internal.pydantic_compatibility import StrictBool, StrictInt, StrictStr, constr, validate_arguments, ValidationError, validator
-from snowflake.core._internal.utils import ApiClientType
 
-from snowflake.core.image_repository._generated.api_client import ApiClient
+from snowflake.core.image_repository._generated.pydantic_compatibility import StrictBool, StrictInt, StrictStr, constr, validate_arguments, ValidationError, validator
+from snowflake.core._internal.snowapi_parameters import SnowApiParameters
+from snowflake.core._internal.utils import ApiClientType, is_running_inside_stored_procedure
+
 from snowflake.core.exceptions import (  # noqa: F401
     _APITypeError,
     _APIValueError
 )
 
 logger  = logging.getLogger(__name__)
 
 class ImageRepositoryApi(object):
     """NOTE: This class is auto generated by OpenAPI Generator
     Ref: https://openapi-generator.tech
 
     Do not edit the class manually.
     """
 
-    def __init__(self, root, resource_class, bridge_client):
+    def __init__(self, root, resource_class, bridge_client, sproc_client):
         self._root = root
-        self._rest_client = ApiClient.get_default(root)
+        self._resource_name = 'image_repository'
         self._resource_class = resource_class
         self._bridge_client = bridge_client
+        self._sproc_client = sproc_client
         self._chosen_client_type = ApiClientType.NONE
 
     @property
     def api_client(self):
         """
             chosen_client is the client we chose , either bridge or rest
-            new_chosen_client is the client we want to choose under the current situation ( value of _supports_rest_api + _can_use_rest_api )
+            new_chosen_client is the client we want to choose under the current situation ( value of
+            _supports_rest_api + _can_use_rest_api, and the server-controlled flag )
             We will log the change if we want to choose another client instead of the current one
         """
-        if self._resource_class._supports_rest_api and self._root._can_use_rest_api:
-            chosen_client = self._rest_client
-            new_chosen_client = ApiClientType.REST
+        from snowflake.core.image_repository._generated.api_client import ApiClient
+
+        # Small helper function for figuring out the correct 'REST' client to use if in stored proc or not
+        def _get_rest_client():
+            if is_running_inside_stored_procedure():
+                return self._sproc_client, ApiClientType.STORED_PROC
+            else:
+                return ApiClient.get_default(self._root), ApiClientType.REST
+
+        use_bridge_override = False
+
+        # We can force use of the bridge if the server dictates it so
+        # But, don't check it for non-resources; _resource_class is not set for non-resources.
+        if self._resource_class is not None:
+            use_bridge_override = self._root.effective_parameters(refresh = False).resource_should_use_client_bridge('image_repository')
+
+        # if the _resource_class is None (such as Session, which is not a resource), then it is implied
+        # that we use REST (or the stored_proc client)
+        if self._resource_class is None:
+            chosen_client, new_chosen_client = _get_rest_client()
+        elif use_bridge_override:
+            # Bridge override is in effect. Use the client bridge.
+            chosen_client = self._bridge_client
+            new_chosen_client = ApiClientType.BRIDGE
+        # Check if it supports REST before choosing the REST client.
+        elif self._resource_class._supports_rest_api and self._root._can_use_rest_api:
+            chosen_client, new_chosen_client = _get_rest_client()
+        # If all else fails, use the BRIDGE (if there is no REST support for this resource)
         else:
             chosen_client = self._bridge_client
             new_chosen_client = ApiClientType.BRIDGE
 
         if new_chosen_client != self._chosen_client_type:
             self._chosen_client_type = new_chosen_client
             logger.info("Going to use client-%s for this resource", new_chosen_client.name)
         return chosen_client
 
     @validate_arguments
-    def create_image_repository(self, database : constr(strict=True), var_schema : constr(strict=True), image_repository : ImageRepository, create_mode : Optional[StrictStr] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+    def create_image_repository(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], image_repository : ImageRepository, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
         """Create an image repository  # noqa: E501
 
         Create an image repository, with standard create modifiers as query parameters. See the ImageRepository component definition for what is required to be provided in the request body.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.create_image_repository(database, var_schema, image_repository, create_mode, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
         :param image_repository: (required)
         :type image_repository: ImageRepository
-        :param create_mode:
+        :param create_mode: A query parameter allowing support for different modes of resource creation.
         :type create_mode: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -102,31 +132,31 @@
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
         return self.create_image_repository_with_http_info(database, var_schema, image_repository, create_mode, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def create_image_repository_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), image_repository : ImageRepository, create_mode : Optional[StrictStr] = None, **kwargs):  # noqa: E501
+    def create_image_repository_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], image_repository : ImageRepository, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, **kwargs):  # noqa: E501
         """Create an image repository  # noqa: E501
 
         Create an image repository, with standard create modifiers as query parameters. See the ImageRepository component definition for what is required to be provided in the request body.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.create_image_repository_with_http_info(database, var_schema, image_repository, create_mode, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
         :param image_repository: (required)
         :type image_repository: ImageRepository
-        :param create_mode:
+        :param create_mode: A query parameter allowing support for different modes of resource creation.
         :type create_mode: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -228,14 +258,15 @@
             '409': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
+            self._root,
             '/api/v2/databases/{database}/schemas/{schema}/image-repositories', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
@@ -245,69 +276,65 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def delete_image_repository(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), if_exists : Optional[StrictBool] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Delete an image repository  # noqa: E501
+    def fetch_image_repository(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> ImageRepository:  # noqa: E501
+        """Fetch an image repository.  # noqa: E501
 
-        Delete an image repository with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
+        Fetch an image repository using the SHOW command output.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.delete_image_repository(database, var_schema, name, if_exists, async_req=True)
+        >>> thread = api.fetch_image_repository(database, var_schema, name, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists:
-        :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: SuccessResponse
+        :rtype: ImageRepository
         """
         kwargs['_return_http_data_only'] = True
-        return self.delete_image_repository_with_http_info(database, var_schema, name, if_exists, **kwargs)  # noqa: E501
+        return self.fetch_image_repository_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def delete_image_repository_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), if_exists : Optional[StrictBool] = None, **kwargs):  # noqa: E501
-        """Delete an image repository  # noqa: E501
+    def fetch_image_repository_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
+        """Fetch an image repository.  # noqa: E501
 
-        Delete an image repository with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
+        Fetch an image repository using the SHOW command output.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.delete_image_repository_with_http_info(database, var_schema, name, if_exists, async_req=True)
+        >>> thread = api.fetch_image_repository_with_http_info(database, var_schema, name, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists:
-        :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -321,24 +348,23 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(ImageRepository, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
             'database',
             'var_schema',
-            'name',
-            'if_exists'
+            'name'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -349,15 +375,15 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method delete_image_repository" % _key
+                    " to method fetch_image_repository" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
@@ -367,16 +393,14 @@
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
-        if _params.get('if_exists') is not None:  # noqa: E501
-            _query_params.append(('ifExists', _params['if_exists']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -388,27 +412,28 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "SuccessResponse",
+            '200': "ImageRepository",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/image-repositories/{name}', 'DELETE',
+            self._root,
+            '/api/v2/databases/{database}/schemas/{schema}/image-repositories/{name}', 'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -417,65 +442,65 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def fetch_image_repository(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), **kwargs) -> ImageRepository:  # noqa: E501
-        """Fetch an image repository.  # noqa: E501
+    def list_image_repositories(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, **kwargs) -> Iterable[ImageRepository]:  # noqa: E501
+        """List image repositories  # noqa: E501
 
-        Fetch an image repository using the SHOW command output.  # noqa: E501
+        Lists the image repositories under the database and schema.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_image_repository(database, var_schema, name, async_req=True)
+        >>> thread = api.list_image_repositories(database, var_schema, like, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
-        :type name: str
+        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
+        :type like: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: ImageRepository
+        :rtype: Iterable[ImageRepository]
         """
         kwargs['_return_http_data_only'] = True
-        return self.fetch_image_repository_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
+        return self.list_image_repositories_with_http_info(database, var_schema, like, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def fetch_image_repository_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), **kwargs):  # noqa: E501
-        """Fetch an image repository.  # noqa: E501
+    def list_image_repositories_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, **kwargs):  # noqa: E501
+        """List image repositories  # noqa: E501
 
-        Fetch an image repository using the SHOW command output.  # noqa: E501
+        Lists the image repositories under the database and schema.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_image_repository_with_http_info(database, var_schema, name, async_req=True)
+        >>> thread = api.list_image_repositories_with_http_info(database, var_schema, like, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
-        :type name: str
+        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
+        :type like: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -489,23 +514,23 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(ImageRepository, status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(Iterable[ImageRepository], status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
             'database',
             'var_schema',
-            'name'
+            'like'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -516,32 +541,32 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method fetch_image_repository" % _key
+                    " to method list_image_repositories" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
         if _params['database']:
             _path_params['database'] = _params['database']
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
-        if _params['name']:
-            _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
+        if _params.get('like') is not None:  # noqa: E501
+            _query_params.append(('like', _params['like']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -553,27 +578,29 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "ImageRepository",
+            '200': "Iterable[ImageRepository]",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '409': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/image-repositories/{name}', 'GET',
+            self._root,
+            '/api/v2/databases/{database}/schemas/{schema}/image-repositories', 'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -582,65 +609,69 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def list_image_repositories(self, database : constr(strict=True), var_schema : constr(strict=True), like : Optional[StrictStr] = None, **kwargs) -> List[ImageRepository]:  # noqa: E501
-        """List image repositories  # noqa: E501
+    def delete_image_repository(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+        """Delete an image repository  # noqa: E501
 
-        Lists the image repositories under the database and schema.  # noqa: E501
+        Delete an image repository with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.list_image_repositories(database, var_schema, like, async_req=True)
+        >>> thread = api.delete_image_repository(database, var_schema, name, if_exists, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param like:
-        :type like: str
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :type name: str
+        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: List[ImageRepository]
+        :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.list_image_repositories_with_http_info(database, var_schema, like, **kwargs)  # noqa: E501
+        return self.delete_image_repository_with_http_info(database, var_schema, name, if_exists, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def list_image_repositories_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), like : Optional[StrictStr] = None, **kwargs):  # noqa: E501
-        """List image repositories  # noqa: E501
+    def delete_image_repository_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs):  # noqa: E501
+        """Delete an image repository  # noqa: E501
 
-        Lists the image repositories under the database and schema.  # noqa: E501
+        Delete an image repository with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.list_image_repositories_with_http_info(database, var_schema, like, async_req=True)
+        >>> thread = api.delete_image_repository_with_http_info(database, var_schema, name, if_exists, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param like:
-        :type like: str
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :type name: str
+        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -654,23 +685,24 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(List[ImageRepository], status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
             'database',
             'var_schema',
-            'like'
+            'name',
+            'if_exists'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -681,32 +713,34 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method list_image_repositories" % _key
+                    " to method delete_image_repository" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
         if _params['database']:
             _path_params['database'] = _params['database']
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
+        if _params['name']:
+            _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
-        if _params.get('like') is not None:  # noqa: E501
-            _query_params.append(('like', _params['like']))
+        if _params.get('if_exists') is not None:  # noqa: E501
+            _query_params.append(('ifExists', _params['if_exists']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -718,28 +752,28 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "List[ImageRepository]",
+            '200': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
-            '409': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/image-repositories', 'GET',
+            self._root,
+            '/api/v2/databases/{database}/schemas/{schema}/image-repositories/{name}', 'DELETE',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/image_repository/_generated/models/__init__.py` & `snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/models/__init__.py`

 * *Files 23% similar despite different names*

```diff
@@ -5,14 +5,16 @@
     Snowflake Image Repository API
 
     The Snowflake Image Repository API is a REST API that you can use to access, update, and perform certain actions on Image Repository resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 # import models into model package
 from snowflake.core.image_repository._generated.models.error_response import ErrorResponse
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/image_repository/_generated/models/error_response.py` & `snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/models/error_response.py`

 * *Files 6% similar despite different names*

```diff
@@ -4,32 +4,35 @@
     Snowflake Image Repository API
 
     The Snowflake Image Repository API is a REST API that you can use to access, update, and perform certain actions on Image Repository resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictStr
+from snowflake.core.image_repository._generated.pydantic_compatibility import BaseModel, StrictStr
 
 class ErrorResponse(BaseModel):
-    message: Optional[StrictStr] = Field(None, description="Error message returned by server")
-    error_code: Optional[StrictStr] = Field(None, description="Error code")
-    request_id: Optional[StrictStr] = Field(None, description="Unique request id")
-    __properties = ["message", "error_code", "request_id"]
+    message: Optional[StrictStr] = None
+    code: Optional[StrictStr] = None
+    error_code: Optional[StrictStr] = None
+    request_id: Optional[StrictStr] = None
+    __properties = ["message", "code", "error_code", "request_id"]
 
 
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
@@ -61,14 +64,16 @@
 
         if type(obj) is not dict:
             return ErrorResponse.parse_obj(obj)
 
         _obj = ErrorResponse.parse_obj({
             "message": obj.get("message"),
 
+            "code": obj.get("code"),
+
             "error_code": obj.get("error_code"),
 
             "request_id": obj.get("request_id"),
 
         })
         return _obj
 
@@ -76,37 +81,43 @@
 from typing import Optional, List, Dict
 
 class ErrorResponseModel():
     def __init__(
         self,
         # optional properties
         message: Optional[str] = None,
+        code: Optional[str] = None,
         error_code: Optional[str] = None,
         request_id: Optional[str] = None,
     ):
         self.message = message
+        self.code = code
         self.error_code = error_code
         self.request_id = request_id
-    __properties = ["message", "error_code", "request_id"]
+    __properties = ["message", "code", "error_code", "request_id"]
 
     def _to_model(self):
         return ErrorResponse(
             message=self.message,
 
+            code=self.code,
+
             error_code=self.error_code,
 
             request_id=self.request_id,
 
         )
 
     @classmethod
     def _from_model(cls, model) -> ErrorResponseModel:
         return ErrorResponseModel(
             message=model.message,
 
+            code=model.code,
+
             error_code=model.error_code,
 
             request_id=model.request_id,
 
         )
 
     def to_dict(self):
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/image_repository/_generated/models/image_repository.py` & `snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/models/image_repository.py`

 * *Files 6% similar despite different names*

```diff
@@ -4,26 +4,28 @@
     Snowflake Image Repository API
 
     The Snowflake Image Repository API is a REST API that you can use to access, update, and perform certain actions on Image Repository resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 from datetime import datetime
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictStr, constr, validator
+from snowflake.core.image_repository._generated.pydantic_compatibility import BaseModel, Field, StrictStr, constr, validator
 
 class ImageRepository(BaseModel):
     name: constr(strict=True) = Field(...)
     database_name: Optional[constr(strict=True)] = None
     schema_name: Optional[constr(strict=True)] = None
     created_on: Optional[datetime] = None
     repository_url: Optional[StrictStr] = None
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/image_repository/_generated/models/success_response.py` & `snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/models/success_response.py`

 * *Files 4% similar despite different names*

```diff
@@ -4,29 +4,31 @@
     Snowflake Image Repository API
 
     The Snowflake Image Repository API is a REST API that you can use to access, update, and perform certain actions on Image Repository resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictStr
+from snowflake.core.image_repository._generated.pydantic_compatibility import BaseModel, StrictStr
 
 class SuccessResponse(BaseModel):
-    status: Optional[StrictStr] = Field(None, description="Message returned by server")
+    status: Optional[StrictStr] = None
     __properties = ["status"]
 
 
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/schema/_schema.py` & `snowflake_core-0.8.0/src/snowflake/core/schema/_schema.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 from functools import cached_property
-from typing import TYPE_CHECKING, Optional, Union
+from typing import TYPE_CHECKING, Iterator, Optional, Union
 
 from snowflake.connector import SnowflakeConnection
-from snowflake.core._internal.pydantic_compatibility import StrictStr
-from snowflake.core.schema._generated.api_client import BridgeApiClient
+from snowflake.core.schema._generated.api_client import BridgeApiClient, StoredProcApiClient
+from snowflake.core.schema._generated.pydantic_compatibility import StrictStr
 from snowflake.snowpark import Session
 
 from .._common import Clone, CreateMode, ObjectCollection, ObjectReferenceMixin, PointOfTime
 from .._internal.telemetry import api_telemetry
+from ..cortex.search_service import CortexSearchServiceCollection
 from ..image_repository import ImageRepositoryCollection
-from ..paging import PagedIter
 from ..service import ServiceCollection
 from ..table import TableCollection
 from ..task import TaskCollection
 from ._generated.api.schema_api import SchemaApi
 from ._generated.models.model_schema import ModelSchemaModel as Schema
 from ._generated.models.point_of_time import PointOfTime as SchemaPointOfTime
 from ._generated.models.schema_clone import SchemaClone
@@ -31,14 +31,15 @@
         self._api = SchemaApi(
             root=root,
             resource_class=self._ref_class,
             bridge_client=BridgeApiClient(
                 root=root,
                 snowflake_connection=database.root.connection,
             ),
+            sproc_client=StoredProcApiClient(root=self.root)
         )
 
     @property
     def database(self) -> "DatabaseResource":
         return self._database
 
     @property
@@ -104,38 +105,39 @@
     def iter(
         self,
         *,
         like: Optional[str] = None,
         starts_with: Optional[str] = None,
         limit: Optional[int] = None,
         from_name: Optional[str] = None
-    ) -> PagedIter[Schema]:
+    ) -> Iterator[Schema]:
         """Look up schemas in Snowflake."""
-        return PagedIter(
-            data=self._api.list_schemas(
-                self.database.name,
-                StrictStr(like) if like is not None else None,
-                StrictStr(starts_with) if starts_with else None,
-                limit,
-                from_name=from_name,
-                async_req=False,
-            ), map_=Schema._from_model
-        )
+        schemas = self._api.list_schemas(
+            self.database.name,
+            StrictStr(like) if like is not None else None,
+            StrictStr(starts_with) if starts_with else None,
+            limit,
+            from_name=from_name,
+            async_req=False,)
+
+        return map(Schema._from_model, iter(schemas))
 
     @property
     def _session(self) -> Session:
         return self.database._session
 
     @property
     def _connection(self) -> SnowflakeConnection:
         return self.database._connection
 
 
 class SchemaResource(ObjectReferenceMixin[SchemaCollection]):
 
+    _supports_rest_api = True
+
     def __init__(self, name: str, collection: SchemaCollection) -> None:
         self.name: str = name
         self.collection: SchemaCollection = collection
 
     @property
     def database(self) -> "DatabaseResource":
         return self.collection.database
@@ -143,15 +145,15 @@
     @property
     def _api(self) -> SchemaApi:
         return self.collection._api
 
     @api_telemetry
     def create_or_update(self, schema: Schema) -> "SchemaResource":
         """Create or update a schema in Snowflake."""
-        self._api.create_or_update_schema(
+        self._api.create_or_alter_schema(
             self.database.name,
             schema.name,
             schema._to_model(),
             async_req=False,
         )
         return self
 
@@ -183,7 +185,11 @@
     @cached_property
     def image_repositories(self) -> ImageRepositoryCollection:
         return ImageRepositoryCollection(self)
 
     @cached_property
     def tables(self) -> TableCollection:
         return TableCollection(self)
+
+    @cached_property
+    def cortex_search_services(self) -> CortexSearchServiceCollection:
+        return CortexSearchServiceCollection(self)
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/schema/_generated/__init__.py` & `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -6,14 +6,16 @@
     Snowflake Schema API
 
     The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 __version__ = "1.0.0"
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/schema/_generated/api_client.py` & `snowflake_core-0.8.0/src/snowflake/core/task/_generated/api_client.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,37 +1,44 @@
 # coding: utf-8
 """
-    Snowflake Schema API
+    Snowflake Task API
 
-    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
+    The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 from __future__ import absolute_import
 
 import atexit
 import datetime
+import time
 import typing
 from dateutil.parser import parse
 import json
 import mimetypes
 from multiprocessing.pool import ThreadPool
 import os
 import re
 import tempfile
 
 from urllib.parse import quote
 
-from snowflake.core.schema._generated.configuration import Configuration
-import snowflake.core.schema._generated.models
-from snowflake.core.schema._generated import rest
-from snowflake.core.exceptions import _APIValueError, APIError
+from functools import partial
+
+from snowflake.core.task._generated.configuration import Configuration
+import snowflake.core.task._generated.models
+from snowflake.core.task._generated import rest
+from snowflake.core.task._generated.paging import PagedIter
+from snowflake.core.exceptions import _APIValueError, APIError, InvalidResponseError, LongRunningQueryTimeout
+from snowflake.core.version import __version__ as VERSION
 
 if typing.TYPE_CHECKING:
     from snowflake.core._root import Root
 
 
 class ApiClient(object):
     """Generic API client for OpenAPI client library builds.
@@ -62,41 +69,48 @@
         'float': float,
         'str': str,
         'bool': bool,
         'date': datetime.date,
         'datetime': datetime.datetime,
         'object': object,
     }
+    DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING = 600.0 # default 10 minutes for long running queries
     _pool = None
 
     def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
                  cookie=None, pool_threads=1):
         # use default configuraiton if none is provided
         if configuration is None:
             configuration = Configuration.get_default()
         self.configuration = configuration
         if (
             hasattr(root, "_connection")
+            and root._connection is not None
             and hasattr(root._connection, "_rest")
+            and root._connection._rest is not None
+            and hasattr(root._connection._rest, "_protocol")
+            and hasattr(root._connection._rest, "_host")
+            and hasattr(root._connection._rest, "_port")
         ):
             self.configuration.host = (
                 f"{root._connection._rest._protocol}://"
                 + root._connection._rest._host
                 + f":{root._connection._rest._port}"
             )
         self.pool_threads = pool_threads
 
         self.rest_client = rest.RESTClientObject(root, configuration)
         self.default_headers = {}
         if header_name is not None:
             self.default_headers[header_name] = header_value
         self.cookie = cookie
         # Set default User-Agent.
-        self.user_agent = 'OpenAPI-Generator/1.0.0/python'
+        self.user_agent = 'python_api/' + VERSION + ''
         self.client_side_validation = configuration.client_side_validation
+        self._enable_long_running_polling = getattr(root, "_enable_long_running_polling", False)
 
     def __enter__(self):
         return self
 
     def __exit__(self, exc_type, exc_value, traceback):
         self.close()
 
@@ -154,15 +168,15 @@
         It stores default ApiClient.
 
         :param default: object of ApiClient.
         """
         cls._default = default
 
     def __call_api(
-            self, resource_path, method, path_params=None,
+            self, root, resource_path, method, path_params=None,
             query_params=None, header_params=None, body=None, post_params=None,
             files=None, response_types_map=None, auth_settings=None,
             _return_http_data_only=None, collection_formats=None,
             _preload_content=True, _request_timeout=None, _host=None,
             _request_auth=None):
 
         config = self.configuration
@@ -218,22 +232,25 @@
         if query_params:
             query_params = self.sanitize_for_serialization(query_params)
             url_query = self.parameters_to_url_query(query_params,
                                                      collection_formats)
             url += "?" + url_query
 
         try:
-            # perform request and return response
-            response_data = self.request(
-                method, url,
+            # perform request and return response, maybe with retry
+            response_data = self.request_with_retry(
+                root,
+                method,
+                url,
                 query_params=query_params,
                 headers=header_params,
                 post_params=post_params, body=body,
                 _preload_content=_preload_content,
-                _request_timeout=_request_timeout)
+                _request_timeout=_request_timeout
+            )
         except APIError as e:
             if e.body:
                 e.body = e.body.decode('utf-8')
             raise e
 
         self.last_response = response_data
 
@@ -251,15 +268,52 @@
         #         match = re.search(r"charset=([a-zA-Z\-\d]+)[\s;]?", content_type)
         #     encoding = match.group(1) if match else "utf-8"
         #     response_data.data = response_data.data.decode(encoding)
 
         # deserialize response data
 
         if response_type:
-            return_data = self.deserialize(response_data, response_type)
+            large_results_resp = self.large_results(response_data)
+            if large_results_resp is None:
+                # regular, non-large results use case
+                return_data = self.deserialize(response_data, response_type)
+            else:
+                # This should be the normal way in which we figure out where to get the results from,
+                # as well as how many chunks there are to get. Due to a bug, we use the alternate logic
+                # (in the "else" clause) to infer the URL from the UUID
+                if "Link" in response_data.getheaders():
+                    results_path, num_chunks = self.get_path_and_chunk_count_from_header(response_data.getheaders()["Link"])
+                else:
+                    handler_id = large_results_resp['result_handler']
+                    results_path = '/api/v2/results/' + handler_id
+
+                    # If there is no "Link" header, there is just one chunk
+                    num_chunks = 1
+
+                # Closure for fetching the next chunk in the PagedIter iterator
+                def _fetch_next_chunk(chunk_index, deserialize_type):
+                    # For now, do this because query_params is not actually being used properly in self.request
+                    chunk_url = f'{self.configuration.host}{results_path}?page={chunk_index}'
+
+                    chunk_response_data = self.request(
+                        root,
+                        "GET",
+                        chunk_url,
+                        headers=header_params,
+                        _preload_content=True,
+                        _request_timeout=_request_timeout)
+
+                    return self.deserialize(chunk_response_data, deserialize_type)
+
+                if 'Iterable' in response_type:
+                    return PagedIter(partial(_fetch_next_chunk, deserialize_type=response_type), num_chunks)
+                else:
+                    # At most, we should only need to fetch one chunk if it's a point lookup,
+                    # i.e., one row return
+                    return_data = _fetch_next_chunk(0, response_type)
         else:
             return_data = None
 
         if _return_http_data_only:
             return (return_data)
         else:
             return (return_data, response_data.status,
@@ -335,42 +389,42 @@
 
         :return: object.
         """
         if data is None:
             return None
 
         if type(klass) == str:
-            if klass.startswith('List['):
-                sub_kls = re.match(r'List\[(.*)]', klass).group(1)
+            if klass.startswith('Iterable['):
+                sub_kls = re.match(r'Iterable\[(.*)]', klass).group(1)
                 return [self.__deserialize(sub_data, sub_kls)
                         for sub_data in data]
 
             if klass.startswith('Dict['):
                 sub_kls = re.match(r'Dict\[([^,]*), (.*)]', klass).group(2)
                 return {k: self.__deserialize(v, sub_kls)
                         for k, v in data.items()}
 
             # convert str to class
             if klass in self.NATIVE_TYPES_MAPPING:
                 klass = self.NATIVE_TYPES_MAPPING[klass]
             else:
-                klass = getattr(snowflake.core.schema._generated.models, klass)
+                klass = getattr(snowflake.core.task._generated.models, klass)
 
         if klass in self.PRIMITIVE_TYPES:
             return self.__deserialize_primitive(data, klass)
         elif klass == object:
             return self.__deserialize_object(data)
         elif klass == datetime.date:
             return self.__deserialize_date(data)
         elif klass == datetime.datetime:
             return self.__deserialize_datetime(data)
         else:
             return self.__deserialize_model(data, klass)
 
-    def call_api(self, resource_path, method,
+    def call_api(self, root, resource_path, method,
                  path_params=None, query_params=None, header_params=None,
                  body=None, post_params=None, files=None,
                  response_types_map=None, auth_settings=None,
                  async_req=None, _return_http_data_only=None,
                  collection_formats=None,_preload_content=True,
                   _request_timeout=None, _host=None, _request_auth=None):
         """Makes the HTTP request (synchronous) and returns deserialized data.
@@ -410,88 +464,198 @@
             If async_req parameter is True,
             the request will be called asynchronously.
             The method will return the request thread.
             If parameter async_req is False or missing,
             then the method will return the response directly.
         """
         if not async_req:
-            return self.__call_api(resource_path, method,
-                                   path_params, query_params, header_params,
-                                   body, post_params, files,
-                                   response_types_map, auth_settings,
-                                   _return_http_data_only, collection_formats,
-                                   _preload_content, _request_timeout, _host,
-                                   _request_auth)
-
-        return self.pool.apply_async(self.__call_api, (resource_path,
-                                                       method, path_params,
-                                                       query_params,
-                                                       header_params, body,
-                                                       post_params, files,
-                                                       response_types_map,
-                                                       auth_settings,
-                                                       _return_http_data_only,
-                                                       collection_formats,
-                                                       _preload_content,
-                                                       _request_timeout,
-                                                       _host, _request_auth))
+            return self.__call_api(
+                root,
+                resource_path,
+                method,
+                path_params,
+                query_params,
+                header_params,
+                body,
+                post_params,
+                files,
+                response_types_map,
+                auth_settings,
+                _return_http_data_only,
+                collection_formats,
+                _preload_content,
+                _request_timeout,
+                _host,
+                _request_auth,
+            )
+
+        return self.pool.apply_async(
+            self.__call_api,
+            (
+                root,
+                resource_path,
+                method,
+                path_params,
+                query_params,
+                header_params,
+                body,
+                post_params,
+                files,
+                response_types_map,
+                auth_settings,
+                _return_http_data_only,
+                collection_formats,
+                _preload_content,
+                _request_timeout,
+                _host,
+                _request_auth,
+            )
+        )
 
-    def request(self, method, url, query_params=None, headers=None,
+
+    def request_with_retry(
+                self, root, method, url, query_params=None, headers=None,
+                post_params=None, body=None, _preload_content=True,
+                _request_timeout=None):
+        """
+            Response time by default one hour
+        """
+        enter_timing = time.time()
+        response_data = self.request(
+                root,
+                method,
+                url,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params, body=body,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout)
+
+        if response_data.status != 202 or not self._enable_long_running_polling:
+            return response_data
+
+        result_endpoint = response_data.getheader('Location')
+        if result_endpoint is None:
+            raise InvalidResponseError("Long Running Queries result endpoint is missing")
+
+        if _request_timeout is None:
+            _request_timeout = self.DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING
+        wait_for_results_timeout = enter_timing + _request_timeout
+
+        exponential_wait_time = 1 # wait time increases exponentially, 30% more everytime
+        while True:
+            time_remaining = wait_for_results_timeout - time.time()
+            if time_remaining <= 0:
+                break
+            wait_time = min(exponential_wait_time, time_remaining)
+            time.sleep(wait_time)
+            response_data = self.request(
+                root,
+                'GET',
+                self.configuration.host + result_endpoint,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params, body=body,
+                _preload_content=_preload_content,
+                _request_timeout=max(time_remaining - wait_time, 1)
+                # request_timeout can never be zero
+            )
+
+            if response_data.status != 202:
+                return response_data
+
+            exponential_wait_time *= 1.3
+
+        raise LongRunningQueryTimeout("Long running queries timeout")
+
+
+    def request(self, root, method, url, query_params=None, headers=None,
                 post_params=None, body=None, _preload_content=True,
                 _request_timeout=None):
         """Makes the HTTP request using RESTClient."""
         if method == "GET":
-            return self.rest_client.get_request(url,
-                                        query_params=query_params,
-                                        _preload_content=_preload_content,
-                                        _request_timeout=_request_timeout,
-                                        headers=headers)
+            return self.rest_client.get_request(
+                root,
+                url,
+                query_params=query_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                headers=headers,
+            )
         elif method == "HEAD":
-            return self.rest_client.head_request(url,
-                                         query_params=query_params,
-                                         _preload_content=_preload_content,
-                                         _request_timeout=_request_timeout,
-                                         headers=headers)
+            return self.rest_client.head_request(
+                root,
+                url,
+                query_params=query_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                headers=headers,
+            )
         elif method == "OPTIONS":
-            return self.rest_client.options_request(url,
-                                            query_params=query_params,
-                                            headers=headers,
-                                            _preload_content=_preload_content,
-                                            _request_timeout=_request_timeout)
+            return self.rest_client.options_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+            )
         elif method == "POST":
-            return self.rest_client.post_request(url,
-                                         query_params=query_params,
-                                         headers=headers,
-                                         post_params=post_params,
-                                         _preload_content=_preload_content,
-                                         _request_timeout=_request_timeout,
-                                         body=body)
+            return self.rest_client.post_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                body=body,
+            )
         elif method == "PUT":
-            return self.rest_client.put_request(url,
-                                        query_params=query_params,
-                                        headers=headers,
-                                        post_params=post_params,
-                                        _preload_content=_preload_content,
-                                        _request_timeout=_request_timeout,
-                                        body=body)
+            try:
+                return self.rest_client.put_request(
+                    root,
+                    url,
+                    query_params=query_params,
+                    headers=headers,
+                    post_params=post_params,
+                    _preload_content=_preload_content,
+                    _request_timeout=_request_timeout,
+                    body=body,
+                )
+            except APIError as error:
+                # Raise a more helpful user error if CoA is not supported for this resource;
+                # this is represented as either 405 or 501 on the server.
+                if error.status in (405, 501):
+                    raise NotImplementedError(
+                        'create_or_update is not yet supported for task. Updating task '
+                        'objects is not supported yet; use create() for creating a task.')
+                raise
+
         elif method == "PATCH":
-            return self.rest_client.patch_request(url,
-                                          query_params=query_params,
-                                          headers=headers,
-                                          post_params=post_params,
-                                          _preload_content=_preload_content,
-                                          _request_timeout=_request_timeout,
-                                          body=body)
+            return self.rest_client.patch_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                body=body,
+            )
         elif method == "DELETE":
-            return self.rest_client.delete_request(url,
-                                           query_params=query_params,
-                                           headers=headers,
-                                           _preload_content=_preload_content,
-                                           _request_timeout=_request_timeout,
-                                           body=body)
+            return self.rest_client.delete_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                body=body,
+            )
         else:
             raise _APIValueError(
                 "http method must be `GET`, `HEAD`, `OPTIONS`,"
                 " `POST`, `PATCH`, `PUT` or `DELETE`."
             )
 
     def parameters_to_tuples(self, params, collection_formats):
@@ -759,13 +923,73 @@
         :param data: dict, list.
         :param klass: class literal.
         :return: model object.
         """
 
         return klass.from_dict(data)
 
+    @staticmethod
+    def large_results(response):
+        try:
+            result = json.loads(response.data)
+            if ("result_handler" in result
+                    and "message" in result and
+                    'Large result set. Use provided Link' in result['message']):
+                return result
+            else:
+                return None
+        except ValueError:
+            pass
+
+        return None
+
+
+    @staticmethod
+    def get_path_and_chunk_count_from_header(links_str):
+        links_list = links_str.split(",")
+
+        def parse_links(s):
+            import re
+            # Use regex to extract necessary parts
+            #
+            # Explanation:
+            # The result links are provided to us in the form:
+            # '</api/v2/results/01b39664-0100-0001-0000-0000000430391?page=0>; rel="first"'
+            #
+            # We wish to find how many chunks there are by finding the one that has rel="last",
+            # therefore we find page index corresponding to the link with that rel value.
+            #
+            # 1. <(.*?)> matches and captures the URL inside the angle brackets
+            # 2. page=(\d+) matches 'page=' followed by one or more digits to find the page number
+            # 3. rel="([^"]*)" matches 'rel="'
+            pattern = r'<(.*?)\?page=(\d+)>; rel="([^"]*)"'
+
+            # Search using the regular expression
+            match = re.search(pattern, s)
+            if match:
+                parse_result = dict()
+                parse_result['url'], parse_result['page_number'], parse_result['rel_value'] = match.groups()
+                return parse_result
+
+            return None
+
+        parsed_links = [parse_links(link) for link in links_list]
+
+        # Find the last one
+        last_link = list(filter(lambda link: link['rel_value'].lower() == 'last', parsed_links)).pop()
+
+        # Return the URL; the number of chunks is the chunk index of the last page plus one
+        return last_link['url'], int(last_link['page_number']) + 1
+
 
 class BridgeApiClient(ApiClient):
     def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
                  cookie=None, pool_threads=1, snowflake_connection=None):
         ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
         self.rest_client = rest.BridgeClientObject(snowflake_connection)
+
+
+class StoredProcApiClient(ApiClient):
+    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
+                 cookie=None, pool_threads=1):
+        ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
+        self.rest_client = rest.StoredProcClientObject()
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/schema/_generated/api_response.py` & `snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/api_response.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 """API response object."""
 
 from __future__ import annotations
 from typing import Any, Dict, Optional
-from snowflake.core._internal.pydantic_compatibility import Field, StrictInt, StrictStr
+from snowflake.core.compute_pool._generated.pydantic_compatibility import Field, StrictInt, StrictStr
 
 class ApiResponse:
     """
     API response object
     """
 
     status_code: Optional[StrictInt] = Field(None, description="HTTP status code")
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/schema/_generated/configuration.py` & `snowflake_core-0.8.0/src/snowflake/core/task/_generated/configuration.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,17 +1,19 @@
 # coding: utf-8
 
 """
-    Snowflake Schema API
+    Snowflake Task API
 
-    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
+    The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 import copy
 import logging
@@ -108,15 +110,15 @@
         """
         self.access_token = access_token
         """Access token
         """
         self.logger = {}
         """Logging Settings
         """
-        self.logger["package_logger"] = logging.getLogger("snowflake.core.schema._generated")
+        self.logger["package_logger"] = logging.getLogger("snowflake.core.task._generated")
         self.logger["urllib3_logger"] = logging.getLogger("urllib3")
         self.logger_format = '%(asctime)s %(levelname)s %(message)s'
         """Log format
         """
         self.logger_stream_handler = None
         """Log stream handler
         """
@@ -333,15 +335,15 @@
         """Gets an array of host settings
 
         :return: An array of host settings
         """
         return [
             {
                 'url': "https://org-account.snowflakecomputing.com",
-                'description': "Snowflake Schema API",
+                'description': "Snowflake Task API",
             }
         ]
 
     def get_host_from_settings(self, index, variables=None, servers=None):
         """Gets host URL based on the index and variables
         :param index: array index of the host settings
         :param variables: hash of variable and the corresponding value
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/schema/_generated/rest.py` & `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/rest.py`

 * *Files 23% similar despite different names*

```diff
@@ -4,14 +4,16 @@
     Snowflake Schema API
 
     The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 import json
 import logging
@@ -49,17 +51,26 @@
     def __init__(self, root: "Root", *args, **kwargs):
         self.root = root
         self.pool_manager = create_connection_pool(
             *args,
             **kwargs,
         )
 
-    def request(self, method, url, query_params=None, headers=None,
-                body=None, post_params=None, _preload_content=True,
-                _request_timeout=None):
+    def request(
+        self,
+        root,
+        method,
+        url,
+        query_params=None,
+        headers=None,
+        body=None,
+        post_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
         """Perform requests.
 
         :param method: http request method
         :param url: http request url
         :param query_params: query parameters in the url
         :param headers: http request headers
         :param body: request json body, for `application/json`
@@ -104,64 +115,64 @@
 
                 # no content type provided or payload is json
                 if not headers.get('Content-Type') or re.search('json', headers['Content-Type'], re.IGNORECASE):
                     request_body = None
                     if body is not None:
                         request_body = json.dumps(body)
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 elif headers['Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         fields=post_params,
                         encode_multipart=False,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 elif headers['Content-Type'] == 'multipart/form-data':
                     # must del headers['Content-Type'], or the correct
                     # Content-Type which generated by urllib3 will be
                     # overwritten.
                     del headers['Content-Type']
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         fields=post_params,
                         encode_multipart=True,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 # Pass a `string` parameter directly in the body to support
                 # other content types than Json when `body` argument is
                 # provided in serialized form
                 elif isinstance(body, str) or isinstance(body, bytes):
                     request_body = body
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 else:
                     # Cannot generate the request from given parameters
                     msg = """Cannot prepare a request message for provided
                              arguments. Please check that your arguments match
                              declared content type."""
                     raise APIError(status=0, reason=msg)
             # For `GET`, `HEAD`
             else:
                 r = self.pool_manager.request(
-                    self.root._session_token,
+                    root,
                     method,
                     url,
                     fields={},
                     preload_content=_preload_content,
                     timeout=timeout,
                     headers=headers,
                 )
@@ -191,88 +202,139 @@
             if 500 <= r.status <= 599:
                 raise ServerError(http_resp=r)
 
             raise APIError(http_resp=r)
 
         return r
 
-    def get_request(self, url, headers=None, query_params=None, _preload_content=True,
-            _request_timeout=None):
-        return self.request("GET", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
-
-    def head_request(self, url, headers=None, query_params=None, _preload_content=True,
-             _request_timeout=None):
-        return self.request("HEAD", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
+    def get_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "GET",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def head_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "HEAD",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
 
-    def options_request(self, url, headers=None, query_params=None, post_params=None,
+    def options_request(self, root, url, headers=None, query_params=None, post_params=None,
                 body=None, _preload_content=True, _request_timeout=None):
-        return self.request("OPTIONS", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "OPTIONS",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def delete_request(self, url, headers=None, query_params=None, body=None,
+    def delete_request(self, root, url, headers=None, query_params=None, body=None,
                _preload_content=True, _request_timeout=None):
-        return self.request("DELETE", url,
-                            headers=headers,
-                            query_params=query_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "DELETE",
+            url,
+            headers=headers,
+            query_params=query_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def post_request(self, url, headers=None, query_params=None, post_params=None,
+    def post_request(self, root, url, headers=None, query_params=None, post_params=None,
              body=None, _preload_content=True, _request_timeout=None):
-        return self.request("POST", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "POST",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def put_request(self, url, headers=None, query_params=None, post_params=None,
+    def put_request(self, root, url, headers=None, query_params=None, post_params=None,
             body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PUT", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "PUT",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def patch_request(self, url, headers=None, query_params=None, post_params=None,
+    def patch_request(self, root, url, headers=None, query_params=None, post_params=None,
               body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PATCH", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "PATCH",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
 
 class BridgeClientObject(object):
 
     def __init__(self, snowflake_connection: SnowflakeConnection):
         self.bridge = SnowBridge(snowflake_connection)
 
-    def request(self, method, url, query_params=None, headers=None,
-                body=None, post_params=None, _preload_content=True,
-                _request_timeout=None):
+    def request(
+        self,
+        root,
+        method,
+        url,
+        query_params=None,
+        headers=None,
+        body=None,
+        post_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
         """Perform requests.
 
         :param method: http request method
         :param url: http request url
         :param query_params: query parameters in the url
         :param headers: http request headers
         :param body: request json body, for `application/json`
@@ -315,71 +377,378 @@
             if 500 <= r.status <= 599:
                 raise ServerError(http_resp=r)
 
             raise APIError(http_resp=r)
 
         return r
 
-    def get_request(self, url, headers=None, query_params=None, _preload_content=True,
-                    _request_timeout=None):
-        return self.request("GET", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
-
-    def head_request(self, url, headers=None, query_params=None, _preload_content=True,
-                     _request_timeout=None):
-        return self.request("HEAD", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
-
-    def options_request(self, url, headers=None, query_params=None, post_params=None,
-                        body=None, _preload_content=True, _request_timeout=None):
-        return self.request("OPTIONS", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def delete_request(self, url, headers=None, query_params=None, body=None,
-                       _preload_content=True, _request_timeout=None):
-        return self.request("DELETE", url,
-                            headers=headers,
-                            query_params=query_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def post_request(self, url, headers=None, query_params=None, post_params=None,
-                     body=None, _preload_content=True, _request_timeout=None):
-        return self.request("POST", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def put_request(self, url, headers=None, query_params=None, post_params=None,
-                    body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PUT", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def patch_request(self, url, headers=None, query_params=None, post_params=None,
-                      body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PATCH", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+    def get_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "GET",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def head_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "HEAD",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def options_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "OPTIONS",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def delete_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "DELETE",
+            url,
+            headers=headers,
+            query_params=query_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def post_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "POST",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def put_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PUT",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def patch_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PATCH",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+
+class StoredProcClientObject(object):
+
+    def request(
+        self,
+        root,
+        method,
+        url,
+        query_params={},
+        headers={},
+        body={},
+        post_params={},
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        """Perform requests.
+        :param method: http request method
+        :param url: http request url
+        :param query_params: query parameters in the url
+        :param headers: http request headers
+        :param body: request json body, for `application/json`
+        :param post_params: request post parameters,
+                            `application/x-www-form-urlencoded`
+                            and `multipart/form-data`
+        :param _preload_content: if False, the urllib3.HTTPResponse object will
+                                 be returned without reading/decoding response
+                                 data. Default is True.
+        :param _request_timeout: timeout setting for this request. If one
+                                 number provided, it will be total request
+                                 timeout. It can also be a pair (tuple) of
+                                 (connection, read) timeouts.
+        """
+        method = method.upper()
+        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
+                          'PATCH', 'OPTIONS']
+        import _snowflake
+        parsed_url = urllib3.util.parse_url(url)
+        response_dict = _snowflake.send_snow_api_request(method, parsed_url.path, dict(query_params), headers, body,
+                                                         post_params, _request_timeout)
+        json_content = json.loads(response_dict["content"])
+        if "data" in json_content:
+            r = urllib3.HTTPResponse(body=json.dumps(json_content["data"]))
+        else:
+            r = urllib3.HTTPResponse(body=json.dumps(json_content).encode("utf-8"))
+        r.status = response_dict["status"]
+        if _preload_content:
+            r = RESTResponse(r)
+            # log response body
+            logger.debug("response body: %s", r.data)
+
+        if not 200 <= r.status <= 299:
+            if r.status == 401:
+                raise UnauthorizedError(http_resp=r)
+
+            if r.status == 403:
+                raise ForbiddenError(http_resp=r)
+
+            if r.status == 404:
+                raise NotFoundError(http_resp=r)
+
+            if r.status == 409:
+                raise ConflictError(http_resp=r)
+
+            if 500 <= r.status <= 599:
+                raise ServerError(http_resp=r)
+
+            raise APIError(http_resp=r)
+
+        return r
+
+    def get_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "GET",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def head_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "HEAD",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def options_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "OPTIONS",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def delete_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "DELETE",
+            url,
+            headers=headers,
+            query_params=query_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def post_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "POST",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def put_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PUT",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def patch_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PATCH",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/schema/_generated/api/schema_api.py` & `snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/api/compute_pool_api.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,102 +1,124 @@
 # coding: utf-8
 
 """
-    Snowflake Schema API
+    Snowflake Compute Pools API
 
-    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
+    The Snowflake Compute Pools API is a REST API that you can use to access, update, and perform certain actions on Compute Pool resources.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 import logging
 
 from typing_extensions import Annotated
-
-from typing_extensions import Annotated
 from pydantic import Field, StrictBool, StrictInt, StrictStr, constr, validator
 
 from typing import List, Optional
 
-from snowflake.core.schema._generated.models.model_schema import ModelSchema
-from snowflake.core.schema._generated.models.schema_clone import SchemaClone
-from snowflake.core.schema._generated.models.success_response import SuccessResponse
+from snowflake.core.compute_pool._generated.models.compute_pool import ComputePool
+from snowflake.core.compute_pool._generated.models.success_response import SuccessResponse
+from typing import Iterable
 
-from snowflake.core._internal.pydantic_compatibility import StrictBool, StrictInt, StrictStr, constr, validate_arguments, ValidationError, validator
-from snowflake.core._internal.utils import ApiClientType
 
-from snowflake.core.schema._generated.api_client import ApiClient
+from snowflake.core.compute_pool._generated.pydantic_compatibility import StrictBool, StrictInt, StrictStr, constr, validate_arguments, ValidationError, validator
+from snowflake.core._internal.snowapi_parameters import SnowApiParameters
+from snowflake.core._internal.utils import ApiClientType, is_running_inside_stored_procedure
+
 from snowflake.core.exceptions import (  # noqa: F401
     _APITypeError,
     _APIValueError
 )
 
 logger  = logging.getLogger(__name__)
 
-class SchemaApi(object):
+class ComputePoolApi(object):
     """NOTE: This class is auto generated by OpenAPI Generator
     Ref: https://openapi-generator.tech
 
     Do not edit the class manually.
     """
 
-    def __init__(self, root, resource_class, bridge_client):
+    def __init__(self, root, resource_class, bridge_client, sproc_client):
         self._root = root
-        self._rest_client = ApiClient.get_default(root)
+        self._resource_name = 'compute_pool'
         self._resource_class = resource_class
         self._bridge_client = bridge_client
+        self._sproc_client = sproc_client
         self._chosen_client_type = ApiClientType.NONE
 
     @property
     def api_client(self):
         """
             chosen_client is the client we chose , either bridge or rest
-            new_chosen_client is the client we want to choose under the current situation ( value of _supports_rest_api + _can_use_rest_api )
+            new_chosen_client is the client we want to choose under the current situation ( value of
+            _supports_rest_api + _can_use_rest_api, and the server-controlled flag )
             We will log the change if we want to choose another client instead of the current one
         """
-        if self._resource_class._supports_rest_api and self._root._can_use_rest_api:
-            chosen_client = self._rest_client
-            new_chosen_client = ApiClientType.REST
+        from snowflake.core.compute_pool._generated.api_client import ApiClient
+
+        # Small helper function for figuring out the correct 'REST' client to use if in stored proc or not
+        def _get_rest_client():
+            if is_running_inside_stored_procedure():
+                return self._sproc_client, ApiClientType.STORED_PROC
+            else:
+                return ApiClient.get_default(self._root), ApiClientType.REST
+
+        use_bridge_override = False
+
+        # We can force use of the bridge if the server dictates it so
+        # But, don't check it for non-resources; _resource_class is not set for non-resources.
+        if self._resource_class is not None:
+            use_bridge_override = self._root.effective_parameters(refresh = False).resource_should_use_client_bridge('compute_pool')
+
+        # if the _resource_class is None (such as Session, which is not a resource), then it is implied
+        # that we use REST (or the stored_proc client)
+        if self._resource_class is None:
+            chosen_client, new_chosen_client = _get_rest_client()
+        elif use_bridge_override:
+            # Bridge override is in effect. Use the client bridge.
+            chosen_client = self._bridge_client
+            new_chosen_client = ApiClientType.BRIDGE
+        # Check if it supports REST before choosing the REST client.
+        elif self._resource_class._supports_rest_api and self._root._can_use_rest_api:
+            chosen_client, new_chosen_client = _get_rest_client()
+        # If all else fails, use the BRIDGE (if there is no REST support for this resource)
         else:
             chosen_client = self._bridge_client
             new_chosen_client = ApiClientType.BRIDGE
 
         if new_chosen_client != self._chosen_client_type:
             self._chosen_client_type = new_chosen_client
             logger.info("Going to use client-%s for this resource", new_chosen_client.name)
         return chosen_client
 
     @validate_arguments
-    def clone_schema(self, database : constr(strict=True), name : constr(strict=True), schema_clone : SchemaClone, create_mode : Optional[StrictStr] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of schema. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, with_managed_access : Annotated[Optional[StrictBool], Field(description="Specifies a managed schema. Managed access schemas centralize privilege management with the schema owner.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Clone a schema  # noqa: E501
+    def create_compute_pool(self, compute_pool : ComputePool, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, initially_suspended : Annotated[Optional[StrictBool], Field(description="Specifies whether the compute pool is created initially in the suspended state.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+        """Create a compute pool  # noqa: E501
 
-        Clone an existing schema, with modifiers as query parameters. See the schema definition for what is required to be provided in the request body. (Cloning not currently supported)  # noqa: E501
+        Create a compute pool, with standard create modifiers as query parameters. See the Compute Pool component definition for what is required to be provided in the request body.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.clone_schema(database, name, schema_clone, create_mode, kind, with_managed_access, async_req=True)
+        >>> thread = api.create_compute_pool(compute_pool, create_mode, initially_suspended, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
-        :type database: str
-        :param name: (required)
-        :type name: str
-        :param schema_clone: (required)
-        :type schema_clone: SchemaClone
-        :param create_mode:
+        :param compute_pool: (required)
+        :type compute_pool: ComputePool
+        :param create_mode: A query parameter allowing support for different modes of resource creation.
         :type create_mode: str
-        :param kind: Type of schema. At the time of writing this transient and permanent (represented by the empty string) are supported.
-        :type kind: str
-        :param with_managed_access: Specifies a managed schema. Managed access schemas centralize privilege management with the schema owner.
-        :type with_managed_access: bool
+        :param initially_suspended: Specifies whether the compute pool is created initially in the suspended state.
+        :type initially_suspended: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
@@ -105,39 +127,33 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.clone_schema_with_http_info(database, name, schema_clone, create_mode, kind, with_managed_access, **kwargs)  # noqa: E501
+        return self.create_compute_pool_with_http_info(compute_pool, create_mode, initially_suspended, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def clone_schema_with_http_info(self, database : constr(strict=True), name : constr(strict=True), schema_clone : SchemaClone, create_mode : Optional[StrictStr] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of schema. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, with_managed_access : Annotated[Optional[StrictBool], Field(description="Specifies a managed schema. Managed access schemas centralize privilege management with the schema owner.")] = None, **kwargs):  # noqa: E501
-        """Clone a schema  # noqa: E501
+    def create_compute_pool_with_http_info(self, compute_pool : ComputePool, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, initially_suspended : Annotated[Optional[StrictBool], Field(description="Specifies whether the compute pool is created initially in the suspended state.")] = None, **kwargs):  # noqa: E501
+        """Create a compute pool  # noqa: E501
 
-        Clone an existing schema, with modifiers as query parameters. See the schema definition for what is required to be provided in the request body. (Cloning not currently supported)  # noqa: E501
+        Create a compute pool, with standard create modifiers as query parameters. See the Compute Pool component definition for what is required to be provided in the request body.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.clone_schema_with_http_info(database, name, schema_clone, create_mode, kind, with_managed_access, async_req=True)
+        >>> thread = api.create_compute_pool_with_http_info(compute_pool, create_mode, initially_suspended, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
-        :type database: str
-        :param name: (required)
-        :type name: str
-        :param schema_clone: (required)
-        :type schema_clone: SchemaClone
-        :param create_mode:
+        :param compute_pool: (required)
+        :type compute_pool: ComputePool
+        :param create_mode: A query parameter allowing support for different modes of resource creation.
         :type create_mode: str
-        :param kind: Type of schema. At the time of writing this transient and permanent (represented by the empty string) are supported.
-        :type kind: str
-        :param with_managed_access: Specifies a managed schema. Managed access schemas centralize privilege management with the schema owner.
-        :type with_managed_access: bool
+        :param initially_suspended: Specifies whether the compute pool is created initially in the suspended state.
+        :type initially_suspended: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -157,20 +173,17 @@
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
-            'database',
-            'name',
-            'schema_clone',
+            'compute_pool',
             'create_mode',
-            'kind',
-            'with_managed_access'
+            'initially_suspended'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -181,48 +194,42 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method clone_schema" % _key
+                    " to method create_compute_pool" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
-        if _params['name']:
-            _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
         if _params.get('create_mode') is not None:  # noqa: E501
             _query_params.append(('createMode', _params['create_mode']))
-        if _params.get('kind') is not None:  # noqa: E501
-            _query_params.append(('kind', _params['kind']))
-        if _params.get('with_managed_access') is not None:  # noqa: E501
-            _query_params.append(('with_managed_access', _params['with_managed_access']))
+        if _params.get('initially_suspended') is not None:  # noqa: E501
+            _query_params.append(('initiallySuspended', _params['initially_suspended']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
-        if _params['schema_clone']:
-            _body_params = _params['schema_clone']
+        if _params['compute_pool']:
+            _body_params = _params['compute_pool']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # set the HTTP header `Content-Type`
         _content_types_list = _params.get('_content_type',
@@ -244,15 +251,16 @@
             '409': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{name}/clone', 'POST',
+            self._root,
+            '/api/v2/compute-pools', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -261,30 +269,28 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def create_or_update_schema(self, database : constr(strict=True), name : constr(strict=True), model_schema : ModelSchema, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Create a (or alter an existing) schema.  # noqa: E501
+    def create_or_alter_compute_pool(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], compute_pool : ComputePool, **kwargs) -> SuccessResponse:  # noqa: E501
+        """Create a (or alter an existing) compute pool.  # noqa: E501
 
-        Create a (or alter an existing) schema. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
+        Create a (or alter an existing) compute pool. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_or_update_schema(database, name, model_schema, async_req=True)
+        >>> thread = api.create_or_alter_compute_pool(name, compute_pool, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
-        :type database: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param model_schema: (required)
-        :type model_schema: ModelSchema
+        :param compute_pool: (required)
+        :type compute_pool: ComputePool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
@@ -293,33 +299,31 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.create_or_update_schema_with_http_info(database, name, model_schema, **kwargs)  # noqa: E501
+        return self.create_or_alter_compute_pool_with_http_info(name, compute_pool, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def create_or_update_schema_with_http_info(self, database : constr(strict=True), name : constr(strict=True), model_schema : ModelSchema, **kwargs):  # noqa: E501
-        """Create a (or alter an existing) schema.  # noqa: E501
+    def create_or_alter_compute_pool_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], compute_pool : ComputePool, **kwargs):  # noqa: E501
+        """Create a (or alter an existing) compute pool.  # noqa: E501
 
-        Create a (or alter an existing) schema. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
+        Create a (or alter an existing) compute pool. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_or_update_schema_with_http_info(database, name, model_schema, async_req=True)
+        >>> thread = api.create_or_alter_compute_pool_with_http_info(name, compute_pool, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
-        :type database: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param model_schema: (required)
-        :type model_schema: ModelSchema
+        :param compute_pool: (required)
+        :type compute_pool: ComputePool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -339,17 +343,16 @@
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
-            'database',
             'name',
-            'model_schema'
+            'compute_pool'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -360,25 +363,23 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method create_or_update_schema" % _key
+                    " to method create_or_alter_compute_pool" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
@@ -386,16 +387,16 @@
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
-        if _params['model_schema']:
-            _body_params = _params['model_schema']
+        if _params['compute_pool']:
+            _body_params = _params['compute_pool']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # set the HTTP header `Content-Type`
         _content_types_list = _params.get('_content_type',
@@ -416,15 +417,16 @@
             '405': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{name}', 'PUT',
+            self._root,
+            '/api/v2/compute-pools/{name}', 'PUT',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -433,34 +435,344 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def create_schema(self, database : constr(strict=True), model_schema : ModelSchema, create_mode : Optional[StrictStr] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of schema. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, with_managed_access : Annotated[Optional[StrictBool], Field(description="Specifies a managed schema. Managed access schemas centralize privilege management with the schema owner.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Create a schema  # noqa: E501
+    def fetch_compute_pool(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> ComputePool:  # noqa: E501
+        """Fetch a compute pool.  # noqa: E501
 
-        Create a schema, with modifiers as query parameters. See the schema definition for what is required to be provided in the request body. (Cloning not currently supported)  # noqa: E501
+        Fetch a compute pool using the SHOW command output.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_schema(database, model_schema, create_mode, kind, with_managed_access, async_req=True)
+        >>> thread = api.fetch_compute_pool(name, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
-        :type database: str
-        :param model_schema: (required)
-        :type model_schema: ModelSchema
-        :param create_mode:
-        :type create_mode: str
-        :param kind: Type of schema. At the time of writing this transient and permanent (represented by the empty string) are supported.
-        :type kind: str
-        :param with_managed_access: Specifies a managed schema. Managed access schemas centralize privilege management with the schema owner.
-        :type with_managed_access: bool
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :type name: str
+        :param async_req: Whether to execute the request asynchronously.
+        :type async_req: bool, optional
+        :param _preload_content: if False, the urllib3.HTTPResponse object will
+                                 be returned without reading/decoding response
+                                 data. Default is True.
+        :type _preload_content: bool, optional
+        :param _request_timeout: timeout setting for this request. If one
+                                 number provided, it will be total request
+                                 timeout. It can also be a pair (tuple) of
+                                 (connection, read) timeouts.
+        :return: Returns the result object.
+                 If the method is called asynchronously,
+                 returns the request thread.
+        :rtype: ComputePool
+        """
+        kwargs['_return_http_data_only'] = True
+        return self.fetch_compute_pool_with_http_info(name, **kwargs)  # noqa: E501
+
+    @validate_arguments
+    def fetch_compute_pool_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
+        """Fetch a compute pool.  # noqa: E501
+
+        Fetch a compute pool using the SHOW command output.  # noqa: E501
+        This method makes a synchronous HTTP request by default. To make an
+        asynchronous HTTP request, please pass async_req=True
+
+        >>> thread = api.fetch_compute_pool_with_http_info(name, async_req=True)
+        >>> result = thread.get()
+
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :type name: str
+        :param async_req: Whether to execute the request asynchronously.
+        :type async_req: bool, optional
+        :param _return_http_data_only: response data without head status code
+                                       and headers
+        :type _return_http_data_only: bool, optional
+        :param _preload_content: if False, the urllib3.HTTPResponse object will
+                                 be returned without reading/decoding response
+                                 data. Default is True.
+        :type _preload_content: bool, optional
+        :param _request_timeout: timeout setting for this request. If one
+                                 number provided, it will be total request
+                                 timeout. It can also be a pair (tuple) of
+                                 (connection, read) timeouts.
+        :param _request_auth: set to override the auth_settings for an a single
+                              request; this effectively ignores the authentication
+                              in the spec for a single request.
+        :type _request_auth: dict, optional
+        :type _content_type: string, optional: force content-type for the request
+        :return: Returns the result object.
+                 If the method is called asynchronously,
+                 returns the request thread.
+        :rtype: tuple(ComputePool, status_code(int), headers(HTTPHeaderDict))
+        """
+
+        _params = locals()
+
+        _all_params = [
+            'name'
+        ]
+        _all_params.extend(
+            [
+                'async_req',
+                '_return_http_data_only',
+                '_preload_content',
+                '_request_timeout',
+                '_request_auth',
+                '_content_type',
+                '_headers'
+            ]
+        )
+
+        # validate the arguments
+        for _key, _val in _params['kwargs'].items():
+            if _key not in _all_params:
+                raise _APITypeError(
+                    "Got an unexpected keyword argument '%s'"
+                    " to method fetch_compute_pool" % _key
+                )
+            _params[_key] = _val
+        del _params['kwargs']
+
+        _collection_formats = {}
+
+        # process the path parameters
+        _path_params = {}
+        if _params['name']:
+            _path_params['name'] = _params['name']
+
+        # process the query parameters
+        _query_params = []
+
+        # process the header parameters
+        _header_params = dict(_params.get('_headers', {}))
+
+        # process the form parameters
+        _form_params = []
+        _files = {}
+
+        # process the body parameter
+        _body_params = None
+
+        # set the HTTP header `Accept`
+        _header_params['Accept'] = self.api_client.select_header_accept(
+            ['application/json'])  # noqa: E501
+
+        # authentication setting
+        _auth_settings = []  # noqa: E501
+
+        _response_types_map = {
+            '200': "ComputePool",
+            '400': "ErrorResponse",
+            '401': "ErrorResponse",
+            '403': "ErrorResponse",
+            '404': "ErrorResponse",
+            '405': "ErrorResponse",
+            '500': "ErrorResponse",
+            '503': "ErrorResponse",
+            '504': "ErrorResponse",
+        }
+
+        return self.api_client.call_api(
+            self._root,
+            '/api/v2/compute-pools/{name}', 'GET',
+            _path_params,
+            _query_params,
+            _header_params,
+            body=_body_params,
+            post_params=_form_params,
+            files=_files,
+            response_types_map=_response_types_map,
+            auth_settings=_auth_settings,
+            async_req=_params.get('async_req'),
+            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _preload_content=_params.get('_preload_content', True),
+            _request_timeout=_params.get('_request_timeout'),
+            collection_formats=_collection_formats,
+            _request_auth=_params.get('_request_auth'))
+
+    @validate_arguments
+    def fetch_compute_pools(self, like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, starts_with : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.")] = None, show_limit : Annotated[Optional[StrictInt], Field(description="A query parameter that limits the maximum number of rows returned by a command.")] = None, **kwargs) -> Iterable[ComputePool]:  # noqa: E501
+        """List compute pools  # noqa: E501
+
+        Lists the compute pools under the account.  # noqa: E501
+        This method makes a synchronous HTTP request by default. To make an
+        asynchronous HTTP request, please pass async_req=True
+
+        >>> thread = api.fetch_compute_pools(like, starts_with, show_limit, async_req=True)
+        >>> result = thread.get()
+
+        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
+        :type like: str
+        :param starts_with: A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
+        :type starts_with: str
+        :param show_limit: A query parameter that limits the maximum number of rows returned by a command.
+        :type show_limit: int
+        :param async_req: Whether to execute the request asynchronously.
+        :type async_req: bool, optional
+        :param _preload_content: if False, the urllib3.HTTPResponse object will
+                                 be returned without reading/decoding response
+                                 data. Default is True.
+        :type _preload_content: bool, optional
+        :param _request_timeout: timeout setting for this request. If one
+                                 number provided, it will be total request
+                                 timeout. It can also be a pair (tuple) of
+                                 (connection, read) timeouts.
+        :return: Returns the result object.
+                 If the method is called asynchronously,
+                 returns the request thread.
+        :rtype: Iterable[ComputePool]
+        """
+        kwargs['_return_http_data_only'] = True
+        return self.fetch_compute_pools_with_http_info(like, starts_with, show_limit, **kwargs)  # noqa: E501
+
+    @validate_arguments
+    def fetch_compute_pools_with_http_info(self, like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, starts_with : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.")] = None, show_limit : Annotated[Optional[StrictInt], Field(description="A query parameter that limits the maximum number of rows returned by a command.")] = None, **kwargs):  # noqa: E501
+        """List compute pools  # noqa: E501
+
+        Lists the compute pools under the account.  # noqa: E501
+        This method makes a synchronous HTTP request by default. To make an
+        asynchronous HTTP request, please pass async_req=True
+
+        >>> thread = api.fetch_compute_pools_with_http_info(like, starts_with, show_limit, async_req=True)
+        >>> result = thread.get()
+
+        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
+        :type like: str
+        :param starts_with: A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
+        :type starts_with: str
+        :param show_limit: A query parameter that limits the maximum number of rows returned by a command.
+        :type show_limit: int
+        :param async_req: Whether to execute the request asynchronously.
+        :type async_req: bool, optional
+        :param _return_http_data_only: response data without head status code
+                                       and headers
+        :type _return_http_data_only: bool, optional
+        :param _preload_content: if False, the urllib3.HTTPResponse object will
+                                 be returned without reading/decoding response
+                                 data. Default is True.
+        :type _preload_content: bool, optional
+        :param _request_timeout: timeout setting for this request. If one
+                                 number provided, it will be total request
+                                 timeout. It can also be a pair (tuple) of
+                                 (connection, read) timeouts.
+        :param _request_auth: set to override the auth_settings for an a single
+                              request; this effectively ignores the authentication
+                              in the spec for a single request.
+        :type _request_auth: dict, optional
+        :type _content_type: string, optional: force content-type for the request
+        :return: Returns the result object.
+                 If the method is called asynchronously,
+                 returns the request thread.
+        :rtype: tuple(Iterable[ComputePool], status_code(int), headers(HTTPHeaderDict))
+        """
+
+        _params = locals()
+
+        _all_params = [
+            'like',
+            'starts_with',
+            'show_limit'
+        ]
+        _all_params.extend(
+            [
+                'async_req',
+                '_return_http_data_only',
+                '_preload_content',
+                '_request_timeout',
+                '_request_auth',
+                '_content_type',
+                '_headers'
+            ]
+        )
+
+        # validate the arguments
+        for _key, _val in _params['kwargs'].items():
+            if _key not in _all_params:
+                raise _APITypeError(
+                    "Got an unexpected keyword argument '%s'"
+                    " to method fetch_compute_pools" % _key
+                )
+            _params[_key] = _val
+        del _params['kwargs']
+
+        _collection_formats = {}
+
+        # process the path parameters
+        _path_params = {}
+
+        # process the query parameters
+        _query_params = []
+        if _params.get('like') is not None:  # noqa: E501
+            _query_params.append(('like', _params['like']))
+        if _params.get('starts_with') is not None:  # noqa: E501
+            _query_params.append(('startsWith', _params['starts_with']))
+        if _params.get('show_limit') is not None:  # noqa: E501
+            _query_params.append(('showLimit', _params['show_limit']))
+
+        # process the header parameters
+        _header_params = dict(_params.get('_headers', {}))
+
+        # process the form parameters
+        _form_params = []
+        _files = {}
+
+        # process the body parameter
+        _body_params = None
+
+        # set the HTTP header `Accept`
+        _header_params['Accept'] = self.api_client.select_header_accept(
+            ['application/json'])  # noqa: E501
+
+        # authentication setting
+        _auth_settings = []  # noqa: E501
+
+        _response_types_map = {
+            '200': "Iterable[ComputePool]",
+            '400': "ErrorResponse",
+            '401': "ErrorResponse",
+            '403': "ErrorResponse",
+            '404': "ErrorResponse",
+            '405': "ErrorResponse",
+            '500': "ErrorResponse",
+            '503': "ErrorResponse",
+            '504': "ErrorResponse",
+        }
+
+        return self.api_client.call_api(
+            self._root,
+            '/api/v2/compute-pools', 'GET',
+            _path_params,
+            _query_params,
+            _header_params,
+            body=_body_params,
+            post_params=_form_params,
+            files=_files,
+            response_types_map=_response_types_map,
+            auth_settings=_auth_settings,
+            async_req=_params.get('async_req'),
+            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _preload_content=_params.get('_preload_content', True),
+            _request_timeout=_params.get('_request_timeout'),
+            collection_formats=_collection_formats,
+            _request_auth=_params.get('_request_auth'))
+
+    @validate_arguments
+    def resume_compute_pool(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> SuccessResponse:  # noqa: E501
+        """Resume a compute pool  # noqa: E501
+
+        Resume a compute pool, if suspended. This is a no-op if it is already running.  # noqa: E501
+        This method makes a synchronous HTTP request by default. To make an
+        asynchronous HTTP request, please pass async_req=True
+
+        >>> thread = api.resume_compute_pool(name, async_req=True)
+        >>> result = thread.get()
+
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
@@ -469,37 +781,29 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.create_schema_with_http_info(database, model_schema, create_mode, kind, with_managed_access, **kwargs)  # noqa: E501
+        return self.resume_compute_pool_with_http_info(name, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def create_schema_with_http_info(self, database : constr(strict=True), model_schema : ModelSchema, create_mode : Optional[StrictStr] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of schema. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, with_managed_access : Annotated[Optional[StrictBool], Field(description="Specifies a managed schema. Managed access schemas centralize privilege management with the schema owner.")] = None, **kwargs):  # noqa: E501
-        """Create a schema  # noqa: E501
+    def resume_compute_pool_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
+        """Resume a compute pool  # noqa: E501
 
-        Create a schema, with modifiers as query parameters. See the schema definition for what is required to be provided in the request body. (Cloning not currently supported)  # noqa: E501
+        Resume a compute pool, if suspended. This is a no-op if it is already running.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_schema_with_http_info(database, model_schema, create_mode, kind, with_managed_access, async_req=True)
+        >>> thread = api.resume_compute_pool_with_http_info(name, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
-        :type database: str
-        :param model_schema: (required)
-        :type model_schema: ModelSchema
-        :param create_mode:
-        :type create_mode: str
-        :param kind: Type of schema. At the time of writing this transient and permanent (represented by the empty string) are supported.
-        :type kind: str
-        :param with_managed_access: Specifies a managed schema. Managed access schemas centralize privilege management with the schema owner.
-        :type with_managed_access: bool
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -519,19 +823,15 @@
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
-            'database',
-            'model_schema',
-            'create_mode',
-            'kind',
-            'with_managed_access'
+            'name'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -542,76 +842,61 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method create_schema" % _key
+                    " to method resume_compute_pool" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
+        if _params['name']:
+            _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
-        if _params.get('create_mode') is not None:  # noqa: E501
-            _query_params.append(('createMode', _params['create_mode']))
-        if _params.get('kind') is not None:  # noqa: E501
-            _query_params.append(('kind', _params['kind']))
-        if _params.get('with_managed_access') is not None:  # noqa: E501
-            _query_params.append(('with_managed_access', _params['with_managed_access']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
-        if _params['model_schema']:
-            _body_params = _params['model_schema']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
-        # set the HTTP header `Content-Type`
-        _content_types_list = _params.get('_content_type',
-            self.api_client.select_header_content_type(
-                ['application/json']))
-        if _content_types_list:
-                _header_params['Content-Type'] = _content_types_list
-
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
-            '409': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas', 'POST',
+            self._root,
+            '/api/v2/compute-pools/{name}:resume', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -620,32 +905,26 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def delete_schema(self, database : constr(strict=True), name : constr(strict=True), if_exists : Optional[StrictBool] = None, restrict : Annotated[Optional[StrictBool], Field(description="Specifies whether the schema should not be droppped if there are existing foreign key references. Returns a warning instead.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Delete a schema.  # noqa: E501
+    def stop_all_services_in_compute_pool(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> SuccessResponse:  # noqa: E501
+        """Stops all services on the compute pool.  # noqa: E501
 
-        Delete a schema with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
+        Stop all services in the compute pool.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.delete_schema(database, name, if_exists, restrict, async_req=True)
+        >>> thread = api.stop_all_services_in_compute_pool(name, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
-        :type database: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists:
-        :type if_exists: bool
-        :param restrict: Specifies whether the schema should not be droppped if there are existing foreign key references. Returns a warning instead.
-        :type restrict: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
@@ -654,35 +933,29 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.delete_schema_with_http_info(database, name, if_exists, restrict, **kwargs)  # noqa: E501
+        return self.stop_all_services_in_compute_pool_with_http_info(name, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def delete_schema_with_http_info(self, database : constr(strict=True), name : constr(strict=True), if_exists : Optional[StrictBool] = None, restrict : Annotated[Optional[StrictBool], Field(description="Specifies whether the schema should not be droppped if there are existing foreign key references. Returns a warning instead.")] = None, **kwargs):  # noqa: E501
-        """Delete a schema.  # noqa: E501
+    def stop_all_services_in_compute_pool_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
+        """Stops all services on the compute pool.  # noqa: E501
 
-        Delete a schema with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
+        Stop all services in the compute pool.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.delete_schema_with_http_info(database, name, if_exists, restrict, async_req=True)
+        >>> thread = api.stop_all_services_in_compute_pool_with_http_info(name, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
-        :type database: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists:
-        :type if_exists: bool
-        :param restrict: Specifies whether the schema should not be droppped if there are existing foreign key references. Returns a warning instead.
-        :type restrict: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -702,18 +975,15 @@
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
-            'database',
-            'name',
-            'if_exists',
-            'restrict'
+            'name'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -724,34 +994,28 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method delete_schema" % _key
+                    " to method stop_all_services_in_compute_pool" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
-        if _params.get('if_exists') is not None:  # noqa: E501
-            _query_params.append(('ifExists', _params['if_exists']))
-        if _params.get('restrict') is not None:  # noqa: E501
-            _query_params.append(('restrict', _params['restrict']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -775,15 +1039,16 @@
             '405': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{name}', 'DELETE',
+            self._root,
+            '/api/v2/compute-pools/{name}:stopallservices', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -792,60 +1057,56 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def fetch_schema(self, database : constr(strict=True), name : constr(strict=True), **kwargs) -> ModelSchema:  # noqa: E501
-        """fetch_schema  # noqa: E501
+    def suspend_compute_pool(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> SuccessResponse:  # noqa: E501
+        """Perform an action on a compute pool  # noqa: E501
 
-        Fetch a schema.  # noqa: E501
+        Suspend a compute pool.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_schema(database, name, async_req=True)
+        >>> thread = api.suspend_compute_pool(name, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
-        :type database: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: ModelSchema
+        :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.fetch_schema_with_http_info(database, name, **kwargs)  # noqa: E501
+        return self.suspend_compute_pool_with_http_info(name, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def fetch_schema_with_http_info(self, database : constr(strict=True), name : constr(strict=True), **kwargs):  # noqa: E501
-        """fetch_schema  # noqa: E501
+    def suspend_compute_pool_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
+        """Perform an action on a compute pool  # noqa: E501
 
-        Fetch a schema.  # noqa: E501
+        Suspend a compute pool.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_schema_with_http_info(database, name, async_req=True)
+        >>> thread = api.suspend_compute_pool_with_http_info(name, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
-        :type database: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -860,21 +1121,20 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(ModelSchema, status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
-            'database',
             'name'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
@@ -886,25 +1146,23 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method fetch_schema" % _key
+                    " to method suspend_compute_pool" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
@@ -921,27 +1179,28 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "ModelSchema",
+            '200': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{name}', 'GET',
+            self._root,
+            '/api/v2/compute-pools/{name}:suspend', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -950,77 +1209,61 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def list_schemas(self, database : constr(strict=True), like : Optional[StrictStr] = None, starts_with : Optional[StrictStr] = None, show_limit : Optional[StrictInt] = None, from_name : Optional[StrictStr] = None, history : Annotated[Optional[StrictBool], Field(description="Includes dropped schemas that have not yet been purged.")] = None, **kwargs) -> List[ModelSchema]:  # noqa: E501
-        """List schemas  # noqa: E501
+    def delete_compute_pool(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+        """Delete a compute pool  # noqa: E501
 
-        Lists the accessible schemas.  # noqa: E501
+        Delete a compute pool with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a 404 failure if the drop is unsuccessful.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.list_schemas(database, like, starts_with, show_limit, from_name, history, async_req=True)
+        >>> thread = api.delete_compute_pool(name, if_exists, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
-        :type database: str
-        :param like:
-        :type like: str
-        :param starts_with:
-        :type starts_with: str
-        :param show_limit:
-        :type show_limit: int
-        :param from_name:
-        :type from_name: str
-        :param history: Includes dropped schemas that have not yet been purged.
-        :type history: bool
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :type name: str
+        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: List[ModelSchema]
+        :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.list_schemas_with_http_info(database, like, starts_with, show_limit, from_name, history, **kwargs)  # noqa: E501
+        return self.delete_compute_pool_with_http_info(name, if_exists, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def list_schemas_with_http_info(self, database : constr(strict=True), like : Optional[StrictStr] = None, starts_with : Optional[StrictStr] = None, show_limit : Optional[StrictInt] = None, from_name : Optional[StrictStr] = None, history : Annotated[Optional[StrictBool], Field(description="Includes dropped schemas that have not yet been purged.")] = None, **kwargs):  # noqa: E501
-        """List schemas  # noqa: E501
+    def delete_compute_pool_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs):  # noqa: E501
+        """Delete a compute pool  # noqa: E501
 
-        Lists the accessible schemas.  # noqa: E501
+        Delete a compute pool with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a 404 failure if the drop is unsuccessful.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.list_schemas_with_http_info(database, like, starts_with, show_limit, from_name, history, async_req=True)
+        >>> thread = api.delete_compute_pool_with_http_info(name, if_exists, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
-        :type database: str
-        :param like:
-        :type like: str
-        :param starts_with:
-        :type starts_with: str
-        :param show_limit:
-        :type show_limit: int
-        :param from_name:
-        :type from_name: str
-        :param history: Includes dropped schemas that have not yet been purged.
-        :type history: bool
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :type name: str
+        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -1034,26 +1277,22 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(List[ModelSchema], status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
-            'database',
-            'like',
-            'starts_with',
-            'show_limit',
-            'from_name',
-            'history'
+            'name',
+            'if_exists'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -1064,38 +1303,30 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method list_schemas" % _key
+                    " to method delete_compute_pool" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
+        if _params['name']:
+            _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
-        if _params.get('like') is not None:  # noqa: E501
-            _query_params.append(('like', _params['like']))
-        if _params.get('starts_with') is not None:  # noqa: E501
-            _query_params.append(('startsWith', _params['starts_with']))
-        if _params.get('show_limit') is not None:  # noqa: E501
-            _query_params.append(('showLimit', _params['show_limit']))
-        if _params.get('from_name') is not None:  # noqa: E501
-            _query_params.append(('fromName', _params['from_name']))
-        if _params.get('history') is not None:  # noqa: E501
-            _query_params.append(('history', _params['history']))
+        if _params.get('if_exists') is not None:  # noqa: E501
+            _query_params.append(('ifExists', _params['if_exists']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -1107,27 +1338,28 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "List[ModelSchema]",
+            '200': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas', 'GET',
+            self._root,
+            '/api/v2/compute-pools/{name}', 'DELETE',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/schema/_generated/models/__init__.py` & `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -5,14 +5,16 @@
     Snowflake Schema API
 
     The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 # import models into model package
 from snowflake.core.schema._generated.models.error_response import ErrorResponse
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/schema/_generated/models/error_response.py` & `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/error_response.py`

 * *Files 5% similar despite different names*

```diff
@@ -4,32 +4,35 @@
     Snowflake Schema API
 
     The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictStr
+from snowflake.core.schema._generated.pydantic_compatibility import BaseModel, StrictStr
 
 class ErrorResponse(BaseModel):
-    message: Optional[StrictStr] = Field(None, description="Error message returned by server")
-    error_code: Optional[StrictStr] = Field(None, description="Error code")
-    request_id: Optional[StrictStr] = Field(None, description="Unique request id")
-    __properties = ["message", "error_code", "request_id"]
+    message: Optional[StrictStr] = None
+    code: Optional[StrictStr] = None
+    error_code: Optional[StrictStr] = None
+    request_id: Optional[StrictStr] = None
+    __properties = ["message", "code", "error_code", "request_id"]
 
 
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
@@ -61,14 +64,16 @@
 
         if type(obj) is not dict:
             return ErrorResponse.parse_obj(obj)
 
         _obj = ErrorResponse.parse_obj({
             "message": obj.get("message"),
 
+            "code": obj.get("code"),
+
             "error_code": obj.get("error_code"),
 
             "request_id": obj.get("request_id"),
 
         })
         return _obj
 
@@ -76,37 +81,43 @@
 from typing import Optional, List, Dict
 
 class ErrorResponseModel():
     def __init__(
         self,
         # optional properties
         message: Optional[str] = None,
+        code: Optional[str] = None,
         error_code: Optional[str] = None,
         request_id: Optional[str] = None,
     ):
         self.message = message
+        self.code = code
         self.error_code = error_code
         self.request_id = request_id
-    __properties = ["message", "error_code", "request_id"]
+    __properties = ["message", "code", "error_code", "request_id"]
 
     def _to_model(self):
         return ErrorResponse(
             message=self.message,
 
+            code=self.code,
+
             error_code=self.error_code,
 
             request_id=self.request_id,
 
         )
 
     @classmethod
     def _from_model(cls, model) -> ErrorResponseModel:
         return ErrorResponseModel(
             message=model.message,
 
+            code=model.code,
+
             error_code=model.error_code,
 
             request_id=model.request_id,
 
         )
 
     def to_dict(self):
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/schema/_generated/models/model_schema.py` & `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/schema_clone.py`

 * *Files 8% similar despite different names*

```diff
@@ -4,47 +4,51 @@
     Snowflake Schema API
 
     The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 from datetime import datetime
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, constr, validator
+from snowflake.core.schema._generated.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, constr, validator
+from snowflake.core.schema._generated.models.point_of_time import PointOfTime
 
-class ModelSchema(BaseModel):
+class SchemaClone(BaseModel):
+    point_of_time: Optional[PointOfTime] = None
     created_on: Optional[datetime] = None
     name: constr(strict=True) = Field(...)
     is_default: Optional[StrictBool] = None
     is_current: Optional[StrictBool] = None
     database_name: Optional[StrictStr] = None
     owner: Optional[StrictStr] = None
     comment: Optional[StrictStr] = None
     options: Optional[StrictStr] = None
     retention_time: Optional[StrictInt] = None
     dropped_on: Optional[datetime] = None
     owner_role_type: Optional[StrictStr] = None
-    budget: Optional[StrictStr] = Field(None, description="Comment representing budget for schema.")
+    budget: Optional[StrictStr] = None
     data_retention_time_in_days: Optional[StrictInt] = None
     default_ddl_collation: Optional[StrictStr] = None
-    log_level: Optional[StrictStr] = Field(None, description="Specifies the severity level of messages that should be ingested and made available in the active event table. At the time of writing the supported values are TRACE, DEBUG, INFO, WARN, ERROR, FATAL and OFF.")
+    log_level: Optional[StrictStr] = None
     pipe_execution_paused: Optional[StrictBool] = None
     max_data_extension_time_in_days: Optional[StrictInt] = None
     suspend_task_after_num_failures: Optional[StrictInt] = None
-    trace_level: Optional[StrictStr] = Field(None, description="Controls how trace events are ingested into the event table. At the time of writing the supported values are ALWAYS, ON_EVENT and OFF.")
+    trace_level: Optional[StrictStr] = None
     user_task_managed_initial_warehouse_size: Optional[StrictStr] = None
     user_task_timeout_ms: Optional[StrictInt] = None
     __properties = ["created_on", "name", "is_default", "is_current", "database_name", "owner", "comment", "options", "retention_time", "dropped_on", "owner_role_type", "budget", "data_retention_time_in_days", "default_ddl_collation", "log_level", "pipe_execution_paused", "max_data_extension_time_in_days", "suspend_task_after_num_failures", "trace_level", "user_task_managed_initial_warehouse_size", "user_task_timeout_ms"]
 
 
     @validator('name')
     def name_validate_regular_expression(cls, v):
@@ -61,16 +65,16 @@
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
         """Returns the JSON representation of the model using alias"""
         return json.dumps(self.to_dict())
 
     @classmethod
-    def from_json(cls, json_str: str) -> ModelSchema:
-        """Create an instance of ModelSchema from a JSON string"""
+    def from_json(cls, json_str: str) -> SchemaClone:
+        """Create an instance of SchemaClone from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         _dict = self.dict(by_alias=True,
                           exclude={
                             "created_on",
@@ -88,23 +92,25 @@
         # set to None if dropped_on (nullable) is None
         if self.dropped_on is None:
             _dict['dropped_on'] = None
 
         return _dict
 
     @classmethod
-    def from_dict(cls, obj: dict) -> ModelSchema:
-        """Create an instance of ModelSchema from a dict"""
+    def from_dict(cls, obj: dict) -> SchemaClone:
+        """Create an instance of SchemaClone from a dict"""
         if obj is None:
             return None
 
         if type(obj) is not dict:
-            return ModelSchema.parse_obj(obj)
+            return SchemaClone.parse_obj(obj)
+
+        _obj = SchemaClone.parse_obj({
+            "point_of_time": PointOfTime.from_dict(obj.get("point_of_time")) if obj.get("point_of_time") is not None else None,
 
-        _obj = ModelSchema.parse_obj({
             "created_on": obj.get("created_on"),
 
             "name": obj.get("name"),
 
             "is_default": obj.get("is_default"),
 
             "is_current": obj.get("is_current"),
@@ -144,20 +150,22 @@
             "user_task_timeout_ms": obj.get("user_task_timeout_ms"),
 
         })
         return _obj
 
 
 from typing import Optional, List, Dict
+from snowflake.core.schema._generated.models.point_of_time import PointOfTime
 
-class ModelSchemaModel():
+class SchemaCloneModel():
     def __init__(
         self,
         name: str,
         # optional properties
+        point_of_time: Optional[PointOfTime] = None,
         created_on: Optional[datetime] = None,
         is_default: Optional[bool] = None,
         is_current: Optional[bool] = None,
         database_name: Optional[str] = None,
         owner: Optional[str] = None,
         comment: Optional[str] = None,
         options: Optional[str] = None,
@@ -171,14 +179,15 @@
         pipe_execution_paused: Optional[bool] = None,
         max_data_extension_time_in_days: Optional[int] = None,
         suspend_task_after_num_failures: Optional[int] = None,
         trace_level: Optional[str] = None,
         user_task_managed_initial_warehouse_size: Optional[str] = None,
         user_task_timeout_ms: Optional[int] = None,
     ):
+        self.point_of_time = point_of_time
         self.created_on = created_on
         self.name = name
         self.is_default = is_default
         self.is_current = is_current
         self.database_name = database_name
         self.owner = owner
         self.comment = comment
@@ -195,15 +204,17 @@
         self.suspend_task_after_num_failures = suspend_task_after_num_failures
         self.trace_level = trace_level
         self.user_task_managed_initial_warehouse_size = user_task_managed_initial_warehouse_size
         self.user_task_timeout_ms = user_task_timeout_ms
     __properties = ["created_on", "name", "is_default", "is_current", "database_name", "owner", "comment", "options", "retention_time", "dropped_on", "owner_role_type", "budget", "data_retention_time_in_days", "default_ddl_collation", "log_level", "pipe_execution_paused", "max_data_extension_time_in_days", "suspend_task_after_num_failures", "trace_level", "user_task_managed_initial_warehouse_size", "user_task_timeout_ms"]
 
     def _to_model(self):
-        return ModelSchema(
+        return SchemaClone(
+            point_of_time=self.point_of_time._to_model() if self.point_of_time is not None else None,
+
             created_on=self.created_on,
 
             name=self.name,
 
             is_default=self.is_default,
 
             is_current=self.is_current,
@@ -241,16 +252,18 @@
             user_task_managed_initial_warehouse_size=self.user_task_managed_initial_warehouse_size,
 
             user_task_timeout_ms=self.user_task_timeout_ms,
 
         )
 
     @classmethod
-    def _from_model(cls, model) -> ModelSchemaModel:
-        return ModelSchemaModel(
+    def _from_model(cls, model) -> SchemaCloneModel:
+        return SchemaCloneModel(
+            point_of_time=PointOfTimeModel._from_model(model.point_of_time) if model.point_of_time is not None else None,
+
             created_on=model.created_on,
 
             name=model.name,
 
             is_default=model.is_default,
 
             is_current=model.is_current,
@@ -292,13 +305,13 @@
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
-    def from_dict(cls, obj: dict) -> ModelSchemaModel:
-        """Create an instance of ModelSchema from a dict"""
-        return cls._from_model(ModelSchema.from_dict(obj))
+    def from_dict(cls, obj: dict) -> SchemaCloneModel:
+        """Create an instance of SchemaClone from a dict"""
+        return cls._from_model(SchemaClone.from_dict(obj))
 
 
-ModelSchema._model_class = ModelSchemaModel
+SchemaClone._model_class = SchemaCloneModel
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/schema/_generated/models/point_of_time.py` & `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/point_of_time.py`

 * *Files 3% similar despite different names*

```diff
@@ -4,32 +4,34 @@
     Snowflake Schema API
 
     The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 import snowflake.core.schema._generated.models
 from snowflake.core.schema._generated.models import *
 
 
 from typing import Optional, Union
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictStr
+from snowflake.core.schema._generated.pydantic_compatibility import BaseModel, Field, StrictStr
 
 class PointOfTime(BaseModel):
     point_of_time_type: StrictStr = Field(...)
-    reference: Optional[StrictStr] = Field(None, description="The relation to the point of time. At the time of writing `at` and `before` are supported.")
+    reference: Optional[StrictStr] = None
     __properties = ["point_of_time_type", "reference"]
 
 
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/schema/_generated/models/point_of_time_offset.py` & `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/point_of_time_offset.py`

 * *Files 9% similar despite different names*

```diff
@@ -4,30 +4,32 @@
     Snowflake Schema API
 
     The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import Field, StrictStr
+from snowflake.core.schema._generated.pydantic_compatibility import StrictStr
 from snowflake.core.schema._generated.models.point_of_time import PointOfTime
 
 class PointOfTimeOffset(PointOfTime):
-    offset: Optional[StrictStr] = Field(None, description="Offset of the point of time.")
+    offset: Optional[StrictStr] = None
     __properties = ["point_of_time_type", "reference"]
 
 
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/schema/_generated/models/point_of_time_statement.py` & `snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/point_of_time_statement.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,33 +1,35 @@
 # coding: utf-8
 
 """
-    Snowflake Schema API
+    Snowflake Table API
 
-    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
+    The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import Field, StrictStr
-from snowflake.core.schema._generated.models.point_of_time import PointOfTime
+from snowflake.core.table._generated.pydantic_compatibility import StrictStr
+from snowflake.core.table._generated.models.point_of_time import PointOfTime
 
 class PointOfTimeStatement(PointOfTime):
-    statement: Optional[StrictStr] = Field(None, description="Statement of the point of time.")
+    statement: Optional[StrictStr] = None
     __properties = ["point_of_time_type", "reference"]
 
 
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
 
@@ -70,15 +72,15 @@
             "statement": obj.get("statement"),
 
         })
         return _obj
 
 
 from typing import Optional, List, Dict
-from snowflake.core.schema._generated.models.point_of_time import PointOfTime
+from snowflake.core.table._generated.models.point_of_time import PointOfTime
 
 class PointOfTimeStatementModel(PointOfTime):
     def __init__(
         self,
         # optional properties
         reference: Optional[str] = None,
         statement: Optional[str] = None,
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/schema/_generated/models/point_of_time_timestamp.py` & `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/point_of_time_timestamp.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,30 +4,32 @@
     Snowflake Schema API
 
     The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import Field, StrictStr
+from snowflake.core.schema._generated.pydantic_compatibility import StrictStr
 from snowflake.core.schema._generated.models.point_of_time import PointOfTime
 
 class PointOfTimeTimestamp(PointOfTime):
-    timestamp: Optional[StrictStr] = Field(None, description="Timestamp of the point of time.")
+    timestamp: Optional[StrictStr] = None
     __properties = ["point_of_time_type", "reference"]
 
 
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/schema/_generated/models/schema_clone.py` & `snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/database.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,55 +1,55 @@
 # coding: utf-8
 
 """
-    Snowflake Schema API
+    Snowflake Database API
 
-    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
+    The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 from datetime import datetime
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, constr, validator
-from snowflake.core.schema._generated.models.point_of_time import PointOfTime
+from snowflake.core.database._generated.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, constr, validator
 
-class SchemaClone(BaseModel):
-    point_of_time: Optional[PointOfTime] = None
+class Database(BaseModel):
     created_on: Optional[datetime] = None
     name: constr(strict=True) = Field(...)
     is_default: Optional[StrictBool] = None
     is_current: Optional[StrictBool] = None
-    database_name: Optional[StrictStr] = None
+    origin: Optional[StrictStr] = None
     owner: Optional[StrictStr] = None
     comment: Optional[StrictStr] = None
     options: Optional[StrictStr] = None
     retention_time: Optional[StrictInt] = None
     dropped_on: Optional[datetime] = None
+    kind: Optional[StrictStr] = None
+    budget: Optional[StrictStr] = None
     owner_role_type: Optional[StrictStr] = None
-    budget: Optional[StrictStr] = Field(None, description="Comment representing budget for schema.")
     data_retention_time_in_days: Optional[StrictInt] = None
     default_ddl_collation: Optional[StrictStr] = None
-    log_level: Optional[StrictStr] = Field(None, description="Specifies the severity level of messages that should be ingested and made available in the active event table. At the time of writing the supported values are TRACE, DEBUG, INFO, WARN, ERROR, FATAL and OFF.")
-    pipe_execution_paused: Optional[StrictBool] = None
+    log_level: Optional[StrictStr] = None
     max_data_extension_time_in_days: Optional[StrictInt] = None
     suspend_task_after_num_failures: Optional[StrictInt] = None
-    trace_level: Optional[StrictStr] = Field(None, description="Controls how trace events are ingested into the event table. At the time of writing the supported values are ALWAYS, ON_EVENT and OFF.")
+    trace_level: Optional[StrictStr] = None
     user_task_managed_initial_warehouse_size: Optional[StrictStr] = None
     user_task_timeout_ms: Optional[StrictInt] = None
-    __properties = ["created_on", "name", "is_default", "is_current", "database_name", "owner", "comment", "options", "retention_time", "dropped_on", "owner_role_type", "budget", "data_retention_time_in_days", "default_ddl_collation", "log_level", "pipe_execution_paused", "max_data_extension_time_in_days", "suspend_task_after_num_failures", "trace_level", "user_task_managed_initial_warehouse_size", "user_task_timeout_ms"]
+    __properties = ["created_on", "name", "is_default", "is_current", "origin", "owner", "comment", "options", "retention_time", "dropped_on", "kind", "budget", "owner_role_type", "data_retention_time_in_days", "default_ddl_collation", "log_level", "max_data_extension_time_in_days", "suspend_task_after_num_failures", "trace_level", "user_task_managed_initial_warehouse_size", "user_task_timeout_ms"]
 
 
     @validator('name')
     def name_validate_regular_expression(cls, v):
         if not re.match(r"""^\"([^\"]|\"\")+\"|[a-zA-Z_][a-zA-Z0-9_$]*$""", v):
             raise ValueError(r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/""")
         return v
@@ -63,84 +63,83 @@
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
         """Returns the JSON representation of the model using alias"""
         return json.dumps(self.to_dict())
 
     @classmethod
-    def from_json(cls, json_str: str) -> SchemaClone:
-        """Create an instance of SchemaClone from a JSON string"""
+    def from_json(cls, json_str: str) -> Database:
+        """Create an instance of Database from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         _dict = self.dict(by_alias=True,
                           exclude={
                             "created_on",
                             "is_default",
                             "is_current",
-                            "database_name",
+                            "origin",
                             "owner",
                             "options",
                             "retention_time",
                             "dropped_on",
-                            "owner_role_type",
+                            "kind",
                             "budget",
+                            "owner_role_type",
                           },
                           exclude_none=True)
         # set to None if dropped_on (nullable) is None
         if self.dropped_on is None:
             _dict['dropped_on'] = None
 
         return _dict
 
     @classmethod
-    def from_dict(cls, obj: dict) -> SchemaClone:
-        """Create an instance of SchemaClone from a dict"""
+    def from_dict(cls, obj: dict) -> Database:
+        """Create an instance of Database from a dict"""
         if obj is None:
             return None
 
         if type(obj) is not dict:
-            return SchemaClone.parse_obj(obj)
-
-        _obj = SchemaClone.parse_obj({
-            "point_of_time": PointOfTime.from_dict(obj.get("point_of_time")) if obj.get("point_of_time") is not None else None,
+            return Database.parse_obj(obj)
 
+        _obj = Database.parse_obj({
             "created_on": obj.get("created_on"),
 
             "name": obj.get("name"),
 
             "is_default": obj.get("is_default"),
 
             "is_current": obj.get("is_current"),
 
-            "database_name": obj.get("database_name"),
+            "origin": obj.get("origin"),
 
             "owner": obj.get("owner"),
 
             "comment": obj.get("comment"),
 
             "options": obj.get("options"),
 
             "retention_time": obj.get("retention_time"),
 
             "dropped_on": obj.get("dropped_on"),
 
-            "owner_role_type": obj.get("owner_role_type"),
+            "kind": obj.get("kind"),
 
             "budget": obj.get("budget"),
 
+            "owner_role_type": obj.get("owner_role_type"),
+
             "data_retention_time_in_days": obj.get("data_retention_time_in_days"),
 
             "default_ddl_collation": obj.get("default_ddl_collation"),
 
             "log_level": obj.get("log_level"),
 
-            "pipe_execution_paused": obj.get("pipe_execution_paused"),
-
             "max_data_extension_time_in_days": obj.get("max_data_extension_time_in_days"),
 
             "suspend_task_after_num_failures": obj.get("suspend_task_after_num_failures"),
 
             "trace_level": obj.get("trace_level"),
 
             "user_task_managed_initial_warehouse_size": obj.get("user_task_managed_initial_warehouse_size"),
@@ -148,152 +147,145 @@
             "user_task_timeout_ms": obj.get("user_task_timeout_ms"),
 
         })
         return _obj
 
 
 from typing import Optional, List, Dict
-from snowflake.core.schema._generated.models.point_of_time import PointOfTime
 
-class SchemaCloneModel():
+class DatabaseModel():
     def __init__(
         self,
         name: str,
         # optional properties
-        point_of_time: Optional[PointOfTime] = None,
         created_on: Optional[datetime] = None,
         is_default: Optional[bool] = None,
         is_current: Optional[bool] = None,
-        database_name: Optional[str] = None,
+        origin: Optional[str] = None,
         owner: Optional[str] = None,
         comment: Optional[str] = None,
         options: Optional[str] = None,
         retention_time: Optional[int] = None,
         dropped_on: Optional[datetime] = None,
-        owner_role_type: Optional[str] = None,
+        kind: Optional[str] = None,
         budget: Optional[str] = None,
+        owner_role_type: Optional[str] = None,
         data_retention_time_in_days: Optional[int] = None,
         default_ddl_collation: Optional[str] = None,
         log_level: Optional[str] = None,
-        pipe_execution_paused: Optional[bool] = None,
         max_data_extension_time_in_days: Optional[int] = None,
         suspend_task_after_num_failures: Optional[int] = None,
         trace_level: Optional[str] = None,
         user_task_managed_initial_warehouse_size: Optional[str] = None,
         user_task_timeout_ms: Optional[int] = None,
     ):
-        self.point_of_time = point_of_time
         self.created_on = created_on
         self.name = name
         self.is_default = is_default
         self.is_current = is_current
-        self.database_name = database_name
+        self.origin = origin
         self.owner = owner
         self.comment = comment
         self.options = options
         self.retention_time = retention_time
         self.dropped_on = dropped_on
-        self.owner_role_type = owner_role_type
+        self.kind = kind
         self.budget = budget
+        self.owner_role_type = owner_role_type
         self.data_retention_time_in_days = data_retention_time_in_days
         self.default_ddl_collation = default_ddl_collation
         self.log_level = log_level
-        self.pipe_execution_paused = pipe_execution_paused
         self.max_data_extension_time_in_days = max_data_extension_time_in_days
         self.suspend_task_after_num_failures = suspend_task_after_num_failures
         self.trace_level = trace_level
         self.user_task_managed_initial_warehouse_size = user_task_managed_initial_warehouse_size
         self.user_task_timeout_ms = user_task_timeout_ms
-    __properties = ["created_on", "name", "is_default", "is_current", "database_name", "owner", "comment", "options", "retention_time", "dropped_on", "owner_role_type", "budget", "data_retention_time_in_days", "default_ddl_collation", "log_level", "pipe_execution_paused", "max_data_extension_time_in_days", "suspend_task_after_num_failures", "trace_level", "user_task_managed_initial_warehouse_size", "user_task_timeout_ms"]
+    __properties = ["created_on", "name", "is_default", "is_current", "origin", "owner", "comment", "options", "retention_time", "dropped_on", "kind", "budget", "owner_role_type", "data_retention_time_in_days", "default_ddl_collation", "log_level", "max_data_extension_time_in_days", "suspend_task_after_num_failures", "trace_level", "user_task_managed_initial_warehouse_size", "user_task_timeout_ms"]
 
     def _to_model(self):
-        return SchemaClone(
-            point_of_time=self.point_of_time._to_model() if self.point_of_time is not None else None,
-
+        return Database(
             created_on=self.created_on,
 
             name=self.name,
 
             is_default=self.is_default,
 
             is_current=self.is_current,
 
-            database_name=self.database_name,
+            origin=self.origin,
 
             owner=self.owner,
 
             comment=self.comment,
 
             options=self.options,
 
             retention_time=self.retention_time,
 
             dropped_on=self.dropped_on,
 
-            owner_role_type=self.owner_role_type,
+            kind=self.kind,
 
             budget=self.budget,
 
+            owner_role_type=self.owner_role_type,
+
             data_retention_time_in_days=self.data_retention_time_in_days,
 
             default_ddl_collation=self.default_ddl_collation,
 
             log_level=self.log_level,
 
-            pipe_execution_paused=self.pipe_execution_paused,
-
             max_data_extension_time_in_days=self.max_data_extension_time_in_days,
 
             suspend_task_after_num_failures=self.suspend_task_after_num_failures,
 
             trace_level=self.trace_level,
 
             user_task_managed_initial_warehouse_size=self.user_task_managed_initial_warehouse_size,
 
             user_task_timeout_ms=self.user_task_timeout_ms,
 
         )
 
     @classmethod
-    def _from_model(cls, model) -> SchemaCloneModel:
-        return SchemaCloneModel(
-            point_of_time=PointOfTimeModel._from_model(model.point_of_time) if model.point_of_time is not None else None,
-
+    def _from_model(cls, model) -> DatabaseModel:
+        return DatabaseModel(
             created_on=model.created_on,
 
             name=model.name,
 
             is_default=model.is_default,
 
             is_current=model.is_current,
 
-            database_name=model.database_name,
+            origin=model.origin,
 
             owner=model.owner,
 
             comment=model.comment,
 
             options=model.options,
 
             retention_time=model.retention_time,
 
             dropped_on=model.dropped_on,
 
-            owner_role_type=model.owner_role_type,
+            kind=model.kind,
 
             budget=model.budget,
 
+            owner_role_type=model.owner_role_type,
+
             data_retention_time_in_days=model.data_retention_time_in_days,
 
             default_ddl_collation=model.default_ddl_collation,
 
             log_level=model.log_level,
 
-            pipe_execution_paused=model.pipe_execution_paused,
-
             max_data_extension_time_in_days=model.max_data_extension_time_in_days,
 
             suspend_task_after_num_failures=model.suspend_task_after_num_failures,
 
             trace_level=model.trace_level,
 
             user_task_managed_initial_warehouse_size=model.user_task_managed_initial_warehouse_size,
@@ -303,13 +295,13 @@
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
-    def from_dict(cls, obj: dict) -> SchemaCloneModel:
-        """Create an instance of SchemaClone from a dict"""
-        return cls._from_model(SchemaClone.from_dict(obj))
+    def from_dict(cls, obj: dict) -> DatabaseModel:
+        """Create an instance of Database from a dict"""
+        return cls._from_model(Database.from_dict(obj))
 
 
-SchemaClone._model_class = SchemaCloneModel
+Database._model_class = DatabaseModel
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/schema/_generated/models/success_response.py` & `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/success_response.py`

 * *Files 7% similar despite different names*

```diff
@@ -4,29 +4,31 @@
     Snowflake Schema API
 
     The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictStr
+from snowflake.core.schema._generated.pydantic_compatibility import BaseModel, StrictStr
 
 class SuccessResponse(BaseModel):
-    status: Optional[StrictStr] = Field(None, description="Message returned by server")
+    status: Optional[StrictStr] = None
     __properties = ["status"]
 
 
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/service/__init__.py` & `snowflake_core-0.8.0/src/snowflake/core/service/__init__.py`

 * *Files 9% similar despite different names*

```diff
@@ -22,20 +22,28 @@
 
 Refer to :class:`snowflake.core.Root` to create the ``root``.
 """
 
 
 from public import public
 
-from ..service._generated.models import ServiceSpec as ServiceSpecification
-from ..service._generated.models import ServiceSpecInlineText, ServiceSpecStageFile
-from ._service import Service, ServiceCollection, ServiceResource
+from snowflake.core.service._generated.models import ServiceSpec as ServiceSpecification
+
+from ._service import (
+    Service,
+    ServiceCollection,
+    ServiceResource,
+    ServiceSpec,
+    ServiceSpecInlineText,
+    ServiceSpecStageFile,
+)
 
 
 public(
     Service=Service,
     ServiceCollection=ServiceCollection,
     ServiceResource=ServiceResource,
+    ServiceSpec=ServiceSpec,
     ServiceSpecification=ServiceSpecification,
     ServiceSpecInlineText=ServiceSpecInlineText,
     ServiceSpecStageFile=ServiceSpecStageFile,
 )
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/service/_service.py` & `snowflake_core-0.8.0/tests/integ/test_service.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,173 +1,199 @@
-import json
-
-from typing import TYPE_CHECKING, Any, Dict, List, Optional
-
-from snowflake.core._internal.pydantic_compatibility import StrictInt, StrictStr
-
-from .._common import (
-    CreateMode,
-    SchemaObjectCollectionParent,
-    SchemaObjectReferenceMixin,
-)
-from .._internal.telemetry import api_telemetry
-from ..paging import PagedIter
-
-
-if TYPE_CHECKING:
-    from snowflake.core.schema import SchemaResource
-
-from snowflake.core.service._generated import ServiceApi
-from snowflake.core.service._generated.api_client import BridgeApiClient
-from snowflake.core.service._generated.models import Service
-
-
-class ServiceCollection(SchemaObjectCollectionParent["ServiceResource"]):
-    """Represents the collection operations of the Snowpark Container Service resource."""
-
-    def __init__(self, schema: "SchemaResource"):
-        super().__init__(schema, ServiceResource)
-        self._api = ServiceApi(
-            root=self.root,
-            resource_class=self._ref_class,
-            bridge_client=BridgeApiClient(
-                root=self.root,
-                snowflake_connection=self._connection or self._session._conn._conn
+#
+# Copyright (c) 2012-2023 Snowflake Computing Inc. All rights reserved.
+#
+from io import BytesIO
+from operator import attrgetter
+from textwrap import dedent
+from time import sleep
+
+import pytest
+
+from snowflake.core.exceptions import APIError, NotFoundError
+from snowflake.core.service import Service, ServiceSpecStageFile
+from snowflake.core.service._generated.models.service_spec_inline_text import ServiceSpecInlineText
+
+from ..utils import random_string
+
+
+pytestmark=pytest.mark.usefixtures("use_rest")
+
+@pytest.fixture(scope="session")
+def seed_temp_service_data():
+    return
+
+
+def test_fetch(services, temp_service, database):
+    service = services[temp_service.name].fetch()
+    assert (
+        service.name == temp_service.name  # for mixed case names
+        or service.name.upper()
+        == temp_service.name.upper()  # for upper/lower case names
+    )
+    service.database_name = database.name
+    for _ in range(5):
+        try:
+            assert (
+                "This message shows that your installation appears to be working "
+                "correctly"
+                in services[temp_service.name].get_service_logs(0, "hello-world")
             )
-        )
-
-    @api_telemetry
-    def iter(
-        self,
-        *,
-        like: Optional[str] = None,
-        starts_with: Optional[str] = None,
-        limit: Optional[int] = None,
-    ) -> PagedIter[Service]:
-        """Look up Snowpark Container services in Snowflake."""
-        return PagedIter(
-            self._api.list_services(
-                self.database.name,
-                self.schema.name,
-                StrictStr(like) if like is not None else None,
-                StrictStr(starts_with) if starts_with else None,
-                limit,
-                async_req=False,
+            break
+        except APIError as e:
+            if (
+                "container: hello-world"
+            ) not in str(e):
+                raise
+            sleep(1)
+
+
+def test_delete(services, session, imagerepo):
+    service_name = random_string(5, "test_service_")
+    stage_name = random_string(5, "test_stage_")
+    session.sql(f"create temp stage {stage_name};").collect()
+    spec_file = "spec.yaml"
+    stage_file = f"@{stage_name}"
+    spec = f"{stage_file}/{spec_file}"
+    session.file.put_stream(
+        BytesIO(
+            dedent(
+                f"""
+                spec:
+                  containers:
+                  - name: hello-world
+                    image: {imagerepo}/hello-world:latest
+                """
+            ).encode()
+        ),
+        spec,
+    )
+    test_service = Service(
+        name=service_name,
+        compute_pool="ci_compute_pool",
+        spec=ServiceSpecStageFile(stage=stage_name, spec_file=spec_file),
+        min_instances=1,
+        max_instances=1,
+    )
+    s = services.create(test_service)
+    s.delete()
+    with pytest.raises(
+        NotFoundError,
+    ):
+        # TODO: HTTP response body: {"description": "list index out of range", "error_details": null}
+        #  Looks wrong
+        s.fetch()
+
+
+def test_iter(services, temp_service):
+    assert any(
+        map(
+            lambda e: e
+            in tuple(
+                map(
+                    attrgetter("name"),
+                    services.iter(),
+                )
+            ),
+            (
+                temp_service.name,  # for mixed case names
+                temp_service.name.upper(),  # for upper/lower case names
+            ),
+        )
+    )
+
+
+def test_suspend_resume(root, services, session, imagerepo):
+    stage_name = random_string(5, "test_stage_")
+    s_name = random_string(5, "test_service_")
+    session.sql(f"create temp stage {stage_name};").collect()
+    spec_file = "spec.yaml"
+    stage_file = f"@{stage_name}"
+    spec = f"{stage_file}/{spec_file}"
+    session.file.put_stream(
+        BytesIO(
+            dedent(
+                f"""
+                spec:
+                  containers:
+                  - name: web-server
+                    image: {imagerepo}/nginx:latest
+                 """
+            ).encode()
+        ),
+        spec,
+    )
+    test_s = Service(
+        name=s_name,
+        compute_pool="ci_compute_pool",
+        spec=ServiceSpecStageFile(stage=stage_name, spec_file=spec_file),
+        min_instances=1,
+        max_instances=1,
+    )
+    s = services.create(test_s)
+    try:
+        for _ in range(10):
+            web_server = s.get_service_status(1)[0]
+            if web_server["status"] in ("READY",):
+                break
+            sleep(1)
+        else:
+            pytest.fail("web_server never came online")
+        services[test_s.name].suspend()
+        for _ in range(10):
+            web_server = s.get_service_status(1)[0]
+            if web_server["status"] in ("SUSPENDED",):
+                break
+            sleep(1)
+        else:
+            pytest.fail("web_server never went to sleep")
+        services[test_s.name].resume()
+        for _ in range(60):
+            web_server = s.get_service_status(1)[0]
+            if web_server["status"] in ("READY",):
+                break
+            print(f"{web_server['status']}")
+            sleep(1)
+        else:
+            pytest.fail("web_server never resumed")
+    finally:
+        s.delete()
+
+
+def test_create_with_spec_inline(services, temp_service_from_spec_inline, database):
+    service = services[temp_service_from_spec_inline.name].fetch()
+    assert (
+            service.name == temp_service_from_spec_inline.name  # for mixed case names
+            or service.name.upper()
+            == temp_service_from_spec_inline.name.upper()  # for upper/lower case names
+    )
+    assert 'name: "hello-world"' in service.spec.spec_text
+    assert service.comment == "created by temp_service_from_spec_inline"
+
+
+@pytest.mark.skip(reason="put isn't supported be Image repository OAS")
+@pytest.mark.parametrize("comment", (None, "ThIs Is A cOmMeNt"))
+@pytest.mark.skip_rest
+def test_update_comment(services, comment, temp_cp, imagerepo):
+    new_s_name = random_string(3, "test_update_comment_")
+    new_s = Service(
+        name=new_s_name,
+        compute_pool=temp_cp.name,
+        min_instances=1,
+        max_instances=1,
+        spec = ServiceSpecInlineText(
+            spec_text = dedent(
+                f"""
+                spec:
+                  containers:
+                  - name: hello-world
+                    image: {imagerepo}/hello-world:latest
+                """
             )
         )
-
-    @api_telemetry
-    def create(
-        self,
-        service: Service,
-        *,
-        mode: CreateMode = CreateMode.error_if_exists,
-    ) -> "ServiceResource":
-        """Create a Snowpark Container service in Snowflake.
-
-        Args:
-            service: an instance of :class:`Service`.
-            mode: One of the following strings.
-
-                CreateMode.error_if_exists: Throw an :class:`snowflake.core.exceptions.ConflictError`
-                if the service already exists in Snowflake. Equivalent to SQL ``create service <name> ...``.
-
-                CreateMode.or_replace: Replace if the service already exists in Snowflake. Equivalent to SQL
-                ``create or replace service <name> ...``.
-
-                CreateMode.if_not_exists: Do nothing if the service already exists in Snowflake. Equivalent to SQL
-                ``create service <name> if not exists...``
-
-                Default value is CreateMode.error_if_exists.
-
-        """
-        real_mode = CreateMode[mode].value
-        self._api.create_service(
-            self.database.name,
-            self.schema.name,
-            service,
-            StrictStr(real_mode),
-            async_req=False,
-        )
-        return self[service.name]
-
-
-class ServiceResource(SchemaObjectReferenceMixin[ServiceCollection]):
-
-    def __init__(self, name: str, collection: ServiceCollection) -> None:
-        self.name = name
-        self.collection = collection
-
-    @api_telemetry
-    def delete(self) -> None:
-        """Delete the service."""
-        self.collection._api.delete_service(
-            self.database.name, self.schema.name, self.name, False, async_req=False
-        )
-
-    @api_telemetry
-    def fetch(self) -> Service:
-        """Fetch a snapshot of the service."""
-        return self.collection._api.fetch_service(
-            self.database.name, self.schema.name, self.name, async_req=False
-        )
-
-    @api_telemetry
-    def suspend(self) -> None:
-        """Suspend the service."""
-        self.collection._api.suspend_service(
-            self.database.name, self.schema.name, self.name, async_req=False
-        )
-
-    @api_telemetry
-    def resume(self) -> None:
-        """Resumes the service."""
-        self.collection._api.resume_service(
-            self.database.name, self.schema.name, self.name, async_req=False
-        )
-
-    @api_telemetry
-    def get_service_status(self, timeout: int = 0) -> List[Dict[str, Any]]:
-        """Get the status of the service.
-
-        Args:
-            timeout: Number of seconds to wait for the service to reach a steady state (for example, READY)
-              before returning the status. If the service does not reach steady state within the specified time,
-              Snowflake returns the current state.
-
-              If not specified or 0, Snowflake returns the current state immediately.
-
-              Default: 0 seconds.
-        """
-        status = self.collection._api.fetch_service_status(
-            self.database.name,
-            self.schema.name,
-            self.name,
-            StrictInt(timeout),
-            async_req=False,
-        )
-        if status.systemget_service_status is None:
-            return list()
-        return json.loads(status.systemget_service_status)
-
-    @api_telemetry
-    def get_service_logs(self, instance_id: str, container_name: str) -> str:
-        """Get the service logs of the service.
-
-        Args:
-            instance_id: Service instance ID.
-            container_name: Container name.
-
-        :meth:`get_service_status` returns the ``instance_id`` and ``container_name`` as a part of its results.
-
-        """
-        logs = self.collection._api.fetch_service_logs(
-            self.database.name,
-            self.schema.name,
-            self.name,
-            StrictInt(instance_id),
-            StrictStr(container_name),
-            async_req=False,
-        )
-        if logs.systemget_service_logs is None:
-            return ""
-        return logs.systemget_service_logs
+    )
+    s = services.create(new_s)
+    try:
+        s.comment = comment
+        s.create_or_update(new_s)
+        assert s.fetch().comment == comment
+    finally:
+        s.delete()
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/service/_generated/__init__.py` & `snowflake_core-0.8.0/src/snowflake/core/service/_generated/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -6,14 +6,16 @@
     Snowflake Services API
 
     The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 __version__ = "1.0.0"
 
@@ -24,11 +26,12 @@
 from snowflake.core.service._generated.api_client import ApiClient
 from snowflake.core.service._generated.configuration import Configuration
 # import models into sdk package
 from snowflake.core.service._generated.models.error_response import ErrorResponse
 from snowflake.core.service._generated.models.fetch_service_logs200_response import FetchServiceLogs200Response
 from snowflake.core.service._generated.models.fetch_service_status200_response import FetchServiceStatus200Response
 from snowflake.core.service._generated.models.service import Service
+from snowflake.core.service._generated.models.service_endpoint import ServiceEndpoint
 from snowflake.core.service._generated.models.service_spec import ServiceSpec
 from snowflake.core.service._generated.models.service_spec_inline_text import ServiceSpecInlineText
 from snowflake.core.service._generated.models.service_spec_stage_file import ServiceSpecStageFile
 from snowflake.core.service._generated.models.success_response import SuccessResponse
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/service/_generated/api_client.py` & `snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/api_client.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,37 +1,44 @@
 # coding: utf-8
 """
-    Snowflake Services API
+    Cortex Search REST API
 
-    The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
+    OpenAPI 3.0 specification for the Cortex Search REST API  # noqa: E501
 
-    The version of the OpenAPI document: 0.0.1
+    The version of the OpenAPI document: 0.1.0
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 from __future__ import absolute_import
 
 import atexit
 import datetime
+import time
 import typing
 from dateutil.parser import parse
 import json
 import mimetypes
 from multiprocessing.pool import ThreadPool
 import os
 import re
 import tempfile
 
 from urllib.parse import quote
 
-from snowflake.core.service._generated.configuration import Configuration
-import snowflake.core.service._generated.models
-from snowflake.core.service._generated import rest
-from snowflake.core.exceptions import _APIValueError, APIError
+from functools import partial
+
+from snowflake.core.cortex.search_service._generated.configuration import Configuration
+import snowflake.core.cortex.search_service._generated.models
+from snowflake.core.cortex.search_service._generated import rest
+from snowflake.core.cortex.search_service._generated.paging import PagedIter
+from snowflake.core.exceptions import _APIValueError, APIError, InvalidResponseError, LongRunningQueryTimeout
+from snowflake.core.version import __version__ as VERSION
 
 if typing.TYPE_CHECKING:
     from snowflake.core._root import Root
 
 
 class ApiClient(object):
     """Generic API client for OpenAPI client library builds.
@@ -62,41 +69,48 @@
         'float': float,
         'str': str,
         'bool': bool,
         'date': datetime.date,
         'datetime': datetime.datetime,
         'object': object,
     }
+    DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING = 600.0 # default 10 minutes for long running queries
     _pool = None
 
     def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
                  cookie=None, pool_threads=1):
         # use default configuraiton if none is provided
         if configuration is None:
             configuration = Configuration.get_default()
         self.configuration = configuration
         if (
             hasattr(root, "_connection")
+            and root._connection is not None
             and hasattr(root._connection, "_rest")
+            and root._connection._rest is not None
+            and hasattr(root._connection._rest, "_protocol")
+            and hasattr(root._connection._rest, "_host")
+            and hasattr(root._connection._rest, "_port")
         ):
             self.configuration.host = (
                 f"{root._connection._rest._protocol}://"
                 + root._connection._rest._host
                 + f":{root._connection._rest._port}"
             )
         self.pool_threads = pool_threads
 
         self.rest_client = rest.RESTClientObject(root, configuration)
         self.default_headers = {}
         if header_name is not None:
             self.default_headers[header_name] = header_value
         self.cookie = cookie
         # Set default User-Agent.
-        self.user_agent = 'OpenAPI-Generator/1.0.0/python'
+        self.user_agent = 'python_api/' + VERSION + ''
         self.client_side_validation = configuration.client_side_validation
+        self._enable_long_running_polling = getattr(root, "_enable_long_running_polling", False)
 
     def __enter__(self):
         return self
 
     def __exit__(self, exc_type, exc_value, traceback):
         self.close()
 
@@ -154,15 +168,15 @@
         It stores default ApiClient.
 
         :param default: object of ApiClient.
         """
         cls._default = default
 
     def __call_api(
-            self, resource_path, method, path_params=None,
+            self, root, resource_path, method, path_params=None,
             query_params=None, header_params=None, body=None, post_params=None,
             files=None, response_types_map=None, auth_settings=None,
             _return_http_data_only=None, collection_formats=None,
             _preload_content=True, _request_timeout=None, _host=None,
             _request_auth=None):
 
         config = self.configuration
@@ -218,22 +232,25 @@
         if query_params:
             query_params = self.sanitize_for_serialization(query_params)
             url_query = self.parameters_to_url_query(query_params,
                                                      collection_formats)
             url += "?" + url_query
 
         try:
-            # perform request and return response
-            response_data = self.request(
-                method, url,
+            # perform request and return response, maybe with retry
+            response_data = self.request_with_retry(
+                root,
+                method,
+                url,
                 query_params=query_params,
                 headers=header_params,
                 post_params=post_params, body=body,
                 _preload_content=_preload_content,
-                _request_timeout=_request_timeout)
+                _request_timeout=_request_timeout
+            )
         except APIError as e:
             if e.body:
                 e.body = e.body.decode('utf-8')
             raise e
 
         self.last_response = response_data
 
@@ -251,15 +268,52 @@
         #         match = re.search(r"charset=([a-zA-Z\-\d]+)[\s;]?", content_type)
         #     encoding = match.group(1) if match else "utf-8"
         #     response_data.data = response_data.data.decode(encoding)
 
         # deserialize response data
 
         if response_type:
-            return_data = self.deserialize(response_data, response_type)
+            large_results_resp = self.large_results(response_data)
+            if large_results_resp is None:
+                # regular, non-large results use case
+                return_data = self.deserialize(response_data, response_type)
+            else:
+                # This should be the normal way in which we figure out where to get the results from,
+                # as well as how many chunks there are to get. Due to a bug, we use the alternate logic
+                # (in the "else" clause) to infer the URL from the UUID
+                if "Link" in response_data.getheaders():
+                    results_path, num_chunks = self.get_path_and_chunk_count_from_header(response_data.getheaders()["Link"])
+                else:
+                    handler_id = large_results_resp['result_handler']
+                    results_path = '/api/v2/results/' + handler_id
+
+                    # If there is no "Link" header, there is just one chunk
+                    num_chunks = 1
+
+                # Closure for fetching the next chunk in the PagedIter iterator
+                def _fetch_next_chunk(chunk_index, deserialize_type):
+                    # For now, do this because query_params is not actually being used properly in self.request
+                    chunk_url = f'{self.configuration.host}{results_path}?page={chunk_index}'
+
+                    chunk_response_data = self.request(
+                        root,
+                        "GET",
+                        chunk_url,
+                        headers=header_params,
+                        _preload_content=True,
+                        _request_timeout=_request_timeout)
+
+                    return self.deserialize(chunk_response_data, deserialize_type)
+
+                if 'Iterable' in response_type:
+                    return PagedIter(partial(_fetch_next_chunk, deserialize_type=response_type), num_chunks)
+                else:
+                    # At most, we should only need to fetch one chunk if it's a point lookup,
+                    # i.e., one row return
+                    return_data = _fetch_next_chunk(0, response_type)
         else:
             return_data = None
 
         if _return_http_data_only:
             return (return_data)
         else:
             return (return_data, response_data.status,
@@ -335,42 +389,42 @@
 
         :return: object.
         """
         if data is None:
             return None
 
         if type(klass) == str:
-            if klass.startswith('List['):
-                sub_kls = re.match(r'List\[(.*)]', klass).group(1)
+            if klass.startswith('Iterable['):
+                sub_kls = re.match(r'Iterable\[(.*)]', klass).group(1)
                 return [self.__deserialize(sub_data, sub_kls)
                         for sub_data in data]
 
             if klass.startswith('Dict['):
                 sub_kls = re.match(r'Dict\[([^,]*), (.*)]', klass).group(2)
                 return {k: self.__deserialize(v, sub_kls)
                         for k, v in data.items()}
 
             # convert str to class
             if klass in self.NATIVE_TYPES_MAPPING:
                 klass = self.NATIVE_TYPES_MAPPING[klass]
             else:
-                klass = getattr(snowflake.core.service._generated.models, klass)
+                klass = getattr(snowflake.core.cortex.search_service._generated.models, klass)
 
         if klass in self.PRIMITIVE_TYPES:
             return self.__deserialize_primitive(data, klass)
         elif klass == object:
             return self.__deserialize_object(data)
         elif klass == datetime.date:
             return self.__deserialize_date(data)
         elif klass == datetime.datetime:
             return self.__deserialize_datetime(data)
         else:
             return self.__deserialize_model(data, klass)
 
-    def call_api(self, resource_path, method,
+    def call_api(self, root, resource_path, method,
                  path_params=None, query_params=None, header_params=None,
                  body=None, post_params=None, files=None,
                  response_types_map=None, auth_settings=None,
                  async_req=None, _return_http_data_only=None,
                  collection_formats=None,_preload_content=True,
                   _request_timeout=None, _host=None, _request_auth=None):
         """Makes the HTTP request (synchronous) and returns deserialized data.
@@ -410,88 +464,198 @@
             If async_req parameter is True,
             the request will be called asynchronously.
             The method will return the request thread.
             If parameter async_req is False or missing,
             then the method will return the response directly.
         """
         if not async_req:
-            return self.__call_api(resource_path, method,
-                                   path_params, query_params, header_params,
-                                   body, post_params, files,
-                                   response_types_map, auth_settings,
-                                   _return_http_data_only, collection_formats,
-                                   _preload_content, _request_timeout, _host,
-                                   _request_auth)
-
-        return self.pool.apply_async(self.__call_api, (resource_path,
-                                                       method, path_params,
-                                                       query_params,
-                                                       header_params, body,
-                                                       post_params, files,
-                                                       response_types_map,
-                                                       auth_settings,
-                                                       _return_http_data_only,
-                                                       collection_formats,
-                                                       _preload_content,
-                                                       _request_timeout,
-                                                       _host, _request_auth))
+            return self.__call_api(
+                root,
+                resource_path,
+                method,
+                path_params,
+                query_params,
+                header_params,
+                body,
+                post_params,
+                files,
+                response_types_map,
+                auth_settings,
+                _return_http_data_only,
+                collection_formats,
+                _preload_content,
+                _request_timeout,
+                _host,
+                _request_auth,
+            )
+
+        return self.pool.apply_async(
+            self.__call_api,
+            (
+                root,
+                resource_path,
+                method,
+                path_params,
+                query_params,
+                header_params,
+                body,
+                post_params,
+                files,
+                response_types_map,
+                auth_settings,
+                _return_http_data_only,
+                collection_formats,
+                _preload_content,
+                _request_timeout,
+                _host,
+                _request_auth,
+            )
+        )
 
-    def request(self, method, url, query_params=None, headers=None,
+
+    def request_with_retry(
+                self, root, method, url, query_params=None, headers=None,
+                post_params=None, body=None, _preload_content=True,
+                _request_timeout=None):
+        """
+            Response time by default one hour
+        """
+        enter_timing = time.time()
+        response_data = self.request(
+                root,
+                method,
+                url,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params, body=body,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout)
+
+        if response_data.status != 202 or not self._enable_long_running_polling:
+            return response_data
+
+        result_endpoint = response_data.getheader('Location')
+        if result_endpoint is None:
+            raise InvalidResponseError("Long Running Queries result endpoint is missing")
+
+        if _request_timeout is None:
+            _request_timeout = self.DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING
+        wait_for_results_timeout = enter_timing + _request_timeout
+
+        exponential_wait_time = 1 # wait time increases exponentially, 30% more everytime
+        while True:
+            time_remaining = wait_for_results_timeout - time.time()
+            if time_remaining <= 0:
+                break
+            wait_time = min(exponential_wait_time, time_remaining)
+            time.sleep(wait_time)
+            response_data = self.request(
+                root,
+                'GET',
+                self.configuration.host + result_endpoint,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params, body=body,
+                _preload_content=_preload_content,
+                _request_timeout=max(time_remaining - wait_time, 1)
+                # request_timeout can never be zero
+            )
+
+            if response_data.status != 202:
+                return response_data
+
+            exponential_wait_time *= 1.3
+
+        raise LongRunningQueryTimeout("Long running queries timeout")
+
+
+    def request(self, root, method, url, query_params=None, headers=None,
                 post_params=None, body=None, _preload_content=True,
                 _request_timeout=None):
         """Makes the HTTP request using RESTClient."""
         if method == "GET":
-            return self.rest_client.get_request(url,
-                                        query_params=query_params,
-                                        _preload_content=_preload_content,
-                                        _request_timeout=_request_timeout,
-                                        headers=headers)
+            return self.rest_client.get_request(
+                root,
+                url,
+                query_params=query_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                headers=headers,
+            )
         elif method == "HEAD":
-            return self.rest_client.head_request(url,
-                                         query_params=query_params,
-                                         _preload_content=_preload_content,
-                                         _request_timeout=_request_timeout,
-                                         headers=headers)
+            return self.rest_client.head_request(
+                root,
+                url,
+                query_params=query_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                headers=headers,
+            )
         elif method == "OPTIONS":
-            return self.rest_client.options_request(url,
-                                            query_params=query_params,
-                                            headers=headers,
-                                            _preload_content=_preload_content,
-                                            _request_timeout=_request_timeout)
+            return self.rest_client.options_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+            )
         elif method == "POST":
-            return self.rest_client.post_request(url,
-                                         query_params=query_params,
-                                         headers=headers,
-                                         post_params=post_params,
-                                         _preload_content=_preload_content,
-                                         _request_timeout=_request_timeout,
-                                         body=body)
+            return self.rest_client.post_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                body=body,
+            )
         elif method == "PUT":
-            return self.rest_client.put_request(url,
-                                        query_params=query_params,
-                                        headers=headers,
-                                        post_params=post_params,
-                                        _preload_content=_preload_content,
-                                        _request_timeout=_request_timeout,
-                                        body=body)
+            try:
+                return self.rest_client.put_request(
+                    root,
+                    url,
+                    query_params=query_params,
+                    headers=headers,
+                    post_params=post_params,
+                    _preload_content=_preload_content,
+                    _request_timeout=_request_timeout,
+                    body=body,
+                )
+            except APIError as error:
+                # Raise a more helpful user error if CoA is not supported for this resource;
+                # this is represented as either 405 or 501 on the server.
+                if error.status in (405, 501):
+                    raise NotImplementedError(
+                        'create_or_update is not yet supported for search_service. Updating search_service '
+                        'objects is not supported yet; use create() for creating a search_service.')
+                raise
+
         elif method == "PATCH":
-            return self.rest_client.patch_request(url,
-                                          query_params=query_params,
-                                          headers=headers,
-                                          post_params=post_params,
-                                          _preload_content=_preload_content,
-                                          _request_timeout=_request_timeout,
-                                          body=body)
+            return self.rest_client.patch_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                body=body,
+            )
         elif method == "DELETE":
-            return self.rest_client.delete_request(url,
-                                           query_params=query_params,
-                                           headers=headers,
-                                           _preload_content=_preload_content,
-                                           _request_timeout=_request_timeout,
-                                           body=body)
+            return self.rest_client.delete_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                body=body,
+            )
         else:
             raise _APIValueError(
                 "http method must be `GET`, `HEAD`, `OPTIONS`,"
                 " `POST`, `PATCH`, `PUT` or `DELETE`."
             )
 
     def parameters_to_tuples(self, params, collection_formats):
@@ -759,13 +923,73 @@
         :param data: dict, list.
         :param klass: class literal.
         :return: model object.
         """
 
         return klass.from_dict(data)
 
+    @staticmethod
+    def large_results(response):
+        try:
+            result = json.loads(response.data)
+            if ("result_handler" in result
+                    and "message" in result and
+                    'Large result set. Use provided Link' in result['message']):
+                return result
+            else:
+                return None
+        except ValueError:
+            pass
+
+        return None
+
+
+    @staticmethod
+    def get_path_and_chunk_count_from_header(links_str):
+        links_list = links_str.split(",")
+
+        def parse_links(s):
+            import re
+            # Use regex to extract necessary parts
+            #
+            # Explanation:
+            # The result links are provided to us in the form:
+            # '</api/v2/results/01b39664-0100-0001-0000-0000000430391?page=0>; rel="first"'
+            #
+            # We wish to find how many chunks there are by finding the one that has rel="last",
+            # therefore we find page index corresponding to the link with that rel value.
+            #
+            # 1. <(.*?)> matches and captures the URL inside the angle brackets
+            # 2. page=(\d+) matches 'page=' followed by one or more digits to find the page number
+            # 3. rel="([^"]*)" matches 'rel="'
+            pattern = r'<(.*?)\?page=(\d+)>; rel="([^"]*)"'
+
+            # Search using the regular expression
+            match = re.search(pattern, s)
+            if match:
+                parse_result = dict()
+                parse_result['url'], parse_result['page_number'], parse_result['rel_value'] = match.groups()
+                return parse_result
+
+            return None
+
+        parsed_links = [parse_links(link) for link in links_list]
+
+        # Find the last one
+        last_link = list(filter(lambda link: link['rel_value'].lower() == 'last', parsed_links)).pop()
+
+        # Return the URL; the number of chunks is the chunk index of the last page plus one
+        return last_link['url'], int(last_link['page_number']) + 1
+
 
 class BridgeApiClient(ApiClient):
     def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
                  cookie=None, pool_threads=1, snowflake_connection=None):
         ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
         self.rest_client = rest.BridgeClientObject(snowflake_connection)
+
+
+class StoredProcApiClient(ApiClient):
+    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
+                 cookie=None, pool_threads=1):
+        ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
+        self.rest_client = rest.StoredProcClientObject()
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/service/_generated/api_response.py` & `snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/api_response.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 """API response object."""
 
 from __future__ import annotations
 from typing import Any, Dict, Optional
-from snowflake.core._internal.pydantic_compatibility import Field, StrictInt, StrictStr
+from snowflake.core.image_repository._generated.pydantic_compatibility import Field, StrictInt, StrictStr
 
 class ApiResponse:
     """
     API response object
     """
 
     status_code: Optional[StrictInt] = Field(None, description="HTTP status code")
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/service/_generated/configuration.py` & `snowflake_core-0.8.0/src/snowflake/core/service/_generated/configuration.py`

 * *Files 1% similar despite different names*

```diff
@@ -4,14 +4,16 @@
     Snowflake Services API
 
     The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 import copy
 import logging
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/service/_generated/rest.py` & `snowflake_core-0.8.0/src/snowflake/core/table/_generated/rest.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,17 +1,19 @@
 # coding: utf-8
 
 """
-    Snowflake Services API
+    Snowflake Table API
 
-    The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
+    The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 import json
 import logging
@@ -49,17 +51,26 @@
     def __init__(self, root: "Root", *args, **kwargs):
         self.root = root
         self.pool_manager = create_connection_pool(
             *args,
             **kwargs,
         )
 
-    def request(self, method, url, query_params=None, headers=None,
-                body=None, post_params=None, _preload_content=True,
-                _request_timeout=None):
+    def request(
+        self,
+        root,
+        method,
+        url,
+        query_params=None,
+        headers=None,
+        body=None,
+        post_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
         """Perform requests.
 
         :param method: http request method
         :param url: http request url
         :param query_params: query parameters in the url
         :param headers: http request headers
         :param body: request json body, for `application/json`
@@ -104,64 +115,64 @@
 
                 # no content type provided or payload is json
                 if not headers.get('Content-Type') or re.search('json', headers['Content-Type'], re.IGNORECASE):
                     request_body = None
                     if body is not None:
                         request_body = json.dumps(body)
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 elif headers['Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         fields=post_params,
                         encode_multipart=False,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 elif headers['Content-Type'] == 'multipart/form-data':
                     # must del headers['Content-Type'], or the correct
                     # Content-Type which generated by urllib3 will be
                     # overwritten.
                     del headers['Content-Type']
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         fields=post_params,
                         encode_multipart=True,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 # Pass a `string` parameter directly in the body to support
                 # other content types than Json when `body` argument is
                 # provided in serialized form
                 elif isinstance(body, str) or isinstance(body, bytes):
                     request_body = body
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 else:
                     # Cannot generate the request from given parameters
                     msg = """Cannot prepare a request message for provided
                              arguments. Please check that your arguments match
                              declared content type."""
                     raise APIError(status=0, reason=msg)
             # For `GET`, `HEAD`
             else:
                 r = self.pool_manager.request(
-                    self.root._session_token,
+                    root,
                     method,
                     url,
                     fields={},
                     preload_content=_preload_content,
                     timeout=timeout,
                     headers=headers,
                 )
@@ -191,88 +202,139 @@
             if 500 <= r.status <= 599:
                 raise ServerError(http_resp=r)
 
             raise APIError(http_resp=r)
 
         return r
 
-    def get_request(self, url, headers=None, query_params=None, _preload_content=True,
-            _request_timeout=None):
-        return self.request("GET", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
-
-    def head_request(self, url, headers=None, query_params=None, _preload_content=True,
-             _request_timeout=None):
-        return self.request("HEAD", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
+    def get_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "GET",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def head_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "HEAD",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
 
-    def options_request(self, url, headers=None, query_params=None, post_params=None,
+    def options_request(self, root, url, headers=None, query_params=None, post_params=None,
                 body=None, _preload_content=True, _request_timeout=None):
-        return self.request("OPTIONS", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "OPTIONS",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def delete_request(self, url, headers=None, query_params=None, body=None,
+    def delete_request(self, root, url, headers=None, query_params=None, body=None,
                _preload_content=True, _request_timeout=None):
-        return self.request("DELETE", url,
-                            headers=headers,
-                            query_params=query_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "DELETE",
+            url,
+            headers=headers,
+            query_params=query_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def post_request(self, url, headers=None, query_params=None, post_params=None,
+    def post_request(self, root, url, headers=None, query_params=None, post_params=None,
              body=None, _preload_content=True, _request_timeout=None):
-        return self.request("POST", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "POST",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def put_request(self, url, headers=None, query_params=None, post_params=None,
+    def put_request(self, root, url, headers=None, query_params=None, post_params=None,
             body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PUT", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "PUT",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def patch_request(self, url, headers=None, query_params=None, post_params=None,
+    def patch_request(self, root, url, headers=None, query_params=None, post_params=None,
               body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PATCH", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "PATCH",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
 
 class BridgeClientObject(object):
 
     def __init__(self, snowflake_connection: SnowflakeConnection):
         self.bridge = SnowBridge(snowflake_connection)
 
-    def request(self, method, url, query_params=None, headers=None,
-                body=None, post_params=None, _preload_content=True,
-                _request_timeout=None):
+    def request(
+        self,
+        root,
+        method,
+        url,
+        query_params=None,
+        headers=None,
+        body=None,
+        post_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
         """Perform requests.
 
         :param method: http request method
         :param url: http request url
         :param query_params: query parameters in the url
         :param headers: http request headers
         :param body: request json body, for `application/json`
@@ -315,71 +377,378 @@
             if 500 <= r.status <= 599:
                 raise ServerError(http_resp=r)
 
             raise APIError(http_resp=r)
 
         return r
 
-    def get_request(self, url, headers=None, query_params=None, _preload_content=True,
-                    _request_timeout=None):
-        return self.request("GET", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
-
-    def head_request(self, url, headers=None, query_params=None, _preload_content=True,
-                     _request_timeout=None):
-        return self.request("HEAD", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
-
-    def options_request(self, url, headers=None, query_params=None, post_params=None,
-                        body=None, _preload_content=True, _request_timeout=None):
-        return self.request("OPTIONS", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def delete_request(self, url, headers=None, query_params=None, body=None,
-                       _preload_content=True, _request_timeout=None):
-        return self.request("DELETE", url,
-                            headers=headers,
-                            query_params=query_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def post_request(self, url, headers=None, query_params=None, post_params=None,
-                     body=None, _preload_content=True, _request_timeout=None):
-        return self.request("POST", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def put_request(self, url, headers=None, query_params=None, post_params=None,
-                    body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PUT", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def patch_request(self, url, headers=None, query_params=None, post_params=None,
-                      body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PATCH", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+    def get_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "GET",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def head_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "HEAD",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def options_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "OPTIONS",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def delete_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "DELETE",
+            url,
+            headers=headers,
+            query_params=query_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def post_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "POST",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def put_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PUT",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def patch_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PATCH",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+
+class StoredProcClientObject(object):
+
+    def request(
+        self,
+        root,
+        method,
+        url,
+        query_params={},
+        headers={},
+        body={},
+        post_params={},
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        """Perform requests.
+        :param method: http request method
+        :param url: http request url
+        :param query_params: query parameters in the url
+        :param headers: http request headers
+        :param body: request json body, for `application/json`
+        :param post_params: request post parameters,
+                            `application/x-www-form-urlencoded`
+                            and `multipart/form-data`
+        :param _preload_content: if False, the urllib3.HTTPResponse object will
+                                 be returned without reading/decoding response
+                                 data. Default is True.
+        :param _request_timeout: timeout setting for this request. If one
+                                 number provided, it will be total request
+                                 timeout. It can also be a pair (tuple) of
+                                 (connection, read) timeouts.
+        """
+        method = method.upper()
+        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
+                          'PATCH', 'OPTIONS']
+        import _snowflake
+        parsed_url = urllib3.util.parse_url(url)
+        response_dict = _snowflake.send_snow_api_request(method, parsed_url.path, dict(query_params), headers, body,
+                                                         post_params, _request_timeout)
+        json_content = json.loads(response_dict["content"])
+        if "data" in json_content:
+            r = urllib3.HTTPResponse(body=json.dumps(json_content["data"]))
+        else:
+            r = urllib3.HTTPResponse(body=json.dumps(json_content).encode("utf-8"))
+        r.status = response_dict["status"]
+        if _preload_content:
+            r = RESTResponse(r)
+            # log response body
+            logger.debug("response body: %s", r.data)
+
+        if not 200 <= r.status <= 299:
+            if r.status == 401:
+                raise UnauthorizedError(http_resp=r)
+
+            if r.status == 403:
+                raise ForbiddenError(http_resp=r)
+
+            if r.status == 404:
+                raise NotFoundError(http_resp=r)
+
+            if r.status == 409:
+                raise ConflictError(http_resp=r)
+
+            if 500 <= r.status <= 599:
+                raise ServerError(http_resp=r)
+
+            raise APIError(http_resp=r)
+
+        return r
+
+    def get_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "GET",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def head_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "HEAD",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def options_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "OPTIONS",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def delete_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "DELETE",
+            url,
+            headers=headers,
+            query_params=query_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def post_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "POST",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def put_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PUT",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def patch_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PATCH",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/service/_generated/api/service_api.py` & `snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/api/warehouse_api.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,98 +1,290 @@
 # coding: utf-8
 
 """
-    Snowflake Services API
+    Snowflake Warehouse API
 
-    The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
+    The Snowflake Warehouse API is a REST API that you can use to access, customize and manage virtual warehouse in a Snowflake account.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 import logging
 
 from typing_extensions import Annotated
-
-from typing_extensions import Annotated
-from pydantic import Field, StrictBool, StrictInt, StrictStr, constr, validator
+from pydantic import Field, StrictBool, StrictStr, constr, validator
 
 from typing import List, Optional
 
-from snowflake.core.service._generated.models.fetch_service_logs200_response import FetchServiceLogs200Response
-from snowflake.core.service._generated.models.fetch_service_status200_response import FetchServiceStatus200Response
-from snowflake.core.service._generated.models.service import Service
-from snowflake.core.service._generated.models.success_response import SuccessResponse
+from snowflake.core.warehouse._generated.models.success_response import SuccessResponse
+from snowflake.core.warehouse._generated.models.warehouse import Warehouse
+from typing import Iterable
 
-from snowflake.core._internal.pydantic_compatibility import StrictBool, StrictInt, StrictStr, constr, validate_arguments, ValidationError, validator
-from snowflake.core._internal.utils import ApiClientType
 
-from snowflake.core.service._generated.api_client import ApiClient
+from snowflake.core.warehouse._generated.pydantic_compatibility import StrictBool, StrictInt, StrictStr, constr, validate_arguments, ValidationError, validator
+from snowflake.core._internal.snowapi_parameters import SnowApiParameters
+from snowflake.core._internal.utils import ApiClientType, is_running_inside_stored_procedure
+
 from snowflake.core.exceptions import (  # noqa: F401
     _APITypeError,
     _APIValueError
 )
 
 logger  = logging.getLogger(__name__)
 
-class ServiceApi(object):
+class WarehouseApi(object):
     """NOTE: This class is auto generated by OpenAPI Generator
     Ref: https://openapi-generator.tech
 
     Do not edit the class manually.
     """
 
-    def __init__(self, root, resource_class, bridge_client):
+    def __init__(self, root, resource_class, bridge_client, sproc_client):
         self._root = root
-        self._rest_client = ApiClient.get_default(root)
+        self._resource_name = 'warehouse'
         self._resource_class = resource_class
         self._bridge_client = bridge_client
+        self._sproc_client = sproc_client
         self._chosen_client_type = ApiClientType.NONE
 
     @property
     def api_client(self):
         """
             chosen_client is the client we chose , either bridge or rest
-            new_chosen_client is the client we want to choose under the current situation ( value of _supports_rest_api + _can_use_rest_api )
+            new_chosen_client is the client we want to choose under the current situation ( value of
+            _supports_rest_api + _can_use_rest_api, and the server-controlled flag )
             We will log the change if we want to choose another client instead of the current one
         """
-        if self._resource_class._supports_rest_api and self._root._can_use_rest_api:
-            chosen_client = self._rest_client
-            new_chosen_client = ApiClientType.REST
+        from snowflake.core.warehouse._generated.api_client import ApiClient
+
+        # Small helper function for figuring out the correct 'REST' client to use if in stored proc or not
+        def _get_rest_client():
+            if is_running_inside_stored_procedure():
+                return self._sproc_client, ApiClientType.STORED_PROC
+            else:
+                return ApiClient.get_default(self._root), ApiClientType.REST
+
+        use_bridge_override = False
+
+        # We can force use of the bridge if the server dictates it so
+        # But, don't check it for non-resources; _resource_class is not set for non-resources.
+        if self._resource_class is not None:
+            use_bridge_override = self._root.effective_parameters(refresh = False).resource_should_use_client_bridge('warehouse')
+
+        # if the _resource_class is None (such as Session, which is not a resource), then it is implied
+        # that we use REST (or the stored_proc client)
+        if self._resource_class is None:
+            chosen_client, new_chosen_client = _get_rest_client()
+        elif use_bridge_override:
+            # Bridge override is in effect. Use the client bridge.
+            chosen_client = self._bridge_client
+            new_chosen_client = ApiClientType.BRIDGE
+        # Check if it supports REST before choosing the REST client.
+        elif self._resource_class._supports_rest_api and self._root._can_use_rest_api:
+            chosen_client, new_chosen_client = _get_rest_client()
+        # If all else fails, use the BRIDGE (if there is no REST support for this resource)
         else:
             chosen_client = self._bridge_client
             new_chosen_client = ApiClientType.BRIDGE
 
         if new_chosen_client != self._chosen_client_type:
             self._chosen_client_type = new_chosen_client
             logger.info("Going to use client-%s for this resource", new_chosen_client.name)
         return chosen_client
 
     @validate_arguments
-    def create_service(self, database : constr(strict=True), var_schema : constr(strict=True), service : Service, create_mode : Optional[StrictStr] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Create a service  # noqa: E501
+    def create_or_alter_warehouse(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], warehouse : Warehouse, **kwargs) -> SuccessResponse:  # noqa: E501
+        """Create a (or alter an existing) warehouse.  # noqa: E501
+
+        Create a (or alter an existing) warehouse. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
+        This method makes a synchronous HTTP request by default. To make an
+        asynchronous HTTP request, please pass async_req=True
+
+        >>> thread = api.create_or_alter_warehouse(name, warehouse, async_req=True)
+        >>> result = thread.get()
+
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :type name: str
+        :param warehouse: (required)
+        :type warehouse: Warehouse
+        :param async_req: Whether to execute the request asynchronously.
+        :type async_req: bool, optional
+        :param _preload_content: if False, the urllib3.HTTPResponse object will
+                                 be returned without reading/decoding response
+                                 data. Default is True.
+        :type _preload_content: bool, optional
+        :param _request_timeout: timeout setting for this request. If one
+                                 number provided, it will be total request
+                                 timeout. It can also be a pair (tuple) of
+                                 (connection, read) timeouts.
+        :return: Returns the result object.
+                 If the method is called asynchronously,
+                 returns the request thread.
+        :rtype: SuccessResponse
+        """
+        kwargs['_return_http_data_only'] = True
+        return self.create_or_alter_warehouse_with_http_info(name, warehouse, **kwargs)  # noqa: E501
+
+    @validate_arguments
+    def create_or_alter_warehouse_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], warehouse : Warehouse, **kwargs):  # noqa: E501
+        """Create a (or alter an existing) warehouse.  # noqa: E501
+
+        Create a (or alter an existing) warehouse. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
+        This method makes a synchronous HTTP request by default. To make an
+        asynchronous HTTP request, please pass async_req=True
+
+        >>> thread = api.create_or_alter_warehouse_with_http_info(name, warehouse, async_req=True)
+        >>> result = thread.get()
+
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :type name: str
+        :param warehouse: (required)
+        :type warehouse: Warehouse
+        :param async_req: Whether to execute the request asynchronously.
+        :type async_req: bool, optional
+        :param _return_http_data_only: response data without head status code
+                                       and headers
+        :type _return_http_data_only: bool, optional
+        :param _preload_content: if False, the urllib3.HTTPResponse object will
+                                 be returned without reading/decoding response
+                                 data. Default is True.
+        :type _preload_content: bool, optional
+        :param _request_timeout: timeout setting for this request. If one
+                                 number provided, it will be total request
+                                 timeout. It can also be a pair (tuple) of
+                                 (connection, read) timeouts.
+        :param _request_auth: set to override the auth_settings for an a single
+                              request; this effectively ignores the authentication
+                              in the spec for a single request.
+        :type _request_auth: dict, optional
+        :type _content_type: string, optional: force content-type for the request
+        :return: Returns the result object.
+                 If the method is called asynchronously,
+                 returns the request thread.
+        :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
+        """
+
+        _params = locals()
+
+        _all_params = [
+            'name',
+            'warehouse'
+        ]
+        _all_params.extend(
+            [
+                'async_req',
+                '_return_http_data_only',
+                '_preload_content',
+                '_request_timeout',
+                '_request_auth',
+                '_content_type',
+                '_headers'
+            ]
+        )
+
+        # validate the arguments
+        for _key, _val in _params['kwargs'].items():
+            if _key not in _all_params:
+                raise _APITypeError(
+                    "Got an unexpected keyword argument '%s'"
+                    " to method create_or_alter_warehouse" % _key
+                )
+            _params[_key] = _val
+        del _params['kwargs']
+
+        _collection_formats = {}
+
+        # process the path parameters
+        _path_params = {}
+        if _params['name']:
+            _path_params['name'] = _params['name']
+
+        # process the query parameters
+        _query_params = []
+
+        # process the header parameters
+        _header_params = dict(_params.get('_headers', {}))
+
+        # process the form parameters
+        _form_params = []
+        _files = {}
+
+        # process the body parameter
+        _body_params = None
+        if _params['warehouse']:
+            _body_params = _params['warehouse']
+
+        # set the HTTP header `Accept`
+        _header_params['Accept'] = self.api_client.select_header_accept(
+            ['application/json'])  # noqa: E501
+
+        # set the HTTP header `Content-Type`
+        _content_types_list = _params.get('_content_type',
+            self.api_client.select_header_content_type(
+                ['application/json']))
+        if _content_types_list:
+                _header_params['Content-Type'] = _content_types_list
+
+        # authentication setting
+        _auth_settings = []  # noqa: E501
+
+        _response_types_map = {
+            '200': "SuccessResponse",
+            '400': "ErrorResponse",
+            '401': "ErrorResponse",
+            '403': "ErrorResponse",
+            '404': "ErrorResponse",
+            '405': "ErrorResponse",
+            '409': "ErrorResponse",
+            '410': "ErrorResponse",
+            '429': "ErrorResponse",
+            '500': "ErrorResponse",
+            '503': "ErrorResponse",
+            '504': "ErrorResponse",
+        }
+
+        return self.api_client.call_api(
+            self._root,
+            '/api/v2/warehouses/{name}', 'PUT',
+            _path_params,
+            _query_params,
+            _header_params,
+            body=_body_params,
+            post_params=_form_params,
+            files=_files,
+            response_types_map=_response_types_map,
+            auth_settings=_auth_settings,
+            async_req=_params.get('async_req'),
+            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _preload_content=_params.get('_preload_content', True),
+            _request_timeout=_params.get('_request_timeout'),
+            collection_formats=_collection_formats,
+            _request_auth=_params.get('_request_auth'))
+
+    @validate_arguments
+    def create_warehouses(self, warehouse : Warehouse, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+        """Create or replace warehouse  # noqa: E501
 
-        Create a service, with standard create modifiers as query parameters. See the Service component definition for what is required to be provided in the request body.  # noqa: E501
+        Create a virtual warehouse. Equivalent to CREATE WAREHOUSE in SQL.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_service(database, var_schema, service, create_mode, async_req=True)
+        >>> thread = api.create_warehouses(warehouse, create_mode, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
-        :type database: str
-        :param var_schema: (required)
-        :type var_schema: str
-        :param service: (required)
-        :type service: Service
-        :param create_mode:
+        :param warehouse: (required)
+        :type warehouse: Warehouse
+        :param create_mode: A query parameter allowing support for different modes of resource creation.
         :type create_mode: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -102,34 +294,30 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.create_service_with_http_info(database, var_schema, service, create_mode, **kwargs)  # noqa: E501
+        return self.create_warehouses_with_http_info(warehouse, create_mode, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def create_service_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), service : Service, create_mode : Optional[StrictStr] = None, **kwargs):  # noqa: E501
-        """Create a service  # noqa: E501
+    def create_warehouses_with_http_info(self, warehouse : Warehouse, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, **kwargs):  # noqa: E501
+        """Create or replace warehouse  # noqa: E501
 
-        Create a service, with standard create modifiers as query parameters. See the Service component definition for what is required to be provided in the request body.  # noqa: E501
+        Create a virtual warehouse. Equivalent to CREATE WAREHOUSE in SQL.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_service_with_http_info(database, var_schema, service, create_mode, async_req=True)
+        >>> thread = api.create_warehouses_with_http_info(warehouse, create_mode, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
-        :type database: str
-        :param var_schema: (required)
-        :type var_schema: str
-        :param service: (required)
-        :type service: Service
-        :param create_mode:
+        :param warehouse: (required)
+        :type warehouse: Warehouse
+        :param create_mode: A query parameter allowing support for different modes of resource creation.
         :type create_mode: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -150,17 +338,15 @@
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
-            'database',
-            'var_schema',
-            'service',
+            'warehouse',
             'create_mode'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
@@ -172,27 +358,23 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method create_service" % _key
+                    " to method create_warehouses" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
-        if _params['var_schema']:
-            _path_params['schema'] = _params['var_schema']
 
         # process the query parameters
         _query_params = []
         if _params.get('create_mode') is not None:  # noqa: E501
             _query_params.append(('createMode', _params['create_mode']))
 
         # process the header parameters
@@ -200,16 +382,16 @@
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
-        if _params['service']:
-            _body_params = _params['service']
+        if _params['warehouse']:
+            _body_params = _params['warehouse']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # set the HTTP header `Content-Type`
         _content_types_list = _params.get('_content_type',
@@ -222,24 +404,26 @@
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
-            '404': "ErrorResponse",
             '405': "ErrorResponse",
             '409': "ErrorResponse",
+            '410': "ErrorResponse",
+            '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/services', 'POST',
+            self._root,
+            '/api/v2/warehouses', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -248,31 +432,27 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def delete_service(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), if_exists : Optional[StrictBool] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Delete a service  # noqa: E501
+    def abort_all_queries_on_warehouse(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+        """abort all queries  # noqa: E501
 
-        Delete a service with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
+        Aborts all the queries currently running or queued on the warehouse.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.delete_service(database, var_schema, name, if_exists, async_req=True)
+        >>> thread = api.abort_all_queries_on_warehouse(name, if_exists, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
-        :type database: str
-        :param var_schema: (required)
-        :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists:
+        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
         :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -282,34 +462,30 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.delete_service_with_http_info(database, var_schema, name, if_exists, **kwargs)  # noqa: E501
+        return self.abort_all_queries_on_warehouse_with_http_info(name, if_exists, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def delete_service_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), if_exists : Optional[StrictBool] = None, **kwargs):  # noqa: E501
-        """Delete a service  # noqa: E501
+    def abort_all_queries_on_warehouse_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs):  # noqa: E501
+        """abort all queries  # noqa: E501
 
-        Delete a service with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
+        Aborts all the queries currently running or queued on the warehouse.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.delete_service_with_http_info(database, var_schema, name, if_exists, async_req=True)
+        >>> thread = api.abort_all_queries_on_warehouse_with_http_info(name, if_exists, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
-        :type database: str
-        :param var_schema: (required)
-        :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists:
+        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
         :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -330,16 +506,14 @@
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
-            'database',
-            'var_schema',
             'name',
             'if_exists'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
@@ -352,27 +526,23 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method delete_service" % _key
+                    " to method abort_all_queries_on_warehouse" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
-        if _params['var_schema']:
-            _path_params['schema'] = _params['var_schema']
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
         if _params.get('if_exists') is not None:  # noqa: E501
             _query_params.append(('ifExists', _params['if_exists']))
@@ -397,21 +567,25 @@
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '409': "ErrorResponse",
+            '410': "ErrorResponse",
+            '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/services/{name}', 'DELETE',
+            self._root,
+            '/api/v2/warehouses/{name}:abort', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -420,64 +594,56 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def fetch_service(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), **kwargs) -> Service:  # noqa: E501
-        """Fetch a service.  # noqa: E501
+    def describe_warehouse(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> Warehouse:  # noqa: E501
+        """Describe warehouse  # noqa: E501
 
-        Fetch a Service.  # noqa: E501
+        Describes the warehouse, show information of the chosen warehouse. Equivalent to DESCRIBE WAREHOUSE in SQL.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_service(database, var_schema, name, async_req=True)
+        >>> thread = api.describe_warehouse(name, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
-        :type database: str
-        :param var_schema: (required)
-        :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: Service
+        :rtype: Warehouse
         """
         kwargs['_return_http_data_only'] = True
-        return self.fetch_service_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
+        return self.describe_warehouse_with_http_info(name, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def fetch_service_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), **kwargs):  # noqa: E501
-        """Fetch a service.  # noqa: E501
+    def describe_warehouse_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
+        """Describe warehouse  # noqa: E501
 
-        Fetch a Service.  # noqa: E501
+        Describes the warehouse, show information of the chosen warehouse. Equivalent to DESCRIBE WAREHOUSE in SQL.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_service_with_http_info(database, var_schema, name, async_req=True)
+        >>> thread = api.describe_warehouse_with_http_info(name, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
-        :type database: str
-        :param var_schema: (required)
-        :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -492,22 +658,20 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(Service, status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(Warehouse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
-            'database',
-            'var_schema',
             'name'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
@@ -519,27 +683,23 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method fetch_service" % _key
+                    " to method describe_warehouse" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
-        if _params['var_schema']:
-            _path_params['schema'] = _params['var_schema']
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
@@ -556,27 +716,31 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "Service",
+            '200': "Warehouse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '409': "ErrorResponse",
+            '410': "ErrorResponse",
+            '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/services/{name}', 'GET',
+            self._root,
+            '/api/v2/warehouses/{name}', 'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -585,77 +749,61 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def fetch_service_logs(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), instance_id : Annotated[StrictInt, Field(..., description="ID of the service instance, starting with 0.")], container_name : Annotated[StrictStr, Field(..., description="Container name as specified in the service specification file.")], num_lines : Annotated[Optional[StrictInt], Field(description="Number of trailing log lines to retrieve.")] = None, **kwargs) -> FetchServiceLogs200Response:  # noqa: E501
-        """Fetch the logs for a given service.  # noqa: E501
+    def drop_warehouse(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+        """Drop warehouse  # noqa: E501
 
-        Fetch the logs for a service.  # noqa: E501
+        Removes the specified virtual warehouse from the system. Equivalent to DROP WAREHOUSE in SQL.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_service_logs(database, var_schema, name, instance_id, container_name, num_lines, async_req=True)
+        >>> thread = api.drop_warehouse(name, if_exists, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
-        :type database: str
-        :param var_schema: (required)
-        :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param instance_id: ID of the service instance, starting with 0. (required)
-        :type instance_id: int
-        :param container_name: Container name as specified in the service specification file. (required)
-        :type container_name: str
-        :param num_lines: Number of trailing log lines to retrieve.
-        :type num_lines: int
+        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: FetchServiceLogs200Response
+        :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.fetch_service_logs_with_http_info(database, var_schema, name, instance_id, container_name, num_lines, **kwargs)  # noqa: E501
+        return self.drop_warehouse_with_http_info(name, if_exists, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def fetch_service_logs_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), instance_id : Annotated[StrictInt, Field(..., description="ID of the service instance, starting with 0.")], container_name : Annotated[StrictStr, Field(..., description="Container name as specified in the service specification file.")], num_lines : Annotated[Optional[StrictInt], Field(description="Number of trailing log lines to retrieve.")] = None, **kwargs):  # noqa: E501
-        """Fetch the logs for a given service.  # noqa: E501
+    def drop_warehouse_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs):  # noqa: E501
+        """Drop warehouse  # noqa: E501
 
-        Fetch the logs for a service.  # noqa: E501
+        Removes the specified virtual warehouse from the system. Equivalent to DROP WAREHOUSE in SQL.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_service_logs_with_http_info(database, var_schema, name, instance_id, container_name, num_lines, async_req=True)
+        >>> thread = api.drop_warehouse_with_http_info(name, if_exists, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
-        :type database: str
-        :param var_schema: (required)
-        :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param instance_id: ID of the service instance, starting with 0. (required)
-        :type instance_id: int
-        :param container_name: Container name as specified in the service specification file. (required)
-        :type container_name: str
-        :param num_lines: Number of trailing log lines to retrieve.
-        :type num_lines: int
+        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -669,26 +817,22 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(FetchServiceLogs200Response, status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
-            'database',
-            'var_schema',
             'name',
-            'instance_id',
-            'container_name',
-            'num_lines'
+            'if_exists'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -699,38 +843,30 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method fetch_service_logs" % _key
+                    " to method drop_warehouse" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
-        if _params['var_schema']:
-            _path_params['schema'] = _params['var_schema']
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
-        if _params.get('instance_id') is not None:  # noqa: E501
-            _query_params.append(('instanceId', _params['instance_id']))
-        if _params.get('container_name') is not None:  # noqa: E501
-            _query_params.append(('containerName', _params['container_name']))
-        if _params.get('num_lines') is not None:  # noqa: E501
-            _query_params.append(('numLines', _params['num_lines']))
+        if _params.get('if_exists') is not None:  # noqa: E501
+            _query_params.append(('ifExists', _params['if_exists']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -742,27 +878,31 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "FetchServiceLogs200Response",
+            '200': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '409': "ErrorResponse",
+            '410': "ErrorResponse",
+            '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/services/{name}/logs', 'GET',
+            self._root,
+            '/api/v2/warehouses/{name}', 'DELETE',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -771,69 +911,220 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def fetch_service_status(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), timeout : Annotated[Optional[StrictInt], Field(description="Number of seconds to wait for the service to reach a steady state (for example, READY) before returning the status. If the service does not reach a steady state within the specified time, Snowflake returns the current state.")] = None, **kwargs) -> FetchServiceStatus200Response:  # noqa: E501
-        """Fetch the status for a given service.  # noqa: E501
+    def list_warehouses(self, like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, **kwargs) -> Iterable[Warehouse]:  # noqa: E501
+        """List warehouse  # noqa: E501
 
-        Fetch the status for a service.  # noqa: E501
+        Show a list of warehouse filtered by pattern. Equivalent to SHOW WAREHOUSE in SQL.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_service_status(database, var_schema, name, timeout, async_req=True)
+        >>> thread = api.list_warehouses(like, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
-        :type database: str
-        :param var_schema: (required)
-        :type var_schema: str
-        :param name: (required)
+        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
+        :type like: str
+        :param async_req: Whether to execute the request asynchronously.
+        :type async_req: bool, optional
+        :param _preload_content: if False, the urllib3.HTTPResponse object will
+                                 be returned without reading/decoding response
+                                 data. Default is True.
+        :type _preload_content: bool, optional
+        :param _request_timeout: timeout setting for this request. If one
+                                 number provided, it will be total request
+                                 timeout. It can also be a pair (tuple) of
+                                 (connection, read) timeouts.
+        :return: Returns the result object.
+                 If the method is called asynchronously,
+                 returns the request thread.
+        :rtype: Iterable[Warehouse]
+        """
+        kwargs['_return_http_data_only'] = True
+        return self.list_warehouses_with_http_info(like, **kwargs)  # noqa: E501
+
+    @validate_arguments
+    def list_warehouses_with_http_info(self, like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, **kwargs):  # noqa: E501
+        """List warehouse  # noqa: E501
+
+        Show a list of warehouse filtered by pattern. Equivalent to SHOW WAREHOUSE in SQL.  # noqa: E501
+        This method makes a synchronous HTTP request by default. To make an
+        asynchronous HTTP request, please pass async_req=True
+
+        >>> thread = api.list_warehouses_with_http_info(like, async_req=True)
+        >>> result = thread.get()
+
+        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
+        :type like: str
+        :param async_req: Whether to execute the request asynchronously.
+        :type async_req: bool, optional
+        :param _return_http_data_only: response data without head status code
+                                       and headers
+        :type _return_http_data_only: bool, optional
+        :param _preload_content: if False, the urllib3.HTTPResponse object will
+                                 be returned without reading/decoding response
+                                 data. Default is True.
+        :type _preload_content: bool, optional
+        :param _request_timeout: timeout setting for this request. If one
+                                 number provided, it will be total request
+                                 timeout. It can also be a pair (tuple) of
+                                 (connection, read) timeouts.
+        :param _request_auth: set to override the auth_settings for an a single
+                              request; this effectively ignores the authentication
+                              in the spec for a single request.
+        :type _request_auth: dict, optional
+        :type _content_type: string, optional: force content-type for the request
+        :return: Returns the result object.
+                 If the method is called asynchronously,
+                 returns the request thread.
+        :rtype: tuple(Iterable[Warehouse], status_code(int), headers(HTTPHeaderDict))
+        """
+
+        _params = locals()
+
+        _all_params = [
+            'like'
+        ]
+        _all_params.extend(
+            [
+                'async_req',
+                '_return_http_data_only',
+                '_preload_content',
+                '_request_timeout',
+                '_request_auth',
+                '_content_type',
+                '_headers'
+            ]
+        )
+
+        # validate the arguments
+        for _key, _val in _params['kwargs'].items():
+            if _key not in _all_params:
+                raise _APITypeError(
+                    "Got an unexpected keyword argument '%s'"
+                    " to method list_warehouses" % _key
+                )
+            _params[_key] = _val
+        del _params['kwargs']
+
+        _collection_formats = {}
+
+        # process the path parameters
+        _path_params = {}
+
+        # process the query parameters
+        _query_params = []
+        if _params.get('like') is not None:  # noqa: E501
+            _query_params.append(('like', _params['like']))
+
+        # process the header parameters
+        _header_params = dict(_params.get('_headers', {}))
+
+        # process the form parameters
+        _form_params = []
+        _files = {}
+
+        # process the body parameter
+        _body_params = None
+
+        # set the HTTP header `Accept`
+        _header_params['Accept'] = self.api_client.select_header_accept(
+            ['application/json'])  # noqa: E501
+
+        # authentication setting
+        _auth_settings = []  # noqa: E501
+
+        _response_types_map = {
+            '200': "Iterable[Warehouse]",
+            '400': "ErrorResponse",
+            '401': "ErrorResponse",
+            '403': "ErrorResponse",
+            '404': "ErrorResponse",
+            '405': "ErrorResponse",
+            '409': "ErrorResponse",
+            '410': "ErrorResponse",
+            '429': "ErrorResponse",
+            '500': "ErrorResponse",
+            '503': "ErrorResponse",
+            '504': "ErrorResponse",
+        }
+
+        return self.api_client.call_api(
+            self._root,
+            '/api/v2/warehouses', 'GET',
+            _path_params,
+            _query_params,
+            _header_params,
+            body=_body_params,
+            post_params=_form_params,
+            files=_files,
+            response_types_map=_response_types_map,
+            auth_settings=_auth_settings,
+            async_req=_params.get('async_req'),
+            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _preload_content=_params.get('_preload_content', True),
+            _request_timeout=_params.get('_request_timeout'),
+            collection_formats=_collection_formats,
+            _request_auth=_params.get('_request_auth'))
+
+    @validate_arguments
+    def rename_warehouse(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], warehouse : Warehouse, if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+        """update and rename warehouse  # noqa: E501
+
+        Specifies a new identifier for the warehouse; must be unique for current account.  # noqa: E501
+        This method makes a synchronous HTTP request by default. To make an
+        asynchronous HTTP request, please pass async_req=True
+
+        >>> thread = api.rename_warehouse(name, warehouse, if_exists, async_req=True)
+        >>> result = thread.get()
+
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param timeout: Number of seconds to wait for the service to reach a steady state (for example, READY) before returning the status. If the service does not reach a steady state within the specified time, Snowflake returns the current state.
-        :type timeout: int
+        :param warehouse: (required)
+        :type warehouse: Warehouse
+        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: FetchServiceStatus200Response
+        :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.fetch_service_status_with_http_info(database, var_schema, name, timeout, **kwargs)  # noqa: E501
+        return self.rename_warehouse_with_http_info(name, warehouse, if_exists, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def fetch_service_status_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), timeout : Annotated[Optional[StrictInt], Field(description="Number of seconds to wait for the service to reach a steady state (for example, READY) before returning the status. If the service does not reach a steady state within the specified time, Snowflake returns the current state.")] = None, **kwargs):  # noqa: E501
-        """Fetch the status for a given service.  # noqa: E501
+    def rename_warehouse_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], warehouse : Warehouse, if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs):  # noqa: E501
+        """update and rename warehouse  # noqa: E501
 
-        Fetch the status for a service.  # noqa: E501
+        Specifies a new identifier for the warehouse; must be unique for current account.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_service_status_with_http_info(database, var_schema, name, timeout, async_req=True)
+        >>> thread = api.rename_warehouse_with_http_info(name, warehouse, if_exists, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
-        :type database: str
-        :param var_schema: (required)
-        :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param timeout: Number of seconds to wait for the service to reach a steady state (for example, READY) before returning the status. If the service does not reach a steady state within the specified time, Snowflake returns the current state.
-        :type timeout: int
+        :param warehouse: (required)
+        :type warehouse: Warehouse
+        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -847,24 +1138,23 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(FetchServiceStatus200Response, status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
-            'database',
-            'var_schema',
             'name',
-            'timeout'
+            'warehouse',
+            'if_exists'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -875,66 +1165,75 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method fetch_service_status" % _key
+                    " to method rename_warehouse" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
-        if _params['var_schema']:
-            _path_params['schema'] = _params['var_schema']
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
-        if _params.get('timeout') is not None:  # noqa: E501
-            _query_params.append(('timeout', _params['timeout']))
+        if _params.get('if_exists') is not None:  # noqa: E501
+            _query_params.append(('ifExists', _params['if_exists']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
+        if _params['warehouse']:
+            _body_params = _params['warehouse']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
+        # set the HTTP header `Content-Type`
+        _content_types_list = _params.get('_content_type',
+            self.api_client.select_header_content_type(
+                ['application/json']))
+        if _content_types_list:
+                _header_params['Content-Type'] = _content_types_list
+
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "FetchServiceStatus200Response",
+            '200': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '409': "ErrorResponse",
+            '410': "ErrorResponse",
+            '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/services/{name}/status', 'GET',
+            self._root,
+            '/api/v2/warehouses/{name}:rename', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -943,73 +1242,61 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def list_services(self, database : constr(strict=True), var_schema : constr(strict=True), like : Optional[StrictStr] = None, starts_with : Optional[StrictStr] = None, show_limit : Optional[StrictInt] = None, **kwargs) -> List[Service]:  # noqa: E501
-        """List services  # noqa: E501
+    def resume_warehouse(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+        """resume warehouse  # noqa: E501
 
-        Lists the services under the database and schema.  # noqa: E501
+        Bring current warehouse to a usable Running state by provisioning compute resources if current warehouse is suspended.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.list_services(database, var_schema, like, starts_with, show_limit, async_req=True)
+        >>> thread = api.resume_warehouse(name, if_exists, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
-        :type database: str
-        :param var_schema: (required)
-        :type var_schema: str
-        :param like:
-        :type like: str
-        :param starts_with:
-        :type starts_with: str
-        :param show_limit:
-        :type show_limit: int
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :type name: str
+        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: List[Service]
+        :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.list_services_with_http_info(database, var_schema, like, starts_with, show_limit, **kwargs)  # noqa: E501
+        return self.resume_warehouse_with_http_info(name, if_exists, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def list_services_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), like : Optional[StrictStr] = None, starts_with : Optional[StrictStr] = None, show_limit : Optional[StrictInt] = None, **kwargs):  # noqa: E501
-        """List services  # noqa: E501
+    def resume_warehouse_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs):  # noqa: E501
+        """resume warehouse  # noqa: E501
 
-        Lists the services under the database and schema.  # noqa: E501
+        Bring current warehouse to a usable Running state by provisioning compute resources if current warehouse is suspended.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.list_services_with_http_info(database, var_schema, like, starts_with, show_limit, async_req=True)
+        >>> thread = api.resume_warehouse_with_http_info(name, if_exists, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
-        :type database: str
-        :param var_schema: (required)
-        :type var_schema: str
-        :param like:
-        :type like: str
-        :param starts_with:
-        :type starts_with: str
-        :param show_limit:
-        :type show_limit: int
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :type name: str
+        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -1023,25 +1310,22 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(List[Service], status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
-            'database',
-            'var_schema',
-            'like',
-            'starts_with',
-            'show_limit'
+            'name',
+            'if_exists'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -1052,36 +1336,30 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method list_services" % _key
+                    " to method resume_warehouse" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
-        if _params['var_schema']:
-            _path_params['schema'] = _params['var_schema']
+        if _params['name']:
+            _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
-        if _params.get('like') is not None:  # noqa: E501
-            _query_params.append(('like', _params['like']))
-        if _params.get('starts_with') is not None:  # noqa: E501
-            _query_params.append(('startsWith', _params['starts_with']))
-        if _params.get('show_limit') is not None:  # noqa: E501
-            _query_params.append(('showLimit', _params['show_limit']))
+        if _params.get('if_exists') is not None:  # noqa: E501
+            _query_params.append(('ifExists', _params['if_exists']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -1093,27 +1371,31 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "List[Service]",
+            '200': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '409': "ErrorResponse",
+            '410': "ErrorResponse",
+            '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/services', 'GET',
+            self._root,
+            '/api/v2/warehouses/{name}:resume', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -1122,30 +1404,28 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def resume_service(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), **kwargs) -> SuccessResponse:  # noqa: E501
-        """Resume a service  # noqa: E501
+    def suspend_warehouse(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+        """suspend warehouse  # noqa: E501
 
-        Resume a service.  # noqa: E501
+        Remove all compute nodes from a warehouse and put the warehouse into a Suspended state if current warehouse is not suspended.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.resume_service(database, var_schema, name, async_req=True)
+        >>> thread = api.suspend_warehouse(name, if_exists, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
-        :type database: str
-        :param var_schema: (required)
-        :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
+        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
@@ -1154,33 +1434,31 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.resume_service_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
+        return self.suspend_warehouse_with_http_info(name, if_exists, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def resume_service_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), **kwargs):  # noqa: E501
-        """Resume a service  # noqa: E501
+    def suspend_warehouse_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs):  # noqa: E501
+        """suspend warehouse  # noqa: E501
 
-        Resume a service.  # noqa: E501
+        Remove all compute nodes from a warehouse and put the warehouse into a Suspended state if current warehouse is not suspended.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.resume_service_with_http_info(database, var_schema, name, async_req=True)
+        >>> thread = api.suspend_warehouse_with_http_info(name, if_exists, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
-        :type database: str
-        :param var_schema: (required)
-        :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
+        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -1200,17 +1478,16 @@
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
-            'database',
-            'var_schema',
-            'name'
+            'name',
+            'if_exists'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -1221,32 +1498,30 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method resume_service" % _key
+                    " to method suspend_warehouse" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
-        if _params['var_schema']:
-            _path_params['schema'] = _params['var_schema']
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
+        if _params.get('if_exists') is not None:  # noqa: E501
+            _query_params.append(('ifExists', _params['if_exists']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -1264,21 +1539,25 @@
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '409': "ErrorResponse",
+            '410': "ErrorResponse",
+            '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/services/{name}:resume', 'POST',
+            self._root,
+            '/api/v2/warehouses/{name}:suspend', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -1287,29 +1566,25 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def suspend_service(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), **kwargs) -> SuccessResponse:  # noqa: E501
-        """Suspend a service  # noqa: E501
+    def use_warehouse(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> SuccessResponse:  # noqa: E501
+        """use current warehouse for session  # noqa: E501
 
-        Suspend a service.  # noqa: E501
+        Specifies the active/current warehouse for the session.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.suspend_service(database, var_schema, name, async_req=True)
+        >>> thread = api.use_warehouse(name, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
-        :type database: str
-        :param var_schema: (required)
-        :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -1319,32 +1594,28 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.suspend_service_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
+        return self.use_warehouse_with_http_info(name, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def suspend_service_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), **kwargs):  # noqa: E501
-        """Suspend a service  # noqa: E501
+    def use_warehouse_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
+        """use current warehouse for session  # noqa: E501
 
-        Suspend a service.  # noqa: E501
+        Specifies the active/current warehouse for the session.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.suspend_service_with_http_info(database, var_schema, name, async_req=True)
+        >>> thread = api.use_warehouse_with_http_info(name, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
-        :type database: str
-        :param var_schema: (required)
-        :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -1365,16 +1636,14 @@
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
-            'database',
-            'var_schema',
             'name'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
@@ -1386,27 +1655,23 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method suspend_service" % _key
+                    " to method use_warehouse" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
-        if _params['var_schema']:
-            _path_params['schema'] = _params['var_schema']
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
@@ -1429,21 +1694,25 @@
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '409': "ErrorResponse",
+            '410': "ErrorResponse",
+            '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/services/{name}:suspend', 'POST',
+            self._root,
+            '/api/v2/warehouses/{name}:use', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/service/_generated/models/__init__.py` & `snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -5,32 +5,36 @@
     Snowflake Services API
 
     The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 # import models into model package
 from snowflake.core.service._generated.models.error_response import ErrorResponse
 from snowflake.core.service._generated.models.fetch_service_logs200_response import FetchServiceLogs200Response
 from snowflake.core.service._generated.models.fetch_service_status200_response import FetchServiceStatus200Response
 from snowflake.core.service._generated.models.service import Service
+from snowflake.core.service._generated.models.service_endpoint import ServiceEndpoint
 from snowflake.core.service._generated.models.service_spec import ServiceSpec
 from snowflake.core.service._generated.models.service_spec_inline_text import ServiceSpecInlineText
 from snowflake.core.service._generated.models.service_spec_stage_file import ServiceSpecStageFile
 from snowflake.core.service._generated.models.success_response import SuccessResponse
 
 __all__ = [
     'ErrorResponse',
     'FetchServiceLogs200Response',
     'FetchServiceStatus200Response',
     'Service',
+    'ServiceEndpoint',
     'ServiceSpec',
     'ServiceSpecInlineText',
     'ServiceSpecStageFile',
     'SuccessResponse',
 ]
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/service/_generated/models/error_response.py` & `snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/error_response.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,35 +1,38 @@
 # coding: utf-8
 
 """
-    Snowflake Services API
+    Snowflake Task API
 
-    The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
+    The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictStr
+from snowflake.core.task._generated.pydantic_compatibility import BaseModel, StrictStr
 
 class ErrorResponse(BaseModel):
-    message: Optional[StrictStr] = Field(None, description="Error message returned by server")
-    error_code: Optional[StrictStr] = Field(None, description="Error code")
-    request_id: Optional[StrictStr] = Field(None, description="Unique request id")
-    __properties = ["message", "error_code", "request_id"]
+    message: Optional[StrictStr] = None
+    code: Optional[StrictStr] = None
+    error_code: Optional[StrictStr] = None
+    request_id: Optional[StrictStr] = None
+    __properties = ["message", "code", "error_code", "request_id"]
 
 
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
@@ -61,14 +64,16 @@
 
         if type(obj) is not dict:
             return ErrorResponse.parse_obj(obj)
 
         _obj = ErrorResponse.parse_obj({
             "message": obj.get("message"),
 
+            "code": obj.get("code"),
+
             "error_code": obj.get("error_code"),
 
             "request_id": obj.get("request_id"),
 
         })
         return _obj
 
@@ -76,37 +81,43 @@
 from typing import Optional, List, Dict
 
 class ErrorResponseModel():
     def __init__(
         self,
         # optional properties
         message: Optional[str] = None,
+        code: Optional[str] = None,
         error_code: Optional[str] = None,
         request_id: Optional[str] = None,
     ):
         self.message = message
+        self.code = code
         self.error_code = error_code
         self.request_id = request_id
-    __properties = ["message", "error_code", "request_id"]
+    __properties = ["message", "code", "error_code", "request_id"]
 
     def _to_model(self):
         return ErrorResponse(
             message=self.message,
 
+            code=self.code,
+
             error_code=self.error_code,
 
             request_id=self.request_id,
 
         )
 
     @classmethod
     def _from_model(cls, model) -> ErrorResponseModel:
         return ErrorResponseModel(
             message=model.message,
 
+            code=model.code,
+
             error_code=model.error_code,
 
             request_id=model.request_id,
 
         )
 
     def to_dict(self):
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/service/_generated/models/fetch_service_logs200_response.py` & `snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/fetch_service_logs200_response.py`

 * *Files 6% similar despite different names*

```diff
@@ -4,26 +4,28 @@
     Snowflake Services API
 
     The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictStr
+from snowflake.core.service._generated.pydantic_compatibility import BaseModel, Field, StrictStr
 
 class FetchServiceLogs200Response(BaseModel):
     systemget_service_logs: Optional[StrictStr] = Field(None, alias="system$get_service_logs")
     __properties = ["system$get_service_logs"]
 
 
     class Config:
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/service/_generated/models/fetch_service_status200_response.py` & `snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/fetch_service_status200_response.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,26 +4,28 @@
     Snowflake Services API
 
     The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictStr
+from snowflake.core.service._generated.pydantic_compatibility import BaseModel, Field, StrictStr
 
 class FetchServiceStatus200Response(BaseModel):
     systemget_service_status: Optional[StrictStr] = Field(None, alias="system$get_service_status")
     __properties = ["system$get_service_status"]
 
 
     class Config:
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/service/_generated/models/service.py` & `snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/service.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,26 +4,28 @@
     Snowflake Services API
 
     The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 from datetime import datetime
 from typing import List, Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, conlist, constr, validator
+from snowflake.core.service._generated.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, conlist, constr, validator
 from snowflake.core.service._generated.models.service_spec import ServiceSpec
 
 class Service(BaseModel):
     name: constr(strict=True) = Field(...)
     compute_pool: StrictStr = Field(...)
     spec: ServiceSpec = Field(...)
     external_access_integrations: Optional[conlist(StrictStr)] = None
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/service/_generated/models/service_spec.py` & `snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/service_spec.py`

 * *Files 5% similar despite different names*

```diff
@@ -4,28 +4,30 @@
     Snowflake Services API
 
     The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 import snowflake.core.service._generated.models
 from snowflake.core.service._generated.models import *
 
 
 from typing import Optional, Union
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, StrictStr
+from snowflake.core.service._generated.pydantic_compatibility import BaseModel, StrictStr
 
 class ServiceSpec(BaseModel):
     spec_type: Optional[StrictStr] = None
     __properties = ["spec_type"]
 
 
     class Config:
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/service/_generated/models/service_spec_inline_text.py` & `snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/service_spec_inline_text.py`

 * *Files 5% similar despite different names*

```diff
@@ -4,26 +4,28 @@
     Snowflake Services API
 
     The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import Field, StrictStr
+from snowflake.core.service._generated.pydantic_compatibility import Field, StrictStr
 from snowflake.core.service._generated.models.service_spec import ServiceSpec
 
 class ServiceSpecInlineText(ServiceSpec):
     spec_text: StrictStr = Field(...)
     __properties = ["spec_type"]
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/service/_generated/models/service_spec_stage_file.py` & `snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/service_spec_stage_file.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,26 +4,28 @@
     Snowflake Services API
 
     The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import Field, StrictStr
+from snowflake.core.service._generated.pydantic_compatibility import Field, StrictStr
 from snowflake.core.service._generated.models.service_spec import ServiceSpec
 
 class ServiceSpecStageFile(ServiceSpec):
     stage: StrictStr = Field(...)
     spec_file: StrictStr = Field(...)
     __properties = ["spec_type"]
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/service/_generated/models/success_response.py` & `snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/success_response.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,32 +1,34 @@
 # coding: utf-8
 
 """
-    Snowflake Services API
+    Snowflake Task API
 
-    The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
+    The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictStr
+from snowflake.core.task._generated.pydantic_compatibility import BaseModel, StrictStr
 
 class SuccessResponse(BaseModel):
-    status: Optional[StrictStr] = Field(None, description="Message returned by server")
+    status: Optional[StrictStr] = None
     __properties = ["status"]
 
 
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/table/_table.py` & `snowflake_core-0.8.0/src/snowflake/core/table/_table.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,17 +1,24 @@
-from typing import TYPE_CHECKING, Optional, Union
+from typing import TYPE_CHECKING, Iterator, Optional, Union
 
-from snowflake.core._common import CreateMode, SchemaObjectCollectionParent, SchemaObjectReferenceMixin
-from snowflake.core._internal.pydantic_compatibility import StrictStr
+from snowflake.core._common import (
+    Clone,
+    CreateMode,
+    PointOfTime,
+    SchemaObjectCollectionParent,
+    SchemaObjectReferenceMixin,
+)
+from snowflake.core.table._generated.pydantic_compatibility import StrictStr
 
 from .._internal.telemetry import api_telemetry
-from ..paging import PagedIter
 from ._generated.api import TableApi
-from ._generated.api_client import BridgeApiClient
-from ._generated.models import Table
+from ._generated.api_client import BridgeApiClient, StoredProcApiClient
+from ._generated.models.point_of_time import PointOfTime as TablePointOfTime
+from ._generated.models.table import Table
+from ._generated.models.table_clone import TableClone
 
 
 if TYPE_CHECKING:
     from snowflake.core.schema import SchemaResource
 
 
 class TableCollection(SchemaObjectCollectionParent["TableResource"]):
@@ -19,25 +26,26 @@
         super().__init__(schema, TableResource)
         self._api = TableApi(
             root=self.root,
             resource_class=self._ref_class,
             bridge_client=BridgeApiClient(
                 root=self.root,
                 snowflake_connection=self._connection or self._session._conn._conn,
-            )
+            ),
+            sproc_client=StoredProcApiClient(root=self.root)
         )
 
     @api_telemetry
     def create(
         self, table: Union[Table, str],
         *,
         as_select: Optional[str] = None,
         template: Optional[str] = None,
         like_table: Optional[str] = None,
-        clone_table: Optional[str] = None,
+        clone_table: Optional[Union[str, Clone]] = None,
         copy_grants: Optional[bool] = False,
         mode: CreateMode=CreateMode.error_if_exists,
     ) -> "TableResource":
         """Create a table.
 
         Args:
             table: The table object, together with the table's properties, object parameters, columns, and constraints.
@@ -64,65 +72,126 @@
         Not currently implemented:
             - Row access policy
             - Column masking policy
             - Search optimization
             - Tags
             - Stage file format and copy options
         """
+        self.validate_table_inputs(table, as_select, template, like_table, clone_table)
+
         if isinstance(table, str):
-            if not as_select and not template and not clone_table and not like_table:
-                raise ValueError(
-                    "When `table` is a str, any one of the `as_select`, `template`, `clone_table`, "
-                    "or `like_table` must not be empty."
-                )
             table = Table(name=table)
+
         real_mode = CreateMode[mode].value
-        self._api.create_table(
-            self.database.name, self.schema.name, table, create_mode=StrictStr(real_mode),
-            as_select=as_select, template_query=template, like_table=like_table, clone_table=clone_table,
-            copy_grants=copy_grants,
-            async_req=False
-        )
+
+        if as_select:
+            # create table by select
+            self._api.create_table_as_select(
+                self.database.name, self.schema.name, table.name,
+                as_select, table, create_mode=StrictStr(real_mode),
+                copy_grants=copy_grants,
+                async_req=False
+            )
+        elif template:
+            # create table by template
+            self._api.create_table_using_template(
+                self.database.name, self.schema.name, table.name,
+                template, create_mode=StrictStr(real_mode),
+                copy_grants=copy_grants,
+                async_req=False
+            )
+        elif clone_table:
+            # create table by clone
+            pot: Optional[TablePointOfTime] = None
+            if isinstance(clone_table, Clone) and isinstance(clone_table.point_of_time, PointOfTime):
+                pot = TablePointOfTime.from_dict(clone_table.point_of_time.to_dict())
+            real_clone = Clone(source=clone_table) if isinstance(clone_table, str) else clone_table
+            req = TableClone(
+                point_of_time = pot,
+                **table.to_dict(),
+            )
+            self._api.clone_table(
+                self.database.name, self.schema.name, real_clone.source,
+                req, create_mode=StrictStr(real_mode),
+                copy_grants=copy_grants,
+                async_req=False
+            )
+        elif like_table:
+            # create table by like
+            self._api.create_table_like(
+                self.database.name, self.schema.name, like_table,
+                table.name, create_mode=StrictStr(real_mode),
+                copy_grants=copy_grants,
+                async_req=False
+            )
+        else:
+            # create empty table
+            self._api.create_table(
+                self.database.name, self.schema.name, table, create_mode=StrictStr(real_mode),
+                copy_grants=copy_grants,
+                async_req=False
+            )
         return TableResource(table.name, self)
 
     @api_telemetry
     def iter(
         self,
         *,
         like: Optional[str] = None,
         starts_with: Optional[str] = None,
         limit: Optional[int] = None,
         from_name: Optional[str] = None,
         history: bool = False,
         deep: bool = False,
-    ) -> PagedIter[Table]:
+    ) -> Iterator[Table]:
         """Search ``Table`` objects from Snowflake.
 
         Args:
             like: The pattern of the Table name. Use ``%`` to represent any number of characters and ``?`` for a
                 single character.
             startswith: The table name starts with this string.
             limit: limits the number of objects returned.
             from_name: enables fetching the specified number of rows following the first row whose object name matches
                 the specified string.
             deep: fetch the sub-resources columns and constraints of every table if it's ``True``. Default ``False``.
             history: includes dropped tables that have not yet been purged.
         """
-        return PagedIter(
-            self._api.list_tables(
-                database=self.database.name, var_schema=self.schema.name, like=like,
+        tables = self._api.list_tables( database=self.database.name, var_schema=self.schema.name, like=like,
                 starts_with=starts_with, show_limit=limit, from_name=from_name, history=history, deep=deep,
-                async_req=False
+                async_req=False)
+
+        return iter(tables)
+
+    def validate_table_inputs(
+        self, table: Union[Table, str],
+        as_select: Optional[str] = None,
+        template: Optional[str] = None,
+        like_table: Optional[str] = None,
+        clone_table: Optional[Union[str, Clone]] = None
+    ) -> None:
+        not_none_count =\
+            sum(bool(x) for x in (as_select, template, like_table, clone_table))
+
+        if not_none_count > 1:
+            raise ValueError(
+                "at most one of the `as_select`, `template`, `clone_table`, "
+                "or `like_table` can has value"
             )
-        )
 
+        if not_none_count == 0 and isinstance(table, str):
+            raise ValueError(
+                "When `table` is a str, any one of the `as_select`, `template`, `clone_table`, "
+                "or `like_table` must not be empty."
+            )
 
 class TableResource(SchemaObjectReferenceMixin[TableCollection]):
     """Represents a reference to a Snowflake Table resource."""
 
+    _supports_rest_api = True
+
     def __init__(self, name: str, collection: TableCollection) -> None:
         self.collection = collection
         self.name = name
 
     @api_telemetry
     def create_or_update(
         self, table: Table,
@@ -141,31 +210,25 @@
                 - Stage file format and copy options
                 - Foreign keys.
                 - Rename the table.
                 - If the name and table's name don't match, an error will be thrown.
                 - Rename or drop a column.
             - New columns can only be added to the back of the column list.
         """
-        self.collection._api.create_or_update_table(self.database.name, self.schema.name, self.name, table)
+        self.collection._api.create_or_alter_table(self.database.name, self.schema.name, self.name, table)
 
-    def fetch(self, *, deep: bool = False) -> Table:
+    def fetch(self) -> Table:
         """Fetch the details of a table.
 
-        Args:
-            deep: Columns and constraints the Table are not fetched when ``deep`` is False.
-              Use ``deep=True`` if you want to fetch a Table object and use create_or_update to update the table later.
-              If you use ``deep=False``, then create_or_update() later will raise an exception.
-              Default ``False``.
-
         Notes:
             Inline constraints will become Outofline constraints because Snowflake database doesn't tell whether a
             constraint is inline or out of line from Snowflake database.
         """
         return self.collection._api.fetch_table(
-            self.database.name, self.schema.name, self.name, deep=deep, async_req=False,
+            self.database.name, self.schema.name, self.name, async_req=False,
         )
 
     @api_telemetry
     def delete(self) -> None:
         """Delete the table."""
         self.collection._api.delete_table(self.database.name, self.schema.name, self.name, async_req=False)
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/table/_generated/__init__.py` & `snowflake_core-0.8.0/src/snowflake/core/table/_generated/__init__.py`

 * *Files 11% similar despite different names*

```diff
@@ -6,14 +6,16 @@
     Snowflake Table API
 
     The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 __version__ = "1.0.0"
 
@@ -23,12 +25,17 @@
 # import ApiClient
 from snowflake.core.table._generated.api_client import ApiClient
 from snowflake.core.table._generated.configuration import Configuration
 # import models into sdk package
 from snowflake.core.table._generated.models.constraint import Constraint
 from snowflake.core.table._generated.models.error_response import ErrorResponse
 from snowflake.core.table._generated.models.foreign_key import ForeignKey
+from snowflake.core.table._generated.models.point_of_time import PointOfTime
+from snowflake.core.table._generated.models.point_of_time_offset import PointOfTimeOffset
+from snowflake.core.table._generated.models.point_of_time_statement import PointOfTimeStatement
+from snowflake.core.table._generated.models.point_of_time_timestamp import PointOfTimeTimestamp
 from snowflake.core.table._generated.models.primary_key import PrimaryKey
 from snowflake.core.table._generated.models.success_response import SuccessResponse
 from snowflake.core.table._generated.models.table import Table
+from snowflake.core.table._generated.models.table_clone import TableClone
 from snowflake.core.table._generated.models.table_column import TableColumn
 from snowflake.core.table._generated.models.unique_key import UniqueKey
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/table/_generated/api_client.py` & `snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/api_client.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,37 +1,44 @@
 # coding: utf-8
 """
-    Snowflake Table API
+    Snowflake Compute Pools API
 
-    The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
+    The Snowflake Compute Pools API is a REST API that you can use to access, update, and perform certain actions on Compute Pool resources.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 from __future__ import absolute_import
 
 import atexit
 import datetime
+import time
 import typing
 from dateutil.parser import parse
 import json
 import mimetypes
 from multiprocessing.pool import ThreadPool
 import os
 import re
 import tempfile
 
 from urllib.parse import quote
 
-from snowflake.core.table._generated.configuration import Configuration
-import snowflake.core.table._generated.models
-from snowflake.core.table._generated import rest
-from snowflake.core.exceptions import _APIValueError, APIError
+from functools import partial
+
+from snowflake.core.compute_pool._generated.configuration import Configuration
+import snowflake.core.compute_pool._generated.models
+from snowflake.core.compute_pool._generated import rest
+from snowflake.core.compute_pool._generated.paging import PagedIter
+from snowflake.core.exceptions import _APIValueError, APIError, InvalidResponseError, LongRunningQueryTimeout
+from snowflake.core.version import __version__ as VERSION
 
 if typing.TYPE_CHECKING:
     from snowflake.core._root import Root
 
 
 class ApiClient(object):
     """Generic API client for OpenAPI client library builds.
@@ -62,41 +69,48 @@
         'float': float,
         'str': str,
         'bool': bool,
         'date': datetime.date,
         'datetime': datetime.datetime,
         'object': object,
     }
+    DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING = 600.0 # default 10 minutes for long running queries
     _pool = None
 
     def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
                  cookie=None, pool_threads=1):
         # use default configuraiton if none is provided
         if configuration is None:
             configuration = Configuration.get_default()
         self.configuration = configuration
         if (
             hasattr(root, "_connection")
+            and root._connection is not None
             and hasattr(root._connection, "_rest")
+            and root._connection._rest is not None
+            and hasattr(root._connection._rest, "_protocol")
+            and hasattr(root._connection._rest, "_host")
+            and hasattr(root._connection._rest, "_port")
         ):
             self.configuration.host = (
                 f"{root._connection._rest._protocol}://"
                 + root._connection._rest._host
                 + f":{root._connection._rest._port}"
             )
         self.pool_threads = pool_threads
 
         self.rest_client = rest.RESTClientObject(root, configuration)
         self.default_headers = {}
         if header_name is not None:
             self.default_headers[header_name] = header_value
         self.cookie = cookie
         # Set default User-Agent.
-        self.user_agent = 'OpenAPI-Generator/1.0.0/python'
+        self.user_agent = 'python_api/' + VERSION + ''
         self.client_side_validation = configuration.client_side_validation
+        self._enable_long_running_polling = getattr(root, "_enable_long_running_polling", False)
 
     def __enter__(self):
         return self
 
     def __exit__(self, exc_type, exc_value, traceback):
         self.close()
 
@@ -154,15 +168,15 @@
         It stores default ApiClient.
 
         :param default: object of ApiClient.
         """
         cls._default = default
 
     def __call_api(
-            self, resource_path, method, path_params=None,
+            self, root, resource_path, method, path_params=None,
             query_params=None, header_params=None, body=None, post_params=None,
             files=None, response_types_map=None, auth_settings=None,
             _return_http_data_only=None, collection_formats=None,
             _preload_content=True, _request_timeout=None, _host=None,
             _request_auth=None):
 
         config = self.configuration
@@ -218,22 +232,25 @@
         if query_params:
             query_params = self.sanitize_for_serialization(query_params)
             url_query = self.parameters_to_url_query(query_params,
                                                      collection_formats)
             url += "?" + url_query
 
         try:
-            # perform request and return response
-            response_data = self.request(
-                method, url,
+            # perform request and return response, maybe with retry
+            response_data = self.request_with_retry(
+                root,
+                method,
+                url,
                 query_params=query_params,
                 headers=header_params,
                 post_params=post_params, body=body,
                 _preload_content=_preload_content,
-                _request_timeout=_request_timeout)
+                _request_timeout=_request_timeout
+            )
         except APIError as e:
             if e.body:
                 e.body = e.body.decode('utf-8')
             raise e
 
         self.last_response = response_data
 
@@ -251,15 +268,52 @@
         #         match = re.search(r"charset=([a-zA-Z\-\d]+)[\s;]?", content_type)
         #     encoding = match.group(1) if match else "utf-8"
         #     response_data.data = response_data.data.decode(encoding)
 
         # deserialize response data
 
         if response_type:
-            return_data = self.deserialize(response_data, response_type)
+            large_results_resp = self.large_results(response_data)
+            if large_results_resp is None:
+                # regular, non-large results use case
+                return_data = self.deserialize(response_data, response_type)
+            else:
+                # This should be the normal way in which we figure out where to get the results from,
+                # as well as how many chunks there are to get. Due to a bug, we use the alternate logic
+                # (in the "else" clause) to infer the URL from the UUID
+                if "Link" in response_data.getheaders():
+                    results_path, num_chunks = self.get_path_and_chunk_count_from_header(response_data.getheaders()["Link"])
+                else:
+                    handler_id = large_results_resp['result_handler']
+                    results_path = '/api/v2/results/' + handler_id
+
+                    # If there is no "Link" header, there is just one chunk
+                    num_chunks = 1
+
+                # Closure for fetching the next chunk in the PagedIter iterator
+                def _fetch_next_chunk(chunk_index, deserialize_type):
+                    # For now, do this because query_params is not actually being used properly in self.request
+                    chunk_url = f'{self.configuration.host}{results_path}?page={chunk_index}'
+
+                    chunk_response_data = self.request(
+                        root,
+                        "GET",
+                        chunk_url,
+                        headers=header_params,
+                        _preload_content=True,
+                        _request_timeout=_request_timeout)
+
+                    return self.deserialize(chunk_response_data, deserialize_type)
+
+                if 'Iterable' in response_type:
+                    return PagedIter(partial(_fetch_next_chunk, deserialize_type=response_type), num_chunks)
+                else:
+                    # At most, we should only need to fetch one chunk if it's a point lookup,
+                    # i.e., one row return
+                    return_data = _fetch_next_chunk(0, response_type)
         else:
             return_data = None
 
         if _return_http_data_only:
             return (return_data)
         else:
             return (return_data, response_data.status,
@@ -335,42 +389,42 @@
 
         :return: object.
         """
         if data is None:
             return None
 
         if type(klass) == str:
-            if klass.startswith('List['):
-                sub_kls = re.match(r'List\[(.*)]', klass).group(1)
+            if klass.startswith('Iterable['):
+                sub_kls = re.match(r'Iterable\[(.*)]', klass).group(1)
                 return [self.__deserialize(sub_data, sub_kls)
                         for sub_data in data]
 
             if klass.startswith('Dict['):
                 sub_kls = re.match(r'Dict\[([^,]*), (.*)]', klass).group(2)
                 return {k: self.__deserialize(v, sub_kls)
                         for k, v in data.items()}
 
             # convert str to class
             if klass in self.NATIVE_TYPES_MAPPING:
                 klass = self.NATIVE_TYPES_MAPPING[klass]
             else:
-                klass = getattr(snowflake.core.table._generated.models, klass)
+                klass = getattr(snowflake.core.compute_pool._generated.models, klass)
 
         if klass in self.PRIMITIVE_TYPES:
             return self.__deserialize_primitive(data, klass)
         elif klass == object:
             return self.__deserialize_object(data)
         elif klass == datetime.date:
             return self.__deserialize_date(data)
         elif klass == datetime.datetime:
             return self.__deserialize_datetime(data)
         else:
             return self.__deserialize_model(data, klass)
 
-    def call_api(self, resource_path, method,
+    def call_api(self, root, resource_path, method,
                  path_params=None, query_params=None, header_params=None,
                  body=None, post_params=None, files=None,
                  response_types_map=None, auth_settings=None,
                  async_req=None, _return_http_data_only=None,
                  collection_formats=None,_preload_content=True,
                   _request_timeout=None, _host=None, _request_auth=None):
         """Makes the HTTP request (synchronous) and returns deserialized data.
@@ -410,88 +464,198 @@
             If async_req parameter is True,
             the request will be called asynchronously.
             The method will return the request thread.
             If parameter async_req is False or missing,
             then the method will return the response directly.
         """
         if not async_req:
-            return self.__call_api(resource_path, method,
-                                   path_params, query_params, header_params,
-                                   body, post_params, files,
-                                   response_types_map, auth_settings,
-                                   _return_http_data_only, collection_formats,
-                                   _preload_content, _request_timeout, _host,
-                                   _request_auth)
-
-        return self.pool.apply_async(self.__call_api, (resource_path,
-                                                       method, path_params,
-                                                       query_params,
-                                                       header_params, body,
-                                                       post_params, files,
-                                                       response_types_map,
-                                                       auth_settings,
-                                                       _return_http_data_only,
-                                                       collection_formats,
-                                                       _preload_content,
-                                                       _request_timeout,
-                                                       _host, _request_auth))
+            return self.__call_api(
+                root,
+                resource_path,
+                method,
+                path_params,
+                query_params,
+                header_params,
+                body,
+                post_params,
+                files,
+                response_types_map,
+                auth_settings,
+                _return_http_data_only,
+                collection_formats,
+                _preload_content,
+                _request_timeout,
+                _host,
+                _request_auth,
+            )
+
+        return self.pool.apply_async(
+            self.__call_api,
+            (
+                root,
+                resource_path,
+                method,
+                path_params,
+                query_params,
+                header_params,
+                body,
+                post_params,
+                files,
+                response_types_map,
+                auth_settings,
+                _return_http_data_only,
+                collection_formats,
+                _preload_content,
+                _request_timeout,
+                _host,
+                _request_auth,
+            )
+        )
 
-    def request(self, method, url, query_params=None, headers=None,
+
+    def request_with_retry(
+                self, root, method, url, query_params=None, headers=None,
+                post_params=None, body=None, _preload_content=True,
+                _request_timeout=None):
+        """
+            Response time by default one hour
+        """
+        enter_timing = time.time()
+        response_data = self.request(
+                root,
+                method,
+                url,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params, body=body,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout)
+
+        if response_data.status != 202 or not self._enable_long_running_polling:
+            return response_data
+
+        result_endpoint = response_data.getheader('Location')
+        if result_endpoint is None:
+            raise InvalidResponseError("Long Running Queries result endpoint is missing")
+
+        if _request_timeout is None:
+            _request_timeout = self.DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING
+        wait_for_results_timeout = enter_timing + _request_timeout
+
+        exponential_wait_time = 1 # wait time increases exponentially, 30% more everytime
+        while True:
+            time_remaining = wait_for_results_timeout - time.time()
+            if time_remaining <= 0:
+                break
+            wait_time = min(exponential_wait_time, time_remaining)
+            time.sleep(wait_time)
+            response_data = self.request(
+                root,
+                'GET',
+                self.configuration.host + result_endpoint,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params, body=body,
+                _preload_content=_preload_content,
+                _request_timeout=max(time_remaining - wait_time, 1)
+                # request_timeout can never be zero
+            )
+
+            if response_data.status != 202:
+                return response_data
+
+            exponential_wait_time *= 1.3
+
+        raise LongRunningQueryTimeout("Long running queries timeout")
+
+
+    def request(self, root, method, url, query_params=None, headers=None,
                 post_params=None, body=None, _preload_content=True,
                 _request_timeout=None):
         """Makes the HTTP request using RESTClient."""
         if method == "GET":
-            return self.rest_client.get_request(url,
-                                        query_params=query_params,
-                                        _preload_content=_preload_content,
-                                        _request_timeout=_request_timeout,
-                                        headers=headers)
+            return self.rest_client.get_request(
+                root,
+                url,
+                query_params=query_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                headers=headers,
+            )
         elif method == "HEAD":
-            return self.rest_client.head_request(url,
-                                         query_params=query_params,
-                                         _preload_content=_preload_content,
-                                         _request_timeout=_request_timeout,
-                                         headers=headers)
+            return self.rest_client.head_request(
+                root,
+                url,
+                query_params=query_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                headers=headers,
+            )
         elif method == "OPTIONS":
-            return self.rest_client.options_request(url,
-                                            query_params=query_params,
-                                            headers=headers,
-                                            _preload_content=_preload_content,
-                                            _request_timeout=_request_timeout)
+            return self.rest_client.options_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+            )
         elif method == "POST":
-            return self.rest_client.post_request(url,
-                                         query_params=query_params,
-                                         headers=headers,
-                                         post_params=post_params,
-                                         _preload_content=_preload_content,
-                                         _request_timeout=_request_timeout,
-                                         body=body)
+            return self.rest_client.post_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                body=body,
+            )
         elif method == "PUT":
-            return self.rest_client.put_request(url,
-                                        query_params=query_params,
-                                        headers=headers,
-                                        post_params=post_params,
-                                        _preload_content=_preload_content,
-                                        _request_timeout=_request_timeout,
-                                        body=body)
+            try:
+                return self.rest_client.put_request(
+                    root,
+                    url,
+                    query_params=query_params,
+                    headers=headers,
+                    post_params=post_params,
+                    _preload_content=_preload_content,
+                    _request_timeout=_request_timeout,
+                    body=body,
+                )
+            except APIError as error:
+                # Raise a more helpful user error if CoA is not supported for this resource;
+                # this is represented as either 405 or 501 on the server.
+                if error.status in (405, 501):
+                    raise NotImplementedError(
+                        'create_or_update is not yet supported for compute_pool. Updating compute_pool '
+                        'objects is not supported yet; use create() for creating a compute_pool.')
+                raise
+
         elif method == "PATCH":
-            return self.rest_client.patch_request(url,
-                                          query_params=query_params,
-                                          headers=headers,
-                                          post_params=post_params,
-                                          _preload_content=_preload_content,
-                                          _request_timeout=_request_timeout,
-                                          body=body)
+            return self.rest_client.patch_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                body=body,
+            )
         elif method == "DELETE":
-            return self.rest_client.delete_request(url,
-                                           query_params=query_params,
-                                           headers=headers,
-                                           _preload_content=_preload_content,
-                                           _request_timeout=_request_timeout,
-                                           body=body)
+            return self.rest_client.delete_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                body=body,
+            )
         else:
             raise _APIValueError(
                 "http method must be `GET`, `HEAD`, `OPTIONS`,"
                 " `POST`, `PATCH`, `PUT` or `DELETE`."
             )
 
     def parameters_to_tuples(self, params, collection_formats):
@@ -759,13 +923,73 @@
         :param data: dict, list.
         :param klass: class literal.
         :return: model object.
         """
 
         return klass.from_dict(data)
 
+    @staticmethod
+    def large_results(response):
+        try:
+            result = json.loads(response.data)
+            if ("result_handler" in result
+                    and "message" in result and
+                    'Large result set. Use provided Link' in result['message']):
+                return result
+            else:
+                return None
+        except ValueError:
+            pass
+
+        return None
+
+
+    @staticmethod
+    def get_path_and_chunk_count_from_header(links_str):
+        links_list = links_str.split(",")
+
+        def parse_links(s):
+            import re
+            # Use regex to extract necessary parts
+            #
+            # Explanation:
+            # The result links are provided to us in the form:
+            # '</api/v2/results/01b39664-0100-0001-0000-0000000430391?page=0>; rel="first"'
+            #
+            # We wish to find how many chunks there are by finding the one that has rel="last",
+            # therefore we find page index corresponding to the link with that rel value.
+            #
+            # 1. <(.*?)> matches and captures the URL inside the angle brackets
+            # 2. page=(\d+) matches 'page=' followed by one or more digits to find the page number
+            # 3. rel="([^"]*)" matches 'rel="'
+            pattern = r'<(.*?)\?page=(\d+)>; rel="([^"]*)"'
+
+            # Search using the regular expression
+            match = re.search(pattern, s)
+            if match:
+                parse_result = dict()
+                parse_result['url'], parse_result['page_number'], parse_result['rel_value'] = match.groups()
+                return parse_result
+
+            return None
+
+        parsed_links = [parse_links(link) for link in links_list]
+
+        # Find the last one
+        last_link = list(filter(lambda link: link['rel_value'].lower() == 'last', parsed_links)).pop()
+
+        # Return the URL; the number of chunks is the chunk index of the last page plus one
+        return last_link['url'], int(last_link['page_number']) + 1
+
 
 class BridgeApiClient(ApiClient):
     def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
                  cookie=None, pool_threads=1, snowflake_connection=None):
         ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
         self.rest_client = rest.BridgeClientObject(snowflake_connection)
+
+
+class StoredProcApiClient(ApiClient):
+    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
+                 cookie=None, pool_threads=1):
+        ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
+        self.rest_client = rest.StoredProcClientObject()
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/table/_generated/api_response.py` & `snowflake_core-0.8.0/src/snowflake/core/service/_generated/api_response.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 """API response object."""
 
 from __future__ import annotations
 from typing import Any, Dict, Optional
-from snowflake.core._internal.pydantic_compatibility import Field, StrictInt, StrictStr
+from snowflake.core.service._generated.pydantic_compatibility import Field, StrictInt, StrictStr
 
 class ApiResponse:
     """
     API response object
     """
 
     status_code: Optional[StrictInt] = Field(None, description="HTTP status code")
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/table/_generated/configuration.py` & `snowflake_core-0.8.0/src/snowflake/core/table/_generated/configuration.py`

 * *Files 0% similar despite different names*

```diff
@@ -4,14 +4,16 @@
     Snowflake Table API
 
     The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 import copy
 import logging
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/table/_generated/rest.py` & `snowflake_core-0.8.0/src/snowflake/core/database/_generated/rest.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,17 +1,19 @@
 # coding: utf-8
 
 """
-    Snowflake Table API
+    Snowflake Database API
 
-    The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
+    The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 import json
 import logging
@@ -49,17 +51,26 @@
     def __init__(self, root: "Root", *args, **kwargs):
         self.root = root
         self.pool_manager = create_connection_pool(
             *args,
             **kwargs,
         )
 
-    def request(self, method, url, query_params=None, headers=None,
-                body=None, post_params=None, _preload_content=True,
-                _request_timeout=None):
+    def request(
+        self,
+        root,
+        method,
+        url,
+        query_params=None,
+        headers=None,
+        body=None,
+        post_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
         """Perform requests.
 
         :param method: http request method
         :param url: http request url
         :param query_params: query parameters in the url
         :param headers: http request headers
         :param body: request json body, for `application/json`
@@ -104,64 +115,64 @@
 
                 # no content type provided or payload is json
                 if not headers.get('Content-Type') or re.search('json', headers['Content-Type'], re.IGNORECASE):
                     request_body = None
                     if body is not None:
                         request_body = json.dumps(body)
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 elif headers['Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         fields=post_params,
                         encode_multipart=False,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 elif headers['Content-Type'] == 'multipart/form-data':
                     # must del headers['Content-Type'], or the correct
                     # Content-Type which generated by urllib3 will be
                     # overwritten.
                     del headers['Content-Type']
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         fields=post_params,
                         encode_multipart=True,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 # Pass a `string` parameter directly in the body to support
                 # other content types than Json when `body` argument is
                 # provided in serialized form
                 elif isinstance(body, str) or isinstance(body, bytes):
                     request_body = body
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 else:
                     # Cannot generate the request from given parameters
                     msg = """Cannot prepare a request message for provided
                              arguments. Please check that your arguments match
                              declared content type."""
                     raise APIError(status=0, reason=msg)
             # For `GET`, `HEAD`
             else:
                 r = self.pool_manager.request(
-                    self.root._session_token,
+                    root,
                     method,
                     url,
                     fields={},
                     preload_content=_preload_content,
                     timeout=timeout,
                     headers=headers,
                 )
@@ -191,88 +202,139 @@
             if 500 <= r.status <= 599:
                 raise ServerError(http_resp=r)
 
             raise APIError(http_resp=r)
 
         return r
 
-    def get_request(self, url, headers=None, query_params=None, _preload_content=True,
-            _request_timeout=None):
-        return self.request("GET", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
-
-    def head_request(self, url, headers=None, query_params=None, _preload_content=True,
-             _request_timeout=None):
-        return self.request("HEAD", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
+    def get_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "GET",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def head_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "HEAD",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
 
-    def options_request(self, url, headers=None, query_params=None, post_params=None,
+    def options_request(self, root, url, headers=None, query_params=None, post_params=None,
                 body=None, _preload_content=True, _request_timeout=None):
-        return self.request("OPTIONS", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "OPTIONS",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def delete_request(self, url, headers=None, query_params=None, body=None,
+    def delete_request(self, root, url, headers=None, query_params=None, body=None,
                _preload_content=True, _request_timeout=None):
-        return self.request("DELETE", url,
-                            headers=headers,
-                            query_params=query_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "DELETE",
+            url,
+            headers=headers,
+            query_params=query_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def post_request(self, url, headers=None, query_params=None, post_params=None,
+    def post_request(self, root, url, headers=None, query_params=None, post_params=None,
              body=None, _preload_content=True, _request_timeout=None):
-        return self.request("POST", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "POST",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def put_request(self, url, headers=None, query_params=None, post_params=None,
+    def put_request(self, root, url, headers=None, query_params=None, post_params=None,
             body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PUT", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "PUT",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def patch_request(self, url, headers=None, query_params=None, post_params=None,
+    def patch_request(self, root, url, headers=None, query_params=None, post_params=None,
               body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PATCH", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "PATCH",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
 
 class BridgeClientObject(object):
 
     def __init__(self, snowflake_connection: SnowflakeConnection):
         self.bridge = SnowBridge(snowflake_connection)
 
-    def request(self, method, url, query_params=None, headers=None,
-                body=None, post_params=None, _preload_content=True,
-                _request_timeout=None):
+    def request(
+        self,
+        root,
+        method,
+        url,
+        query_params=None,
+        headers=None,
+        body=None,
+        post_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
         """Perform requests.
 
         :param method: http request method
         :param url: http request url
         :param query_params: query parameters in the url
         :param headers: http request headers
         :param body: request json body, for `application/json`
@@ -315,71 +377,378 @@
             if 500 <= r.status <= 599:
                 raise ServerError(http_resp=r)
 
             raise APIError(http_resp=r)
 
         return r
 
-    def get_request(self, url, headers=None, query_params=None, _preload_content=True,
-                    _request_timeout=None):
-        return self.request("GET", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
-
-    def head_request(self, url, headers=None, query_params=None, _preload_content=True,
-                     _request_timeout=None):
-        return self.request("HEAD", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
-
-    def options_request(self, url, headers=None, query_params=None, post_params=None,
-                        body=None, _preload_content=True, _request_timeout=None):
-        return self.request("OPTIONS", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def delete_request(self, url, headers=None, query_params=None, body=None,
-                       _preload_content=True, _request_timeout=None):
-        return self.request("DELETE", url,
-                            headers=headers,
-                            query_params=query_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def post_request(self, url, headers=None, query_params=None, post_params=None,
-                     body=None, _preload_content=True, _request_timeout=None):
-        return self.request("POST", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def put_request(self, url, headers=None, query_params=None, post_params=None,
-                    body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PUT", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def patch_request(self, url, headers=None, query_params=None, post_params=None,
-                      body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PATCH", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+    def get_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "GET",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def head_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "HEAD",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def options_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "OPTIONS",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def delete_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "DELETE",
+            url,
+            headers=headers,
+            query_params=query_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def post_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "POST",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def put_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PUT",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def patch_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PATCH",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+
+class StoredProcClientObject(object):
+
+    def request(
+        self,
+        root,
+        method,
+        url,
+        query_params={},
+        headers={},
+        body={},
+        post_params={},
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        """Perform requests.
+        :param method: http request method
+        :param url: http request url
+        :param query_params: query parameters in the url
+        :param headers: http request headers
+        :param body: request json body, for `application/json`
+        :param post_params: request post parameters,
+                            `application/x-www-form-urlencoded`
+                            and `multipart/form-data`
+        :param _preload_content: if False, the urllib3.HTTPResponse object will
+                                 be returned without reading/decoding response
+                                 data. Default is True.
+        :param _request_timeout: timeout setting for this request. If one
+                                 number provided, it will be total request
+                                 timeout. It can also be a pair (tuple) of
+                                 (connection, read) timeouts.
+        """
+        method = method.upper()
+        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
+                          'PATCH', 'OPTIONS']
+        import _snowflake
+        parsed_url = urllib3.util.parse_url(url)
+        response_dict = _snowflake.send_snow_api_request(method, parsed_url.path, dict(query_params), headers, body,
+                                                         post_params, _request_timeout)
+        json_content = json.loads(response_dict["content"])
+        if "data" in json_content:
+            r = urllib3.HTTPResponse(body=json.dumps(json_content["data"]))
+        else:
+            r = urllib3.HTTPResponse(body=json.dumps(json_content).encode("utf-8"))
+        r.status = response_dict["status"]
+        if _preload_content:
+            r = RESTResponse(r)
+            # log response body
+            logger.debug("response body: %s", r.data)
+
+        if not 200 <= r.status <= 299:
+            if r.status == 401:
+                raise UnauthorizedError(http_resp=r)
+
+            if r.status == 403:
+                raise ForbiddenError(http_resp=r)
+
+            if r.status == 404:
+                raise NotFoundError(http_resp=r)
+
+            if r.status == 409:
+                raise ConflictError(http_resp=r)
+
+            if 500 <= r.status <= 599:
+                raise ServerError(http_resp=r)
+
+            raise APIError(http_resp=r)
+
+        return r
+
+    def get_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "GET",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def head_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "HEAD",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def options_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "OPTIONS",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def delete_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "DELETE",
+            url,
+            headers=headers,
+            query_params=query_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def post_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "POST",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def put_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PUT",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def patch_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PATCH",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/table/_generated/api/table_api.py` & `snowflake_core-0.8.0/src/snowflake/core/service/_generated/api/service_api.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,288 +1,129 @@
 # coding: utf-8
 
 """
-    Snowflake Table API
+    Snowflake Services API
 
-    The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
+    The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 import logging
 
 from typing_extensions import Annotated
+from pydantic import Field, StrictBool, StrictInt, StrictStr, constr, validator
 
-from pydantic import StrictBool, StrictInt, StrictStr, constr, validator
+from typing import List, Optional
 
-from typing import Any, Dict, List, Optional
+from snowflake.core.service._generated.models.fetch_service_logs200_response import FetchServiceLogs200Response
+from snowflake.core.service._generated.models.fetch_service_status200_response import FetchServiceStatus200Response
+from snowflake.core.service._generated.models.service import Service
+from snowflake.core.service._generated.models.service_endpoint import ServiceEndpoint
+from snowflake.core.service._generated.models.success_response import SuccessResponse
+from typing import Iterable
 
-from snowflake.core.table._generated.models.success_response import SuccessResponse
-from snowflake.core.table._generated.models.table import Table
 
-from snowflake.core._internal.pydantic_compatibility import StrictBool, StrictInt, StrictStr, constr, validate_arguments, ValidationError, validator
-from snowflake.core._internal.utils import ApiClientType
+from snowflake.core.service._generated.pydantic_compatibility import StrictBool, StrictInt, StrictStr, constr, validate_arguments, ValidationError, validator
+from snowflake.core._internal.snowapi_parameters import SnowApiParameters
+from snowflake.core._internal.utils import ApiClientType, is_running_inside_stored_procedure
 
-from snowflake.core.table._generated.api_client import ApiClient
 from snowflake.core.exceptions import (  # noqa: F401
     _APITypeError,
     _APIValueError
 )
 
 logger  = logging.getLogger(__name__)
 
-class TableApi(object):
+class ServiceApi(object):
     """NOTE: This class is auto generated by OpenAPI Generator
     Ref: https://openapi-generator.tech
 
     Do not edit the class manually.
     """
 
-    def __init__(self, root, resource_class, bridge_client):
+    def __init__(self, root, resource_class, bridge_client, sproc_client):
         self._root = root
-        self._rest_client = ApiClient.get_default(root)
+        self._resource_name = 'service'
         self._resource_class = resource_class
         self._bridge_client = bridge_client
+        self._sproc_client = sproc_client
         self._chosen_client_type = ApiClientType.NONE
 
     @property
     def api_client(self):
         """
             chosen_client is the client we chose , either bridge or rest
-            new_chosen_client is the client we want to choose under the current situation ( value of _supports_rest_api + _can_use_rest_api )
+            new_chosen_client is the client we want to choose under the current situation ( value of
+            _supports_rest_api + _can_use_rest_api, and the server-controlled flag )
             We will log the change if we want to choose another client instead of the current one
         """
-        if self._resource_class._supports_rest_api and self._root._can_use_rest_api:
-            chosen_client = self._rest_client
-            new_chosen_client = ApiClientType.REST
+        from snowflake.core.service._generated.api_client import ApiClient
+
+        # Small helper function for figuring out the correct 'REST' client to use if in stored proc or not
+        def _get_rest_client():
+            if is_running_inside_stored_procedure():
+                return self._sproc_client, ApiClientType.STORED_PROC
+            else:
+                return ApiClient.get_default(self._root), ApiClientType.REST
+
+        use_bridge_override = False
+
+        # We can force use of the bridge if the server dictates it so
+        # But, don't check it for non-resources; _resource_class is not set for non-resources.
+        if self._resource_class is not None:
+            use_bridge_override = self._root.effective_parameters(refresh = False).resource_should_use_client_bridge('service')
+
+        # if the _resource_class is None (such as Session, which is not a resource), then it is implied
+        # that we use REST (or the stored_proc client)
+        if self._resource_class is None:
+            chosen_client, new_chosen_client = _get_rest_client()
+        elif use_bridge_override:
+            # Bridge override is in effect. Use the client bridge.
+            chosen_client = self._bridge_client
+            new_chosen_client = ApiClientType.BRIDGE
+        # Check if it supports REST before choosing the REST client.
+        elif self._resource_class._supports_rest_api and self._root._can_use_rest_api:
+            chosen_client, new_chosen_client = _get_rest_client()
+        # If all else fails, use the BRIDGE (if there is no REST support for this resource)
         else:
             chosen_client = self._bridge_client
             new_chosen_client = ApiClientType.BRIDGE
 
         if new_chosen_client != self._chosen_client_type:
             self._chosen_client_type = new_chosen_client
             logger.info("Going to use client-%s for this resource", new_chosen_client.name)
         return chosen_client
 
     @validate_arguments
-    def create_or_update_table(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), table : Table, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Create a (or alter an existing) table.  # noqa: E501
-
-        Create a (or alter an existing) table. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
-        This method makes a synchronous HTTP request by default. To make an
-        asynchronous HTTP request, please pass async_req=True
-
-        >>> thread = api.create_or_update_table(database, var_schema, name, table, async_req=True)
-        >>> result = thread.get()
-
-        :param database: (required)
-        :type database: str
-        :param var_schema: (required)
-        :type var_schema: str
-        :param name: (required)
-        :type name: str
-        :param table: (required)
-        :type table: Table
-        :param async_req: Whether to execute the request asynchronously.
-        :type async_req: bool, optional
-        :param _preload_content: if False, the urllib3.HTTPResponse object will
-                                 be returned without reading/decoding response
-                                 data. Default is True.
-        :type _preload_content: bool, optional
-        :param _request_timeout: timeout setting for this request. If one
-                                 number provided, it will be total request
-                                 timeout. It can also be a pair (tuple) of
-                                 (connection, read) timeouts.
-        :return: Returns the result object.
-                 If the method is called asynchronously,
-                 returns the request thread.
-        :rtype: SuccessResponse
-        """
-        kwargs['_return_http_data_only'] = True
-        return self.create_or_update_table_with_http_info(database, var_schema, name, table, **kwargs)  # noqa: E501
-
-    @validate_arguments
-    def create_or_update_table_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), table : Table, **kwargs):  # noqa: E501
-        """Create a (or alter an existing) table.  # noqa: E501
-
-        Create a (or alter an existing) table. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
-        This method makes a synchronous HTTP request by default. To make an
-        asynchronous HTTP request, please pass async_req=True
-
-        >>> thread = api.create_or_update_table_with_http_info(database, var_schema, name, table, async_req=True)
-        >>> result = thread.get()
-
-        :param database: (required)
-        :type database: str
-        :param var_schema: (required)
-        :type var_schema: str
-        :param name: (required)
-        :type name: str
-        :param table: (required)
-        :type table: Table
-        :param async_req: Whether to execute the request asynchronously.
-        :type async_req: bool, optional
-        :param _return_http_data_only: response data without head status code
-                                       and headers
-        :type _return_http_data_only: bool, optional
-        :param _preload_content: if False, the urllib3.HTTPResponse object will
-                                 be returned without reading/decoding response
-                                 data. Default is True.
-        :type _preload_content: bool, optional
-        :param _request_timeout: timeout setting for this request. If one
-                                 number provided, it will be total request
-                                 timeout. It can also be a pair (tuple) of
-                                 (connection, read) timeouts.
-        :param _request_auth: set to override the auth_settings for an a single
-                              request; this effectively ignores the authentication
-                              in the spec for a single request.
-        :type _request_auth: dict, optional
-        :type _content_type: string, optional: force content-type for the request
-        :return: Returns the result object.
-                 If the method is called asynchronously,
-                 returns the request thread.
-        :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
-        """
-
-        _params = locals()
-
-        _all_params = [
-            'database',
-            'var_schema',
-            'name',
-            'table'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
-
-        # validate the arguments
-        for _key, _val in _params['kwargs'].items():
-            if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method create_or_update_table" % _key
-                )
-            _params[_key] = _val
-        del _params['kwargs']
-
-        _collection_formats = {}
-
-        # process the path parameters
-        _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
-        if _params['var_schema']:
-            _path_params['schema'] = _params['var_schema']
-        if _params['name']:
-            _path_params['name'] = _params['name']
-
-        # process the query parameters
-        _query_params = []
-
-        # process the header parameters
-        _header_params = dict(_params.get('_headers', {}))
-
-        # process the form parameters
-        _form_params = []
-        _files = {}
-
-        # process the body parameter
-        _body_params = None
-        if _params['table']:
-            _body_params = _params['table']
-
-        # set the HTTP header `Accept`
-        _header_params['Accept'] = self.api_client.select_header_accept(
-            ['application/json'])  # noqa: E501
-
-        # set the HTTP header `Content-Type`
-        _content_types_list = _params.get('_content_type',
-            self.api_client.select_header_content_type(
-                ['application/json']))
-        if _content_types_list:
-                _header_params['Content-Type'] = _content_types_list
-
-        # authentication setting
-        _auth_settings = []  # noqa: E501
-
-        _response_types_map = {
-            '200': "SuccessResponse",
-            '201': "SuccessResponse",
-            '400': "ErrorResponse",
-            '401': "ErrorResponse",
-            '403': "ErrorResponse",
-            '404': "ErrorResponse",
-            '405': "ErrorResponse",
-            '500': "ErrorResponse",
-            '503': "ErrorResponse",
-            '504': "ErrorResponse",
-        }
-
-        return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/tables/{name}', 'PUT',
-            _path_params,
-            _query_params,
-            _header_params,
-            body=_body_params,
-            post_params=_form_params,
-            files=_files,
-            response_types_map=_response_types_map,
-            auth_settings=_auth_settings,
-            async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
-            _preload_content=_params.get('_preload_content', True),
-            _request_timeout=_params.get('_request_timeout'),
-            collection_formats=_collection_formats,
-            _request_auth=_params.get('_request_auth'))
-
-    @validate_arguments
-    def create_table(self, database : constr(strict=True), var_schema : constr(strict=True), table : Table, create_mode : Optional[StrictStr] = None, as_select : Optional[StrictStr] = None, template_query : Optional[StrictStr] = None, like_table : Optional[StrictStr] = None, clone_table : Optional[StrictStr] = None, copy_grants : Optional[StrictBool] = None, undelete : Optional[StrictBool] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Create a table  # noqa: E501
+    def create_service(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], service : Service, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+        """Create a service  # noqa: E501
 
-        Create a table.  # noqa: E501
+        Create a service, with standard create modifiers as query parameters. See the Service component definition for what is required to be provided in the request body.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_table(database, var_schema, table, create_mode, as_select, template_query, like_table, clone_table, copy_grants, undelete, async_req=True)
+        >>> thread = api.create_service(database, var_schema, service, create_mode, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param table: (required)
-        :type table: Table
-        :param create_mode:
+        :param service: (required)
+        :type service: Service
+        :param create_mode: A query parameter allowing support for different modes of resource creation.
         :type create_mode: str
-        :param as_select:
-        :type as_select: str
-        :param template_query:
-        :type template_query: str
-        :param like_table:
-        :type like_table: str
-        :param clone_table:
-        :type clone_table: str
-        :param copy_grants:
-        :type copy_grants: bool
-        :param undelete:
-        :type undelete: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
@@ -291,47 +132,35 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.create_table_with_http_info(database, var_schema, table, create_mode, as_select, template_query, like_table, clone_table, copy_grants, undelete, **kwargs)  # noqa: E501
+        return self.create_service_with_http_info(database, var_schema, service, create_mode, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def create_table_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), table : Table, create_mode : Optional[StrictStr] = None, as_select : Optional[StrictStr] = None, template_query : Optional[StrictStr] = None, like_table : Optional[StrictStr] = None, clone_table : Optional[StrictStr] = None, copy_grants : Optional[StrictBool] = None, undelete : Optional[StrictBool] = None, **kwargs):  # noqa: E501
-        """Create a table  # noqa: E501
+    def create_service_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], service : Service, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, **kwargs):  # noqa: E501
+        """Create a service  # noqa: E501
 
-        Create a table.  # noqa: E501
+        Create a service, with standard create modifiers as query parameters. See the Service component definition for what is required to be provided in the request body.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_table_with_http_info(database, var_schema, table, create_mode, as_select, template_query, like_table, clone_table, copy_grants, undelete, async_req=True)
+        >>> thread = api.create_service_with_http_info(database, var_schema, service, create_mode, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param table: (required)
-        :type table: Table
-        :param create_mode:
+        :param service: (required)
+        :type service: Service
+        :param create_mode: A query parameter allowing support for different modes of resource creation.
         :type create_mode: str
-        :param as_select:
-        :type as_select: str
-        :param template_query:
-        :type template_query: str
-        :param like_table:
-        :type like_table: str
-        :param clone_table:
-        :type clone_table: str
-        :param copy_grants:
-        :type copy_grants: bool
-        :param undelete:
-        :type undelete: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -353,22 +182,16 @@
         """
 
         _params = locals()
 
         _all_params = [
             'database',
             'var_schema',
-            'table',
-            'create_mode',
-            'as_select',
-            'template_query',
-            'like_table',
-            'clone_table',
-            'copy_grants',
-            'undelete'
+            'service',
+            'create_mode'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -379,15 +202,15 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method create_table" % _key
+                    " to method create_service" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
@@ -397,38 +220,26 @@
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
 
         # process the query parameters
         _query_params = []
         if _params.get('create_mode') is not None:  # noqa: E501
             _query_params.append(('createMode', _params['create_mode']))
-        if _params.get('as_select') is not None:  # noqa: E501
-            _query_params.append(('as_select', _params['as_select']))
-        if _params.get('template_query') is not None:  # noqa: E501
-            _query_params.append(('template_query', _params['template_query']))
-        if _params.get('like_table') is not None:  # noqa: E501
-            _query_params.append(('like_table', _params['like_table']))
-        if _params.get('clone_table') is not None:  # noqa: E501
-            _query_params.append(('clone_table', _params['clone_table']))
-        if _params.get('copy_grants') is not None:  # noqa: E501
-            _query_params.append(('copy_grants', _params['copy_grants']))
-        if _params.get('undelete') is not None:  # noqa: E501
-            _query_params.append(('undelete', _params['undelete']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
-        if _params['table']:
-            _body_params = _params['table']
+        if _params['service']:
+            _body_params = _params['service']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # set the HTTP header `Content-Type`
         _content_types_list = _params.get('_content_type',
@@ -437,28 +248,29 @@
         if _content_types_list:
                 _header_params['Content-Type'] = _content_types_list
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '201': "SuccessResponse",
+            '200': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
             '409': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/tables', 'POST',
+            self._root,
+            '/api/v2/databases/{database}/schemas/{schema}/services', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -467,64 +279,64 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def delete_table(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), **kwargs) -> SuccessResponse:  # noqa: E501
-        """Delete a table  # noqa: E501
+    def fetch_service(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> Service:  # noqa: E501
+        """Fetch a service.  # noqa: E501
 
-        Delete a table with the given name.  # noqa: E501
+        Fetch a Service.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.delete_table(database, var_schema, name, async_req=True)
+        >>> thread = api.fetch_service(database, var_schema, name, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: SuccessResponse
+        :rtype: Service
         """
         kwargs['_return_http_data_only'] = True
-        return self.delete_table_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
+        return self.fetch_service_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def delete_table_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), **kwargs):  # noqa: E501
-        """Delete a table  # noqa: E501
+    def fetch_service_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
+        """Fetch a service.  # noqa: E501
 
-        Delete a table with the given name.  # noqa: E501
+        Fetch a Service.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.delete_table_with_http_info(database, var_schema, name, async_req=True)
+        >>> thread = api.fetch_service_with_http_info(database, var_schema, name, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -539,15 +351,15 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(Service, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
             'database',
             'var_schema',
@@ -566,15 +378,15 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method delete_table" % _key
+                    " to method fetch_service" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
@@ -603,27 +415,28 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "SuccessResponse",
+            '200': "Service",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/tables/{name}', 'DELETE',
+            self._root,
+            '/api/v2/databases/{database}/schemas/{schema}/services/{name}', 'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -632,65 +445,77 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def fetch_effective_parameters(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), **kwargs) -> Dict[str, object]:  # noqa: E501
-        """Fetch the effective parameters of a table.  # noqa: E501
+    def fetch_service_logs(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], instance_id : Annotated[StrictInt, Field(..., description="ID of the service instance, starting with 0.")], container_name : Annotated[StrictStr, Field(..., description="Container name as specified in the service specification file.")], num_lines : Annotated[Optional[StrictInt], Field(description="Number of trailing log lines to retrieve.")] = None, **kwargs) -> FetchServiceLogs200Response:  # noqa: E501
+        """Fetch the logs for a given service.  # noqa: E501
 
-        Fetch the effective parameters of a table.  # noqa: E501
+        Fetch the logs for a service.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_effective_parameters(database, var_schema, name, async_req=True)
+        >>> thread = api.fetch_service_logs(database, var_schema, name, instance_id, container_name, num_lines, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
+        :param instance_id: ID of the service instance, starting with 0. (required)
+        :type instance_id: int
+        :param container_name: Container name as specified in the service specification file. (required)
+        :type container_name: str
+        :param num_lines: Number of trailing log lines to retrieve.
+        :type num_lines: int
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: Dict[str, object]
+        :rtype: FetchServiceLogs200Response
         """
         kwargs['_return_http_data_only'] = True
-        return self.fetch_effective_parameters_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
+        return self.fetch_service_logs_with_http_info(database, var_schema, name, instance_id, container_name, num_lines, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def fetch_effective_parameters_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), **kwargs):  # noqa: E501
-        """Fetch the effective parameters of a table.  # noqa: E501
+    def fetch_service_logs_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], instance_id : Annotated[StrictInt, Field(..., description="ID of the service instance, starting with 0.")], container_name : Annotated[StrictStr, Field(..., description="Container name as specified in the service specification file.")], num_lines : Annotated[Optional[StrictInt], Field(description="Number of trailing log lines to retrieve.")] = None, **kwargs):  # noqa: E501
+        """Fetch the logs for a given service.  # noqa: E501
 
-        Fetch the effective parameters of a table.  # noqa: E501
+        Fetch the logs for a service.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_effective_parameters_with_http_info(database, var_schema, name, async_req=True)
+        >>> thread = api.fetch_service_logs_with_http_info(database, var_schema, name, instance_id, container_name, num_lines, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
+        :param instance_id: ID of the service instance, starting with 0. (required)
+        :type instance_id: int
+        :param container_name: Container name as specified in the service specification file. (required)
+        :type container_name: str
+        :param num_lines: Number of trailing log lines to retrieve.
+        :type num_lines: int
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -704,23 +529,26 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(Dict[str, object], status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(FetchServiceLogs200Response, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
             'database',
             'var_schema',
-            'name'
+            'name',
+            'instance_id',
+            'container_name',
+            'num_lines'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -731,15 +559,15 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method fetch_effective_parameters" % _key
+                    " to method fetch_service_logs" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
@@ -749,14 +577,20 @@
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
+        if _params.get('instance_id') is not None:  # noqa: E501
+            _query_params.append(('instanceId', _params['instance_id']))
+        if _params.get('container_name') is not None:  # noqa: E501
+            _query_params.append(('containerName', _params['container_name']))
+        if _params.get('num_lines') is not None:  # noqa: E501
+            _query_params.append(('numLines', _params['num_lines']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -768,27 +602,28 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "Dict[str, object]",
+            '200': "FetchServiceLogs200Response",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/tables/{name}/parameters/effective', 'GET',
+            self._root,
+            '/api/v2/databases/{database}/schemas/{schema}/services/{name}/logs', 'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -797,69 +632,69 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def fetch_table(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), deep : Optional[StrictBool] = None, **kwargs) -> Table:  # noqa: E501
-        """Fetch a table.  # noqa: E501
+    def fetch_service_status(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], timeout : Annotated[Optional[StrictInt], Field(description="Number of seconds to wait for the service to reach a steady state (for example, READY) before returning the status. If the service does not reach a steady state within the specified time, Snowflake returns the current state.")] = None, **kwargs) -> FetchServiceStatus200Response:  # noqa: E501
+        """Fetch the status for a given service.  # noqa: E501
 
-        Fetch a Table using the SHOW command output.  # noqa: E501
+        Fetch the status for a service.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_table(database, var_schema, name, deep, async_req=True)
+        >>> thread = api.fetch_service_status(database, var_schema, name, timeout, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param deep:
-        :type deep: bool
+        :param timeout: Number of seconds to wait for the service to reach a steady state (for example, READY) before returning the status. If the service does not reach a steady state within the specified time, Snowflake returns the current state.
+        :type timeout: int
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: Table
+        :rtype: FetchServiceStatus200Response
         """
         kwargs['_return_http_data_only'] = True
-        return self.fetch_table_with_http_info(database, var_schema, name, deep, **kwargs)  # noqa: E501
+        return self.fetch_service_status_with_http_info(database, var_schema, name, timeout, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def fetch_table_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), deep : Optional[StrictBool] = None, **kwargs):  # noqa: E501
-        """Fetch a table.  # noqa: E501
+    def fetch_service_status_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], timeout : Annotated[Optional[StrictInt], Field(description="Number of seconds to wait for the service to reach a steady state (for example, READY) before returning the status. If the service does not reach a steady state within the specified time, Snowflake returns the current state.")] = None, **kwargs):  # noqa: E501
+        """Fetch the status for a given service.  # noqa: E501
 
-        Fetch a Table using the SHOW command output.  # noqa: E501
+        Fetch the status for a service.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_table_with_http_info(database, var_schema, name, deep, async_req=True)
+        >>> thread = api.fetch_service_status_with_http_info(database, var_schema, name, timeout, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param deep:
-        :type deep: bool
+        :param timeout: Number of seconds to wait for the service to reach a steady state (for example, READY) before returning the status. If the service does not reach a steady state within the specified time, Snowflake returns the current state.
+        :type timeout: int
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -873,24 +708,24 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(Table, status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(FetchServiceStatus200Response, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
             'database',
             'var_schema',
             'name',
-            'deep'
+            'timeout'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -901,15 +736,15 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method fetch_table" % _key
+                    " to method fetch_service_status" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
@@ -919,16 +754,16 @@
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
-        if _params.get('deep') is not None:  # noqa: E501
-            _query_params.append(('deep', _params['deep']))
+        if _params.get('timeout') is not None:  # noqa: E501
+            _query_params.append(('timeout', _params['timeout']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -940,27 +775,28 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "Table",
+            '200': "FetchServiceStatus200Response",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/tables/{name}', 'GET',
+            self._root,
+            '/api/v2/databases/{database}/schemas/{schema}/services/{name}/status', 'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -969,85 +805,73 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def list_tables(self, database : constr(strict=True), var_schema : constr(strict=True), like : Optional[StrictStr] = None, starts_with : Optional[StrictStr] = None, show_limit : Optional[StrictInt] = None, from_name : Optional[StrictStr] = None, history : Optional[StrictBool] = None, deep : Optional[StrictBool] = None, **kwargs) -> List[Table]:  # noqa: E501
-        """List tables  # noqa: E501
+    def list_services(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, starts_with : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.")] = None, show_limit : Annotated[Optional[StrictInt], Field(description="A query parameter that limits the maximum number of rows returned by a command.")] = None, **kwargs) -> Iterable[Service]:  # noqa: E501
+        """List services  # noqa: E501
 
-        Lists the tables under the database and schema.  # noqa: E501
+        Lists the services under the database and schema.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.list_tables(database, var_schema, like, starts_with, show_limit, from_name, history, deep, async_req=True)
+        >>> thread = api.list_services(database, var_schema, like, starts_with, show_limit, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param like:
+        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
         :type like: str
-        :param starts_with:
+        :param starts_with: A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
         :type starts_with: str
-        :param show_limit:
+        :param show_limit: A query parameter that limits the maximum number of rows returned by a command.
         :type show_limit: int
-        :param from_name:
-        :type from_name: str
-        :param history:
-        :type history: bool
-        :param deep:
-        :type deep: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: List[Table]
+        :rtype: Iterable[Service]
         """
         kwargs['_return_http_data_only'] = True
-        return self.list_tables_with_http_info(database, var_schema, like, starts_with, show_limit, from_name, history, deep, **kwargs)  # noqa: E501
+        return self.list_services_with_http_info(database, var_schema, like, starts_with, show_limit, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def list_tables_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), like : Optional[StrictStr] = None, starts_with : Optional[StrictStr] = None, show_limit : Optional[StrictInt] = None, from_name : Optional[StrictStr] = None, history : Optional[StrictBool] = None, deep : Optional[StrictBool] = None, **kwargs):  # noqa: E501
-        """List tables  # noqa: E501
+    def list_services_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, starts_with : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.")] = None, show_limit : Annotated[Optional[StrictInt], Field(description="A query parameter that limits the maximum number of rows returned by a command.")] = None, **kwargs):  # noqa: E501
+        """List services  # noqa: E501
 
-        Lists the tables under the database and schema.  # noqa: E501
+        Lists the services under the database and schema.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.list_tables_with_http_info(database, var_schema, like, starts_with, show_limit, from_name, history, deep, async_req=True)
+        >>> thread = api.list_services_with_http_info(database, var_schema, like, starts_with, show_limit, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param like:
+        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
         :type like: str
-        :param starts_with:
+        :param starts_with: A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
         :type starts_with: str
-        :param show_limit:
+        :param show_limit: A query parameter that limits the maximum number of rows returned by a command.
         :type show_limit: int
-        :param from_name:
-        :type from_name: str
-        :param history:
-        :type history: bool
-        :param deep:
-        :type deep: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -1061,28 +885,25 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(List[Table], status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(Iterable[Service], status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
             'database',
             'var_schema',
             'like',
             'starts_with',
-            'show_limit',
-            'from_name',
-            'history',
-            'deep'
+            'show_limit'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -1093,15 +914,15 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method list_tables" % _key
+                    " to method list_services" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
@@ -1115,20 +936,14 @@
         _query_params = []
         if _params.get('like') is not None:  # noqa: E501
             _query_params.append(('like', _params['like']))
         if _params.get('starts_with') is not None:  # noqa: E501
             _query_params.append(('startsWith', _params['starts_with']))
         if _params.get('show_limit') is not None:  # noqa: E501
             _query_params.append(('showLimit', _params['show_limit']))
-        if _params.get('from_name') is not None:  # noqa: E501
-            _query_params.append(('fromName', _params['from_name']))
-        if _params.get('history') is not None:  # noqa: E501
-            _query_params.append(('history', _params['history']))
-        if _params.get('deep') is not None:  # noqa: E501
-            _query_params.append(('deep', _params['deep']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -1140,27 +955,28 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "List[Table]",
+            '200': "Iterable[Service]",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/tables', 'GET',
+            self._root,
+            '/api/v2/databases/{database}/schemas/{schema}/services', 'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -1169,32 +985,30 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def rename_table(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), new_name : StrictStr, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Rename a table  # noqa: E501
+    def resume_service(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> SuccessResponse:  # noqa: E501
+        """Resume a service  # noqa: E501
 
-        Rename a table  # noqa: E501
+        Resume a service.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.rename_table(database, var_schema, name, new_name, async_req=True)
+        >>> thread = api.resume_service(database, var_schema, name, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param new_name: (required)
-        :type new_name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
@@ -1203,35 +1017,33 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.rename_table_with_http_info(database, var_schema, name, new_name, **kwargs)  # noqa: E501
+        return self.resume_service_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def rename_table_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), new_name : StrictStr, **kwargs):  # noqa: E501
-        """Rename a table  # noqa: E501
+    def resume_service_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
+        """Resume a service  # noqa: E501
 
-        Rename a table  # noqa: E501
+        Resume a service.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.rename_table_with_http_info(database, var_schema, name, new_name, async_req=True)
+        >>> thread = api.resume_service_with_http_info(database, var_schema, name, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param new_name: (required)
-        :type new_name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -1253,16 +1065,15 @@
         """
 
         _params = locals()
 
         _all_params = [
             'database',
             'var_schema',
-            'name',
-            'new_name'
+            'name'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -1273,15 +1084,15 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method rename_table" % _key
+                    " to method resume_service" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
@@ -1291,16 +1102,14 @@
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
-        if _params.get('new_name') is not None:  # noqa: E501
-            _query_params.append(('new_name', _params['new_name']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -1324,15 +1133,16 @@
             '405': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/tables/{name}:rename', 'POST',
+            self._root,
+            '/api/v2/databases/{database}/schemas/{schema}/services/{name}:resume', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -1341,64 +1151,62 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def resume_recluster(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), **kwargs) -> SuccessResponse:  # noqa: E501
-        """Resume recluster of a table  # noqa: E501
+    def show_service_endpoints(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> Iterable[ServiceEndpoint]:  # noqa: E501
+        """List the endpoints in a service.  # noqa: E501
 
-        Resume recluster of a table  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.resume_recluster(database, var_schema, name, async_req=True)
+        >>> thread = api.show_service_endpoints(database, var_schema, name, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: SuccessResponse
+        :rtype: Iterable[ServiceEndpoint]
         """
         kwargs['_return_http_data_only'] = True
-        return self.resume_recluster_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
+        return self.show_service_endpoints_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def resume_recluster_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), **kwargs):  # noqa: E501
-        """Resume recluster of a table  # noqa: E501
+    def show_service_endpoints_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
+        """List the endpoints in a service.  # noqa: E501
 
-        Resume recluster of a table  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.resume_recluster_with_http_info(database, var_schema, name, async_req=True)
+        >>> thread = api.show_service_endpoints_with_http_info(database, var_schema, name, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -1413,15 +1221,15 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(Iterable[ServiceEndpoint], status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
             'database',
             'var_schema',
@@ -1440,15 +1248,15 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method resume_recluster" % _key
+                    " to method show_service_endpoints" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
@@ -1477,27 +1285,28 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "SuccessResponse",
+            '200': "Iterable[ServiceEndpoint]",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/tables/{name}:resume_recluster', 'POST',
+            self._root,
+            '/api/v2/databases/{database}/schemas/{schema}/services/{name}/endpoints', 'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -1506,29 +1315,29 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def suspend_recluster(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), **kwargs) -> SuccessResponse:  # noqa: E501
-        """Suspend recluster of a table  # noqa: E501
+    def suspend_service(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> SuccessResponse:  # noqa: E501
+        """Suspend a service  # noqa: E501
 
-        Suspend recluster of a table  # noqa: E501
+        Suspend a service.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.suspend_recluster(database, var_schema, name, async_req=True)
+        >>> thread = api.suspend_service(database, var_schema, name, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -1538,32 +1347,32 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.suspend_recluster_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
+        return self.suspend_service_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def suspend_recluster_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), **kwargs):  # noqa: E501
-        """Suspend recluster of a table  # noqa: E501
+    def suspend_service_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
+        """Suspend a service  # noqa: E501
 
-        Suspend recluster of a table  # noqa: E501
+        Suspend a service.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.suspend_recluster_with_http_info(database, var_schema, name, async_req=True)
+        >>> thread = api.suspend_service_with_http_info(database, var_schema, name, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -1605,15 +1414,15 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method suspend_recluster" % _key
+                    " to method suspend_service" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
@@ -1654,15 +1463,16 @@
             '405': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/tables/{name}:suspend_recluster', 'POST',
+            self._root,
+            '/api/v2/databases/{database}/schemas/{schema}/services/{name}:suspend', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -1671,32 +1481,32 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def swap_with(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), to_swap_table_name : StrictStr, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Swap with another table  # noqa: E501
+    def delete_service(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+        """Delete a service  # noqa: E501
 
-        Swap with another table  # noqa: E501
+        Delete a service with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.swap_with(database, var_schema, name, to_swap_table_name, async_req=True)
+        >>> thread = api.delete_service(database, var_schema, name, if_exists, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param to_swap_table_name: (required)
-        :type to_swap_table_name: str
+        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
@@ -1705,35 +1515,35 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.swap_with_with_http_info(database, var_schema, name, to_swap_table_name, **kwargs)  # noqa: E501
+        return self.delete_service_with_http_info(database, var_schema, name, if_exists, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def swap_with_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), to_swap_table_name : StrictStr, **kwargs):  # noqa: E501
-        """Swap with another table  # noqa: E501
+    def delete_service_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs):  # noqa: E501
+        """Delete a service  # noqa: E501
 
-        Swap with another table  # noqa: E501
+        Delete a service with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.swap_with_with_http_info(database, var_schema, name, to_swap_table_name, async_req=True)
+        >>> thread = api.delete_service_with_http_info(database, var_schema, name, if_exists, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param to_swap_table_name: (required)
-        :type to_swap_table_name: str
+        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -1756,15 +1566,15 @@
 
         _params = locals()
 
         _all_params = [
             'database',
             'var_schema',
             'name',
-            'to_swap_table_name'
+            'if_exists'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -1775,15 +1585,15 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method swap_with" % _key
+                    " to method delete_service" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
@@ -1793,16 +1603,16 @@
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
-        if _params.get('to_swap_table_name') is not None:  # noqa: E501
-            _query_params.append(('to_swap_table_name', _params['to_swap_table_name']))
+        if _params.get('if_exists') is not None:  # noqa: E501
+            _query_params.append(('ifExists', _params['if_exists']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -1826,15 +1636,16 @@
             '405': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/tables/{name}:swapwith', 'POST',
+            self._root,
+            '/api/v2/databases/{database}/schemas/{schema}/services/{name}', 'DELETE',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/table/_generated/models/__init__.py` & `snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/__init__.py`

 * *Files 26% similar despite different names*

```diff
@@ -5,32 +5,44 @@
     Snowflake Table API
 
     The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 # import models into model package
 from snowflake.core.table._generated.models.constraint import Constraint
 from snowflake.core.table._generated.models.error_response import ErrorResponse
 from snowflake.core.table._generated.models.foreign_key import ForeignKey
+from snowflake.core.table._generated.models.point_of_time import PointOfTime
+from snowflake.core.table._generated.models.point_of_time_offset import PointOfTimeOffset
+from snowflake.core.table._generated.models.point_of_time_statement import PointOfTimeStatement
+from snowflake.core.table._generated.models.point_of_time_timestamp import PointOfTimeTimestamp
 from snowflake.core.table._generated.models.primary_key import PrimaryKey
 from snowflake.core.table._generated.models.success_response import SuccessResponse
 from snowflake.core.table._generated.models.table import Table
+from snowflake.core.table._generated.models.table_clone import TableClone
 from snowflake.core.table._generated.models.table_column import TableColumn
 from snowflake.core.table._generated.models.unique_key import UniqueKey
 
 __all__ = [
     'Constraint',
     'ErrorResponse',
     'ForeignKey',
+    'PointOfTime',
+    'PointOfTimeOffset',
+    'PointOfTimeStatement',
+    'PointOfTimeTimestamp',
     'PrimaryKey',
     'SuccessResponse',
     'Table',
+    'TableClone',
     'TableColumn',
     'UniqueKey',
 ]
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/table/_generated/models/constraint.py` & `snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/constraint.py`

 * *Files 4% similar despite different names*

```diff
@@ -4,28 +4,30 @@
     Snowflake Table API
 
     The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 import snowflake.core.table._generated.models
 from snowflake.core.table._generated.models import *
 
 
 from typing import List, Optional, Union
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, StrictStr, conlist
+from snowflake.core.table._generated.pydantic_compatibility import BaseModel, StrictStr, conlist
 
 class Constraint(BaseModel):
     name: Optional[StrictStr] = None
     column_names: Optional[conlist(StrictStr)] = None
     constraint_type: Optional[StrictStr] = None
     __properties = ["name", "column_names", "constraint_type"]
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/table/_generated/models/error_response.py` & `snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/error_response.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,35 +1,38 @@
 # coding: utf-8
 
 """
-    Snowflake Table API
+    Snowflake Services API
 
-    The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
+    The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictStr
+from snowflake.core.service._generated.pydantic_compatibility import BaseModel, StrictStr
 
 class ErrorResponse(BaseModel):
-    message: Optional[StrictStr] = Field(None, description="Error message returned by server")
-    error_code: Optional[StrictStr] = Field(None, description="Error code")
-    request_id: Optional[StrictStr] = Field(None, description="Unique request id")
-    __properties = ["message", "error_code", "request_id"]
+    message: Optional[StrictStr] = None
+    code: Optional[StrictStr] = None
+    error_code: Optional[StrictStr] = None
+    request_id: Optional[StrictStr] = None
+    __properties = ["message", "code", "error_code", "request_id"]
 
 
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
@@ -61,14 +64,16 @@
 
         if type(obj) is not dict:
             return ErrorResponse.parse_obj(obj)
 
         _obj = ErrorResponse.parse_obj({
             "message": obj.get("message"),
 
+            "code": obj.get("code"),
+
             "error_code": obj.get("error_code"),
 
             "request_id": obj.get("request_id"),
 
         })
         return _obj
 
@@ -76,37 +81,43 @@
 from typing import Optional, List, Dict
 
 class ErrorResponseModel():
     def __init__(
         self,
         # optional properties
         message: Optional[str] = None,
+        code: Optional[str] = None,
         error_code: Optional[str] = None,
         request_id: Optional[str] = None,
     ):
         self.message = message
+        self.code = code
         self.error_code = error_code
         self.request_id = request_id
-    __properties = ["message", "error_code", "request_id"]
+    __properties = ["message", "code", "error_code", "request_id"]
 
     def _to_model(self):
         return ErrorResponse(
             message=self.message,
 
+            code=self.code,
+
             error_code=self.error_code,
 
             request_id=self.request_id,
 
         )
 
     @classmethod
     def _from_model(cls, model) -> ErrorResponseModel:
         return ErrorResponseModel(
             message=model.message,
 
+            code=model.code,
+
             error_code=model.error_code,
 
             request_id=model.request_id,
 
         )
 
     def to_dict(self):
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/table/_generated/models/foreign_key.py` & `snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/foreign_key.py`

 * *Files 4% similar despite different names*

```diff
@@ -4,26 +4,28 @@
     Snowflake Table API
 
     The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 from typing import List
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import Field, StrictStr, conlist
+from snowflake.core.table._generated.pydantic_compatibility import Field, StrictStr, conlist
 from snowflake.core.table._generated.models.constraint import Constraint
 
 class ForeignKey(Constraint):
     referenced_table_name: StrictStr = Field(...)
     referenced_column_names: conlist(StrictStr) = Field(...)
     __properties = ["name", "column_names", "constraint_type"]
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/table/_generated/models/primary_key.py` & `snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/primary_key.py`

 * *Files 5% similar despite different names*

```diff
@@ -4,14 +4,16 @@
     Snowflake Table API
 
     The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/table/_generated/models/success_response.py` & `snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/success_response.py`

 * *Files 3% similar despite different names*

```diff
@@ -4,29 +4,31 @@
     Snowflake Table API
 
     The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictStr
+from snowflake.core.table._generated.pydantic_compatibility import BaseModel, StrictStr
 
 class SuccessResponse(BaseModel):
-    status: Optional[StrictStr] = Field(None, description="Message returned by server")
+    status: Optional[StrictStr] = None
     __properties = ["status"]
 
 
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/table/_generated/models/table.py` & `snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/table.py`

 * *Files 0% similar despite different names*

```diff
@@ -4,26 +4,28 @@
     Snowflake Table API
 
     The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 from datetime import datetime
-from typing import List, Optional, Union
+from typing import List, Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictBool, StrictFloat, StrictInt, StrictStr, conlist
+from snowflake.core.table._generated.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, conlist
 from snowflake.core.table._generated.models.constraint import Constraint
 from snowflake.core.table._generated.models.table_column import TableColumn
 
 class Table(BaseModel):
     name: StrictStr = Field(...)
     kind: Optional[StrictStr] = None
     cluster_by: Optional[conlist(StrictStr)] = None
@@ -40,18 +42,19 @@
     schema_name: Optional[StrictStr] = None
     rows: Optional[StrictInt] = None
     bytes: Optional[StrictInt] = None
     owner: Optional[StrictStr] = None
     dropped_on: Optional[datetime] = None
     automatic_clustering: Optional[StrictBool] = None
     search_optimization: Optional[StrictBool] = None
-    search_optimization_progress: Optional[Union[StrictFloat, StrictInt]] = None
+    search_optimization_progress: Optional[StrictInt] = None
     search_optimization_bytes: Optional[StrictInt] = None
     owner_role_type: Optional[StrictStr] = None
-    __properties = ["name", "kind", "cluster_by", "enable_schema_evolution", "change_tracking", "data_retention_time_in_days", "max_data_extension_time_in_days", "default_ddl_collation", "columns", "constraints", "comment", "created_on", "database_name", "schema_name", "rows", "bytes", "owner", "dropped_on", "automatic_clustering", "search_optimization", "search_optimization_progress", "search_optimization_bytes", "owner_role_type"]
+    budget: Optional[StrictStr] = None
+    __properties = ["name", "kind", "cluster_by", "enable_schema_evolution", "change_tracking", "data_retention_time_in_days", "max_data_extension_time_in_days", "default_ddl_collation", "columns", "constraints", "comment", "created_on", "database_name", "schema_name", "rows", "bytes", "owner", "dropped_on", "automatic_clustering", "search_optimization", "search_optimization_progress", "search_optimization_bytes", "owner_role_type", "budget"]
 
 
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
@@ -141,14 +144,16 @@
 
             "search_optimization_progress": obj.get("search_optimization_progress"),
 
             "search_optimization_bytes": obj.get("search_optimization_bytes"),
 
             "owner_role_type": obj.get("owner_role_type"),
 
+            "budget": obj.get("budget"),
+
         })
         return _obj
 
 
 from typing import Optional, List, Dict
 from snowflake.core.table._generated.models.constraint import Constraint
 from snowflake.core.table._generated.models.table_column import TableColumn
@@ -173,17 +178,18 @@
         schema_name: Optional[str] = None,
         rows: Optional[int] = None,
         bytes: Optional[int] = None,
         owner: Optional[str] = None,
         dropped_on: Optional[datetime] = None,
         automatic_clustering: Optional[bool] = None,
         search_optimization: Optional[bool] = None,
-        search_optimization_progress: Optional[float] = None,
+        search_optimization_progress: Optional[int] = None,
         search_optimization_bytes: Optional[int] = None,
         owner_role_type: Optional[str] = None,
+        budget: Optional[str] = None,
     ):
         self.name = name
         self.kind = kind
         self.cluster_by = cluster_by
         self.enable_schema_evolution = enable_schema_evolution
         self.change_tracking = change_tracking
         self.data_retention_time_in_days = data_retention_time_in_days
@@ -200,15 +206,16 @@
         self.owner = owner
         self.dropped_on = dropped_on
         self.automatic_clustering = automatic_clustering
         self.search_optimization = search_optimization
         self.search_optimization_progress = search_optimization_progress
         self.search_optimization_bytes = search_optimization_bytes
         self.owner_role_type = owner_role_type
-    __properties = ["name", "kind", "cluster_by", "enable_schema_evolution", "change_tracking", "data_retention_time_in_days", "max_data_extension_time_in_days", "default_ddl_collation", "columns", "constraints", "comment", "created_on", "database_name", "schema_name", "rows", "bytes", "owner", "dropped_on", "automatic_clustering", "search_optimization", "search_optimization_progress", "search_optimization_bytes", "owner_role_type"]
+        self.budget = budget
+    __properties = ["name", "kind", "cluster_by", "enable_schema_evolution", "change_tracking", "data_retention_time_in_days", "max_data_extension_time_in_days", "default_ddl_collation", "columns", "constraints", "comment", "created_on", "database_name", "schema_name", "rows", "bytes", "owner", "dropped_on", "automatic_clustering", "search_optimization", "search_optimization_progress", "search_optimization_bytes", "owner_role_type", "budget"]
 
     def _to_model(self):
         return Table(
             name=self.name,
 
             kind=self.kind,
 
@@ -250,14 +257,16 @@
 
             search_optimization_progress=self.search_optimization_progress,
 
             search_optimization_bytes=self.search_optimization_bytes,
 
             owner_role_type=self.owner_role_type,
 
+            budget=self.budget,
+
         )
 
     @classmethod
     def _from_model(cls, model) -> TableModel:
         return TableModel(
             name=model.name,
 
@@ -301,14 +310,16 @@
 
             search_optimization_progress=model.search_optimization_progress,
 
             search_optimization_bytes=model.search_optimization_bytes,
 
             owner_role_type=model.owner_role_type,
 
+            budget=model.budget,
+
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/table/_generated/models/table_column.py` & `snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/table_column.py`

 * *Files 14% similar despite different names*

```diff
@@ -4,40 +4,42 @@
     Snowflake Table API
 
     The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 from typing import List, Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, conlist
+from snowflake.core.table._generated.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, conlist
 from snowflake.core.table._generated.models.constraint import Constraint
 
 class TableColumn(BaseModel):
     name: StrictStr = Field(...)
     datatype: StrictStr = Field(...)
     nullable: Optional[StrictBool] = True
     collate: Optional[StrictStr] = None
     default: Optional[StrictStr] = None
-    identity: Optional[StrictBool] = None
-    identity_start: Optional[StrictInt] = None
-    identity_increment: Optional[StrictInt] = None
+    autoincrement: Optional[StrictBool] = None
+    autoincrement_start: Optional[StrictInt] = None
+    autoincrement_increment: Optional[StrictInt] = None
     constraints: Optional[conlist(Constraint)] = None
     comment: Optional[StrictStr] = None
-    __properties = ["name", "datatype", "nullable", "collate", "default", "identity", "identity_start", "identity_increment", "constraints", "comment"]
+    __properties = ["name", "datatype", "nullable", "collate", "default", "autoincrement", "autoincrement_start", "autoincrement_increment", "constraints", "comment"]
 
 
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
@@ -84,19 +86,19 @@
 
             "nullable": obj.get("nullable") if obj.get("nullable") is not None else True,
 
             "collate": obj.get("collate"),
 
             "default": obj.get("default"),
 
-            "identity": obj.get("identity"),
+            "autoincrement": obj.get("autoincrement"),
 
-            "identity_start": obj.get("identity_start"),
+            "autoincrement_start": obj.get("autoincrement_start"),
 
-            "identity_increment": obj.get("identity_increment"),
+            "autoincrement_increment": obj.get("autoincrement_increment"),
 
             "constraints": [Constraint.from_dict(_item) for _item in obj.get("constraints")] if obj.get("constraints") is not None else None,
 
             "comment": obj.get("comment"),
 
         })
         return _obj
@@ -110,49 +112,49 @@
         self,
         name: str,
         datatype: str,
         # optional properties
         nullable: Optional[bool] = True,
         collate: Optional[str] = None,
         default: Optional[str] = None,
-        identity: Optional[bool] = None,
-        identity_start: Optional[int] = None,
-        identity_increment: Optional[int] = None,
+        autoincrement: Optional[bool] = None,
+        autoincrement_start: Optional[int] = None,
+        autoincrement_increment: Optional[int] = None,
         constraints: Optional[List[Constraint]] = None,
         comment: Optional[str] = None,
     ):
         self.name = name
         self.datatype = datatype
         self.nullable = nullable
         self.collate = collate
         self.default = default
-        self.identity = identity
-        self.identity_start = identity_start
-        self.identity_increment = identity_increment
+        self.autoincrement = autoincrement
+        self.autoincrement_start = autoincrement_start
+        self.autoincrement_increment = autoincrement_increment
         self.constraints = constraints
         self.comment = comment
-    __properties = ["name", "datatype", "nullable", "collate", "default", "identity", "identity_start", "identity_increment", "constraints", "comment"]
+    __properties = ["name", "datatype", "nullable", "collate", "default", "autoincrement", "autoincrement_start", "autoincrement_increment", "constraints", "comment"]
 
     def _to_model(self):
         return TableColumn(
             name=self.name,
 
             datatype=self.datatype,
 
             nullable=self.nullable,
 
             collate=self.collate,
 
             default=self.default,
 
-            identity=self.identity,
+            autoincrement=self.autoincrement,
 
-            identity_start=self.identity_start,
+            autoincrement_start=self.autoincrement_start,
 
-            identity_increment=self.identity_increment,
+            autoincrement_increment=self.autoincrement_increment,
 
             constraints=[x._to_model() for x in self.constraints] if self.constraints is not None else None,
 
             comment=self.comment,
 
         )
 
@@ -165,19 +167,19 @@
 
             nullable=model.nullable,
 
             collate=model.collate,
 
             default=model.default,
 
-            identity=model.identity,
+            autoincrement=model.autoincrement,
 
-            identity_start=model.identity_start,
+            autoincrement_start=model.autoincrement_start,
 
-            identity_increment=model.identity_increment,
+            autoincrement_increment=model.autoincrement_increment,
 
             constraints=[ConstraintModel._from_model(x) for x in model.constraints] if model.constraints is not None else None,
 
             comment=model.comment,
 
         )
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/table/_generated/models/unique_key.py` & `snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/unique_key.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,14 +4,16 @@
     Snowflake Table API
 
     The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/task/__init__.py` & `snowflake_core-0.8.0/src/snowflake/core/task/__init__.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.7.0/src/snowflake/core/task/_task.py` & `snowflake_core-0.8.0/src/snowflake/core/task/_task.py`

 * *Files 1% similar despite different names*

```diff
@@ -6,40 +6,41 @@
 from logging import getLogger
 from types import ModuleType
 from typing import (
     TYPE_CHECKING,
     Any,
     Callable,
     Dict,
+    Iterable,
+    Iterator,
     List,
     NamedTuple,
     Optional,
     Tuple,
     Union,
 )
 
 from snowflake.core._common import (
     CreateMode,
     SchemaObjectCollectionParent,
     SchemaObjectReferenceMixin,
 )
-from snowflake.core._internal.pydantic_compatibility import StrictStr
 from snowflake.core._internal.telemetry import api_telemetry
-from snowflake.core.paging import PagedIter
 from snowflake.core.task._generated import (
     CronSchedule,
     MinutesSchedule,
     TaskApi,
     TaskRun,
     TaskSchedule,
 )
-from snowflake.core.task._generated.api_client import BridgeApiClient
+from snowflake.core.task._generated.api_client import BridgeApiClient, StoredProcApiClient
 from snowflake.core.task._generated.models import (
     Task as TaskModel,
 )
+from snowflake.core.task._generated.pydantic_compatibility import StrictStr
 from snowflake.snowpark._internal.udf_utils import generate_call_python_sp_sql
 from snowflake.snowpark._internal.utils import is_in_stored_procedure
 from snowflake.snowpark.stored_procedure import StoredProcedure
 from snowflake.snowpark.types import DataType
 
 
 if TYPE_CHECKING:
@@ -443,14 +444,16 @@
         >>> tasks: TaskCollection = root.databases["mydb"].schemas["myschema"].tasks
         >>> mytask = tasks["mytask"]
         >>> # Then call other APIs to manage this task.
         >>> mytask.resume()
         >>> mytask.suspend()
     """
 
+    _supports_rest_api = True
+
     def __init__(self, name: str, collection: "TaskCollection") -> None:
         self.collection = collection
         self.name = name
 
     @api_telemetry
     def create_or_update(self, task: Task) -> None:
         """Create or update a task in the Snowflake database.
@@ -538,15 +541,15 @@
             _list_task_converter(x)
             for x in self.collection._api.fetch_task_dependents(
                 self.database.name, self.schema.name, self.name, async_req=False
             )
         ]
 
     @api_telemetry
-    def get_complete_graphs(self, *, error_only: bool = True) -> List[TaskRun]:
+    def get_complete_graphs(self, *, error_only: bool = True) -> Iterable[TaskRun]:
         """Return the status of a completed graph run.
 
         It returns details for runs that executed successfully, failed, or were cancelled in the past 60 minutes.
 
         To retrieve the details for graph runs that are currently executing, or are next scheduled to run within the
         next 8 days, use :meth:`get_current_graphs`.
         """
@@ -555,15 +558,15 @@
             self.schema.name,
             self.name,
             error_only=error_only,
             async_req=False,
         )
 
     @api_telemetry
-    def get_current_graphs(self) -> List[TaskRun]:
+    def get_current_graphs(self) -> Iterable[TaskRun]:
         """Return the status of a graph run that is currently scheduled or is executing.
 
         It returns details for graph runs that are currently executing or are next scheduled to run within the next 8
         days.  To retrieve the details for graph runs that have completed in the past 60 minutes, use
         :meth:`get_complete_graphs`.
 
         """
@@ -585,15 +588,16 @@
         super().__init__(schema, TaskResource)
         self._api = TaskApi(
             root=self.root,
             resource_class=self._ref_class,
             bridge_client=BridgeApiClient(
                 root=self.root,
                 snowflake_connection=self._connection or self._session._conn._conn
-            )
+            ),
+            sproc_client=StoredProcApiClient(root=self.root)
         )
 
     @api_telemetry
     def create(
         self,
         task: Task,
         *,
@@ -628,36 +632,35 @@
     def iter(
         self,
         *,
         like: Optional[str] = None,
         starts_with: Optional[str] = None,
         limit: Optional[int] = None,
         root_only: bool = False,
-    ) -> PagedIter[Task]:
+    ) -> Iterator[Task]:
         """Search for tasks in Snowflake.
 
         Args:
             like: The pattern of the Task name. Use ``%`` to represent any number of characters and ``?`` for a
                 single character.
             startswith: The task name starts with this string.
             root_only: Look for root tasks only.
         """
-        return PagedIter(
-            data=self._api.list_tasks(
-                self.database.name,
-                self.schema.name,
-                root_only,
-                StrictStr(like) if like is not None else None,
-                StrictStr(starts_with) if starts_with else None,
-                limit,
-                async_req=False,
-            ),
-            map_=_list_task_converter,
+        tasks = self._api.list_tasks(
+            self.database.name,
+            self.schema.name,
+            root_only,
+            StrictStr(like) if like is not None else None,
+            StrictStr(starts_with) if starts_with else None,
+            limit,
+            async_req=False,
         )
 
+        return map(_list_task_converter, iter(tasks))
+
     def _extract_definition(self, task: Task) -> None:
         definition = task.definition
         if isinstance(definition, StoredProcedureCall):
             if not task.warehouse:
                 raise ValueError(
                     "warehouse must be specified when creating a task with a StoredProcedureCall object"
                 )
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/task/context.py` & `snowflake_core-0.8.0/src/snowflake/core/task/context.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.7.0/src/snowflake/core/task/dagv1.py` & `snowflake_core-0.8.0/src/snowflake/core/task/dagv1.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.7.0/src/snowflake/core/task/_generated/__init__.py` & `snowflake_core-0.8.0/src/snowflake/core/task/_generated/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -6,14 +6,16 @@
     Snowflake Task API
 
     The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 __version__ = "1.0.0"
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/task/_generated/api_client.py` & `snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/api_client.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,37 +1,44 @@
 # coding: utf-8
 """
-    Snowflake Task API
+    Snowflake Warehouse API
 
-    The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
+    The Snowflake Warehouse API is a REST API that you can use to access, customize and manage virtual warehouse in a Snowflake account.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 from __future__ import absolute_import
 
 import atexit
 import datetime
+import time
 import typing
 from dateutil.parser import parse
 import json
 import mimetypes
 from multiprocessing.pool import ThreadPool
 import os
 import re
 import tempfile
 
 from urllib.parse import quote
 
-from snowflake.core.task._generated.configuration import Configuration
-import snowflake.core.task._generated.models
-from snowflake.core.task._generated import rest
-from snowflake.core.exceptions import _APIValueError, APIError
+from functools import partial
+
+from snowflake.core.warehouse._generated.configuration import Configuration
+import snowflake.core.warehouse._generated.models
+from snowflake.core.warehouse._generated import rest
+from snowflake.core.warehouse._generated.paging import PagedIter
+from snowflake.core.exceptions import _APIValueError, APIError, InvalidResponseError, LongRunningQueryTimeout
+from snowflake.core.version import __version__ as VERSION
 
 if typing.TYPE_CHECKING:
     from snowflake.core._root import Root
 
 
 class ApiClient(object):
     """Generic API client for OpenAPI client library builds.
@@ -62,41 +69,48 @@
         'float': float,
         'str': str,
         'bool': bool,
         'date': datetime.date,
         'datetime': datetime.datetime,
         'object': object,
     }
+    DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING = 600.0 # default 10 minutes for long running queries
     _pool = None
 
     def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
                  cookie=None, pool_threads=1):
         # use default configuraiton if none is provided
         if configuration is None:
             configuration = Configuration.get_default()
         self.configuration = configuration
         if (
             hasattr(root, "_connection")
+            and root._connection is not None
             and hasattr(root._connection, "_rest")
+            and root._connection._rest is not None
+            and hasattr(root._connection._rest, "_protocol")
+            and hasattr(root._connection._rest, "_host")
+            and hasattr(root._connection._rest, "_port")
         ):
             self.configuration.host = (
                 f"{root._connection._rest._protocol}://"
                 + root._connection._rest._host
                 + f":{root._connection._rest._port}"
             )
         self.pool_threads = pool_threads
 
         self.rest_client = rest.RESTClientObject(root, configuration)
         self.default_headers = {}
         if header_name is not None:
             self.default_headers[header_name] = header_value
         self.cookie = cookie
         # Set default User-Agent.
-        self.user_agent = 'OpenAPI-Generator/1.0.0/python'
+        self.user_agent = 'python_api/' + VERSION + ''
         self.client_side_validation = configuration.client_side_validation
+        self._enable_long_running_polling = getattr(root, "_enable_long_running_polling", False)
 
     def __enter__(self):
         return self
 
     def __exit__(self, exc_type, exc_value, traceback):
         self.close()
 
@@ -154,15 +168,15 @@
         It stores default ApiClient.
 
         :param default: object of ApiClient.
         """
         cls._default = default
 
     def __call_api(
-            self, resource_path, method, path_params=None,
+            self, root, resource_path, method, path_params=None,
             query_params=None, header_params=None, body=None, post_params=None,
             files=None, response_types_map=None, auth_settings=None,
             _return_http_data_only=None, collection_formats=None,
             _preload_content=True, _request_timeout=None, _host=None,
             _request_auth=None):
 
         config = self.configuration
@@ -218,22 +232,25 @@
         if query_params:
             query_params = self.sanitize_for_serialization(query_params)
             url_query = self.parameters_to_url_query(query_params,
                                                      collection_formats)
             url += "?" + url_query
 
         try:
-            # perform request and return response
-            response_data = self.request(
-                method, url,
+            # perform request and return response, maybe with retry
+            response_data = self.request_with_retry(
+                root,
+                method,
+                url,
                 query_params=query_params,
                 headers=header_params,
                 post_params=post_params, body=body,
                 _preload_content=_preload_content,
-                _request_timeout=_request_timeout)
+                _request_timeout=_request_timeout
+            )
         except APIError as e:
             if e.body:
                 e.body = e.body.decode('utf-8')
             raise e
 
         self.last_response = response_data
 
@@ -251,15 +268,52 @@
         #         match = re.search(r"charset=([a-zA-Z\-\d]+)[\s;]?", content_type)
         #     encoding = match.group(1) if match else "utf-8"
         #     response_data.data = response_data.data.decode(encoding)
 
         # deserialize response data
 
         if response_type:
-            return_data = self.deserialize(response_data, response_type)
+            large_results_resp = self.large_results(response_data)
+            if large_results_resp is None:
+                # regular, non-large results use case
+                return_data = self.deserialize(response_data, response_type)
+            else:
+                # This should be the normal way in which we figure out where to get the results from,
+                # as well as how many chunks there are to get. Due to a bug, we use the alternate logic
+                # (in the "else" clause) to infer the URL from the UUID
+                if "Link" in response_data.getheaders():
+                    results_path, num_chunks = self.get_path_and_chunk_count_from_header(response_data.getheaders()["Link"])
+                else:
+                    handler_id = large_results_resp['result_handler']
+                    results_path = '/api/v2/results/' + handler_id
+
+                    # If there is no "Link" header, there is just one chunk
+                    num_chunks = 1
+
+                # Closure for fetching the next chunk in the PagedIter iterator
+                def _fetch_next_chunk(chunk_index, deserialize_type):
+                    # For now, do this because query_params is not actually being used properly in self.request
+                    chunk_url = f'{self.configuration.host}{results_path}?page={chunk_index}'
+
+                    chunk_response_data = self.request(
+                        root,
+                        "GET",
+                        chunk_url,
+                        headers=header_params,
+                        _preload_content=True,
+                        _request_timeout=_request_timeout)
+
+                    return self.deserialize(chunk_response_data, deserialize_type)
+
+                if 'Iterable' in response_type:
+                    return PagedIter(partial(_fetch_next_chunk, deserialize_type=response_type), num_chunks)
+                else:
+                    # At most, we should only need to fetch one chunk if it's a point lookup,
+                    # i.e., one row return
+                    return_data = _fetch_next_chunk(0, response_type)
         else:
             return_data = None
 
         if _return_http_data_only:
             return (return_data)
         else:
             return (return_data, response_data.status,
@@ -335,42 +389,42 @@
 
         :return: object.
         """
         if data is None:
             return None
 
         if type(klass) == str:
-            if klass.startswith('List['):
-                sub_kls = re.match(r'List\[(.*)]', klass).group(1)
+            if klass.startswith('Iterable['):
+                sub_kls = re.match(r'Iterable\[(.*)]', klass).group(1)
                 return [self.__deserialize(sub_data, sub_kls)
                         for sub_data in data]
 
             if klass.startswith('Dict['):
                 sub_kls = re.match(r'Dict\[([^,]*), (.*)]', klass).group(2)
                 return {k: self.__deserialize(v, sub_kls)
                         for k, v in data.items()}
 
             # convert str to class
             if klass in self.NATIVE_TYPES_MAPPING:
                 klass = self.NATIVE_TYPES_MAPPING[klass]
             else:
-                klass = getattr(snowflake.core.task._generated.models, klass)
+                klass = getattr(snowflake.core.warehouse._generated.models, klass)
 
         if klass in self.PRIMITIVE_TYPES:
             return self.__deserialize_primitive(data, klass)
         elif klass == object:
             return self.__deserialize_object(data)
         elif klass == datetime.date:
             return self.__deserialize_date(data)
         elif klass == datetime.datetime:
             return self.__deserialize_datetime(data)
         else:
             return self.__deserialize_model(data, klass)
 
-    def call_api(self, resource_path, method,
+    def call_api(self, root, resource_path, method,
                  path_params=None, query_params=None, header_params=None,
                  body=None, post_params=None, files=None,
                  response_types_map=None, auth_settings=None,
                  async_req=None, _return_http_data_only=None,
                  collection_formats=None,_preload_content=True,
                   _request_timeout=None, _host=None, _request_auth=None):
         """Makes the HTTP request (synchronous) and returns deserialized data.
@@ -410,88 +464,198 @@
             If async_req parameter is True,
             the request will be called asynchronously.
             The method will return the request thread.
             If parameter async_req is False or missing,
             then the method will return the response directly.
         """
         if not async_req:
-            return self.__call_api(resource_path, method,
-                                   path_params, query_params, header_params,
-                                   body, post_params, files,
-                                   response_types_map, auth_settings,
-                                   _return_http_data_only, collection_formats,
-                                   _preload_content, _request_timeout, _host,
-                                   _request_auth)
-
-        return self.pool.apply_async(self.__call_api, (resource_path,
-                                                       method, path_params,
-                                                       query_params,
-                                                       header_params, body,
-                                                       post_params, files,
-                                                       response_types_map,
-                                                       auth_settings,
-                                                       _return_http_data_only,
-                                                       collection_formats,
-                                                       _preload_content,
-                                                       _request_timeout,
-                                                       _host, _request_auth))
+            return self.__call_api(
+                root,
+                resource_path,
+                method,
+                path_params,
+                query_params,
+                header_params,
+                body,
+                post_params,
+                files,
+                response_types_map,
+                auth_settings,
+                _return_http_data_only,
+                collection_formats,
+                _preload_content,
+                _request_timeout,
+                _host,
+                _request_auth,
+            )
+
+        return self.pool.apply_async(
+            self.__call_api,
+            (
+                root,
+                resource_path,
+                method,
+                path_params,
+                query_params,
+                header_params,
+                body,
+                post_params,
+                files,
+                response_types_map,
+                auth_settings,
+                _return_http_data_only,
+                collection_formats,
+                _preload_content,
+                _request_timeout,
+                _host,
+                _request_auth,
+            )
+        )
 
-    def request(self, method, url, query_params=None, headers=None,
+
+    def request_with_retry(
+                self, root, method, url, query_params=None, headers=None,
+                post_params=None, body=None, _preload_content=True,
+                _request_timeout=None):
+        """
+            Response time by default one hour
+        """
+        enter_timing = time.time()
+        response_data = self.request(
+                root,
+                method,
+                url,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params, body=body,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout)
+
+        if response_data.status != 202 or not self._enable_long_running_polling:
+            return response_data
+
+        result_endpoint = response_data.getheader('Location')
+        if result_endpoint is None:
+            raise InvalidResponseError("Long Running Queries result endpoint is missing")
+
+        if _request_timeout is None:
+            _request_timeout = self.DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING
+        wait_for_results_timeout = enter_timing + _request_timeout
+
+        exponential_wait_time = 1 # wait time increases exponentially, 30% more everytime
+        while True:
+            time_remaining = wait_for_results_timeout - time.time()
+            if time_remaining <= 0:
+                break
+            wait_time = min(exponential_wait_time, time_remaining)
+            time.sleep(wait_time)
+            response_data = self.request(
+                root,
+                'GET',
+                self.configuration.host + result_endpoint,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params, body=body,
+                _preload_content=_preload_content,
+                _request_timeout=max(time_remaining - wait_time, 1)
+                # request_timeout can never be zero
+            )
+
+            if response_data.status != 202:
+                return response_data
+
+            exponential_wait_time *= 1.3
+
+        raise LongRunningQueryTimeout("Long running queries timeout")
+
+
+    def request(self, root, method, url, query_params=None, headers=None,
                 post_params=None, body=None, _preload_content=True,
                 _request_timeout=None):
         """Makes the HTTP request using RESTClient."""
         if method == "GET":
-            return self.rest_client.get_request(url,
-                                        query_params=query_params,
-                                        _preload_content=_preload_content,
-                                        _request_timeout=_request_timeout,
-                                        headers=headers)
+            return self.rest_client.get_request(
+                root,
+                url,
+                query_params=query_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                headers=headers,
+            )
         elif method == "HEAD":
-            return self.rest_client.head_request(url,
-                                         query_params=query_params,
-                                         _preload_content=_preload_content,
-                                         _request_timeout=_request_timeout,
-                                         headers=headers)
+            return self.rest_client.head_request(
+                root,
+                url,
+                query_params=query_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                headers=headers,
+            )
         elif method == "OPTIONS":
-            return self.rest_client.options_request(url,
-                                            query_params=query_params,
-                                            headers=headers,
-                                            _preload_content=_preload_content,
-                                            _request_timeout=_request_timeout)
+            return self.rest_client.options_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+            )
         elif method == "POST":
-            return self.rest_client.post_request(url,
-                                         query_params=query_params,
-                                         headers=headers,
-                                         post_params=post_params,
-                                         _preload_content=_preload_content,
-                                         _request_timeout=_request_timeout,
-                                         body=body)
+            return self.rest_client.post_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                body=body,
+            )
         elif method == "PUT":
-            return self.rest_client.put_request(url,
-                                        query_params=query_params,
-                                        headers=headers,
-                                        post_params=post_params,
-                                        _preload_content=_preload_content,
-                                        _request_timeout=_request_timeout,
-                                        body=body)
+            try:
+                return self.rest_client.put_request(
+                    root,
+                    url,
+                    query_params=query_params,
+                    headers=headers,
+                    post_params=post_params,
+                    _preload_content=_preload_content,
+                    _request_timeout=_request_timeout,
+                    body=body,
+                )
+            except APIError as error:
+                # Raise a more helpful user error if CoA is not supported for this resource;
+                # this is represented as either 405 or 501 on the server.
+                if error.status in (405, 501):
+                    raise NotImplementedError(
+                        'create_or_update is not yet supported for warehouse. Updating warehouse '
+                        'objects is not supported yet; use create() for creating a warehouse.')
+                raise
+
         elif method == "PATCH":
-            return self.rest_client.patch_request(url,
-                                          query_params=query_params,
-                                          headers=headers,
-                                          post_params=post_params,
-                                          _preload_content=_preload_content,
-                                          _request_timeout=_request_timeout,
-                                          body=body)
+            return self.rest_client.patch_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                body=body,
+            )
         elif method == "DELETE":
-            return self.rest_client.delete_request(url,
-                                           query_params=query_params,
-                                           headers=headers,
-                                           _preload_content=_preload_content,
-                                           _request_timeout=_request_timeout,
-                                           body=body)
+            return self.rest_client.delete_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                body=body,
+            )
         else:
             raise _APIValueError(
                 "http method must be `GET`, `HEAD`, `OPTIONS`,"
                 " `POST`, `PATCH`, `PUT` or `DELETE`."
             )
 
     def parameters_to_tuples(self, params, collection_formats):
@@ -759,13 +923,73 @@
         :param data: dict, list.
         :param klass: class literal.
         :return: model object.
         """
 
         return klass.from_dict(data)
 
+    @staticmethod
+    def large_results(response):
+        try:
+            result = json.loads(response.data)
+            if ("result_handler" in result
+                    and "message" in result and
+                    'Large result set. Use provided Link' in result['message']):
+                return result
+            else:
+                return None
+        except ValueError:
+            pass
+
+        return None
+
+
+    @staticmethod
+    def get_path_and_chunk_count_from_header(links_str):
+        links_list = links_str.split(",")
+
+        def parse_links(s):
+            import re
+            # Use regex to extract necessary parts
+            #
+            # Explanation:
+            # The result links are provided to us in the form:
+            # '</api/v2/results/01b39664-0100-0001-0000-0000000430391?page=0>; rel="first"'
+            #
+            # We wish to find how many chunks there are by finding the one that has rel="last",
+            # therefore we find page index corresponding to the link with that rel value.
+            #
+            # 1. <(.*?)> matches and captures the URL inside the angle brackets
+            # 2. page=(\d+) matches 'page=' followed by one or more digits to find the page number
+            # 3. rel="([^"]*)" matches 'rel="'
+            pattern = r'<(.*?)\?page=(\d+)>; rel="([^"]*)"'
+
+            # Search using the regular expression
+            match = re.search(pattern, s)
+            if match:
+                parse_result = dict()
+                parse_result['url'], parse_result['page_number'], parse_result['rel_value'] = match.groups()
+                return parse_result
+
+            return None
+
+        parsed_links = [parse_links(link) for link in links_list]
+
+        # Find the last one
+        last_link = list(filter(lambda link: link['rel_value'].lower() == 'last', parsed_links)).pop()
+
+        # Return the URL; the number of chunks is the chunk index of the last page plus one
+        return last_link['url'], int(last_link['page_number']) + 1
+
 
 class BridgeApiClient(ApiClient):
     def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
                  cookie=None, pool_threads=1, snowflake_connection=None):
         ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
         self.rest_client = rest.BridgeClientObject(snowflake_connection)
+
+
+class StoredProcApiClient(ApiClient):
+    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
+                 cookie=None, pool_threads=1):
+        ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
+        self.rest_client = rest.StoredProcClientObject()
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/task/_generated/api_response.py` & `snowflake_core-0.8.0/src/snowflake/core/table/_generated/api_response.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 """API response object."""
 
 from __future__ import annotations
 from typing import Any, Dict, Optional
-from snowflake.core._internal.pydantic_compatibility import Field, StrictInt, StrictStr
+from snowflake.core.table._generated.pydantic_compatibility import Field, StrictInt, StrictStr
 
 class ApiResponse:
     """
     API response object
     """
 
     status_code: Optional[StrictInt] = Field(None, description="HTTP status code")
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/task/_generated/configuration.py` & `snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/configuration.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,17 +1,19 @@
 # coding: utf-8
 
 """
-    Snowflake Task API
+    Snowflake Warehouse API
 
-    The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
+    The Snowflake Warehouse API is a REST API that you can use to access, customize and manage virtual warehouse in a Snowflake account.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 import copy
 import logging
@@ -108,15 +110,15 @@
         """
         self.access_token = access_token
         """Access token
         """
         self.logger = {}
         """Logging Settings
         """
-        self.logger["package_logger"] = logging.getLogger("snowflake.core.task._generated")
+        self.logger["package_logger"] = logging.getLogger("snowflake.core.warehouse._generated")
         self.logger["urllib3_logger"] = logging.getLogger("urllib3")
         self.logger_format = '%(asctime)s %(levelname)s %(message)s'
         """Log format
         """
         self.logger_stream_handler = None
         """Log stream handler
         """
@@ -333,15 +335,15 @@
         """Gets an array of host settings
 
         :return: An array of host settings
         """
         return [
             {
                 'url': "https://org-account.snowflakecomputing.com",
-                'description': "Snowflake Task API",
+                'description': "Snowflake Warehouse API",
             }
         ]
 
     def get_host_from_settings(self, index, variables=None, servers=None):
         """Gets host URL based on the index and variables
         :param index: array index of the host settings
         :param variables: hash of variable and the corresponding value
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/task/_generated/rest.py` & `snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/rest.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,17 +1,19 @@
 # coding: utf-8
 
 """
-    Snowflake Task API
+    Snowflake Warehouse API
 
-    The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
+    The Snowflake Warehouse API is a REST API that you can use to access, customize and manage virtual warehouse in a Snowflake account.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 import json
 import logging
@@ -49,17 +51,26 @@
     def __init__(self, root: "Root", *args, **kwargs):
         self.root = root
         self.pool_manager = create_connection_pool(
             *args,
             **kwargs,
         )
 
-    def request(self, method, url, query_params=None, headers=None,
-                body=None, post_params=None, _preload_content=True,
-                _request_timeout=None):
+    def request(
+        self,
+        root,
+        method,
+        url,
+        query_params=None,
+        headers=None,
+        body=None,
+        post_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
         """Perform requests.
 
         :param method: http request method
         :param url: http request url
         :param query_params: query parameters in the url
         :param headers: http request headers
         :param body: request json body, for `application/json`
@@ -104,64 +115,64 @@
 
                 # no content type provided or payload is json
                 if not headers.get('Content-Type') or re.search('json', headers['Content-Type'], re.IGNORECASE):
                     request_body = None
                     if body is not None:
                         request_body = json.dumps(body)
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 elif headers['Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         fields=post_params,
                         encode_multipart=False,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 elif headers['Content-Type'] == 'multipart/form-data':
                     # must del headers['Content-Type'], or the correct
                     # Content-Type which generated by urllib3 will be
                     # overwritten.
                     del headers['Content-Type']
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         fields=post_params,
                         encode_multipart=True,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 # Pass a `string` parameter directly in the body to support
                 # other content types than Json when `body` argument is
                 # provided in serialized form
                 elif isinstance(body, str) or isinstance(body, bytes):
                     request_body = body
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 else:
                     # Cannot generate the request from given parameters
                     msg = """Cannot prepare a request message for provided
                              arguments. Please check that your arguments match
                              declared content type."""
                     raise APIError(status=0, reason=msg)
             # For `GET`, `HEAD`
             else:
                 r = self.pool_manager.request(
-                    self.root._session_token,
+                    root,
                     method,
                     url,
                     fields={},
                     preload_content=_preload_content,
                     timeout=timeout,
                     headers=headers,
                 )
@@ -191,88 +202,139 @@
             if 500 <= r.status <= 599:
                 raise ServerError(http_resp=r)
 
             raise APIError(http_resp=r)
 
         return r
 
-    def get_request(self, url, headers=None, query_params=None, _preload_content=True,
-            _request_timeout=None):
-        return self.request("GET", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
-
-    def head_request(self, url, headers=None, query_params=None, _preload_content=True,
-             _request_timeout=None):
-        return self.request("HEAD", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
+    def get_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "GET",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def head_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "HEAD",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
 
-    def options_request(self, url, headers=None, query_params=None, post_params=None,
+    def options_request(self, root, url, headers=None, query_params=None, post_params=None,
                 body=None, _preload_content=True, _request_timeout=None):
-        return self.request("OPTIONS", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "OPTIONS",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def delete_request(self, url, headers=None, query_params=None, body=None,
+    def delete_request(self, root, url, headers=None, query_params=None, body=None,
                _preload_content=True, _request_timeout=None):
-        return self.request("DELETE", url,
-                            headers=headers,
-                            query_params=query_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "DELETE",
+            url,
+            headers=headers,
+            query_params=query_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def post_request(self, url, headers=None, query_params=None, post_params=None,
+    def post_request(self, root, url, headers=None, query_params=None, post_params=None,
              body=None, _preload_content=True, _request_timeout=None):
-        return self.request("POST", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "POST",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def put_request(self, url, headers=None, query_params=None, post_params=None,
+    def put_request(self, root, url, headers=None, query_params=None, post_params=None,
             body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PUT", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "PUT",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def patch_request(self, url, headers=None, query_params=None, post_params=None,
+    def patch_request(self, root, url, headers=None, query_params=None, post_params=None,
               body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PATCH", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "PATCH",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
 
 class BridgeClientObject(object):
 
     def __init__(self, snowflake_connection: SnowflakeConnection):
         self.bridge = SnowBridge(snowflake_connection)
 
-    def request(self, method, url, query_params=None, headers=None,
-                body=None, post_params=None, _preload_content=True,
-                _request_timeout=None):
+    def request(
+        self,
+        root,
+        method,
+        url,
+        query_params=None,
+        headers=None,
+        body=None,
+        post_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
         """Perform requests.
 
         :param method: http request method
         :param url: http request url
         :param query_params: query parameters in the url
         :param headers: http request headers
         :param body: request json body, for `application/json`
@@ -315,71 +377,378 @@
             if 500 <= r.status <= 599:
                 raise ServerError(http_resp=r)
 
             raise APIError(http_resp=r)
 
         return r
 
-    def get_request(self, url, headers=None, query_params=None, _preload_content=True,
-                    _request_timeout=None):
-        return self.request("GET", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
-
-    def head_request(self, url, headers=None, query_params=None, _preload_content=True,
-                     _request_timeout=None):
-        return self.request("HEAD", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
-
-    def options_request(self, url, headers=None, query_params=None, post_params=None,
-                        body=None, _preload_content=True, _request_timeout=None):
-        return self.request("OPTIONS", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def delete_request(self, url, headers=None, query_params=None, body=None,
-                       _preload_content=True, _request_timeout=None):
-        return self.request("DELETE", url,
-                            headers=headers,
-                            query_params=query_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def post_request(self, url, headers=None, query_params=None, post_params=None,
-                     body=None, _preload_content=True, _request_timeout=None):
-        return self.request("POST", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def put_request(self, url, headers=None, query_params=None, post_params=None,
-                    body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PUT", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def patch_request(self, url, headers=None, query_params=None, post_params=None,
-                      body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PATCH", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+    def get_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "GET",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def head_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "HEAD",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def options_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "OPTIONS",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def delete_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "DELETE",
+            url,
+            headers=headers,
+            query_params=query_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def post_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "POST",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def put_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PUT",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def patch_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PATCH",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+
+class StoredProcClientObject(object):
+
+    def request(
+        self,
+        root,
+        method,
+        url,
+        query_params={},
+        headers={},
+        body={},
+        post_params={},
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        """Perform requests.
+        :param method: http request method
+        :param url: http request url
+        :param query_params: query parameters in the url
+        :param headers: http request headers
+        :param body: request json body, for `application/json`
+        :param post_params: request post parameters,
+                            `application/x-www-form-urlencoded`
+                            and `multipart/form-data`
+        :param _preload_content: if False, the urllib3.HTTPResponse object will
+                                 be returned without reading/decoding response
+                                 data. Default is True.
+        :param _request_timeout: timeout setting for this request. If one
+                                 number provided, it will be total request
+                                 timeout. It can also be a pair (tuple) of
+                                 (connection, read) timeouts.
+        """
+        method = method.upper()
+        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
+                          'PATCH', 'OPTIONS']
+        import _snowflake
+        parsed_url = urllib3.util.parse_url(url)
+        response_dict = _snowflake.send_snow_api_request(method, parsed_url.path, dict(query_params), headers, body,
+                                                         post_params, _request_timeout)
+        json_content = json.loads(response_dict["content"])
+        if "data" in json_content:
+            r = urllib3.HTTPResponse(body=json.dumps(json_content["data"]))
+        else:
+            r = urllib3.HTTPResponse(body=json.dumps(json_content).encode("utf-8"))
+        r.status = response_dict["status"]
+        if _preload_content:
+            r = RESTResponse(r)
+            # log response body
+            logger.debug("response body: %s", r.data)
+
+        if not 200 <= r.status <= 299:
+            if r.status == 401:
+                raise UnauthorizedError(http_resp=r)
+
+            if r.status == 403:
+                raise ForbiddenError(http_resp=r)
+
+            if r.status == 404:
+                raise NotFoundError(http_resp=r)
+
+            if r.status == 409:
+                raise ConflictError(http_resp=r)
+
+            if 500 <= r.status <= 599:
+                raise ServerError(http_resp=r)
+
+            raise APIError(http_resp=r)
+
+        return r
+
+    def get_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "GET",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def head_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "HEAD",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def options_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "OPTIONS",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def delete_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "DELETE",
+            url,
+            headers=headers,
+            query_params=query_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def post_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "POST",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def put_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PUT",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def patch_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PATCH",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/task/_generated/api/task_api.py` & `snowflake_core-0.8.0/src/snowflake/core/task/_generated/api/task_api.py`

 * *Files 17% similar despite different names*

```diff
@@ -4,92 +4,121 @@
     Snowflake Task API
 
     The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 import logging
 
 from typing_extensions import Annotated
-
-from typing_extensions import Annotated
 from pydantic import Field, StrictBool, StrictInt, StrictStr, constr, validator
 
 from typing import List, Optional
 
 from snowflake.core.task._generated.models.success_response import SuccessResponse
 from snowflake.core.task._generated.models.task import Task
 from snowflake.core.task._generated.models.task_run import TaskRun
+from typing import Iterable
 
-from snowflake.core._internal.pydantic_compatibility import StrictBool, StrictInt, StrictStr, constr, validate_arguments, ValidationError, validator
-from snowflake.core._internal.utils import ApiClientType
 
-from snowflake.core.task._generated.api_client import ApiClient
+from snowflake.core.task._generated.pydantic_compatibility import StrictBool, StrictInt, StrictStr, constr, validate_arguments, ValidationError, validator
+from snowflake.core._internal.snowapi_parameters import SnowApiParameters
+from snowflake.core._internal.utils import ApiClientType, is_running_inside_stored_procedure
+
 from snowflake.core.exceptions import (  # noqa: F401
     _APITypeError,
     _APIValueError
 )
 
 logger  = logging.getLogger(__name__)
 
 class TaskApi(object):
     """NOTE: This class is auto generated by OpenAPI Generator
     Ref: https://openapi-generator.tech
 
     Do not edit the class manually.
     """
 
-    def __init__(self, root, resource_class, bridge_client):
+    def __init__(self, root, resource_class, bridge_client, sproc_client):
         self._root = root
-        self._rest_client = ApiClient.get_default(root)
+        self._resource_name = 'task'
         self._resource_class = resource_class
         self._bridge_client = bridge_client
+        self._sproc_client = sproc_client
         self._chosen_client_type = ApiClientType.NONE
 
     @property
     def api_client(self):
         """
             chosen_client is the client we chose , either bridge or rest
-            new_chosen_client is the client we want to choose under the current situation ( value of _supports_rest_api + _can_use_rest_api )
+            new_chosen_client is the client we want to choose under the current situation ( value of
+            _supports_rest_api + _can_use_rest_api, and the server-controlled flag )
             We will log the change if we want to choose another client instead of the current one
         """
-        if self._resource_class._supports_rest_api and self._root._can_use_rest_api:
-            chosen_client = self._rest_client
-            new_chosen_client = ApiClientType.REST
+        from snowflake.core.task._generated.api_client import ApiClient
+
+        # Small helper function for figuring out the correct 'REST' client to use if in stored proc or not
+        def _get_rest_client():
+            if is_running_inside_stored_procedure():
+                return self._sproc_client, ApiClientType.STORED_PROC
+            else:
+                return ApiClient.get_default(self._root), ApiClientType.REST
+
+        use_bridge_override = False
+
+        # We can force use of the bridge if the server dictates it so
+        # But, don't check it for non-resources; _resource_class is not set for non-resources.
+        if self._resource_class is not None:
+            use_bridge_override = self._root.effective_parameters(refresh = False).resource_should_use_client_bridge('task')
+
+        # if the _resource_class is None (such as Session, which is not a resource), then it is implied
+        # that we use REST (or the stored_proc client)
+        if self._resource_class is None:
+            chosen_client, new_chosen_client = _get_rest_client()
+        elif use_bridge_override:
+            # Bridge override is in effect. Use the client bridge.
+            chosen_client = self._bridge_client
+            new_chosen_client = ApiClientType.BRIDGE
+        # Check if it supports REST before choosing the REST client.
+        elif self._resource_class._supports_rest_api and self._root._can_use_rest_api:
+            chosen_client, new_chosen_client = _get_rest_client()
+        # If all else fails, use the BRIDGE (if there is no REST support for this resource)
         else:
             chosen_client = self._bridge_client
             new_chosen_client = ApiClientType.BRIDGE
 
         if new_chosen_client != self._chosen_client_type:
             self._chosen_client_type = new_chosen_client
             logger.info("Going to use client-%s for this resource", new_chosen_client.name)
         return chosen_client
 
     @validate_arguments
-    def create_or_alter_task(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), task : Task, **kwargs) -> SuccessResponse:  # noqa: E501
+    def create_or_alter_task(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], task : Task, **kwargs) -> SuccessResponse:  # noqa: E501
         """Create a (or alter an existing) task  # noqa: E501
 
         Create a (or alter an existing) task. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.create_or_alter_task(database, var_schema, name, task, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param task: (required)
         :type task: Task
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -104,29 +133,29 @@
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
         return self.create_or_alter_task_with_http_info(database, var_schema, name, task, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def create_or_alter_task_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), task : Task, **kwargs):  # noqa: E501
+    def create_or_alter_task_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], task : Task, **kwargs):  # noqa: E501
         """Create a (or alter an existing) task  # noqa: E501
 
         Create a (or alter an existing) task. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.create_or_alter_task_with_http_info(database, var_schema, name, task, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param task: (required)
         :type task: Task
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
@@ -230,14 +259,15 @@
             '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
+            self._root,
             '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}', 'PUT',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
@@ -247,31 +277,31 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def create_task(self, database : constr(strict=True), var_schema : constr(strict=True), task : Task, create_mode : Optional[StrictStr] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+    def create_task(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], task : Task, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
         """Create a task  # noqa: E501
 
         Create a task, with standard create modifiers as query parameters. See the Task component definition for what is required to be provided in the request body.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.create_task(database, var_schema, task, create_mode, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
         :param task: (required)
         :type task: Task
-        :param create_mode:
+        :param create_mode: A query parameter allowing support for different modes of resource creation.
         :type create_mode: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -284,31 +314,31 @@
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
         return self.create_task_with_http_info(database, var_schema, task, create_mode, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def create_task_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), task : Task, create_mode : Optional[StrictStr] = None, **kwargs):  # noqa: E501
+    def create_task_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], task : Task, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, **kwargs):  # noqa: E501
         """Create a task  # noqa: E501
 
         Create a task, with standard create modifiers as query parameters. See the Task component definition for what is required to be provided in the request body.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.create_task_with_http_info(database, var_schema, task, create_mode, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
         :param task: (required)
         :type task: Task
-        :param create_mode:
+        :param create_mode: A query parameter allowing support for different modes of resource creation.
         :type create_mode: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -411,14 +441,15 @@
             '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
+            self._root,
             '/api/v2/databases/{database}/schemas/{schema}/tasks', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
@@ -428,32 +459,32 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def delete_task(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), if_exists : Optional[StrictBool] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Delete a task  # noqa: E501
+    def execute_task(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], retry_last : Annotated[Optional[StrictBool], Field(description="Retry the last failed run of the DAG.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+        """Execute a task object.  # noqa: E501
 
-        Delete a task with the task name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
+        Execute a task -- this is equivalent to EXECUTE IMMEDIATE.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.delete_task(database, var_schema, name, if_exists, async_req=True)
+        >>> thread = api.execute_task(database, var_schema, name, retry_last, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists:
-        :type if_exists: bool
+        :param retry_last: Retry the last failed run of the DAG.
+        :type retry_last: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
@@ -462,35 +493,35 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.delete_task_with_http_info(database, var_schema, name, if_exists, **kwargs)  # noqa: E501
+        return self.execute_task_with_http_info(database, var_schema, name, retry_last, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def delete_task_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), if_exists : Optional[StrictBool] = None, **kwargs):  # noqa: E501
-        """Delete a task  # noqa: E501
+    def execute_task_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], retry_last : Annotated[Optional[StrictBool], Field(description="Retry the last failed run of the DAG.")] = None, **kwargs):  # noqa: E501
+        """Execute a task object.  # noqa: E501
 
-        Delete a task with the task name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
+        Execute a task -- this is equivalent to EXECUTE IMMEDIATE.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.delete_task_with_http_info(database, var_schema, name, if_exists, async_req=True)
+        >>> thread = api.execute_task_with_http_info(database, var_schema, name, retry_last, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists:
-        :type if_exists: bool
+        :param retry_last: Retry the last failed run of the DAG.
+        :type retry_last: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -513,15 +544,15 @@
 
         _params = locals()
 
         _all_params = [
             'database',
             'var_schema',
             'name',
-            'if_exists'
+            'retry_last'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -532,15 +563,15 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method delete_task" % _key
+                    " to method execute_task" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
@@ -550,16 +581,16 @@
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
-        if _params.get('if_exists') is not None:  # noqa: E501
-            _query_params.append(('ifExists', _params['if_exists']))
+        if _params.get('retry_last') is not None:  # noqa: E501
+            _query_params.append(('retryLast', _params['retry_last']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -584,15 +615,16 @@
             '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}', 'DELETE',
+            self._root,
+            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}:execute', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -601,69 +633,65 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def execute_task(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), retry_last : Annotated[Optional[StrictBool], Field(description="Retry the last failed run of the DAG.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Execute a task object.  # noqa: E501
+    def fetch_task(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> Task:  # noqa: E501
+        """Fetch a task  # noqa: E501
 
-        Execute a task -- this is equivalent to EXECUTE IMMEDIATE.  # noqa: E501
+        Fetch a task using the describe command output.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.execute_task(database, var_schema, name, retry_last, async_req=True)
+        >>> thread = api.fetch_task(database, var_schema, name, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param retry_last: Retry the last failed run of the DAG.
-        :type retry_last: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: SuccessResponse
+        :rtype: Task
         """
         kwargs['_return_http_data_only'] = True
-        return self.execute_task_with_http_info(database, var_schema, name, retry_last, **kwargs)  # noqa: E501
+        return self.fetch_task_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def execute_task_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), retry_last : Annotated[Optional[StrictBool], Field(description="Retry the last failed run of the DAG.")] = None, **kwargs):  # noqa: E501
-        """Execute a task object.  # noqa: E501
+    def fetch_task_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
+        """Fetch a task  # noqa: E501
 
-        Execute a task -- this is equivalent to EXECUTE IMMEDIATE.  # noqa: E501
+        Fetch a task using the describe command output.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.execute_task_with_http_info(database, var_schema, name, retry_last, async_req=True)
+        >>> thread = api.fetch_task_with_http_info(database, var_schema, name, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param retry_last: Retry the last failed run of the DAG.
-        :type retry_last: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -677,24 +705,23 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(Task, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
             'database',
             'var_schema',
-            'name',
-            'retry_last'
+            'name'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -705,15 +732,15 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method execute_task" % _key
+                    " to method fetch_task" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
@@ -723,16 +750,14 @@
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
-        if _params.get('retry_last') is not None:  # noqa: E501
-            _query_params.append(('retryLast', _params['retry_last']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -744,28 +769,29 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "SuccessResponse",
+            '200': "Task",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
             '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}:execute', 'POST',
+            self._root,
+            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}', 'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -774,65 +800,69 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def fetch_task(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), **kwargs) -> Task:  # noqa: E501
-        """Fetch a task  # noqa: E501
+    def fetch_task_dependents(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], recursive : Annotated[Optional[StrictBool], Field(description="Specifies whether to limit the output to include only direct child tasks or to include all recursive child tasks.")] = None, **kwargs) -> Iterable[Task]:  # noqa: E501
+        """Fetch the dependent tasks of a task  # noqa: E501
 
-        Fetch a task using the describe command output.  # noqa: E501
+        This operation returns a list of the dependent tasks of the task with identifier {name}.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_task(database, var_schema, name, async_req=True)
+        >>> thread = api.fetch_task_dependents(database, var_schema, name, recursive, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
+        :param recursive: Specifies whether to limit the output to include only direct child tasks or to include all recursive child tasks.
+        :type recursive: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: Task
+        :rtype: Iterable[Task]
         """
         kwargs['_return_http_data_only'] = True
-        return self.fetch_task_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
+        return self.fetch_task_dependents_with_http_info(database, var_schema, name, recursive, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def fetch_task_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), **kwargs):  # noqa: E501
-        """Fetch a task  # noqa: E501
+    def fetch_task_dependents_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], recursive : Annotated[Optional[StrictBool], Field(description="Specifies whether to limit the output to include only direct child tasks or to include all recursive child tasks.")] = None, **kwargs):  # noqa: E501
+        """Fetch the dependent tasks of a task  # noqa: E501
 
-        Fetch a task using the describe command output.  # noqa: E501
+        This operation returns a list of the dependent tasks of the task with identifier {name}.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_task_with_http_info(database, var_schema, name, async_req=True)
+        >>> thread = api.fetch_task_dependents_with_http_info(database, var_schema, name, recursive, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
+        :param recursive: Specifies whether to limit the output to include only direct child tasks or to include all recursive child tasks.
+        :type recursive: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -846,23 +876,24 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(Task, status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(Iterable[Task], status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
             'database',
             'var_schema',
-            'name'
+            'name',
+            'recursive'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -873,15 +904,15 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method fetch_task" % _key
+                    " to method fetch_task_dependents" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
@@ -891,14 +922,16 @@
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
+        if _params.get('recursive') is not None:  # noqa: E501
+            _query_params.append(('recursive', _params['recursive']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -910,28 +943,29 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "Task",
+            '200': "Iterable[Task]",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
             '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}', 'GET',
+            self._root,
+            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}/dependents', 'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -940,65 +974,73 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def fetch_task_dependents(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), **kwargs) -> List[Task]:  # noqa: E501
-        """Fetch the dependent tasks of a task  # noqa: E501
+    def get_complete_graphs(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], result_limit : Annotated[Optional[StrictInt], Field(description="Number of results to return, at most. Default is 1000, valid range is 1 to 10000.")] = None, error_only : Annotated[Optional[StrictBool], Field(description="Whether to only return results for tasks runs that have failed. Default is false.")] = None, **kwargs) -> Iterable[TaskRun]:  # noqa: E501
+        """Get the graph runs that are completed for the task.  # noqa: E501
 
-        This operation returns a list of the dependent tasks of the task with identifier {name}.  # noqa: E501
+        This function returns details for graph runs that are completed.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_task_dependents(database, var_schema, name, async_req=True)
+        >>> thread = api.get_complete_graphs(database, var_schema, name, result_limit, error_only, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
+        :param result_limit: Number of results to return, at most. Default is 1000, valid range is 1 to 10000.
+        :type result_limit: int
+        :param error_only: Whether to only return results for tasks runs that have failed. Default is false.
+        :type error_only: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: List[Task]
+        :rtype: Iterable[TaskRun]
         """
         kwargs['_return_http_data_only'] = True
-        return self.fetch_task_dependents_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
+        return self.get_complete_graphs_with_http_info(database, var_schema, name, result_limit, error_only, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def fetch_task_dependents_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), **kwargs):  # noqa: E501
-        """Fetch the dependent tasks of a task  # noqa: E501
+    def get_complete_graphs_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], result_limit : Annotated[Optional[StrictInt], Field(description="Number of results to return, at most. Default is 1000, valid range is 1 to 10000.")] = None, error_only : Annotated[Optional[StrictBool], Field(description="Whether to only return results for tasks runs that have failed. Default is false.")] = None, **kwargs):  # noqa: E501
+        """Get the graph runs that are completed for the task.  # noqa: E501
 
-        This operation returns a list of the dependent tasks of the task with identifier {name}.  # noqa: E501
+        This function returns details for graph runs that are completed.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_task_dependents_with_http_info(database, var_schema, name, async_req=True)
+        >>> thread = api.get_complete_graphs_with_http_info(database, var_schema, name, result_limit, error_only, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
+        :param result_limit: Number of results to return, at most. Default is 1000, valid range is 1 to 10000.
+        :type result_limit: int
+        :param error_only: Whether to only return results for tasks runs that have failed. Default is false.
+        :type error_only: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -1012,23 +1054,25 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(List[Task], status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(Iterable[TaskRun], status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
             'database',
             'var_schema',
-            'name'
+            'name',
+            'result_limit',
+            'error_only'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -1039,15 +1083,15 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method fetch_task_dependents" % _key
+                    " to method get_complete_graphs" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
@@ -1057,14 +1101,18 @@
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
+        if _params.get('result_limit') is not None:  # noqa: E501
+            _query_params.append(('resultLimit', _params['result_limit']))
+        if _params.get('error_only') is not None:  # noqa: E501
+            _query_params.append(('errorOnly', _params['error_only']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -1076,28 +1124,29 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "List[Task]",
+            '200': "Iterable[TaskRun]",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
             '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}/dependents', 'GET',
+            self._root,
+            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}/complete_graphs', 'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -1106,73 +1155,69 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def get_complete_graphs(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), result_limit : Annotated[Optional[StrictInt], Field(description="Number of results to return, at most. Default is 1000, valid range is 1 to 10000.")] = None, error_only : Annotated[Optional[StrictBool], Field(description="Whether to only return results for tasks runs that have failed. Default is false.")] = None, **kwargs) -> List[TaskRun]:  # noqa: E501
-        """Get the graph runs that are completed for the task.  # noqa: E501
+    def get_current_graphs(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], result_limit : Optional[StrictInt] = None, **kwargs) -> Iterable[TaskRun]:  # noqa: E501
+        """Get the graph runs that are executing or scheduled for the task for the next 8 days.  # noqa: E501
 
-        This function returns details for graph runs that are completed.  # noqa: E501
+        This function returns details for graph runs that are currently executing or are next scheduled to run within the next 8 days.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.get_complete_graphs(database, var_schema, name, result_limit, error_only, async_req=True)
+        >>> thread = api.get_current_graphs(database, var_schema, name, result_limit, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param result_limit: Number of results to return, at most. Default is 1000, valid range is 1 to 10000.
+        :param result_limit:
         :type result_limit: int
-        :param error_only: Whether to only return results for tasks runs that have failed. Default is false.
-        :type error_only: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: List[TaskRun]
+        :rtype: Iterable[TaskRun]
         """
         kwargs['_return_http_data_only'] = True
-        return self.get_complete_graphs_with_http_info(database, var_schema, name, result_limit, error_only, **kwargs)  # noqa: E501
+        return self.get_current_graphs_with_http_info(database, var_schema, name, result_limit, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def get_complete_graphs_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), result_limit : Annotated[Optional[StrictInt], Field(description="Number of results to return, at most. Default is 1000, valid range is 1 to 10000.")] = None, error_only : Annotated[Optional[StrictBool], Field(description="Whether to only return results for tasks runs that have failed. Default is false.")] = None, **kwargs):  # noqa: E501
-        """Get the graph runs that are completed for the task.  # noqa: E501
+    def get_current_graphs_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], result_limit : Optional[StrictInt] = None, **kwargs):  # noqa: E501
+        """Get the graph runs that are executing or scheduled for the task for the next 8 days.  # noqa: E501
 
-        This function returns details for graph runs that are completed.  # noqa: E501
+        This function returns details for graph runs that are currently executing or are next scheduled to run within the next 8 days.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.get_complete_graphs_with_http_info(database, var_schema, name, result_limit, error_only, async_req=True)
+        >>> thread = api.get_current_graphs_with_http_info(database, var_schema, name, result_limit, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param result_limit: Number of results to return, at most. Default is 1000, valid range is 1 to 10000.
+        :param result_limit:
         :type result_limit: int
-        :param error_only: Whether to only return results for tasks runs that have failed. Default is false.
-        :type error_only: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -1186,25 +1231,24 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(List[TaskRun], status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(Iterable[TaskRun], status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
             'database',
             'var_schema',
             'name',
-            'result_limit',
-            'error_only'
+            'result_limit'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -1215,15 +1259,15 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method get_complete_graphs" % _key
+                    " to method get_current_graphs" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
@@ -1235,16 +1279,14 @@
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
         if _params.get('result_limit') is not None:  # noqa: E501
             _query_params.append(('resultLimit', _params['result_limit']))
-        if _params.get('error_only') is not None:  # noqa: E501
-            _query_params.append(('errorOnly', _params['error_only']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -1256,28 +1298,29 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "List[TaskRun]",
+            '200': "Iterable[TaskRun]",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
             '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}/complete_graphs', 'GET',
+            self._root,
+            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}/current_graphs', 'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -1286,69 +1329,77 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def get_current_graphs(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), result_limit : Optional[StrictInt] = None, **kwargs) -> List[TaskRun]:  # noqa: E501
-        """Get the graph runs that are executing or scheduled for the task for the next 8 days.  # noqa: E501
+    def list_tasks(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], root_only : Annotated[Optional[StrictBool], Field(description="A query parameter that filters the command output to return only root resources (resources with no predecessors).")] = None, like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, starts_with : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.")] = None, show_limit : Annotated[Optional[StrictInt], Field(description="A query parameter that limits the maximum number of rows returned by a command.")] = None, **kwargs) -> Iterable[Task]:  # noqa: E501
+        """List tasks  # noqa: E501
 
-        This function returns details for graph runs that are currently executing or are next scheduled to run within the next 8 days.  # noqa: E501
+        Lists tasks under the database and schema, with show options as query parameters.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.get_current_graphs(database, var_schema, name, result_limit, async_req=True)
+        >>> thread = api.list_tasks(database, var_schema, root_only, like, starts_with, show_limit, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
-        :type name: str
-        :param result_limit:
-        :type result_limit: int
+        :param root_only: A query parameter that filters the command output to return only root resources (resources with no predecessors).
+        :type root_only: bool
+        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
+        :type like: str
+        :param starts_with: A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
+        :type starts_with: str
+        :param show_limit: A query parameter that limits the maximum number of rows returned by a command.
+        :type show_limit: int
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: List[TaskRun]
+        :rtype: Iterable[Task]
         """
         kwargs['_return_http_data_only'] = True
-        return self.get_current_graphs_with_http_info(database, var_schema, name, result_limit, **kwargs)  # noqa: E501
+        return self.list_tasks_with_http_info(database, var_schema, root_only, like, starts_with, show_limit, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def get_current_graphs_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), result_limit : Optional[StrictInt] = None, **kwargs):  # noqa: E501
-        """Get the graph runs that are executing or scheduled for the task for the next 8 days.  # noqa: E501
+    def list_tasks_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], root_only : Annotated[Optional[StrictBool], Field(description="A query parameter that filters the command output to return only root resources (resources with no predecessors).")] = None, like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, starts_with : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.")] = None, show_limit : Annotated[Optional[StrictInt], Field(description="A query parameter that limits the maximum number of rows returned by a command.")] = None, **kwargs):  # noqa: E501
+        """List tasks  # noqa: E501
 
-        This function returns details for graph runs that are currently executing or are next scheduled to run within the next 8 days.  # noqa: E501
+        Lists tasks under the database and schema, with show options as query parameters.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.get_current_graphs_with_http_info(database, var_schema, name, result_limit, async_req=True)
+        >>> thread = api.list_tasks_with_http_info(database, var_schema, root_only, like, starts_with, show_limit, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
-        :type name: str
-        :param result_limit:
-        :type result_limit: int
+        :param root_only: A query parameter that filters the command output to return only root resources (resources with no predecessors).
+        :type root_only: bool
+        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
+        :type like: str
+        :param starts_with: A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
+        :type starts_with: str
+        :param show_limit: A query parameter that limits the maximum number of rows returned by a command.
+        :type show_limit: int
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -1362,24 +1413,26 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(List[TaskRun], status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(Iterable[Task], status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
             'database',
             'var_schema',
-            'name',
-            'result_limit'
+            'root_only',
+            'like',
+            'starts_with',
+            'show_limit'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -1390,34 +1443,38 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method get_current_graphs" % _key
+                    " to method list_tasks" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
         if _params['database']:
             _path_params['database'] = _params['database']
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
-        if _params['name']:
-            _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
-        if _params.get('result_limit') is not None:  # noqa: E501
-            _query_params.append(('resultLimit', _params['result_limit']))
+        if _params.get('root_only') is not None:  # noqa: E501
+            _query_params.append(('rootOnly', _params['root_only']))
+        if _params.get('like') is not None:  # noqa: E501
+            _query_params.append(('like', _params['like']))
+        if _params.get('starts_with') is not None:  # noqa: E501
+            _query_params.append(('startsWith', _params['starts_with']))
+        if _params.get('show_limit') is not None:  # noqa: E501
+            _query_params.append(('showLimit', _params['show_limit']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -1429,28 +1486,30 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "List[TaskRun]",
+            '200': "Iterable[Task]",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '409': "ErrorResponse",
             '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}/current_graphs', 'GET',
+            self._root,
+            '/api/v2/databases/{database}/schemas/{schema}/tasks', 'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -1459,77 +1518,65 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def list_tasks(self, database : constr(strict=True), var_schema : constr(strict=True), root_only : Optional[StrictBool] = None, like : Optional[StrictStr] = None, starts_with : Optional[StrictStr] = None, show_limit : Optional[StrictInt] = None, **kwargs) -> List[Task]:  # noqa: E501
-        """List tasks  # noqa: E501
+    def resume_task(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> SuccessResponse:  # noqa: E501
+        """Resume a suspended task.  # noqa: E501
 
-        Lists tasks under the database and schema, with show options as query parameters.  # noqa: E501
+        Resumes a suspended task object. This is equivalento an ALTER TASK ... RESUME.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.list_tasks(database, var_schema, root_only, like, starts_with, show_limit, async_req=True)
+        >>> thread = api.resume_task(database, var_schema, name, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param root_only:
-        :type root_only: bool
-        :param like:
-        :type like: str
-        :param starts_with:
-        :type starts_with: str
-        :param show_limit:
-        :type show_limit: int
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: List[Task]
+        :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.list_tasks_with_http_info(database, var_schema, root_only, like, starts_with, show_limit, **kwargs)  # noqa: E501
+        return self.resume_task_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def list_tasks_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), root_only : Optional[StrictBool] = None, like : Optional[StrictStr] = None, starts_with : Optional[StrictStr] = None, show_limit : Optional[StrictInt] = None, **kwargs):  # noqa: E501
-        """List tasks  # noqa: E501
+    def resume_task_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
+        """Resume a suspended task.  # noqa: E501
 
-        Lists tasks under the database and schema, with show options as query parameters.  # noqa: E501
+        Resumes a suspended task object. This is equivalento an ALTER TASK ... RESUME.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.list_tasks_with_http_info(database, var_schema, root_only, like, starts_with, show_limit, async_req=True)
+        >>> thread = api.resume_task_with_http_info(database, var_schema, name, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param root_only:
-        :type root_only: bool
-        :param like:
-        :type like: str
-        :param starts_with:
-        :type starts_with: str
-        :param show_limit:
-        :type show_limit: int
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -1543,26 +1590,23 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(List[Task], status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
             'database',
             'var_schema',
-            'root_only',
-            'like',
-            'starts_with',
-            'show_limit'
+            'name'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -1573,38 +1617,32 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method list_tasks" % _key
+                    " to method resume_task" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
         if _params['database']:
             _path_params['database'] = _params['database']
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
+        if _params['name']:
+            _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
-        if _params.get('root_only') is not None:  # noqa: E501
-            _query_params.append(('rootOnly', _params['root_only']))
-        if _params.get('like') is not None:  # noqa: E501
-            _query_params.append(('like', _params['like']))
-        if _params.get('starts_with') is not None:  # noqa: E501
-            _query_params.append(('startsWith', _params['starts_with']))
-        if _params.get('show_limit') is not None:  # noqa: E501
-            _query_params.append(('showLimit', _params['show_limit']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -1616,29 +1654,29 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "List[Task]",
+            '200': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
-            '409': "ErrorResponse",
             '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/tasks', 'GET',
+            self._root,
+            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}:resume', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -1647,29 +1685,29 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def resume_task(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), **kwargs) -> SuccessResponse:  # noqa: E501
-        """Resume a suspended task.  # noqa: E501
+    def suspend_task(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> SuccessResponse:  # noqa: E501
+        """Suspends a running task.  # noqa: E501
 
-        Resumes a suspended task object. This is equivalento an ALTER TASK ... RESUME.  # noqa: E501
+        Suspends a running task. This is equivalent to an ALTER TASK ... SUSPEND.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.resume_task(database, var_schema, name, async_req=True)
+        >>> thread = api.suspend_task(database, var_schema, name, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -1679,32 +1717,32 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.resume_task_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
+        return self.suspend_task_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def resume_task_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), **kwargs):  # noqa: E501
-        """Resume a suspended task.  # noqa: E501
+    def suspend_task_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
+        """Suspends a running task.  # noqa: E501
 
-        Resumes a suspended task object. This is equivalento an ALTER TASK ... RESUME.  # noqa: E501
+        Suspends a running task. This is equivalent to an ALTER TASK ... SUSPEND.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.resume_task_with_http_info(database, var_schema, name, async_req=True)
+        >>> thread = api.suspend_task_with_http_info(database, var_schema, name, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -1746,15 +1784,15 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method resume_task" % _key
+                    " to method suspend_task" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
@@ -1796,15 +1834,16 @@
             '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}:resume', 'POST',
+            self._root,
+            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}:suspend', 'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
@@ -1813,30 +1852,32 @@
             _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
     @validate_arguments
-    def suspend_task(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), **kwargs) -> SuccessResponse:  # noqa: E501
-        """Suspends a running task.  # noqa: E501
+    def delete_task(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+        """Delete a task  # noqa: E501
 
-        Suspends a running task. This is equivalent to an ALTER TASK ... SUSPEND.  # noqa: E501
+        Delete a task with the task name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.suspend_task(database, var_schema, name, async_req=True)
+        >>> thread = api.delete_task(database, var_schema, name, if_exists, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
+        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
@@ -1845,33 +1886,35 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.suspend_task_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
+        return self.delete_task_with_http_info(database, var_schema, name, if_exists, **kwargs)  # noqa: E501
 
     @validate_arguments
-    def suspend_task_with_http_info(self, database : constr(strict=True), var_schema : constr(strict=True), name : constr(strict=True), **kwargs):  # noqa: E501
-        """Suspends a running task.  # noqa: E501
+    def delete_task_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs):  # noqa: E501
+        """Delete a task  # noqa: E501
 
-        Suspends a running task. This is equivalent to an ALTER TASK ... SUSPEND.  # noqa: E501
+        Delete a task with the task name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.suspend_task_with_http_info(database, var_schema, name, async_req=True)
+        >>> thread = api.delete_task_with_http_info(database, var_schema, name, if_exists, async_req=True)
         >>> result = thread.get()
 
-        :param database: (required)
+        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
         :type database: str
-        :param var_schema: (required)
+        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
         :type var_schema: str
-        :param name: (required)
+        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
         :type name: str
+        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -1893,15 +1936,16 @@
         """
 
         _params = locals()
 
         _all_params = [
             'database',
             'var_schema',
-            'name'
+            'name',
+            'if_exists'
         ]
         _all_params.extend(
             [
                 'async_req',
                 '_return_http_data_only',
                 '_preload_content',
                 '_request_timeout',
@@ -1912,15 +1956,15 @@
         )
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method suspend_task" % _key
+                    " to method delete_task" % _key
                 )
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
@@ -1930,14 +1974,16 @@
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
+        if _params.get('if_exists') is not None:  # noqa: E501
+            _query_params.append(('ifExists', _params['if_exists']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -1962,15 +2008,16 @@
             '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
-            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}:suspend', 'POST',
+            self._root,
+            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}', 'DELETE',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/task/_generated/models/__init__.py` & `snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -5,14 +5,16 @@
     Snowflake Task API
 
     The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 # import models into model package
 from snowflake.core.task._generated.models.cron_schedule import CronSchedule
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/task/_generated/models/cron_schedule.py` & `snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/cron_schedule.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,26 +4,28 @@
     Snowflake Task API
 
     The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import Field, StrictStr
+from snowflake.core.task._generated.pydantic_compatibility import Field, StrictStr
 from snowflake.core.task._generated.models.task_schedule import TaskSchedule
 
 class CronSchedule(TaskSchedule):
     cron_expr: StrictStr = Field(...)
     timezone: StrictStr = Field(...)
     __properties = ["schedule_type"]
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/task/_generated/models/error_response.py` & `snowflake_core-0.8.0/src/snowflake/core/session/_generated/models/error_response.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,35 +1,38 @@
 # coding: utf-8
 
 """
-    Snowflake Task API
+    Snowflake Session API
 
-    The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
+    The Snowflake Session API is a REST API that you can use to query your current session properties.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictStr
+from snowflake.core.session._generated.pydantic_compatibility import BaseModel, StrictStr
 
 class ErrorResponse(BaseModel):
-    message: Optional[StrictStr] = Field(None, description="Error message returned by server")
-    error_code: Optional[StrictStr] = Field(None, description="Error code")
-    request_id: Optional[StrictStr] = Field(None, description="Unique request id")
-    __properties = ["message", "error_code", "request_id"]
+    message: Optional[StrictStr] = None
+    code: Optional[StrictStr] = None
+    error_code: Optional[StrictStr] = None
+    request_id: Optional[StrictStr] = None
+    __properties = ["message", "code", "error_code", "request_id"]
 
 
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
@@ -61,14 +64,16 @@
 
         if type(obj) is not dict:
             return ErrorResponse.parse_obj(obj)
 
         _obj = ErrorResponse.parse_obj({
             "message": obj.get("message"),
 
+            "code": obj.get("code"),
+
             "error_code": obj.get("error_code"),
 
             "request_id": obj.get("request_id"),
 
         })
         return _obj
 
@@ -76,37 +81,43 @@
 from typing import Optional, List, Dict
 
 class ErrorResponseModel():
     def __init__(
         self,
         # optional properties
         message: Optional[str] = None,
+        code: Optional[str] = None,
         error_code: Optional[str] = None,
         request_id: Optional[str] = None,
     ):
         self.message = message
+        self.code = code
         self.error_code = error_code
         self.request_id = request_id
-    __properties = ["message", "error_code", "request_id"]
+    __properties = ["message", "code", "error_code", "request_id"]
 
     def _to_model(self):
         return ErrorResponse(
             message=self.message,
 
+            code=self.code,
+
             error_code=self.error_code,
 
             request_id=self.request_id,
 
         )
 
     @classmethod
     def _from_model(cls, model) -> ErrorResponseModel:
         return ErrorResponseModel(
             message=model.message,
 
+            code=model.code,
+
             error_code=model.error_code,
 
             request_id=model.request_id,
 
         )
 
     def to_dict(self):
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/task/_generated/models/minutes_schedule.py` & `snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/minutes_schedule.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,26 +4,28 @@
     Snowflake Task API
 
     The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import Field, StrictInt
+from snowflake.core.task._generated.pydantic_compatibility import Field, StrictInt
 from snowflake.core.task._generated.models.task_schedule import TaskSchedule
 
 class MinutesSchedule(TaskSchedule):
     minutes: StrictInt = Field(...)
     __properties = ["schedule_type"]
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/task/_generated/models/success_response.py` & `snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/models/success_response.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,32 +1,34 @@
 # coding: utf-8
 
 """
-    Snowflake Task API
+    Snowflake Warehouse API
 
-    The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
+    The Snowflake Warehouse API is a REST API that you can use to access, customize and manage virtual warehouse in a Snowflake account.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictStr
+from snowflake.core.warehouse._generated.pydantic_compatibility import BaseModel, StrictStr
 
 class SuccessResponse(BaseModel):
-    status: Optional[StrictStr] = Field(None, description="Message returned by server")
+    status: Optional[StrictStr] = None
     __properties = ["status"]
 
 
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/task/_generated/models/task.py` & `snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/task.py`

 * *Files 3% similar despite different names*

```diff
@@ -4,35 +4,37 @@
     Snowflake Task API
 
     The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 from datetime import datetime
 from typing import Any, Dict, List, Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, conlist, constr, validator
+from snowflake.core.task._generated.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, conlist, constr, validator
 from snowflake.core.task._generated.models.task_schedule import TaskSchedule
 
 class Task(BaseModel):
     name: constr(strict=True) = Field(...)
     warehouse: Optional[constr(strict=True)] = None
     schedule: Optional[TaskSchedule] = None
     comment: Optional[StrictStr] = None
-    config: Optional[Dict[str, Any]] = Field(None, description="Task Config")
-    session_parameters: Optional[Dict[str, Any]] = Field(None, description="Session Parameters for the task at runtime.")
+    config: Optional[Dict[str, Any]] = None
+    session_parameters: Optional[Dict[str, Any]] = None
     definition: StrictStr = Field(...)
     predecessors: Optional[conlist(StrictStr)] = None
     user_task_managed_initial_warehouse_size: Optional[StrictStr] = None
     user_task_timeout_ms: Optional[StrictInt] = None
     suspend_task_after_num_failures: Optional[StrictInt] = None
     condition: Optional[StrictStr] = None
     allow_overlapping_execution: Optional[StrictBool] = None
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/task/_generated/models/task_run.py` & `snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/task_run.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,26 +4,28 @@
     Snowflake Task API
 
     The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 from datetime import datetime
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictInt, StrictStr, validator
+from snowflake.core.task._generated.pydantic_compatibility import BaseModel, Field, StrictInt, StrictStr, validator
 
 class TaskRun(BaseModel):
     root_task_name: StrictStr = Field(...)
     database_name: StrictStr = Field(...)
     schema_name: StrictStr = Field(...)
     state: StrictStr = Field(...)
     first_error_task_name: Optional[StrictStr] = None
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/task/_generated/models/task_schedule.py` & `snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/task_schedule.py`

 * *Files 1% similar despite different names*

```diff
@@ -4,28 +4,30 @@
     Snowflake Task API
 
     The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 import snowflake.core.task._generated.models
 from snowflake.core.task._generated.models import *
 
 
 from typing import Optional, Union
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, StrictStr
+from snowflake.core.task._generated.pydantic_compatibility import BaseModel, StrictStr
 
 class TaskSchedule(BaseModel):
     schedule_type: Optional[StrictStr] = None
     __properties = ["schedule_type"]
 
 
     class Config:
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/warehouse/_warehouse.py` & `snowflake_core-0.8.0/src/snowflake/core/warehouse/_warehouse.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,16 +1,15 @@
-from typing import TYPE_CHECKING, Optional
+from typing import TYPE_CHECKING, Iterator, Optional
 
 from snowflake.core._common import AccountObjectCollectionParent, CreateMode, ObjectReferenceMixin
-from snowflake.core._internal.pydantic_compatibility import StrictStr
 from snowflake.core._internal.telemetry import api_telemetry
-from snowflake.core.paging import PagedIter
 from snowflake.core.warehouse._generated.api import WarehouseApi
-from snowflake.core.warehouse._generated.api_client import BridgeApiClient
+from snowflake.core.warehouse._generated.api_client import BridgeApiClient, StoredProcApiClient
 from snowflake.core.warehouse._generated.models.warehouse import WarehouseModel as Warehouse
+from snowflake.core.warehouse._generated.pydantic_compatibility import StrictStr
 
 
 if TYPE_CHECKING:
     from snowflake.core import Root
 
 
 class WarehouseCollection(AccountObjectCollectionParent["WarehouseResource"]):
@@ -32,15 +31,16 @@
         super().__init__(root, ref_class=WarehouseResource)
         self._api = WarehouseApi(
             root=self.root,
             resource_class=self._ref_class,
             bridge_client=BridgeApiClient(
                 root=self.root,
                 snowflake_connection=root.connection,
-            )
+            ),
+            sproc_client=StoredProcApiClient(root=self.root)
         )
 
     @api_telemetry
     def create(
         self,
         warehouse: Warehouse,
         *,
@@ -82,15 +82,15 @@
         return self[warehouse.name]
 
     @api_telemetry
     def iter(
             self,
             *,
             like: Optional[str] = None,
-    ) -> PagedIter[Warehouse]:
+    ) -> Iterator[Warehouse]:
         """Iterate over the list of warehouses in Snowflake, filtering on any optional `like` pattern.
 
         Args:
             like:
                 A case-insensitive :class:`string` functioning as a filter, with support for SQL
                 wildcard characters (% and _).
 
@@ -104,25 +104,27 @@
             >>> warehouses = warehouse_collection.iter(like="your-warehouse-name")
             >>> # Show warehouses starting with 'your-warehouse-name-'.
             >>> warehouses = warehouse_collection.iter(like="your-warehouse-name-%")
             >>> # Use for loop to retrieve information from iterator.
             >>> for warehouse in warehouses:
             >>>     print(warehouse.name, warehouse.warehouse_size)
         """
-        return PagedIter(
-            data=self._api.list_warehouses(
-                StrictStr(like) if like is not None else None,
-                async_req=False,
-            ), map_=Warehouse._from_model
+        warehouses = self._api.list_warehouses(
+            StrictStr(like) if like is not None else None,
+            async_req=False,
         )
 
+        return map(Warehouse._from_model, iter(warehouses))
+
 
 class WarehouseResource(ObjectReferenceMixin[WarehouseCollection]):
     """A reference to a Warehouse in Snowflake."""
 
+    _supports_rest_api = True
+
     def __init__(self, name: str, collection: WarehouseCollection):
         self.name = name
         self.collection = collection
 
     @api_telemetry
     def create_or_update(
         self,
@@ -141,15 +143,15 @@
             ...     name="your-warehouse-name",
             ...     warehouse_size="SMALL",
             ...     auto_suspend=500,
             ...)
             >>> # Use warehouse collection to create a reference to warehouse resource in Snowflake server.
             >>> root.warehouses["your-warehouse-name"].create_or_update(warehouse_parameters)
         """
-        self.collection._api.create_warehouses(warehouse._to_model(), async_req=False)
+        self.collection._api.create_or_alter_warehouse(warehouse.name, warehouse._to_model(), async_req=False)
 
     @api_telemetry
     def suspend(self) -> None:
         """Suspend the warehouse.
 
         Example:
             Use warehouse reference to suspend a warehouse:
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/warehouse/_generated/__init__.py` & `snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/__init__.py`

 * *Files 12% similar despite different names*

```diff
@@ -6,14 +6,16 @@
     Snowflake Warehouse API
 
     The Snowflake Warehouse API is a REST API that you can use to access, customize and manage virtual warehouse in a Snowflake account.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 __version__ = "1.0.0"
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/warehouse/_generated/api_client.py` & `snowflake_core-0.8.0/src/snowflake/core/database/_generated/api_client.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,37 +1,44 @@
 # coding: utf-8
 """
-    Snowflake Warehouse API
+    Snowflake Database API
 
-    The Snowflake Warehouse API is a REST API that you can use to access, customize and manage virtual warehouse in a Snowflake account.  # noqa: E501
+    The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 from __future__ import absolute_import
 
 import atexit
 import datetime
+import time
 import typing
 from dateutil.parser import parse
 import json
 import mimetypes
 from multiprocessing.pool import ThreadPool
 import os
 import re
 import tempfile
 
 from urllib.parse import quote
 
-from snowflake.core.warehouse._generated.configuration import Configuration
-import snowflake.core.warehouse._generated.models
-from snowflake.core.warehouse._generated import rest
-from snowflake.core.exceptions import _APIValueError, APIError
+from functools import partial
+
+from snowflake.core.database._generated.configuration import Configuration
+import snowflake.core.database._generated.models
+from snowflake.core.database._generated import rest
+from snowflake.core.database._generated.paging import PagedIter
+from snowflake.core.exceptions import _APIValueError, APIError, InvalidResponseError, LongRunningQueryTimeout
+from snowflake.core.version import __version__ as VERSION
 
 if typing.TYPE_CHECKING:
     from snowflake.core._root import Root
 
 
 class ApiClient(object):
     """Generic API client for OpenAPI client library builds.
@@ -62,41 +69,48 @@
         'float': float,
         'str': str,
         'bool': bool,
         'date': datetime.date,
         'datetime': datetime.datetime,
         'object': object,
     }
+    DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING = 600.0 # default 10 minutes for long running queries
     _pool = None
 
     def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
                  cookie=None, pool_threads=1):
         # use default configuraiton if none is provided
         if configuration is None:
             configuration = Configuration.get_default()
         self.configuration = configuration
         if (
             hasattr(root, "_connection")
+            and root._connection is not None
             and hasattr(root._connection, "_rest")
+            and root._connection._rest is not None
+            and hasattr(root._connection._rest, "_protocol")
+            and hasattr(root._connection._rest, "_host")
+            and hasattr(root._connection._rest, "_port")
         ):
             self.configuration.host = (
                 f"{root._connection._rest._protocol}://"
                 + root._connection._rest._host
                 + f":{root._connection._rest._port}"
             )
         self.pool_threads = pool_threads
 
         self.rest_client = rest.RESTClientObject(root, configuration)
         self.default_headers = {}
         if header_name is not None:
             self.default_headers[header_name] = header_value
         self.cookie = cookie
         # Set default User-Agent.
-        self.user_agent = 'OpenAPI-Generator/1.0.0/python'
+        self.user_agent = 'python_api/' + VERSION + ''
         self.client_side_validation = configuration.client_side_validation
+        self._enable_long_running_polling = getattr(root, "_enable_long_running_polling", False)
 
     def __enter__(self):
         return self
 
     def __exit__(self, exc_type, exc_value, traceback):
         self.close()
 
@@ -154,15 +168,15 @@
         It stores default ApiClient.
 
         :param default: object of ApiClient.
         """
         cls._default = default
 
     def __call_api(
-            self, resource_path, method, path_params=None,
+            self, root, resource_path, method, path_params=None,
             query_params=None, header_params=None, body=None, post_params=None,
             files=None, response_types_map=None, auth_settings=None,
             _return_http_data_only=None, collection_formats=None,
             _preload_content=True, _request_timeout=None, _host=None,
             _request_auth=None):
 
         config = self.configuration
@@ -218,22 +232,25 @@
         if query_params:
             query_params = self.sanitize_for_serialization(query_params)
             url_query = self.parameters_to_url_query(query_params,
                                                      collection_formats)
             url += "?" + url_query
 
         try:
-            # perform request and return response
-            response_data = self.request(
-                method, url,
+            # perform request and return response, maybe with retry
+            response_data = self.request_with_retry(
+                root,
+                method,
+                url,
                 query_params=query_params,
                 headers=header_params,
                 post_params=post_params, body=body,
                 _preload_content=_preload_content,
-                _request_timeout=_request_timeout)
+                _request_timeout=_request_timeout
+            )
         except APIError as e:
             if e.body:
                 e.body = e.body.decode('utf-8')
             raise e
 
         self.last_response = response_data
 
@@ -251,15 +268,52 @@
         #         match = re.search(r"charset=([a-zA-Z\-\d]+)[\s;]?", content_type)
         #     encoding = match.group(1) if match else "utf-8"
         #     response_data.data = response_data.data.decode(encoding)
 
         # deserialize response data
 
         if response_type:
-            return_data = self.deserialize(response_data, response_type)
+            large_results_resp = self.large_results(response_data)
+            if large_results_resp is None:
+                # regular, non-large results use case
+                return_data = self.deserialize(response_data, response_type)
+            else:
+                # This should be the normal way in which we figure out where to get the results from,
+                # as well as how many chunks there are to get. Due to a bug, we use the alternate logic
+                # (in the "else" clause) to infer the URL from the UUID
+                if "Link" in response_data.getheaders():
+                    results_path, num_chunks = self.get_path_and_chunk_count_from_header(response_data.getheaders()["Link"])
+                else:
+                    handler_id = large_results_resp['result_handler']
+                    results_path = '/api/v2/results/' + handler_id
+
+                    # If there is no "Link" header, there is just one chunk
+                    num_chunks = 1
+
+                # Closure for fetching the next chunk in the PagedIter iterator
+                def _fetch_next_chunk(chunk_index, deserialize_type):
+                    # For now, do this because query_params is not actually being used properly in self.request
+                    chunk_url = f'{self.configuration.host}{results_path}?page={chunk_index}'
+
+                    chunk_response_data = self.request(
+                        root,
+                        "GET",
+                        chunk_url,
+                        headers=header_params,
+                        _preload_content=True,
+                        _request_timeout=_request_timeout)
+
+                    return self.deserialize(chunk_response_data, deserialize_type)
+
+                if 'Iterable' in response_type:
+                    return PagedIter(partial(_fetch_next_chunk, deserialize_type=response_type), num_chunks)
+                else:
+                    # At most, we should only need to fetch one chunk if it's a point lookup,
+                    # i.e., one row return
+                    return_data = _fetch_next_chunk(0, response_type)
         else:
             return_data = None
 
         if _return_http_data_only:
             return (return_data)
         else:
             return (return_data, response_data.status,
@@ -335,42 +389,42 @@
 
         :return: object.
         """
         if data is None:
             return None
 
         if type(klass) == str:
-            if klass.startswith('List['):
-                sub_kls = re.match(r'List\[(.*)]', klass).group(1)
+            if klass.startswith('Iterable['):
+                sub_kls = re.match(r'Iterable\[(.*)]', klass).group(1)
                 return [self.__deserialize(sub_data, sub_kls)
                         for sub_data in data]
 
             if klass.startswith('Dict['):
                 sub_kls = re.match(r'Dict\[([^,]*), (.*)]', klass).group(2)
                 return {k: self.__deserialize(v, sub_kls)
                         for k, v in data.items()}
 
             # convert str to class
             if klass in self.NATIVE_TYPES_MAPPING:
                 klass = self.NATIVE_TYPES_MAPPING[klass]
             else:
-                klass = getattr(snowflake.core.warehouse._generated.models, klass)
+                klass = getattr(snowflake.core.database._generated.models, klass)
 
         if klass in self.PRIMITIVE_TYPES:
             return self.__deserialize_primitive(data, klass)
         elif klass == object:
             return self.__deserialize_object(data)
         elif klass == datetime.date:
             return self.__deserialize_date(data)
         elif klass == datetime.datetime:
             return self.__deserialize_datetime(data)
         else:
             return self.__deserialize_model(data, klass)
 
-    def call_api(self, resource_path, method,
+    def call_api(self, root, resource_path, method,
                  path_params=None, query_params=None, header_params=None,
                  body=None, post_params=None, files=None,
                  response_types_map=None, auth_settings=None,
                  async_req=None, _return_http_data_only=None,
                  collection_formats=None,_preload_content=True,
                   _request_timeout=None, _host=None, _request_auth=None):
         """Makes the HTTP request (synchronous) and returns deserialized data.
@@ -410,88 +464,198 @@
             If async_req parameter is True,
             the request will be called asynchronously.
             The method will return the request thread.
             If parameter async_req is False or missing,
             then the method will return the response directly.
         """
         if not async_req:
-            return self.__call_api(resource_path, method,
-                                   path_params, query_params, header_params,
-                                   body, post_params, files,
-                                   response_types_map, auth_settings,
-                                   _return_http_data_only, collection_formats,
-                                   _preload_content, _request_timeout, _host,
-                                   _request_auth)
-
-        return self.pool.apply_async(self.__call_api, (resource_path,
-                                                       method, path_params,
-                                                       query_params,
-                                                       header_params, body,
-                                                       post_params, files,
-                                                       response_types_map,
-                                                       auth_settings,
-                                                       _return_http_data_only,
-                                                       collection_formats,
-                                                       _preload_content,
-                                                       _request_timeout,
-                                                       _host, _request_auth))
+            return self.__call_api(
+                root,
+                resource_path,
+                method,
+                path_params,
+                query_params,
+                header_params,
+                body,
+                post_params,
+                files,
+                response_types_map,
+                auth_settings,
+                _return_http_data_only,
+                collection_formats,
+                _preload_content,
+                _request_timeout,
+                _host,
+                _request_auth,
+            )
+
+        return self.pool.apply_async(
+            self.__call_api,
+            (
+                root,
+                resource_path,
+                method,
+                path_params,
+                query_params,
+                header_params,
+                body,
+                post_params,
+                files,
+                response_types_map,
+                auth_settings,
+                _return_http_data_only,
+                collection_formats,
+                _preload_content,
+                _request_timeout,
+                _host,
+                _request_auth,
+            )
+        )
 
-    def request(self, method, url, query_params=None, headers=None,
+
+    def request_with_retry(
+                self, root, method, url, query_params=None, headers=None,
+                post_params=None, body=None, _preload_content=True,
+                _request_timeout=None):
+        """
+            Response time by default one hour
+        """
+        enter_timing = time.time()
+        response_data = self.request(
+                root,
+                method,
+                url,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params, body=body,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout)
+
+        if response_data.status != 202 or not self._enable_long_running_polling:
+            return response_data
+
+        result_endpoint = response_data.getheader('Location')
+        if result_endpoint is None:
+            raise InvalidResponseError("Long Running Queries result endpoint is missing")
+
+        if _request_timeout is None:
+            _request_timeout = self.DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING
+        wait_for_results_timeout = enter_timing + _request_timeout
+
+        exponential_wait_time = 1 # wait time increases exponentially, 30% more everytime
+        while True:
+            time_remaining = wait_for_results_timeout - time.time()
+            if time_remaining <= 0:
+                break
+            wait_time = min(exponential_wait_time, time_remaining)
+            time.sleep(wait_time)
+            response_data = self.request(
+                root,
+                'GET',
+                self.configuration.host + result_endpoint,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params, body=body,
+                _preload_content=_preload_content,
+                _request_timeout=max(time_remaining - wait_time, 1)
+                # request_timeout can never be zero
+            )
+
+            if response_data.status != 202:
+                return response_data
+
+            exponential_wait_time *= 1.3
+
+        raise LongRunningQueryTimeout("Long running queries timeout")
+
+
+    def request(self, root, method, url, query_params=None, headers=None,
                 post_params=None, body=None, _preload_content=True,
                 _request_timeout=None):
         """Makes the HTTP request using RESTClient."""
         if method == "GET":
-            return self.rest_client.get_request(url,
-                                        query_params=query_params,
-                                        _preload_content=_preload_content,
-                                        _request_timeout=_request_timeout,
-                                        headers=headers)
+            return self.rest_client.get_request(
+                root,
+                url,
+                query_params=query_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                headers=headers,
+            )
         elif method == "HEAD":
-            return self.rest_client.head_request(url,
-                                         query_params=query_params,
-                                         _preload_content=_preload_content,
-                                         _request_timeout=_request_timeout,
-                                         headers=headers)
+            return self.rest_client.head_request(
+                root,
+                url,
+                query_params=query_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                headers=headers,
+            )
         elif method == "OPTIONS":
-            return self.rest_client.options_request(url,
-                                            query_params=query_params,
-                                            headers=headers,
-                                            _preload_content=_preload_content,
-                                            _request_timeout=_request_timeout)
+            return self.rest_client.options_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+            )
         elif method == "POST":
-            return self.rest_client.post_request(url,
-                                         query_params=query_params,
-                                         headers=headers,
-                                         post_params=post_params,
-                                         _preload_content=_preload_content,
-                                         _request_timeout=_request_timeout,
-                                         body=body)
+            return self.rest_client.post_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                body=body,
+            )
         elif method == "PUT":
-            return self.rest_client.put_request(url,
-                                        query_params=query_params,
-                                        headers=headers,
-                                        post_params=post_params,
-                                        _preload_content=_preload_content,
-                                        _request_timeout=_request_timeout,
-                                        body=body)
+            try:
+                return self.rest_client.put_request(
+                    root,
+                    url,
+                    query_params=query_params,
+                    headers=headers,
+                    post_params=post_params,
+                    _preload_content=_preload_content,
+                    _request_timeout=_request_timeout,
+                    body=body,
+                )
+            except APIError as error:
+                # Raise a more helpful user error if CoA is not supported for this resource;
+                # this is represented as either 405 or 501 on the server.
+                if error.status in (405, 501):
+                    raise NotImplementedError(
+                        'create_or_update is not yet supported for database. Updating database '
+                        'objects is not supported yet; use create() for creating a database.')
+                raise
+
         elif method == "PATCH":
-            return self.rest_client.patch_request(url,
-                                          query_params=query_params,
-                                          headers=headers,
-                                          post_params=post_params,
-                                          _preload_content=_preload_content,
-                                          _request_timeout=_request_timeout,
-                                          body=body)
+            return self.rest_client.patch_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                post_params=post_params,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                body=body,
+            )
         elif method == "DELETE":
-            return self.rest_client.delete_request(url,
-                                           query_params=query_params,
-                                           headers=headers,
-                                           _preload_content=_preload_content,
-                                           _request_timeout=_request_timeout,
-                                           body=body)
+            return self.rest_client.delete_request(
+                root,
+                url,
+                query_params=query_params,
+                headers=headers,
+                _preload_content=_preload_content,
+                _request_timeout=_request_timeout,
+                body=body,
+            )
         else:
             raise _APIValueError(
                 "http method must be `GET`, `HEAD`, `OPTIONS`,"
                 " `POST`, `PATCH`, `PUT` or `DELETE`."
             )
 
     def parameters_to_tuples(self, params, collection_formats):
@@ -759,13 +923,73 @@
         :param data: dict, list.
         :param klass: class literal.
         :return: model object.
         """
 
         return klass.from_dict(data)
 
+    @staticmethod
+    def large_results(response):
+        try:
+            result = json.loads(response.data)
+            if ("result_handler" in result
+                    and "message" in result and
+                    'Large result set. Use provided Link' in result['message']):
+                return result
+            else:
+                return None
+        except ValueError:
+            pass
+
+        return None
+
+
+    @staticmethod
+    def get_path_and_chunk_count_from_header(links_str):
+        links_list = links_str.split(",")
+
+        def parse_links(s):
+            import re
+            # Use regex to extract necessary parts
+            #
+            # Explanation:
+            # The result links are provided to us in the form:
+            # '</api/v2/results/01b39664-0100-0001-0000-0000000430391?page=0>; rel="first"'
+            #
+            # We wish to find how many chunks there are by finding the one that has rel="last",
+            # therefore we find page index corresponding to the link with that rel value.
+            #
+            # 1. <(.*?)> matches and captures the URL inside the angle brackets
+            # 2. page=(\d+) matches 'page=' followed by one or more digits to find the page number
+            # 3. rel="([^"]*)" matches 'rel="'
+            pattern = r'<(.*?)\?page=(\d+)>; rel="([^"]*)"'
+
+            # Search using the regular expression
+            match = re.search(pattern, s)
+            if match:
+                parse_result = dict()
+                parse_result['url'], parse_result['page_number'], parse_result['rel_value'] = match.groups()
+                return parse_result
+
+            return None
+
+        parsed_links = [parse_links(link) for link in links_list]
+
+        # Find the last one
+        last_link = list(filter(lambda link: link['rel_value'].lower() == 'last', parsed_links)).pop()
+
+        # Return the URL; the number of chunks is the chunk index of the last page plus one
+        return last_link['url'], int(last_link['page_number']) + 1
+
 
 class BridgeApiClient(ApiClient):
     def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
                  cookie=None, pool_threads=1, snowflake_connection=None):
         ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
         self.rest_client = rest.BridgeClientObject(snowflake_connection)
+
+
+class StoredProcApiClient(ApiClient):
+    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
+                 cookie=None, pool_threads=1):
+        ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
+        self.rest_client = rest.StoredProcClientObject()
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/warehouse/_generated/api_response.py` & `snowflake_core-0.8.0/src/snowflake/core/task/_generated/api_response.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 """API response object."""
 
 from __future__ import annotations
 from typing import Any, Dict, Optional
-from snowflake.core._internal.pydantic_compatibility import Field, StrictInt, StrictStr
+from snowflake.core.task._generated.pydantic_compatibility import Field, StrictInt, StrictStr
 
 class ApiResponse:
     """
     API response object
     """
 
     status_code: Optional[StrictInt] = Field(None, description="HTTP status code")
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/warehouse/_generated/configuration.py` & `snowflake_core-0.8.0/src/snowflake/core/session/_generated/configuration.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,17 +1,19 @@
 # coding: utf-8
 
 """
-    Snowflake Warehouse API
+    Snowflake Session API
 
-    The Snowflake Warehouse API is a REST API that you can use to access, customize and manage virtual warehouse in a Snowflake account.  # noqa: E501
+    The Snowflake Session API is a REST API that you can use to query your current session properties.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 import copy
 import logging
@@ -108,15 +110,15 @@
         """
         self.access_token = access_token
         """Access token
         """
         self.logger = {}
         """Logging Settings
         """
-        self.logger["package_logger"] = logging.getLogger("snowflake.core.warehouse._generated")
+        self.logger["package_logger"] = logging.getLogger("snowflake.core.session._generated")
         self.logger["urllib3_logger"] = logging.getLogger("urllib3")
         self.logger_format = '%(asctime)s %(levelname)s %(message)s'
         """Log format
         """
         self.logger_stream_handler = None
         """Log stream handler
         """
@@ -333,15 +335,15 @@
         """Gets an array of host settings
 
         :return: An array of host settings
         """
         return [
             {
                 'url': "https://org-account.snowflakecomputing.com",
-                'description': "Snowflake Warehouse API",
+                'description': "Snowflake Session API. Always refers to user's current, ongoing session.",
             }
         ]
 
     def get_host_from_settings(self, index, variables=None, servers=None):
         """Gets host URL based on the index and variables
         :param index: array index of the host settings
         :param variables: hash of variable and the corresponding value
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/warehouse/_generated/rest.py` & `snowflake_core-0.8.0/src/snowflake/core/session/_generated/rest.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,17 +1,19 @@
 # coding: utf-8
 
 """
-    Snowflake Warehouse API
+    Snowflake Session API
 
-    The Snowflake Warehouse API is a REST API that you can use to access, customize and manage virtual warehouse in a Snowflake account.  # noqa: E501
+    The Snowflake Session API is a REST API that you can use to query your current session properties.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 import json
 import logging
@@ -49,17 +51,26 @@
     def __init__(self, root: "Root", *args, **kwargs):
         self.root = root
         self.pool_manager = create_connection_pool(
             *args,
             **kwargs,
         )
 
-    def request(self, method, url, query_params=None, headers=None,
-                body=None, post_params=None, _preload_content=True,
-                _request_timeout=None):
+    def request(
+        self,
+        root,
+        method,
+        url,
+        query_params=None,
+        headers=None,
+        body=None,
+        post_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
         """Perform requests.
 
         :param method: http request method
         :param url: http request url
         :param query_params: query parameters in the url
         :param headers: http request headers
         :param body: request json body, for `application/json`
@@ -104,64 +115,64 @@
 
                 # no content type provided or payload is json
                 if not headers.get('Content-Type') or re.search('json', headers['Content-Type'], re.IGNORECASE):
                     request_body = None
                     if body is not None:
                         request_body = json.dumps(body)
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 elif headers['Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         fields=post_params,
                         encode_multipart=False,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 elif headers['Content-Type'] == 'multipart/form-data':
                     # must del headers['Content-Type'], or the correct
                     # Content-Type which generated by urllib3 will be
                     # overwritten.
                     del headers['Content-Type']
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         fields=post_params,
                         encode_multipart=True,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 # Pass a `string` parameter directly in the body to support
                 # other content types than Json when `body` argument is
                 # provided in serialized form
                 elif isinstance(body, str) or isinstance(body, bytes):
                     request_body = body
                     r = self.pool_manager.request(
-                        self.root._session_token,
+                        root,
                         method, url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 else:
                     # Cannot generate the request from given parameters
                     msg = """Cannot prepare a request message for provided
                              arguments. Please check that your arguments match
                              declared content type."""
                     raise APIError(status=0, reason=msg)
             # For `GET`, `HEAD`
             else:
                 r = self.pool_manager.request(
-                    self.root._session_token,
+                    root,
                     method,
                     url,
                     fields={},
                     preload_content=_preload_content,
                     timeout=timeout,
                     headers=headers,
                 )
@@ -191,88 +202,139 @@
             if 500 <= r.status <= 599:
                 raise ServerError(http_resp=r)
 
             raise APIError(http_resp=r)
 
         return r
 
-    def get_request(self, url, headers=None, query_params=None, _preload_content=True,
-            _request_timeout=None):
-        return self.request("GET", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
-
-    def head_request(self, url, headers=None, query_params=None, _preload_content=True,
-             _request_timeout=None):
-        return self.request("HEAD", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
+    def get_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "GET",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def head_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "HEAD",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
 
-    def options_request(self, url, headers=None, query_params=None, post_params=None,
+    def options_request(self, root, url, headers=None, query_params=None, post_params=None,
                 body=None, _preload_content=True, _request_timeout=None):
-        return self.request("OPTIONS", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "OPTIONS",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def delete_request(self, url, headers=None, query_params=None, body=None,
+    def delete_request(self, root, url, headers=None, query_params=None, body=None,
                _preload_content=True, _request_timeout=None):
-        return self.request("DELETE", url,
-                            headers=headers,
-                            query_params=query_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "DELETE",
+            url,
+            headers=headers,
+            query_params=query_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def post_request(self, url, headers=None, query_params=None, post_params=None,
+    def post_request(self, root, url, headers=None, query_params=None, post_params=None,
              body=None, _preload_content=True, _request_timeout=None):
-        return self.request("POST", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "POST",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def put_request(self, url, headers=None, query_params=None, post_params=None,
+    def put_request(self, root, url, headers=None, query_params=None, post_params=None,
             body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PUT", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "PUT",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
-    def patch_request(self, url, headers=None, query_params=None, post_params=None,
+    def patch_request(self, root, url, headers=None, query_params=None, post_params=None,
               body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PATCH", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+        return self.request(
+            root,
+            "PATCH",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
 
 
 class BridgeClientObject(object):
 
     def __init__(self, snowflake_connection: SnowflakeConnection):
         self.bridge = SnowBridge(snowflake_connection)
 
-    def request(self, method, url, query_params=None, headers=None,
-                body=None, post_params=None, _preload_content=True,
-                _request_timeout=None):
+    def request(
+        self,
+        root,
+        method,
+        url,
+        query_params=None,
+        headers=None,
+        body=None,
+        post_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
         """Perform requests.
 
         :param method: http request method
         :param url: http request url
         :param query_params: query parameters in the url
         :param headers: http request headers
         :param body: request json body, for `application/json`
@@ -315,71 +377,378 @@
             if 500 <= r.status <= 599:
                 raise ServerError(http_resp=r)
 
             raise APIError(http_resp=r)
 
         return r
 
-    def get_request(self, url, headers=None, query_params=None, _preload_content=True,
-                    _request_timeout=None):
-        return self.request("GET", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
-
-    def head_request(self, url, headers=None, query_params=None, _preload_content=True,
-                     _request_timeout=None):
-        return self.request("HEAD", url,
-                            headers=headers,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            query_params=query_params)
-
-    def options_request(self, url, headers=None, query_params=None, post_params=None,
-                        body=None, _preload_content=True, _request_timeout=None):
-        return self.request("OPTIONS", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def delete_request(self, url, headers=None, query_params=None, body=None,
-                       _preload_content=True, _request_timeout=None):
-        return self.request("DELETE", url,
-                            headers=headers,
-                            query_params=query_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def post_request(self, url, headers=None, query_params=None, post_params=None,
-                     body=None, _preload_content=True, _request_timeout=None):
-        return self.request("POST", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def put_request(self, url, headers=None, query_params=None, post_params=None,
-                    body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PUT", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
-
-    def patch_request(self, url, headers=None, query_params=None, post_params=None,
-                      body=None, _preload_content=True, _request_timeout=None):
-        return self.request("PATCH", url,
-                            headers=headers,
-                            query_params=query_params,
-                            post_params=post_params,
-                            _preload_content=_preload_content,
-                            _request_timeout=_request_timeout,
-                            body=body)
+    def get_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "GET",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def head_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "HEAD",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def options_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "OPTIONS",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def delete_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "DELETE",
+            url,
+            headers=headers,
+            query_params=query_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def post_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "POST",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def put_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PUT",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def patch_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PATCH",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+
+class StoredProcClientObject(object):
+
+    def request(
+        self,
+        root,
+        method,
+        url,
+        query_params={},
+        headers={},
+        body={},
+        post_params={},
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        """Perform requests.
+        :param method: http request method
+        :param url: http request url
+        :param query_params: query parameters in the url
+        :param headers: http request headers
+        :param body: request json body, for `application/json`
+        :param post_params: request post parameters,
+                            `application/x-www-form-urlencoded`
+                            and `multipart/form-data`
+        :param _preload_content: if False, the urllib3.HTTPResponse object will
+                                 be returned without reading/decoding response
+                                 data. Default is True.
+        :param _request_timeout: timeout setting for this request. If one
+                                 number provided, it will be total request
+                                 timeout. It can also be a pair (tuple) of
+                                 (connection, read) timeouts.
+        """
+        method = method.upper()
+        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
+                          'PATCH', 'OPTIONS']
+        import _snowflake
+        parsed_url = urllib3.util.parse_url(url)
+        response_dict = _snowflake.send_snow_api_request(method, parsed_url.path, dict(query_params), headers, body,
+                                                         post_params, _request_timeout)
+        json_content = json.loads(response_dict["content"])
+        if "data" in json_content:
+            r = urllib3.HTTPResponse(body=json.dumps(json_content["data"]))
+        else:
+            r = urllib3.HTTPResponse(body=json.dumps(json_content).encode("utf-8"))
+        r.status = response_dict["status"]
+        if _preload_content:
+            r = RESTResponse(r)
+            # log response body
+            logger.debug("response body: %s", r.data)
+
+        if not 200 <= r.status <= 299:
+            if r.status == 401:
+                raise UnauthorizedError(http_resp=r)
+
+            if r.status == 403:
+                raise ForbiddenError(http_resp=r)
+
+            if r.status == 404:
+                raise NotFoundError(http_resp=r)
+
+            if r.status == 409:
+                raise ConflictError(http_resp=r)
+
+            if 500 <= r.status <= 599:
+                raise ServerError(http_resp=r)
+
+            raise APIError(http_resp=r)
+
+        return r
+
+    def get_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "GET",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def head_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "HEAD",
+            url,
+            headers=headers,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            query_params=query_params,
+        )
+
+    def options_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "OPTIONS",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def delete_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "DELETE",
+            url,
+            headers=headers,
+            query_params=query_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def post_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "POST",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def put_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PUT",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
+
+    def patch_request(
+        self,
+        root,
+        url,
+        headers=None,
+        query_params=None,
+        post_params=None,
+        body=None,
+        _preload_content=True,
+        _request_timeout=None,
+    ):
+        return self.request(
+            root,
+            "PATCH",
+            url,
+            headers=headers,
+            query_params=query_params,
+            post_params=post_params,
+            _preload_content=_preload_content,
+            _request_timeout=_request_timeout,
+            body=body,
+        )
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/warehouse/_generated/models/__init__.py` & `snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/models/__init__.py`

 * *Files 20% similar despite different names*

```diff
@@ -5,14 +5,16 @@
     Snowflake Warehouse API
 
     The Snowflake Warehouse API is a REST API that you can use to access, customize and manage virtual warehouse in a Snowflake account.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import absolute_import
 
 # import models into model package
 from snowflake.core.warehouse._generated.models.error_response import ErrorResponse
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/warehouse/_generated/models/error_response.py` & `snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/models/error_response.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,35 +1,38 @@
 # coding: utf-8
 
 """
-    Snowflake Warehouse API
+    Cortex Search REST API
 
-    The Snowflake Warehouse API is a REST API that you can use to access, customize and manage virtual warehouse in a Snowflake account.  # noqa: E501
+    OpenAPI 3.0 specification for the Cortex Search REST API  # noqa: E501
 
-    The version of the OpenAPI document: 0.0.1
+    The version of the OpenAPI document: 0.1.0
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictStr
+from snowflake.core.cortex.search_service._generated.pydantic_compatibility import BaseModel, StrictStr
 
 class ErrorResponse(BaseModel):
-    message: Optional[StrictStr] = Field(None, description="Error message returned by server")
-    error_code: Optional[StrictStr] = Field(None, description="Error code")
-    request_id: Optional[StrictStr] = Field(None, description="Unique request id")
-    __properties = ["message", "error_code", "request_id"]
+    message: Optional[StrictStr] = None
+    code: Optional[StrictStr] = None
+    error_code: Optional[StrictStr] = None
+    request_id: Optional[StrictStr] = None
+    __properties = ["message", "code", "error_code", "request_id"]
 
 
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
@@ -61,14 +64,16 @@
 
         if type(obj) is not dict:
             return ErrorResponse.parse_obj(obj)
 
         _obj = ErrorResponse.parse_obj({
             "message": obj.get("message"),
 
+            "code": obj.get("code"),
+
             "error_code": obj.get("error_code"),
 
             "request_id": obj.get("request_id"),
 
         })
         return _obj
 
@@ -76,37 +81,43 @@
 from typing import Optional, List, Dict
 
 class ErrorResponseModel():
     def __init__(
         self,
         # optional properties
         message: Optional[str] = None,
+        code: Optional[str] = None,
         error_code: Optional[str] = None,
         request_id: Optional[str] = None,
     ):
         self.message = message
+        self.code = code
         self.error_code = error_code
         self.request_id = request_id
-    __properties = ["message", "error_code", "request_id"]
+    __properties = ["message", "code", "error_code", "request_id"]
 
     def _to_model(self):
         return ErrorResponse(
             message=self.message,
 
+            code=self.code,
+
             error_code=self.error_code,
 
             request_id=self.request_id,
 
         )
 
     @classmethod
     def _from_model(cls, model) -> ErrorResponseModel:
         return ErrorResponseModel(
             message=model.message,
 
+            code=model.code,
+
             error_code=model.error_code,
 
             request_id=model.request_id,
 
         )
 
     def to_dict(self):
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/warehouse/_generated/models/success_response.py` & `snowflake_core-0.8.0/src/snowflake/core/session/_generated/models/success_response.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,32 +1,34 @@
 # coding: utf-8
 
 """
-    Snowflake Warehouse API
+    Snowflake Session API
 
-    The Snowflake Warehouse API is a REST API that you can use to access, customize and manage virtual warehouse in a Snowflake account.  # noqa: E501
+    The Snowflake Session API is a REST API that you can use to query your current session properties.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 
 from typing import Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictStr
+from snowflake.core.session._generated.pydantic_compatibility import BaseModel, StrictStr
 
 class SuccessResponse(BaseModel):
-    status: Optional[StrictStr] = Field(None, description="Message returned by server")
+    status: Optional[StrictStr] = None
     __properties = ["status"]
 
 
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
```

### Comparing `snowflake_core-0.7.0/src/snowflake/core/warehouse/_generated/models/warehouse.py` & `snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/models/warehouse.py`

 * *Files 12% similar despite different names*

```diff
@@ -4,63 +4,65 @@
     Snowflake Warehouse API
 
     The Snowflake Warehouse API is a REST API that you can use to access, customize and manage virtual warehouse in a Snowflake account.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
+
+    Do not edit this file manually.
 """
 
 
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
 from datetime import datetime
 from typing import Dict, Optional
 from typing import Union
-from snowflake.core._internal.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, constr, validator
+from snowflake.core.warehouse._generated.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, constr, validator
 
 class Warehouse(BaseModel):
     name: constr(strict=True) = Field(...)
-    warehouse_type: Optional[StrictStr] = Field(None, description="Type of warehouse, possible types: STANDARD, SNOWPARK-OPTIMIZED")
-    warehouse_size: Optional[StrictStr] = Field(None, description="Size of warehouse, possible sizes: XSMALL, SMALL, MEDIUM, LARGE, XLARGE, XXLARGE, XXXLARGE, X4LARGE, X5LARGE, X6LARGE")
+    warehouse_type: Optional[StrictStr] = None
+    warehouse_size: Optional[StrictStr] = None
     wait_for_completion: Optional[StrictStr] = None
     max_cluster_count: Optional[StrictInt] = None
     min_cluster_count: Optional[StrictInt] = None
-    scaling_policy: Optional[StrictStr] = Field(None, description="Scaling policy of warehouse, possible scaling policies: STANDARD, ECONOMY")
-    auto_suspend: Optional[StrictInt] = Field(None, description="time in seconds before auto suspend")
+    scaling_policy: Optional[StrictStr] = None
+    auto_suspend: Optional[StrictInt] = None
     auto_resume: Optional[StrictStr] = None
     initially_suspended: Optional[StrictStr] = None
     resource_monitor: Optional[constr(strict=True)] = None
     comment: Optional[StrictStr] = None
     enable_query_acceleration: Optional[StrictStr] = None
     query_acceleration_max_scale_factor: Optional[StrictInt] = None
     max_concurrency_level: Optional[StrictInt] = None
     statement_queued_timeout_in_seconds: Optional[StrictInt] = None
     statement_timeout_in_seconds: Optional[StrictInt] = None
-    tags: Optional[Dict[str, StrictStr]] = Field(None, description="<tag_name> = '<tag_value>' , ...")
-    type: Optional[StrictStr] = Field(None, description="Type of warehouse, possible types: STANDARD, SNOWPARK-OPTIMIZED")
-    size: Optional[StrictStr] = Field(None, description="names of size: X-Small, Small, Medium, Large, X-Large, 2X-Large, 3X-Large, 4X-Large, 5X-Large, 6X-Large")
-    state: Optional[StrictStr] = Field(None, description="The state of warehouse, possible states: STARTED, STARTING, DYNAMIC, SUSPENDED, RESIZING, RESUMING, SUSPENDING")
-    started_clusters: Optional[StrictInt] = Field(None, description="Number of clusters currently started.")
-    running: Optional[StrictInt] = Field(None, description="Number of SQL statements that are being executed by the warehouse.")
-    queued: Optional[StrictInt] = Field(None, description="Number of SQL statements that are queued for the warehouse.")
-    is_default: Optional[StrictBool] = Field(None, description="Whether the warehouse is the default for the current user.")
-    is_current: Optional[StrictBool] = Field(None, description="Whether the warehouse is in use for the session. Only one warehouse can be in use at a time for a session. To specify or change the warehouse for a session, use the USE WAREHOUSE command.")
-    available: Optional[StrictStr] = Field(None, description="Percentage of the warehouse compute resources that are provisioned and available.")
-    provisioning: Optional[StrictStr] = Field(None, description="Percentage of the warehouse compute resources that are in the process of provisioning.")
-    quiescing: Optional[StrictStr] = Field(None, description="Percentage of the warehouse compute resources that are executing SQL statements, but will be shut down once the queries complete.")
-    other: Optional[StrictStr] = Field(None, description="Percentage of the warehouse compute resources that are in a state other than available, provisioning, or quiescing.")
-    created_on: Optional[datetime] = Field(None, description="Date and time when the warehouse was created.")
-    resumed_on: Optional[datetime] = Field(None, description="Date and time when the warehouse was last started or restarted.")
-    updated_on: Optional[datetime] = Field(None, description="Date and time when the warehouse was last updated, which includes changing any of the properties of the warehouse or changing the state (STARTED, SUSPENDED, RESIZING) of the warehouse.")
-    owner: Optional[StrictStr] = Field(None, description="Role that owns the warehouse.")
-    budget: Optional[StrictStr] = Field(None, description="Comment representing budget for warehouse.")
+    tags: Optional[Dict[str, StrictStr]] = None
+    type: Optional[StrictStr] = None
+    size: Optional[StrictStr] = None
+    state: Optional[StrictStr] = None
+    started_clusters: Optional[StrictInt] = None
+    running: Optional[StrictInt] = None
+    queued: Optional[StrictInt] = None
+    is_default: Optional[StrictBool] = None
+    is_current: Optional[StrictBool] = None
+    available: Optional[StrictStr] = None
+    provisioning: Optional[StrictStr] = None
+    quiescing: Optional[StrictStr] = None
+    other: Optional[StrictStr] = None
+    created_on: Optional[datetime] = None
+    resumed_on: Optional[datetime] = None
+    updated_on: Optional[datetime] = None
+    owner: Optional[StrictStr] = None
+    budget: Optional[StrictStr] = None
     kind: Optional[StrictStr] = None
     __properties = ["name", "warehouse_type", "warehouse_size", "wait_for_completion", "max_cluster_count", "min_cluster_count", "scaling_policy", "auto_suspend", "auto_resume", "initially_suspended", "resource_monitor", "comment", "enable_query_acceleration", "query_acceleration_max_scale_factor", "max_concurrency_level", "statement_queued_timeout_in_seconds", "statement_timeout_in_seconds", "tags", "type", "size", "state", "started_clusters", "running", "queued", "is_default", "is_current", "available", "provisioning", "quiescing", "other", "created_on", "resumed_on", "updated_on", "owner", "budget", "kind"]
 
 
     @validator('name')
     def name_validate_regular_expression(cls, v):
         if not re.match(r"""^\"([^\"]|\"\")+\"|[a-zA-Z_][a-zA-Z0-9_$]*$""", v):
```

### Comparing `snowflake_core-0.7.0/tests/utils.py` & `snowflake_core-0.8.0/tests/utils.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.7.0/tests/integ/test_image_repository.py` & `snowflake_core-0.8.0/tests/integ/test_image_repository.py`

 * *Files 22% similar despite different names*

```diff
@@ -2,20 +2,23 @@
 # Copyright (c) 2012-2023 Snowflake Computing Inc. All rights reserved.
 #
 
 from operator import attrgetter
 
 import pytest
 
-from snowflake.core.exceptions import ServerError
+from snowflake.core.exceptions import NotFoundError
 from snowflake.core.image_repository import ImageRepository
 
 from ..utils import random_string
 
 
+pytestmark = pytest.mark.usefixtures("use_rest")
+
+
 def test_fetch(image_repositories, temp_ir):
     ir: ImageRepository = image_repositories[temp_ir.name].fetch()
     assert (
         ir.name == temp_ir.name  # for mixed case names
         or ir.name.upper() == temp_ir.name.upper()  # for upper/lower case names
     )
     assert ir.created_on
@@ -26,18 +29,16 @@
     ir_name = random_string(5, "test_ir_")
     test_ir = ImageRepository(
         name=ir_name,
     )
     image_repositories.create(test_ir)
     image_repositories[test_ir.name].delete()
     with pytest.raises(
-        ServerError,
+        NotFoundError,
     ):
-        # TODO: HTTP response body: {"description": "list index out of range", "error_details": null}
-        #  Looks wrong
         image_repositories[test_ir.name].fetch()
 
 
 def test_iter(image_repositories, temp_ir):
     assert any(
         map(
             lambda e: e
@@ -49,7 +50,21 @@
             ),
             (
                 temp_ir.name,  # for mixed case names
                 temp_ir.name.upper(),  # for upper/lower case names
             ),
         )
     )
+
+
+@pytest.mark.skip(reason="put isn't supported be Image repository OAS")
+@pytest.mark.parametrize("comment", (None, "ThIs Is A cOmMeNt"))
+def test_update_comment(image_repositories, comment):
+    new_ir_name = random_string(3, "test_update_comment_")
+    new_ir = ImageRepository(name=new_ir_name)
+    ir = image_repositories.create(new_ir)
+    try:
+        new_ir.comment = comment
+        ir.create_or_update(new_ir)
+        assert ir.fetch().comment == comment
+    finally:
+        ir.delete()
```

### Comparing `snowflake_core-0.7.0/tests/integ/test_schema.py` & `snowflake_core-0.8.0/tests/integ/test_schema.py`

 * *Files 19% similar despite different names*

```diff
@@ -5,49 +5,44 @@
 from snowflake.core import Clone, PointOfTimeOffset
 from snowflake.core.exceptions import NotFoundError
 from snowflake.core.schema import Schema, SchemaCollection, SchemaResource
 
 from .utils import random_string
 
 
-@pytest.fixture(scope="module", autouse=True)
-def revert_schema(connection):
-    """Ensure that the original schema is restored after the test runs.
-
-    This module messes with the current schema, we have to clean things up by reverting back to whatever
-    schema was used before these tests were run.
-    """
-    with connection.cursor() as cursor:
-        database = cursor.execute("SELECT CURRENT_DATABASE()").fetchone()[0]
-        schema = cursor.execute("SELECT CURRENT_SCHEMA()").fetchone()[0]
-        yield
-        if schema is not None:
-            cursor.execute(f"USE SCHEMA {database}.{schema}")
-        elif database is not None:
-            cursor.execute(f"USE DATABASE {database}")
+pytestmark = pytest.mark.usefixtures("backup_database_schema", "use_rest")
 
 
-def test_fetch(schemas, temp_schema):
+@pytest.mark.skip_rest
+@pytest.mark.jenkins
+def test_fetch(temp_schema):
     schema = temp_schema.fetch()
     assert (
         schema.name == temp_schema.name  # for mixed case names
         or temp_schema.name.upper()
         == temp_schema.name.upper()  # for upper/lower case names
     )
+    # Make sure that issuing an empty alter doesn't create a malformed SQL
+    temp_schema.create_or_update(schema)
 
+
+@pytest.mark.jenkins
 def test_delete(schemas):
+    comment = "my comment"
     new_schema = Schema(
-        name=random_string(5, "test_schema_")
+        name=random_string(5, "test_schema_"),
+        comment=comment,
     )
-    new_schema = schemas.create(new_schema)
-    new_schema.delete()
+    s = schemas.create(new_schema)
+    assert s.fetch().comment == comment
+    s.delete()
     with pytest.raises(
         NotFoundError,
     ):
-        new_schema.fetch()
+        s.fetch()
 
 
 def test_iter(schemas, temp_schema):
     schema_names = tuple(
                 map(
                     attrgetter("name"),
                     schemas.iter(),
@@ -61,19 +56,21 @@
                 temp_schema.name,  # for mixed case names
                 temp_schema.name.upper(),  # for upper/lower case names
             ),
         )
     )
 
 
+@pytest.mark.jenkins
 def test_iter_limit(schemas):
     data = list(schemas.iter(limit=10))
     assert len(data) <= 10
 
 
+@pytest.mark.skip_rest
 def test_update_all_params(schemas, temp_schema: SchemaResource):
     new_sc_def = temp_schema.fetch()
     new_sc_def.comment = "my new comment"
     new_sc_def.data_retention_time_in_days = 0
     new_sc_def.default_ddl_collation = "en_US-trim"
     new_sc_def.log_level = "INFO"
     new_sc_def.pipe_execution_paused = True
@@ -92,14 +89,17 @@
     assert new_sc.pipe_execution_paused is True
     assert new_sc.max_data_extension_time_in_days == 7
     assert new_sc.suspend_task_after_num_failures == 1
     assert new_sc.trace_level == "ALWAYS"
     assert new_sc.user_task_managed_initial_warehouse_size == "SMALL"
     assert new_sc.user_task_timeout_ms == 3600001
 
+
+@pytest.mark.jenkins
+@pytest.mark.skip("Temporarily disabled. TODO: Investigate why this is flaky.")
 def test_create_clone(schemas: SchemaCollection, temp_schema: SchemaResource):
     # for locally running this test run:
     #  create or replace schema TESTDB_PYTHON DATA_RETENTION_TIME_IN_DAYS=1;
     new_schema_def = Schema(name="TEST_CLONE_TESTSCHEMA_PYTHON")
     schema = schemas.create(
         new_schema_def,
         clone=Clone(
@@ -108,7 +108,22 @@
         ),
         mode='orreplace',
     )
     try:
         schema.fetch()
     finally:
         schema.delete()
+
+
+@pytest.mark.parametrize("comment", (None, "ThIs Is A cOmMeNt"))
+@pytest.mark.jenkins
+@pytest.mark.skip_rest
+def test_update_comment(schemas, comment):
+    new_s_name = random_string(3, "test_update_comment_")
+    new_s = Schema(name=new_s_name)
+    s = schemas.create(new_s)
+    try:
+        new_s.comment = comment
+        s.create_or_update(new_s)
+        assert s.fetch().comment == comment
+    finally:
+        s.delete()
```

### Comparing `snowflake_core-0.7.0/tests/integ/test_warehouse.py` & `snowflake_core-0.8.0/tests/integ/test_warehouse.py`

 * *Files 3% similar despite different names*

```diff
@@ -8,14 +8,17 @@
 from snowflake.core._common import CreateMode
 from snowflake.core.exceptions import NotFoundError
 from snowflake.core.warehouse import Warehouse
 
 from ..utils import random_string
 
 
+pytestmark = pytest.mark.usefixtures("backup_warehouse", "use_rest")
+
+
 def test_create_and_delete(warehouses, session):
     warehouse_name = random_string(5, "test_create_and_delete_warehouse_")
     test_warehouse = Warehouse(
         name=warehouse_name,
         warehouse_size="SMALL",
         auto_suspend=500,
     )
@@ -38,25 +41,28 @@
         warehouse_list = warehouses.iter(like=warehouse_name)
         for warehouse in warehouse_list:
             if warehouse is not None:
                 assert warehouse_name.upper() != warehouse.name.upper()
         session.sql("USE WAREHOUSE TESTWH_PYTHON").collect()
 
 
+@pytest.mark.skip_rest
 def test_create_or_update(warehouses, session):
     warehouse_name = random_string(5, "test_create_or_update_warehouse_")
     test_warehouse = Warehouse(name=warehouse_name)
     warehouse_ref = None
     try:
         # Test create when the warehouse does not exist.
         warehouse_ref = warehouses[warehouse_name]
         warehouse_ref.create_or_update(test_warehouse)
         warehouse_list = warehouses.iter(like=warehouse_name)
         result = next(warehouse_list)
         assert warehouse_name.upper() == result.name.upper()
+        # Make sure that issuing an empty alter doesn't create a malformed SQL
+        warehouse_ref.create_or_update(test_warehouse)
 
     finally:
         with suppress(NotFoundError):
             warehouse_ref.delete()
         session.sql("USE WAREHOUSE TESTWH_PYTHON").collect()
 
     # Test altering the warehouse.
@@ -85,14 +91,15 @@
 
     finally:
         with suppress(NotFoundError):
             warehouse_ref.delete()
         session.sql("USE WAREHOUSE TESTWH_PYTHON").collect()
 
 
+@pytest.mark.skip_rest
 def test_create_or_update_with_wildcardish_name(warehouses, session):
     # 2023-10-20(bwarsaw): Don't forget we have to filter out pre-existing warehouses, since we do not
     # have a clean test environment.
 
     # Create multiple warehouses with similar names.  Because the underscore is a wildcard character, and SHOW
     # WAREHOUSE does not support ILIKE or RLIKE, names can overlap.
     warehouse1_name = random_string(5, "warehouseXabcdef_")
@@ -116,14 +123,15 @@
     finally:
         for warehouse_ref in warehouse_refs:
             with suppress(NotFoundError):
                 warehouse_ref.delete()
         session.sql("USE WAREHOUSE TESTWH_PYTHON").collect()
 
 
+@pytest.mark.skip_rest
 def test_create_or_update_twice_without_change(warehouses, session):
     # Create multiple warehouses with the same name and no parameter change.
     warehouse1_name = random_string(5, "test_wh_pattern1_")
     warehouse2_name = warehouse1_name
 
     warehouse_refs = []
     try:
@@ -141,14 +149,15 @@
     finally:
         for warehouse_ref in warehouse_refs:
             with suppress(NotFoundError):
                 warehouse_ref.delete()
         session.sql("USE WAREHOUSE TESTWH_PYTHON").collect()
 
 
+@pytest.mark.skip_rest
 def test_create_or_update_twice_with_change(warehouses, session):
     # Create multiple warehouses with the same name, but this time the second one has a parameter change, so
     # it gets updated.
     warehouse1_name = random_string(5, "test_wh_pattern1_")
     warehouse2_name = warehouse1_name
 
     warehouse_refs = []
@@ -307,44 +316,60 @@
         with suppress(NotFoundError):
             warehouse_ref.delete()
         session.sql("USE WAREHOUSE TESTWH_PYTHON").collect()
 
 
 def test_properties(warehouses, session):
     warehouse_name = random_string(5, "test_create_and_delete_warehouse_")
+    comment = "CoMpLiCaTeD sTrInG"
     test_warehouse = Warehouse(
         name=warehouse_name,
         warehouse_size="SMALL",
         warehouse_type="STANDARD",
         auto_suspend=500,
         auto_resume="true",
         max_concurrency_level=10,
-        statement_timeout_in_seconds=17000
+        statement_timeout_in_seconds=17000,
+        comment=comment,
     )
 
-    warehouse_ref = None
+    warehouse_ref = warehouses.create(test_warehouse)
     try:
-        warehouse_ref = warehouses.create(test_warehouse)
         warehouse_list = warehouses.iter(like=warehouse_name)
         result = next(warehouse_list)
 
         assert warehouse_name.upper() == result.name.upper()
         assert result.size.upper() == "SMALL"
         assert result.type.upper() == "STANDARD"
         assert result.auto_suspend == 500
         assert result.auto_resume.upper() == "TRUE"
         assert result.max_concurrency_level == 10
         assert result.statement_timeout_in_seconds == 17000
+        assert result.comment == comment
         with pytest.raises(TypeError):
             test_empty_name_warehouse = Warehouse() # noqa: F841
-
     finally:
         with suppress(NotFoundError):
             warehouse_ref.delete()
         session.sql("USE WAREHOUSE TESTWH_PYTHON").collect()
 
 @pytest.mark.skip(reason="instable because no isolation of test env")
 def test_no_warehouses(warehouses, session):
     found = list(wh.name for wh in warehouses.iter())
     pre_existing = list(wh.name for wh in warehouses._pre_existing)
     new_warehouses = set(found) - set(pre_existing)
     assert len(new_warehouses) == 0
+
+
+# @pytest.mark.skip(reason="put isn't supported be Image repository OAS")
+@pytest.mark.parametrize("comment", (None, "ThIs Is A cOmMeNt"))
+@pytest.mark.skip_rest
+def test_update_comment(warehouses, comment):
+    new_w_name = random_string(3, "test_update_comment_")
+    new_w = Warehouse(name=new_w_name)
+    w = warehouses.create(new_w)
+    try:
+        new_w.comment = comment
+        w.create_or_update(new_w)
+        assert w.fetch().comment == comment
+    finally:
+        w.delete()
```

### Comparing `snowflake_core-0.7.0/tests/integ/utils.py` & `snowflake_core-0.8.0/tests/integ/utils.py`

 * *Files 26% similar despite different names*

```diff
@@ -14,7 +14,21 @@
 def get_task_history(session: Session, name: str) -> List[Row]:
     query = (
         f"select * from table(information_schema.task_history("
         f"scheduled_time_range_start=>dateadd('hour',-1,current_timestamp()),"
         f"result_limit => 10,task_name=>'{name}'))"
     )
     return session.sql(query).collect()
+
+
+def string_skip_space_and_cases(s):
+    return s.replace(' ','').upper()
+
+
+def array_equal_comparison(arr1, arr2):
+    if not arr1 and not arr2:
+        return True
+    if not arr1 or not arr2:
+        return False
+
+    return [string_skip_space_and_cases(i) for i in arr1] \
+        == [string_skip_space_and_cases(i) for i in arr2]
```

### Comparing `snowflake_core-0.7.0/tests/integ/task/conftest.py` & `snowflake_core-0.8.0/tests/integ/task/conftest.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.7.0/tests/integ/task/test_create_or_update_task.py` & `snowflake_core-0.8.0/tests/integ/task/test_create_or_update_task.py`

 * *Files 1% similar despite different names*

```diff
@@ -7,14 +7,17 @@
 from snowflake.core.task import Cron, StoredProcedureCall, Task
 from snowflake.snowpark import Session
 from snowflake.snowpark._internal.utils import parse_table_name
 
 from ..utils import random_object_name
 
 
+pytestmark=pytest.mark.usefixtures("use_rest")
+
+
 def test_create_or_update(tasks, db_parameters):
     task_name1 = random_object_name()
     task_name2 = random_object_name()
     try:
         task1 = tasks[task_name1]
         task1.create_or_update(
             Task(
```

### Comparing `snowflake_core-0.7.0/tests/integ/task/test_create_task.py` & `snowflake_core-0.8.0/tests/integ/task/test_create_task.py`

 * *Files 2% similar despite different names*

```diff
@@ -15,14 +15,18 @@
 
 
 task_name1 = random_object_name()
 task_name2 = random_object_name()
 task_name3 = random_object_name()
 
 
+pytestmark=pytest.mark.usefixtures("use_rest")
+
+
+@pytest.mark.jenkins
 def test_get_task(tasks):
     with pytest.raises(NotFoundError):
         tasks["abc"].fetch()
 
 
 def test_create_task_session_parameter(tasks):
     query = "select current_version()"
@@ -239,16 +243,15 @@
     finally:
         with suppress(NotFoundError):
             tasks[task_name1].delete()
 
 
 def test_create_task_predecessors(tasks):
     try:
-        # TODO: revert task_name1_with_special_char to '"a b"' when SNOW-1057963 is resolved
-        task_name1_with_special_char = 'ab'
+        task_name1_with_special_char = '"a b"'
         task1 = tasks.create(
             Task(name=task_name1_with_special_char, definition="select current_version()"),
         )
 
         task2 = tasks.create(
             Task(name=task_name2, definition="select current_version()"),
         )
@@ -272,15 +275,15 @@
                 tasks[task_name2].fetch().name,
                 tasks[task_name1_with_special_char].fetch().name,
             ]
         )
         assert expected == task3_predecessors
     finally:
         with suppress(Exception):
-            tasks[task_name1].delete()
+            tasks[task_name1_with_special_char].delete()
         with suppress(Exception):
             tasks[task_name2].delete()
         with suppress(Exception):
             tasks[task_name3].delete()
 
 
 def test_create_task_condition(tasks):
```

### Comparing `snowflake_core-0.7.0/tests/integ/task/test_drop_task.py` & `snowflake_core-0.8.0/tests/integ/task/test_drop_task.py`

 * *Files 4% similar despite different names*

```diff
@@ -5,14 +5,17 @@
 import pytest
 
 from snowflake.core.exceptions import NotFoundError
 
 from ..utils import random_object_name
 
 
+pytestmark=pytest.mark.usefixtures("use_rest")
+
+
 def test_drop_basic(tasks, root):
     task_name = random_object_name()
     try:
         create_task = (
             f"create or replace task {task_name} "
             "ALLOW_OVERLAPPING_EXECUTION = true SUSPEND_TASK_AFTER_NUM_FAILURES = 10 "
             "schedule = '10 minute' as select current_version()"
```

### Comparing `snowflake_core-0.7.0/tests/integ/task/test_execute_task.py` & `snowflake_core-0.8.0/tests/integ/task/test_execute_task.py`

 * *Files 3% similar despite different names*

```diff
@@ -7,14 +7,17 @@
 
 from snowflake.core.exceptions import APIError, NotFoundError
 from snowflake.core.task import Task
 
 from ..utils import get_task_history, random_object_name
 
 
+pytestmark=pytest.mark.usefixtures("use_rest")
+
+
 def test_execute_basic(tasks, session):
     task_name = random_object_name()
     try:
         task = tasks.create(Task(name=task_name, definition="select 1"))
         assert not get_task_history(session, task.name)
         task.execute()
         assert len(get_task_history(session, task.name)) == 1
```

### Comparing `snowflake_core-0.7.0/tests/integ/task/test_load_task.py` & `snowflake_core-0.8.0/tests/integ/task/test_load_task.py`

 * *Files 5% similar despite different names*

```diff
@@ -15,14 +15,17 @@
 
 
 task_name1 = random_object_name()
 task_name2 = random_object_name()
 task_name3 = random_object_name()
 
 
+pytestmark=pytest.mark.usefixtures("use_rest")
+
+
 @pytest.fixture(scope="module", autouse=True)
 def setup(tasks, session) -> Generator[None, None, None]:
     warehouse_name: str = session.get_current_warehouse()
     create_task2 = (
         f"create or replace task {task_name2} "
         "ALLOW_OVERLAPPING_EXECUTION = true SUSPEND_TASK_AFTER_NUM_FAILURES = 10 "
         "TIMEZONE='America/Los_Angeles' SNOWPARK_REQUEST_TIMEOUT_IN_SECONDS = 100 QUERY_RESULT_FORMAT='ARROW'"
```

### Comparing `snowflake_core-0.7.0/tests/integ/task/test_python_function.py` & `snowflake_core-0.8.0/tests/integ/task/test_python_function.py`

 * *Files 4% similar despite different names*

```diff
@@ -27,14 +27,17 @@
     # Clients do not need to use `atpublic`; it's a convenient decorator used in TaskContext so it needs to be
     # named in the stored procedure packages list.
     "atpublic",
     "snowflake-snowpark-python",
 ]
 
 
+pytestmark=pytest.mark.usefixtures("use_rest")
+
+
 def test_create_task_from_python_function(tasks, session):
     def f(session: Session, table_name: str) -> str:
         context = TaskContext(session)
         value = context.get_current_task_name()
         session.sql(f"insert into {table_name} values(1, '{value}')").collect()
         context.set_return_value(value)
         return session.sql("select 'snowflake'").collect()[0][0]
@@ -134,14 +137,15 @@
             result = get_task_history(session, task_name)
             assert len(result) > 0
             state = result[0]["STATE"]
             if state in ["SCHEDULED", "EXECUTING"]:
                 time.sleep(1)
                 time_count += 1
                 if time_count > time_limit:  # run for 2 min
+                    pytest.xfail("Flaky test, fix trace by SNOW-1317265")
                     raise ValueError(
                         f"Running more than {time_limit} seconds. task: {task_name}, result: {result}"
                     )
                 continue
             elif state == "SUCCEEDED":
                 assert result[0]["ERROR_CODE"] is None
                 if task_name == task_name2:
@@ -239,14 +243,15 @@
             result = get_task_history(session, task_name)
             assert len(result) > 0
             state = result[0]["STATE"]
             if state in ["SCHEDULED", "EXECUTING"]:
                 time.sleep(1)
                 time_count += 1
                 if time_count > time_limit:  # run for 2 min
+                    pytest.xfail("Flaky test, fix trace by SNOW-1317265")
                     raise ValueError(
                         f"Running more than {time_limit} seconds. task: {task_name}, result: {result}"
                     )
                 continue
             elif state == "SUCCEEDED":
                 assert result[0]["ERROR_CODE"] is None
                 if task_name == task_name2:
@@ -264,14 +269,15 @@
         session.sql(f"drop table if exists {table_name}").collect()
         session.sql(f"drop task if exists {task_name1}").collect()
         session.sql(f"drop task if exists {task_name2}").collect()
         session.sql(f"drop procedure if exists {sp1_name}(string)").collect()
         session.sql(f"drop procedure if exists {sp2_name}(string)").collect()
 
 
+@pytest.mark.jenkins
 def test_create_task_from_python_function_negative(tasks):
     with pytest.raises(
         ValueError,
         match="stage_location has to be specified when func is a Python function",
     ):
         StoredProcedureCall(lambda: 1)
 
@@ -282,14 +288,15 @@
     with pytest.raises(
         ValueError,
         match="warehouse must be specified when creating a task with a StoredProcedureCall object",
     ):
         tasks.create(t1)
 
 
+@pytest.mark.jenkins
 def test_task_context(tasks, session):
     # we are not able to test it in a real task, so just call functions here
     task_context = TaskContext(session)
 
     with pytest.raises(SnowparkSQLException, match="must be called from within a task"):
         task_context.set_return_value("1")
```

### Comparing `snowflake_core-0.7.0/tests/integ/task/test_show_task.py` & `snowflake_core-0.8.0/tests/integ/task/test_show_task.py`

 * *Files 5% similar despite different names*

```diff
@@ -12,14 +12,17 @@
 
 
 task_name1 = random_object_name()
 task_name2 = random_object_name()
 task_name3 = random_object_name()
 
 
+pytestmark=pytest.mark.usefixtures("use_rest")
+
+
 @pytest.fixture(scope="module", autouse=True)
 def setup(tasks, session) -> Generator[None, None, None]:
     warehouse_name: str = session.get_current_warehouse()
     create_task2 = (
         f"create or replace task {task_name2} "
         "ALLOW_OVERLAPPING_EXECUTION = true SUSPEND_TASK_AFTER_NUM_FAILURES = 10 "
         "schedule = '10 minute' as select current_version()"
```

### Comparing `snowflake_core-0.7.0/tests/integ/task/dag/test_dag.py` & `snowflake_core-0.8.0/tests/integ/task/dag/test_dag.py`

 * *Files 2% similar despite different names*

```diff
@@ -13,14 +13,17 @@
 from snowflake.core.task.dagv1 import DAG, DAGOperation, DAGTask, DAGTaskBranch, _use_func_return_value
 from snowflake.core.warehouse import Warehouse
 from snowflake.snowpark import Session
 
 from ...utils import get_task_history, random_object_name
 
 
+pytestmark=[pytest.mark.usefixtures("use_rest")]
+
+
 def test_deploy_dag(schema):
     test_dag = random_object_name()
     with DAG(test_dag, schedule=timedelta(minutes=10)) as dag:
         task1 = DAGTask("task1", "select 1")
         task2 = DAGTask("task2", "select 2")
         task3 = DAGTask("task3", "select 3")
         task2 << task1 >> task3
@@ -49,45 +52,36 @@
         fetched = schema.tasks[test_dag].fetch_task_dependents()
         assert len(fetched) == 4
         assert fetched[0].name.lower() == test_dag
         assert fetched[1].name.lower() == f"{test_dag}$task1"
     finally:
         op.delete(dag)
 
-
+@pytest.mark.usefixtures("backup_database_schema")
 def test_deploy_dag_to_not_default_schema(root, db_parameters):
-    cursor = root.connection.cursor()
-    database_name = cursor.execute("SELECT CURRENT_DATABASE()").fetchone()[0]
-    schema_name = cursor.execute("SELECT CURRENT_SCHEMA()").fetchone()[0]
+    database = db_parameters["database"]
+    new_schema_name = random_object_name()
+    test_dag = random_object_name()
+    root.connection.execute_string(f"create schema {database}.{new_schema_name}")
     try:
-        database = db_parameters["database"]
-        new_schema_name = random_object_name()
-        test_dag = random_object_name()
-        root.connection.execute_string(f"create schema {database}.{new_schema_name}")
-        try:
-            new_schema = root.databases[database].schemas[new_schema_name]
-            with DAG(test_dag, schedule=timedelta(minutes=10)) as dag:
-                task1 = DAGTask("task1", "select 1")
-                task2 = DAGTask("task2", "select 2")
-                task3 = DAGTask("task3", "select 3")
-                task2 << task1 >> task3
-            op = DAGOperation(new_schema)
-            op.deploy(dag, mode=CreateMode.or_replace)
-            fetched = new_schema.tasks[test_dag].fetch_task_dependents()
-            assert len(fetched) == 4
-            assert fetched[0].name.lower() == test_dag
-            assert fetched[1].name.lower() == f"{test_dag}$task1"
-            op.delete(dag)
-        finally:
-            root.connection.execute_string(f"drop schema if exists {new_schema_name}")
+        new_schema = root.databases[database].schemas[new_schema_name]
+        with DAG(test_dag, schedule=timedelta(minutes=10)) as dag:
+            task1 = DAGTask("task1", "select 1")
+            task2 = DAGTask("task2", "select 2")
+            task3 = DAGTask("task3", "select 3")
+            task2 << task1 >> task3
+        op = DAGOperation(new_schema)
+        op.deploy(dag, mode=CreateMode.or_replace)
+        fetched = new_schema.tasks[test_dag].fetch_task_dependents()
+        assert len(fetched) == 4
+        assert fetched[0].name.lower() == test_dag
+        assert fetched[1].name.lower() == f"{test_dag}$task1"
+        op.delete(dag)
     finally:
-        if schema_name is not None:
-            cursor.execute(f"USE SCHEMA {database_name}.{schema_name}")
-        elif database_name is not None:
-            cursor.execute(f"USE DATABASE {database_name}")
+        root.connection.execute_string(f"drop schema if exists {new_schema_name}")
 
 
 def test_deploy_dag_circle(schema):
     test_dag = random_object_name()
     with DAG(test_dag, schedule=timedelta(minutes=10)) as dag:
         task1 = DAGTask("task1", "select 1")
         task2 = DAGTask("task2", "select 2")
```

### Comparing `snowflake_core-0.7.0/tests/unit/common.py` & `snowflake_core-0.8.0/tests/unit/test_common.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,22 +1,26 @@
 #
 # Copyright (c) 2012-2023 Snowflake Computing Inc. All rights reserved.
 #
-
 from unittest.mock import MagicMock
 
+import pytest
+
 from snowflake.core._common import (
     CreateMode,
     SchemaObjectCollectionParent,
     SchemaObjectReferenceMixin,
 )
 from snowflake.core.database import DatabaseCollection
 from snowflake.core.schema import SchemaResource
 
 
+pytestmark = pytest.mark.jenkins
+
+
 class XyzCollection(SchemaObjectCollectionParent["XyzReference"]):
     def __init__(self, schema: "SchemaResource") -> None:
         super().__init__(schema, XyzReference)
 
 
 class XyzReference(SchemaObjectReferenceMixin):
     def __init__(self, name: str, collection: "XyzCollection") -> None:
```

### Comparing `snowflake_core-0.7.0/tests/unit/test_database.py` & `snowflake_core-0.8.0/tests/unit/test_database.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,220 +1,259 @@
+from collections import defaultdict
 from contextlib import suppress
 from unittest import mock
 
-from snowflake.core.database import Database, DatabaseCollection
+import pytest
 
+from snowflake.core.database import Database
+from snowflake.core.version import __version__ as VERSION
 
-def test_fetch(fake_root):
-    dbs = DatabaseCollection(fake_root)
+
+pytestmark = pytest.mark.jenkins
+
+
+SNOWPY_USER_AGENT_VAL = "python_api/" + VERSION
+
+def test_fetch(fake_root, db):
     with suppress(Exception):
-        with mock.patch(
-            "snowflake.core.database._generated.api_client.ApiClient.request"
-        ) as mocked_request:
-            dbs["my_db"].fetch()
+        with mock.patch("snowflake.core.database._generated.api_client.ApiClient.request") as mocked_request:
+            db.fetch()
     mocked_request.assert_called_once_with(
-        'GET',
-        'http://localhost:80/api/v2/databases/my_db',
+        fake_root,
+        "GET",
+        "http://localhost:80/api/v2/databases/my_db",
         query_params=[],
-        headers={'Accept': 'application/json', 'User-Agent': 'OpenAPI-Generator/1.0.0/python'},
+        headers={"Accept": "application/json", "User-Agent": SNOWPY_USER_AGENT_VAL},
         post_params=[],
         body=None,
         _preload_content=True,
         _request_timeout=None,
     )
 
-def test_delete(fake_root):
-    dbs = DatabaseCollection(fake_root)
-    with mock.patch(
-        "snowflake.core.database._generated.api_client.ApiClient.request"
-    ) as mocked_request:
-        dbs["my_db"].delete()
+
+def test_delete(fake_root, db):
+    with mock.patch("snowflake.core.database._generated.api_client.ApiClient.request") as mocked_request:
+        db.delete()
     mocked_request.assert_called_once_with(
-        'DELETE',
-        'http://localhost:80/api/v2/databases/my_db',
+        fake_root,
+        "DELETE",
+        "http://localhost:80/api/v2/databases/my_db",
         query_params=[],
-        headers={'Accept': 'application/json', 'User-Agent': 'OpenAPI-Generator/1.0.0/python'},
+        headers={"Accept": "application/json", "User-Agent": SNOWPY_USER_AGENT_VAL},
         post_params=[],
         body=None,
         _preload_content=True,
         _request_timeout=None,
     )
 
-def test_create(fake_root):
-    dbs = DatabaseCollection(fake_root)
-    with mock.patch(
-        "snowflake.core.database._generated.api_client.ApiClient.request"
-    ) as mocked_request:
+
+def test_create(fake_root, dbs):
+    with mock.patch("snowflake.core.database._generated.api_client.ApiClient.request") as mocked_request:
         dbs.create(
             Database(
                 name="sophie_db",
                 comment="This is Sophie's database",
                 trace_level="always",
             ),
             kind="transient",
         )
     mocked_request.assert_called_once_with(
-        'POST',
-        'http://localhost:80/api/v2/databases?createMode=errorIfExists&kind=transient',
+        fake_root,
+        "POST",
+        "http://localhost:80/api/v2/databases?createMode=errorIfExists&kind=transient",
         query_params=[
-            ('createMode', 'errorIfExists'),
-            ('kind', 'transient'),
+            ("createMode", "errorIfExists"),
+            ("kind", "transient"),
         ],
         headers={
-            'Accept': 'application/json',
-            'Content-Type': 'application/json',
-            'User-Agent': 'OpenAPI-Generator/1.0.0/python',
+            "Accept": "application/json",
+            "Content-Type": "application/json",
+            "User-Agent": SNOWPY_USER_AGENT_VAL,
         },
         post_params=[],
-        body={'name': 'sophie_db', 'comment': "This is Sophie's database", 'trace_level': 'always', 'dropped_on': None},
+        body={"name": "sophie_db", "comment": "This is Sophie's database", "trace_level": "always", "dropped_on": None},
         _preload_content=True,
         _request_timeout=None,
     )
 
-def test_create_from_share(fake_root):
-    dbs = DatabaseCollection(fake_root)
-    with mock.patch(
-        "snowflake.core.database._generated.api_client.ApiClient.request"
-    ) as mocked_request:
+
+def test_create_from_share(fake_root, dbs):
+    with mock.patch("snowflake.core.database._generated.api_client.ApiClient.request") as mocked_request:
         dbs._create_from_share(
             name="name",
             share="share",
         )
     mocked_request.assert_called_once_with(
-        'POST',
-        'http://localhost:80/api/v2/databases/from_share?createMode=errorIfExists&name=name&share=share&kind=',
+        fake_root,
+        "POST",
+        "http://localhost:80/api/v2/databases/name:from_share?createMode=errorIfExists&share=share&kind=",
         query_params=[
-            ('createMode', 'errorIfExists'),
-            ('name', 'name'),
-            ('share', 'share'),
-            ('kind', ''),
+            ("createMode", "errorIfExists"),
+            ("share", "share"),
+            ("kind", ""),
         ],
-        headers={'Accept': 'application/json', 'User-Agent': 'OpenAPI-Generator/1.0.0/python'},
+        headers={"Accept": "application/json", "User-Agent": SNOWPY_USER_AGENT_VAL},
         post_params=[],
         body=None,
         _preload_content=True,
         _request_timeout=None,
     )
 
-def test_enable_replication(fake_root):
-    dbs = DatabaseCollection(fake_root)
-    with mock.patch(
-        "snowflake.core.database._generated.api_client.ApiClient.request"
-    ) as mocked_request:
-        dbs["my_db2"].enable_replication(
-            ["fake_identifier1", "fake_identifier2"]
-        )
+
+def test_enable_replication(fake_root, db):
+    with mock.patch("snowflake.core.database._generated.api_client.ApiClient.request") as mocked_request:
+        db.enable_replication(["fake_identifier1", "fake_identifier2"])
     mocked_request.assert_called_once_with(
-        'POST',
-        'http://localhost:80/api/v2/databases/my_db2/replication:enable?ignore_edition_check=False',
+        fake_root,
+        "POST",
+        "http://localhost:80/api/v2/databases/my_db/replication:enable?ignore_edition_check=False",
         query_params=[
-            ('ignore_edition_check', False),
+            ("ignore_edition_check", False),
         ],
         headers={
-            'Accept': 'application/json',
-            'Content-Type': 'application/json',
-            'User-Agent': 'OpenAPI-Generator/1.0.0/python',
+            "Accept": "application/json",
+            "Content-Type": "application/json",
+            "User-Agent": SNOWPY_USER_AGENT_VAL,
         },
         post_params=[],
-        body={'accounts': ['fake_identifier1', 'fake_identifier2']},
+        body={"accounts": ["fake_identifier1", "fake_identifier2"]},
         _preload_content=True,
         _request_timeout=None,
     )
 
-def test_disable_replication(fake_root):
-    dbs = DatabaseCollection(fake_root)
-    with mock.patch(
-        "snowflake.core.database._generated.api_client.ApiClient.request"
-    ) as mocked_request:
-        dbs["my_db2"].disable_replication()
+
+def test_disable_replication(fake_root, db):
+    with mock.patch("snowflake.core.database._generated.api_client.ApiClient.request") as mocked_request:
+        db.disable_replication()
     mocked_request.assert_called_once_with(
-        'POST',
-        'http://localhost:80/api/v2/databases/my_db2/replication:disable',
+        fake_root,
+        "POST",
+        "http://localhost:80/api/v2/databases/my_db/replication:disable",
         query_params=[],
         headers={
-            'Accept': 'application/json',
-            'Content-Type': 'application/json',
-            'User-Agent': 'OpenAPI-Generator/1.0.0/python',
+            "Accept": "application/json",
+            "Content-Type": "application/json",
+            "User-Agent": SNOWPY_USER_AGENT_VAL,
         },
         post_params=[],
-        body={'accounts': []},
+        body={"accounts": []},
         _preload_content=True,
         _request_timeout=None,
     )
 
-def test_refresh_replication(fake_root):
-    dbs = DatabaseCollection(fake_root)
-    with mock.patch(
-        "snowflake.core.database._generated.api_client.ApiClient.request"
-    ) as mocked_request:
-        dbs["my_db2"].refresh_replication()
+
+def test_refresh_replication(fake_root, db):
+    with mock.patch("snowflake.core.database._generated.api_client.ApiClient.request") as mocked_request:
+        db.refresh_replication()
     mocked_request.assert_called_once_with(
-        'POST',
-        'http://localhost:80/api/v2/databases/my_db2/replication:refresh',
+        fake_root,
+        "POST",
+        "http://localhost:80/api/v2/databases/my_db/replication:refresh",
         query_params=[],
-        headers={'Accept': 'application/json', 'User-Agent': 'OpenAPI-Generator/1.0.0/python'},
+        headers={"Accept": "application/json", "User-Agent": SNOWPY_USER_AGENT_VAL},
         post_params=[],
         body=None,
         _preload_content=True,
         _request_timeout=None,
     )
 
-def test_enable_failover(fake_root):
-    dbs = DatabaseCollection(fake_root)
-    with mock.patch(
-        "snowflake.core.database._generated.api_client.ApiClient.request"
-    ) as mocked_request:
-        dbs["my_db2"].enable_failover(
-            ["fake_identifier1", "fake_identifier2"]
-        )
+
+def test_enable_failover(fake_root, db):
+    with mock.patch("snowflake.core.database._generated.api_client.ApiClient.request") as mocked_request:
+        db.enable_failover(["fake_identifier1", "fake_identifier2"])
     mocked_request.assert_called_once_with(
-        'POST',
-        'http://localhost:80/api/v2/databases/my_db2/failover:enable',
+        fake_root,
+        "POST",
+        "http://localhost:80/api/v2/databases/my_db/failover:enable",
         query_params=[],
         headers={
-            'Accept': 'application/json',
-            'Content-Type': 'application/json',
-            'User-Agent': 'OpenAPI-Generator/1.0.0/python',
+            "Accept": "application/json",
+            "Content-Type": "application/json",
+            "User-Agent": SNOWPY_USER_AGENT_VAL,
         },
         post_params=[],
-        body={'accounts': ['fake_identifier1', 'fake_identifier2']},
+        body={"accounts": ["fake_identifier1", "fake_identifier2"]},
         _preload_content=True,
         _request_timeout=None,
     )
 
-def test_disable_failover(fake_root):
-    dbs = DatabaseCollection(fake_root)
-    with mock.patch(
-        "snowflake.core.database._generated.api_client.ApiClient.request"
-    ) as mocked_request:
-        dbs["my_db2"].disable_failover()
+
+def test_disable_failover(fake_root, db):
+    with mock.patch("snowflake.core.database._generated.api_client.ApiClient.request") as mocked_request:
+        db.disable_failover()
     mocked_request.assert_called_once_with(
-        'POST',
-        'http://localhost:80/api/v2/databases/my_db2/failover:disable',
+        fake_root,
+        "POST",
+        "http://localhost:80/api/v2/databases/my_db/failover:disable",
         query_params=[],
         headers={
-            'Accept': 'application/json',
-            'Content-Type': 'application/json',
-            'User-Agent': 'OpenAPI-Generator/1.0.0/python',
+            "Accept": "application/json",
+            "Content-Type": "application/json",
+            "User-Agent": SNOWPY_USER_AGENT_VAL,
         },
         post_params=[],
-        body={'accounts': []},
+        body={"accounts": []},
         _preload_content=True,
         _request_timeout=None,
     )
 
-def test_promote_to_primary_failover(fake_root):
-    dbs = DatabaseCollection(fake_root)
-    with mock.patch(
-        "snowflake.core.database._generated.api_client.ApiClient.request"
-    ) as mocked_request:
-        dbs["my_db2"].promote_to_primary_failover()
+
+def test_promote_to_primary_failover(fake_root, db):
+    with mock.patch("snowflake.core.database._generated.api_client.ApiClient.request") as mocked_request:
+        db.promote_to_primary_failover()
     mocked_request.assert_called_once_with(
-        'POST',
-        'http://localhost:80/api/v2/databases/my_db2/failover:primary',
+        fake_root,
+        "POST",
+        "http://localhost:80/api/v2/databases/my_db/failover:primary",
         query_params=[],
-        headers={'Accept': 'application/json', 'User-Agent': 'OpenAPI-Generator/1.0.0/python'},
+        headers={"Accept": "application/json", "User-Agent": SNOWPY_USER_AGENT_VAL},
         post_params=[],
         body=None,
         _preload_content=True,
         _request_timeout=None,
     )
+
+
+request_called_count_for_long_running = defaultdict(int)
+
+
+def mocked_request_get(*args, **kwargs):
+    class MockResponse:
+        def __init__(self, data, status):
+            self.data = data
+            self.status = status
+
+        def getheader(self, param):
+            return {"Location": "/api/v2/results/XXXX"}.get(param, None)
+
+    url = args[2]
+
+    global request_called_count_for_long_running
+    if "api/v2/databases" in url:
+        request_called_count_for_long_running["database"] += 1
+        return MockResponse(None, 202)
+
+    assert "api/v2/result" in url
+    request_called_count_for_long_running["result"] += 1
+    if request_called_count_for_long_running.get("result", 0) < 2:
+        return MockResponse(None, 202)
+    return None
+
+
+# def test_fetch_with_long_running(fake_root, setup_enable_rest_api_with_long_running):
+#     dbs = DatabaseCollection(fake_root)
+#     with setup_enable_rest_api_with_long_running(dbs._ref_class):
+#         with mock.patch(
+#             "snowflake.core.database._generated.api_client.ApiClient.request",
+#             side_effect=mocked_request_get,
+#         ):
+#             # TODO: Improve fetch results instead of error
+#             try:
+#                 dbs["my_db"].fetch()
+#             except AttributeError:
+#                 # TODO: The AttributeError message is not reliable, so we just catch it and
+#                 # pass for now. Make this better
+#                 # assert e.args[0] == "'NoneType' object has no attribute 'status'"
+#                 pass
+#         global request_called_count_for_long_running
+#         assert request_called_count_for_long_running['database'] == 1
+#         assert request_called_count_for_long_running['result'] == 2
```

### Comparing `snowflake_core-0.7.0/tests/unit/api/general_api_test.py` & `snowflake_core-0.8.0/tests/unit/api/general_api_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -17,32 +17,35 @@
 from snowflake.core.table._generated.api_client import ApiClient as TableApiClient
 from snowflake.core.task._generated.api.task_api import TaskApi
 from snowflake.core.task._generated.api_client import ApiClient as TaskApiClient
 from snowflake.core.warehouse._generated.api.warehouse_api import WarehouseApi
 from snowflake.core.warehouse._generated.api_client import ApiClient as WarehouseApiClient
 
 
+pytestmark = pytest.mark.jenkins
+
+
 def logging_message_on_change_api_client(api_client_type):
-    return "Going to use client-%s for this resource" % api_client_type.name
+    return f"Going to use client-{api_client_type.name} for this resource"
 
 @pytest.mark.parametrize("resource_api, resource_api_client", [
     (ComputePoolApi, ComputePoolApiClient),
     (DatabaseApi, DatabaseApiClient),
     (ImageRepositoryApi, ImageRepositoryApiClient),
     (SchemaApi, SchemaApiClient),
     (ServiceApi, ServiceApiClient),
     (TaskApi, TaskApiClient),
     (TableApi, TableApiClient),
-    (WarehouseApi, WarehouseApiClient)])
+    (WarehouseApi, WarehouseApiClient),])
 @pytest.mark.usefixtures("logger_level_info")
 def test_api_client_source_change(fake_root, resource_api, resource_api_client, caplog):
     # Test each Api's general client choosing mechanism
     fake_resource = mock.MagicMock()
 
-    api = resource_api(fake_root, fake_resource, None)
+    api = resource_api(fake_root, fake_resource, None, None)
     assert api._chosen_client_type == ApiClientType.NONE
     caplog.clear()
 
     # Test changing Api Client None -> Bridge
     fake_root._can_use_rest_api = False
     fake_resource._supports_rest_api = False
     assert api.api_client is None
@@ -72,15 +75,15 @@
     assert api.api_client is None
     assert logging_message_on_change_api_client(ApiClientType.BRIDGE) not in caplog.text
     assert logging_message_on_change_api_client(ApiClientType.REST) not in caplog.text
     caplog.clear()
     assert api._chosen_client_type == ApiClientType.BRIDGE
 
     # Test changing Api Client None -> Rest
-    api = resource_api(fake_root, fake_resource, None)
+    api = resource_api(fake_root, fake_resource, None, None)
     assert api._chosen_client_type == ApiClientType.NONE
     fake_root._can_use_rest_api = True
     fake_resource._supports_rest_api = True
     assert isinstance(api.api_client, resource_api_client)
     assert logging_message_on_change_api_client(ApiClientType.REST) in caplog.text
     caplog.clear()
     assert api._chosen_client_type == ApiClientType.REST
```

### Comparing `snowflake_core-0.7.0/tests/unit/bridge/test_database.py` & `snowflake_core-0.8.0/tests/unit/bridge/test_database.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,14 +4,17 @@
 
 from snowflake.core import Clone, PointOfTimeOffset
 from snowflake.core._internal.bridge.rest_errors import NotFound
 from snowflake.core.database import Database, DatabaseCollection
 from snowflake.core.exceptions import NotFoundError, ServerError
 
 
+pytestmark = pytest.mark.jenkins
+
+
 def test_fetch(fake_root):
     dbs = DatabaseCollection(fake_root)
     with mock.patch(
         "snowflake.core._internal.bridge.executor.SnowExecute.execute"
     ) as mocked_execute:
         with pytest.raises(NotFoundError):
             dbs["my_db"].fetch()
@@ -111,15 +114,15 @@
     ) as mocked_execute:
         with pytest.raises(ServerError):
             dbs._create_from_share(
                 name="my_own_db",
                 share="share.db",
             )
     mocked_execute.assert_called_once_with(
-        "CREATE DATABASE my_own_db FROM SHARE share.db "
+        "CREATE DATABASE MY_OWN_DB FROM SHARE share.db "
     )
 
 def test_delete(fake_root):
     dbs = DatabaseCollection(fake_root)
     with mock.patch(
         "snowflake.core._internal.bridge.executor.SnowExecute.execute"
     ) as mocked_execute:
@@ -196,7 +199,22 @@
         "snowflake.core._internal.bridge.executor.SnowExecute.execute"
     ) as mocked_execute:
         with pytest.raises(ServerError):
             dbs["my_db"].promote_to_primary_failover()
     mocked_execute.assert_called_once_with(
         "ALTER DATABASE MY_DB PRIMARY",
     )
+
+def test_empty_alter(fake_root):
+    dbs = DatabaseCollection(fake_root)
+    with \
+    mock.patch(
+        "snowflake.core._internal.bridge.executor.SnowExecute.execute"
+    ) as mocked_execute, \
+    mock.patch(
+        "snowflake.core._internal.bridge.resources.database_resource.DatabaseResource.desc_db",
+        return_value=(None, {"name": "MY_DB", "comment": "a"}),
+    ):
+        dbs["my_db"].create_or_update(
+            database=Database(name="MY_DB", comment="a"),
+        )
+    mocked_execute.assert_not_called()
```

### Comparing `snowflake_core-0.7.0/tests/unit/bridge/test_executor.py` & `snowflake_core-0.8.0/tests/unit/bridge/test_executor.py`

 * *Files 2% similar despite different names*

```diff
@@ -9,14 +9,17 @@
 
 from snowflake.connector import SnowflakeConnection, errors
 from snowflake.connector.cursor import DictCursor
 from snowflake.core._internal.bridge.executor import SnowExecute
 from snowflake.core._internal.bridge.rest_errors import NotFound
 
 
+pytestmark = pytest.mark.jenkins
+
+
 class TestSnowExecutor:
     @patch("snowflake.connector.cursor", spec=DictCursor)
     @patch("snowflake.connector", spec=SnowflakeConnection)
     def test_execute(self, mocked_conn, mocked_cursor):
         mocked_response = [
             {"col1": "row1", "col2": "row1", "col3": "row1"},
             {"col1": "row2", "col2": "row2", "col3": "row2"},
```

### Comparing `snowflake_core-0.7.0/tests/unit/bridge/test_rest_errors.py` & `snowflake_core-0.8.0/tests/unit/bridge/test_rest_errors.py`

 * *Files 7% similar despite different names*

```diff
@@ -15,14 +15,17 @@
     NotFound,
     RestError,
     ServiceUnavailable,
     UnauthorizedRequest,
 )
 
 
+pytestmark = pytest.mark.jenkins
+
+
 class TestRestErrors:
     def test_rest_error_default_values(self):
         r = RestError()
         assert r.msg != "", "message cannot be empty"
         assert r.status_code == 500, "status code mismatch!"
 
     def test_rest_error_details(self):
```

### Comparing `snowflake_core-0.7.0/tests/unit/bridge/test_schema.py` & `snowflake_core-0.8.0/tests/unit/bridge/test_schema.py`

 * *Files 3% similar despite different names*

```diff
@@ -5,14 +5,17 @@
 from snowflake.core import Clone, PointOfTimeOffset
 from snowflake.core._internal.bridge.rest_errors import NotFound
 from snowflake.core.database import DatabaseCollection
 from snowflake.core.exceptions import NotFoundError, ServerError
 from snowflake.core.schema import Schema, SchemaCollection
 
 
+pytestmark = pytest.mark.jenkins
+
+
 fake_root = mock.MagicMock(
     _connection=mock.MagicMock(
         _rest=mock.MagicMock(
             _host="localhost",
             _protocol="http",
             _port="80",
         )
@@ -119,7 +122,21 @@
         "snowflake.core._internal.bridge.executor.SnowExecute.execute"
     ) as mocked_execute:
         with pytest.raises(ServerError):
             schemas["schema"].delete()
     mocked_execute.assert_called_once_with(
         "DROP SCHEMA MY_DB.SCHEMA"
     )
+
+def test_empty_alter(fake_root):
+    with \
+    mock.patch(
+        "snowflake.core._internal.bridge.executor.SnowExecute.execute"
+    ) as mocked_execute, \
+    mock.patch(
+        "snowflake.core._internal.bridge.resources.schema_resource.SchemaResource.desc_schema",
+        return_value=(None, {"name": "MY_SCHEMA", "comment": "a"}),
+    ):
+        schemas["new_schema"].create_or_update(
+            schema=Schema(name="MY_SCHEMA", comment="a"),
+        )
+    mocked_execute.assert_not_called()
```

### Comparing `snowflake_core-0.7.0/tests/unit/resources/test_computepool_resource.py` & `snowflake_core-0.8.0/tests/unit/resources/test_computepool_resource.py`

 * *Files 4% similar despite different names*

```diff
@@ -9,14 +9,17 @@
 from snowflake.connector import connect
 from snowflake.core._internal.bridge.resources.computepools_resource import (
     ComputePoolsResource,
 )
 from snowflake.core._internal.bridge.snow_request import SnowRequest
 
 
+pytestmark = pytest.mark.jenkins
+
+
 @pytest.mark.skip()
 def test_create():
     req_body = {
         "name": "cp1",
         "warehouse": "snowapi_wh",
         "min_nodes": "1",
         "max_nodes": "2",
```

### Comparing `snowflake_core-0.7.0/tests/unit/resources/test_task_resource.py` & `snowflake_core-0.8.0/tests/unit/resources/test_task_resource.py`

 * *Files 12% similar despite different names*

```diff
@@ -7,14 +7,17 @@
 import pytest
 
 from snowflake.connector import connect
 from snowflake.core._internal.bridge.resources.task_resource import TaskResource
 from snowflake.core._internal.bridge.snow_request import SnowRequest
 
 
+pytestmark = pytest.mark.jenkins
+
+
 @pytest.mark.skip()
 def test_create():
     req_body = {
         "name": "t1",
         "warehouse": "snowapi_wh",
         "schedule": {"minutes": "1"},
         "comment": "test comment",
```

### Comparing `snowflake_core-0.7.0/tests/unit/task/test_dagv1.py` & `snowflake_core-0.8.0/tests/unit/task/test_dagv1.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,12 +1,17 @@
+import pytest
+
 from snowflake.core.task import StoredProcedureCall
 from snowflake.core.task.dagv1 import DAG, DAGTask
 from snowflake.snowpark import Session
 
 
+pytestmark = pytest.mark.jenkins
+
+
 def foo1(session: Session) -> str:
     return "abc"
 
 def foo2(session: Session) -> str:
     return "abc"
```

### Comparing `snowflake_core-0.7.0/tests/unit/task/test_task_context.py` & `snowflake_core-0.8.0/tests/unit/task/test_task_context.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,14 +4,17 @@
 
 import pytest
 
 from snowflake.core.task.context import TaskContext
 from snowflake.snowpark.exceptions import SnowparkSQLException
 
 
+pytestmark = pytest.mark.jenkins
+
+
 def test_task_context(fake_root):
     task_context = TaskContext(fake_root)
     mock_result_str = Mock()
 
     def side_effect_collect_str():
         return [["abc"]]
     mock_result_str.collect.side_effect = side_effect_collect_str
```

### Comparing `snowflake_core-0.7.0/tests/unit/task/test_task_reference.py` & `snowflake_core-0.8.0/tests/unit/task/test_task_reference.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,15 +1,20 @@
 #
 # Copyright (c) 2012-2023 Snowflake Computing Inc. All rights reserved.
 #
 
 
+import pytest
+
 from snowflake.core.database import DatabaseCollection
 
 
+pytestmark = pytest.mark.jenkins
+
+
 def test_collection_and_references(fake_root):
     db_collection = DatabaseCollection(fake_root)
     my_db_ref = db_collection["my_db"]
     my_schema_ref = my_db_ref.schemas["my_schema"]
     my_task_ref = my_schema_ref.tasks["my_task"]
 
     assert my_task_ref.name == "my_task"
```

### Comparing `snowflake_core-0.7.0/.gitignore` & `snowflake_core-0.8.0/.gitignore`

 * *Files 13% similar despite different names*

```diff
@@ -74,9 +74,9 @@
 
 ##############################
 ## Auto Summary
 ##############################
 docs/source/_autosummary/*
 
 .coverage
-/libs/*/coverage-3.*.xml
+/libs/*/coverage-*.xml
 /.github/workflows/parameters/connections.toml
```

### Comparing `snowflake_core-0.7.0/pyproject.toml` & `snowflake_core-0.8.0/pyproject.toml`

 * *Files 6% similar despite different names*

```diff
@@ -68,35 +68,36 @@
     'README.md',
     'tests/',
     'docs/',
     'CHANGELOG.md',
     'pyproject.toml',
 ]
 
-[[tool.hatch.envs.test.matrix]]
+[tool.hatch.envs.test_all]
+template = 'test'
+
+[[tool.hatch.envs.test_all.matrix]]
 python = ['3.8', '3.9', '3.10', '3.11']
 
 [tool.hatch.envs.test]
+# Our minimum supported version.
+python = '3.8'
 dependencies = [
     'coverage[toml]',
     'diff-cover',
     'pytest<8.0.0',
     'pytest-cov',
     'sybil',
 ]
 
 [tool.hatch.envs.test.scripts]
 check = [
-    # Since our tests are essentially end-to-end integration tests, we must
-    # have and make a valid connection to Snowflake.  We might as well exit
-    # early if the connection name is not given.
-    'printenv | grep SNOWFLAKE_CONNECTION || exit 1',
-    'pytest --cov-report=xml:coverage-{matrix:python}.xml {args:tests}',
+    'pytest --cov-report=xml:coverage-{matrix:python:{env:PYTHON_VERSION:unset}}.xml {args:tests}',
     # The following is only useful in a git repository; thus errors are ignored.
-    '- diff-cover coverage-{matrix:python}.xml',
+    '- diff-cover coverage-{matrix:python:{env:PYTHON_VERSION:unset}}.xml',
 ]
 
 [[tool.hatch.envs.precommit.matrix]]
 python = ['3.10']
 
 [tool.hatch.envs.precommit]
 dependencies = [
@@ -117,25 +118,33 @@
     'ruff check --fix src/snowflake tests',
     'mypy --install-types --non-interactive -p snowflake.core',
 ]
 
 [tool.hatch.envs.docs]
 dependencies = [
     'sphinx',
+    'tomli; python_version < "3.11"',
 ]
 [tool.hatch.envs.docs.scripts]
 build = [
     'cd ../../docs && make clean',
     'cd ../../docs && make html SPHINXOPTS="-W --keep-going"'
 ]
 
 [tool.pytest.ini_options]
 addopts = '--cov=snowflake --cov-report=term'
 testpaths = 'integ unit'
 pythonpath = 'src'
+markers = [
+    "env(name): mark test to run only on named environment",
+    "skip_bridge: tests with this mark will skip testing with the client bridge",
+    "skip_rest: tests with  this mark will skip testing wtih REST",
+    # TODO: rework the following into a block list instead of an allow list
+    "jenkins: tests that should be run on Jenkins",
+]
 
 [tool.coverage.run]
 branch = true
 parallel = true
 source_pkgs = [
     'snowflake.core',
 ]
```

### Comparing `snowflake_core-0.7.0/PKG-INFO` & `snowflake_core-0.8.0/PKG-INFO`

 * *Files 8% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 Metadata-Version: 2.3
 Name: snowflake.core
-Version: 0.7.0
+Version: 0.8.0
 Summary: Snowflake Python API for Resource Management
 Author-email: "Snowflake, Inc." <snowflake-python-libraries-dl@snowflake.com>
 License: Apache-2.0
+License-File: LICENSE
 Keywords: Snowflake,analytics,cloud,database,db,warehouse
 Classifier: Development Status :: 4 - Beta
 Classifier: Environment :: Console
 Classifier: Environment :: Other Environment
 Classifier: Intended Audience :: Developers
 Classifier: Intended Audience :: Education
 Classifier: Intended Audience :: Information Technology
```

